{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains predictive modeling for various distinct target options, namely:\n",
    "\n",
    "3 Modeling: Binary Classification (**PRICE_BINARY**)\n",
    "- Binary split is set as a USD Price amount in the Dashboard\n",
    "\n",
    "4 Modeling: Multi-Class Classification (**PRICE_CLASS**)\n",
    "- TBD\n",
    "\n",
    "5 Modeling: Regression (**PRICE_LOG**)\n",
    "- TBD\n",
    "\n",
    "**As a consequence, the respective targets need to be selected via the Dashboard BEFORE running the corresponding section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "import joblib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline  # Same, but with the latter it is not necessary to name estimator and transformer\n",
    "#from imblearn.pipeline import Pipeline as Imb_Pipe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, GenericUnivariateSelect, mutual_info_classif\n",
    "#import eli5\n",
    "\n",
    "# Predictive Modeling (Models)\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score, cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, NuSVC, SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PassiveAggressiveRegressor, ElasticNet, SGDRegressor, RANSACRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor, VotingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from scipy.stats import randint\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer, fbeta_score, accuracy_score, confusion_matrix, f1_score, precision_recall_curve, recall_score, precision_score, roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Neural Networks\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dashboard (Global Variables)\n",
    "dataset_loc = \"berlin\"              # \"berlin\", \"paris\", \"amsterdam\"\n",
    "dataset_date = \"2020-03-17\"         # \"2019-12-11\", \"2020-01-10\", \"2020-02-18\", \"2020-03-17\", \"2020-05-14\"\n",
    "target = 'price_log'             # for regression: 'occupancy_rate', 'price_log' | for classification: 'price_class', 'occupancy_class'\n",
    "binary_split = 50                   # price at which \"price_binary\" will be split\n",
    "# !Important: Please select features for prediction in cell \"Feature selection\" below!\n",
    "scoring = 'neg_median_absolute_error'  # for regression: 'neg_mean_squared_error', 'r2', 'neg_mean_poisson_deviance', 'neg_median_absolute_error' | for classification: \"f1(_micro, _macro, _weighted for multiclass)\", \"recall\", \"precision\", \"accuracy\", \"roc_auc\"\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import data_engineered\n",
    "data = pd.read_pickle(f\"saves/{dataset_loc}_{dataset_date}/data_engineered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "\n",
    "#... by removing certain features\n",
    "all_features = [\n",
    "    el for el in data.columns if el not in [\n",
    "        'occupancy_rate', 'occupancy_class', 'listing_no', 'price_log',\n",
    "        'price_class', 'price_binary', \"review_scores_class_new\",\n",
    "        \"review_scores_class\", \"review_scores_calc\", \"neighbourhood_cleansed\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "#... by only considering certain features\n",
    "key_features = [\n",
    "    \"accommodates_per_bed\", \"am_balcony\", \"am_breakfast\", \"am_child_friendly\",\n",
    "    \"am_elevator\", \"am_essentials\", \"am_pets_allowed\", \"am_private_entrance\",\n",
    "    \"am_smoking_allowed\", \"am_tv\", \"bathrooms_log\", \"bedrooms\",\n",
    "    \"calc_host_lst_count_sqrt_log\", \"cancellation_policy\",\n",
    "    \"guests_included_calc\", \"host_is_superhost\", \"instant_bookable\",\n",
    "    \"maximum_nights\", \"minimum_nights_sqrt\", \"property_type\", \"room_type\",\n",
    "    \"wk_mth_discount\", \"zipcode\"\n",
    "]\n",
    "\n",
    "# select features for predictive modeling from above: [all_features, key_features]\n",
    "pred_features = key_features\n",
    "\n",
    "#Display columns:\n",
    "#all_features\n",
    "#key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_LOG\u001b[0m as the target and \u001b[1mneg_median_absolute_error\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'guests_included_calc', 'host_is_superhost', 'instant_bookable', 'maximum_nights', 'minimum_nights_sqrt', 'property_type', 'room_type', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n",
      "No issues with your selection of pred_features have been detected. Please make sure to manually check for correctness nevertheless.\n"
     ]
    }
   ],
   "source": [
    "# Display target and used features\n",
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "print(f\"You are currently using \\033[1m{target_upper}\\033[0m as the target and \\033[1m{scoring}\\033[0m for scoring to predict prices for \\033[1m{dataset_loc}\\033[0m on \\033[1m{dataset_date}\\033[0m\\n\")\n",
    "print(f\"You are currently using these features for its prediction:\\n\\033[1m{pred_features}\\033[0m\\n\")\n",
    "\n",
    "if target in pred_features:\n",
    "    print(f\"WARNING: You are using \\033[1m{target_upper}\\033[0m as predictor. Please remove before proceeding.\\n\")\n",
    "\n",
    "if target == 'price_binary':\n",
    "    if 'price_class' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_class'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_log' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_log'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "if target == 'price_class':\n",
    "    if 'price_binary' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_binary'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_log' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_log'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "if target == 'price_log':\n",
    "    if 'price_class' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_class'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_binary' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_binary'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "        \n",
    "if \"occupancy_class\" in pred_features and \"occupancy_rate\" in pred_features:\n",
    "    print(f\"WARNING: Please remove \\033[1m'ocupancy_class'\\033[0m or \\033[1m'ocupancy_rate'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "else:\n",
    "    print(\"No issues with your selection of pred_features have been detected. Please make sure to manually check for correctness nevertheless.\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (Train/Test Split and Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "drop_columns = [el for el in data.columns if el not in pred_features]\n",
    "drop_columns.remove(target)\n",
    "data.drop(labels=drop_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Drop rows (optional, just temporary)\n",
    "#data = data[data.number_of_reviews_ltm_log>1.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancellation_policy', 'property_type', 'room_type', 'zipcode']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\")\n",
    "cat_features = list(data.columns[data.dtypes == object])\n",
    "#cat_features.remove(\"neighbourhood\")\n",
    "#cat_features.remove(\"zipcode\")\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates_per_bed',\n",
       " 'am_balcony',\n",
       " 'am_breakfast',\n",
       " 'am_child_friendly',\n",
       " 'am_elevator',\n",
       " 'am_essentials',\n",
       " 'am_pets_allowed',\n",
       " 'am_private_entrance',\n",
       " 'am_smoking_allowed',\n",
       " 'am_tv',\n",
       " 'bathrooms_log',\n",
       " 'bedrooms',\n",
       " 'calc_host_lst_count_sqrt_log',\n",
       " 'guests_included_calc',\n",
       " 'host_is_superhost',\n",
       " 'instant_bookable',\n",
       " 'maximum_nights',\n",
       " 'minimum_nights_sqrt',\n",
       " 'wk_mth_discount']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "num_features = list(data.columns[data.dtypes != object])\n",
    "num_features.remove(target)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Build preprocessor pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([('imputer_num', SimpleImputer(strategy='median')),\n",
    "                         ('std_scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([('num', num_pipeline, num_features),\n",
    "                                  ('cat', cat_pipeline, cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state,\n",
    "                                                    shuffle=True)\n",
    "#                                                   stratify=y) # Use stratify=y if labels are inbalanced (e.g. most wines are 5 or 6; check with value_counts()!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving preprocessed X_train and X_test\n",
    "X_train_prep_preprocessor = preprocessor.fit(X_train)\n",
    "\n",
    "X_train_prep = X_train_prep_preprocessor.transform(X_train)\n",
    "X_train_num_prep = num_pipeline.fit_transform(X_train[num_features])\n",
    "X_test_prep = X_train_prep_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get feature names from pipeline after one-hot encoding as \"column_names\"\n",
    "onehot_columns = list(preprocessor.named_transformers_['cat']['1hot'].get_feature_names(cat_features))\n",
    "column_names = num_features + onehot_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save preprocessor\n",
    "save_model(X_train_prep_preprocessor, title=\"preprocessor_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save X_test\n",
    "save_model(X_test, title=\"X_test_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Functions and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create \"price_binary\" at given split\n",
    "price_binary = []\n",
    "for price in data.price_log:\n",
    "    if math.exp(price) <= binary_split:\n",
    "        price_binary.append(1)\n",
    "    else:\n",
    "        price_binary.append(2)\n",
    "data[\"price_binary\"] = price_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"mean_absolute_percentage_error\": Function for mean absolute percentage error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"median_absolute_percentage_error\": Function for median absolute percentage error (MAPE median)\n",
    "def median_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.median(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"print_target_setting\": Function for printing current setting for TARGET and the corresponding features\n",
    "def print_target_setting():\n",
    "    target_upper = target.upper()\n",
    "    y_upper = y_train.name.upper()\n",
    "    print(f\"You are currently using \\033[1m{target_upper}\\033[0m as the target and \\033[1m{scoring}\\033[0m for scoring to predict prices for \\033[1m{dataset_loc}\\033[0m on \\033[1m{dataset_date}\\033[0m\\n\")\n",
    "    print(f\"The target variable y is set to \\033[1m{y_upper}\\033[0m\\n\")\n",
    "    print(f\"You are currently using these features for its prediction:\\n\\033[1m{pred_features}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"get_feat_importances\": Function for retrieving feature importances\n",
    "def get_feat_importances(model, column_names=column_names):\n",
    "    model=model\n",
    "    feat_importances = pd.DataFrame(model.feature_importances_,\n",
    "                 columns=['weight'],\n",
    "                 index=column_names)\n",
    "    feat_importances.sort_values('weight', inplace=True, ascending=False)\n",
    "    return feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"model_eval\": Function for final evaluation of \"best model\"\n",
    "def model_eval(y, y_pred, model=\"reg\"):\n",
    "    \"\"\"\n",
    "    Please always specify the type of model:\n",
    "    Regression: model=\"reg\"\n",
    "    Binary Classification: model=\"bclf\"\n",
    "    Multiclass Classification: model=\"clf\"\n",
    "    \"\"\"\n",
    "    if model==\"reg\":\n",
    "        print(\"MSE: {:.2f}\".format(mean_squared_error(y, y_pred)))\n",
    "        print(\"RMSE: {:.2f}\".format(\n",
    "        mean_squared_error(y, y_pred, squared=False)))\n",
    "        print(\"MAE: {:.2f}\".format(mean_absolute_error(y, y_pred)))\n",
    "        print(\"R2: {:.2f}\".format(r2_score(y, y_pred)))\n",
    "        print(\"MAPE: {:.2f}\".format(mean_absolute_percentage_error(y, y_pred)))\n",
    "        print(\"MAPE median: {:.2f}\".format(median_absolute_percentage_error(y, y_pred)))\n",
    "\n",
    "    elif model==\"bclf\":\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy_score(y, y_pred)))\n",
    "        print(\"Recall: {:.2f}\".format(recall_score(y, y_pred)))\n",
    "        print(\"Precision: {:.2f}\".format(precision_score(y, y_pred)))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred)))\n",
    "        print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y, y_pred)))\n",
    "        print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y, y_pred)))\n",
    "\n",
    "    elif model==\"clf\":\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy_score(y, y_pred)))\n",
    "        print(\"Recall: {:.2f}\".format(recall_score(y, y_pred, average='weighted')))\n",
    "        print(\"Precision: {:.2f}\".format(precision_score(y, y_pred, average='weighted')))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred, average='weighted')))\n",
    "        print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y, y_pred)))\n",
    "    \n",
    "    else:\n",
    "        print(\"Please revise your parameters (e.g. provide a valid model).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# \"save_model\": Function for saving model (pickle or joblib)\n",
    "def save_model(model, title=\"unknown\", save=\"joblib\"):\n",
    "    if save==\"joblib\":\n",
    "        joblib.dump(model, f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")\n",
    "    elif save==\"pickle\":\n",
    "        model.to_pickle(f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")\n",
    "#        save also evaluation (from y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"load_model\": Function for loading model (pickle or joblib)\n",
    "def load_model(title=\"unknown\", dataset_loc=dataset_loc, dataset_date=dataset_date, load=\"joblib\"):\n",
    "    if load==\"joblib\":\n",
    "        return joblib.load(f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"clf_learning_curves\": Function to evaluate classification model based on learning curves\n",
    "def clf_learning_curves(model):\n",
    "# Fit model on training data\n",
    "    model = model\n",
    "    eval_set = [(X_train_prep, y_train), (X_test_prep, y_test)]\n",
    "    model.fit(X_train_prep, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=True)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    y_pred = model.predict(X_test_prep)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # Evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    \n",
    "    # Retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "    \n",
    "    # Plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Plot classification error\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Classification Error')\n",
    "    pyplot.title('XGBoost Classification Error')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Binary Classification (\"price_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_BINARY\u001b[0m as the target and \u001b[1mroc_auc\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_BINARY\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'bathrooms_log', 'host_is_superhost', 'property_type', 'room_type', 'zipcode']\u001b[0m\n",
      "\n",
      "Binary Split:  \u001b[1mUSD 50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()\n",
    "print(f\"Binary Split:  \\033[1mUSD {binary_split}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "bclfmodels = {\n",
    "    'Baseline':\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    'LogReg':\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    'KNN':\n",
    "    KNeighborsClassifier(),\n",
    "    'SVC':\n",
    "    SVC(kernel='rbf', C=1E6),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeClassifier(criterion=\"gini\",\n",
    "                           max_depth=3,\n",
    "                           random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestClassifier(random_state=random_state,\n",
    "                           max_features='sqrt',\n",
    "                           n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBClassifier(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostClassifier(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.6s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[   0 3993]\n",
      " [   0 4497]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[2941 1052]\n",
      " [ 793 3704]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN: \n",
      "[[2837 1156]\n",
      " [ 962 3535]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVC: \n",
      "[[2926 1067]\n",
      " [ 938 3559]]\n",
      "Confusion Matrix Decision Tree: \n",
      "[[2775 1218]\n",
      " [ 693 3804]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[2906 1087]\n",
      " [ 867 3630]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Gradient Boost: \n",
      "[[2871 1122]\n",
      " [ 666 3831]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[2860 1133]\n",
      " [ 667 3830]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[2904 1089]\n",
      " [ 792 3705]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.280563</td>\n",
       "      <td>0.366825</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>0.782955</td>\n",
       "      <td>0.782085</td>\n",
       "      <td>0.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.750375</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>0.748286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.763656</td>\n",
       "      <td>0.763571</td>\n",
       "      <td>0.762099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.777552</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.770432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.769864</td>\n",
       "      <td>0.769335</td>\n",
       "      <td>0.767489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.791453</td>\n",
       "      <td>0.788104</td>\n",
       "      <td>0.785455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.786639</td>\n",
       "      <td>0.783966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.778896</td>\n",
       "      <td>0.777707</td>\n",
       "      <td>0.775578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy    Recall  Precision  F1 Score   ROC/AUC\n",
       "0        Baseline  0.529682  0.529682   0.280563  0.366825  0.500000\n",
       "1          LogReg  0.782686  0.782686   0.782955  0.782085  0.780100\n",
       "2             KNN  0.750530  0.750530   0.750375  0.750058  0.748286\n",
       "3             SVC  0.763840  0.763840   0.763656  0.763571  0.762099\n",
       "4   Decision Tree  0.774912  0.774912   0.777552  0.773200  0.770432\n",
       "5   Random Forest  0.769847  0.769847   0.769864  0.769335  0.767489\n",
       "6  Gradient Boost  0.789399  0.789399   0.791453  0.788104  0.785455\n",
       "7         XGBoost  0.787986  0.787986   0.790136  0.786639  0.783966\n",
       "8        AdaBoost  0.778445  0.778445   0.778896  0.777707  0.775578"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1 Score', 'ROC/AUC'])\n",
    "i = 0\n",
    "for m in bclfmodels.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(\n",
    "                y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'ROC/AUC': roc_auc_score(y_train, y_train_pred)\n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" +\n",
    "          str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_lr_bclf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('lr_bclf',\n",
    "                             LogisticRegression(penalty='l2',\n",
    "                                                max_iter=100,\n",
    "                                                C=0.9,\n",
    "                                                random_state=random_state,\n",
    "                                                l1_ratio=0.5,\n",
    "                                                n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_lr_bclf = LogisticRegression()\n",
    "test_lr_bclf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_lr_bclf = {\n",
    "    'lr_bclf__penalty': ['l1', 'l2'],\n",
    "    'lr_bclf__max_iter': randint(low=10, high=100),\n",
    "    'lr_bclf__C': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
    "    'lr_bclf__l1_ratio': [None, 0.1, 0.2, 0.3, 0.5, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.5s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_lr_bclf = RandomizedSearchCV(pipeline_lr_bclf,\n",
    "                                 param_distribs_lr_bclf,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=50,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_lr_bclf = rnd_lr_bclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.85\n",
      "Best parameters:\n",
      "{'lr_bclf__C': 20, 'lr_bclf__l1_ratio': 0.1, 'lr_bclf__max_iter': 83, 'lr_bclf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_lr_bclf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_lr_bclf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_lr_bclf = {\n",
    "    'lr_bclf__penalty': ['l1', 'l2'],\n",
    "    'lr_bclf__max_iter': [100, 125, 150, 200],\n",
    "    'lr_bclf__C': [10, 20, 30],\n",
    "    'lr_bclf__l1_ratio': [None, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   18.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_lr_bclf = GridSearchCV(pipeline_lr_bclf,\n",
    "                            param_grid_lr_bclf,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_lr_bclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_lr_bclf = grid_lr_bclf.best_estimator_['lr_bclf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.85\n",
      "Best parameters:\n",
      "{'lr_bclf__C': 20, 'lr_bclf__l1_ratio': None, 'lr_bclf__max_iter': 150, 'lr_bclf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_lr_bclf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_lr_bclf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get and print feature importances\n",
    "#grid_lr_bclf_fi = feat_importances(grid_lr_bclf, cv_model=True, named_steps='lr_bclf', column_names=column_names)\n",
    "#grid_lr_bclf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_lr_bclf = best_model_lr_bclf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_lr_bclf, model=\"bclf\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-567-ddc2260eef86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_grid_lr_bclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the best model\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_lr_bclf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_lr_bclf = best_model_lr_bclf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_lr_bclf, model=\"bclf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! NN Model 1: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Evaluation with Testing Set and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf_best_model = best_model_grid_lr_bclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model at given binary_split\n",
    "bclf_best_model.to_pickle(f\"saves/{dataset_loc}_{dataset_date}/{target}_{binary_split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Multi-Class Classification (\"price_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_CLASS\u001b[0m as the target and \u001b[1mf1\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_CLASS\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_nature_and_views', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'am_white_goods', 'availability_90', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'first_review_days_sqrt', 'host_acceptance_rate', 'host_is_superhost', 'host_response_rate', 'host_response_time', 'instant_bookable', 'last_review_days_sqrt', 'latitude', 'listing_no', 'longitude', 'maximum_nights', 'minimum_nights_log', 'neighbourhood_cleansed', 'number_of_reviews_ltm_log', 'price_extra_fees_sqrt', 'price_extra_people', 'property_type', 'review_scores_location', 'review_scores_rating_sqrt', 'room_type', 'text_len_sqrt', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "clfmodels = {\n",
    "    'Baseline':\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    'LogReg':\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    'KNN':\n",
    "    KNeighborsClassifier(),\n",
    "    'SVC':\n",
    "    SVC(kernel='rbf', C=1E6),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeClassifier(criterion=\"gini\",\n",
    "                           max_depth=3,\n",
    "                           random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestClassifier(random_state=random_state,\n",
    "                           max_features='sqrt',\n",
    "                           n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBClassifier(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostClassifier(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.2s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[   0    0  307    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1057    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1276    0    0    0    0    0    0    0    0]\n",
      " [   0    0  926    0    0    0    0    0    0    0    0]\n",
      " [   0    0  817    0    0    0    0    0    0    0    0]\n",
      " [   0    0  665    0    0    0    0    0    0    0    0]\n",
      " [   0    0  449    0    0    0    0    0    0    0    0]\n",
      " [   0    0  457    0    0    0    0    0    0    0    0]\n",
      " [   0    0  786    0    0    0    0    0    0    0    0]\n",
      " [   0    0  397    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[ 55 125  78  21   4   4   3   0   1  11   5]\n",
      " [ 27 447 404 121  25   9   3   0   0  18   3]\n",
      " [ 12 347 497 301  81  61  22  10   1  18   3]\n",
      " [ 15 167 401 297 150 125  39  12  14  47   9]\n",
      " [  3  54 177 217 167 130  61  21  26  61   9]\n",
      " [  1  30  86 196 129 143  94  23  22  80  13]\n",
      " [  1  15  53 105  99 139  71  17  25 122  18]\n",
      " [  1   8  25  51  63  79  47  21  19 116  19]\n",
      " [  1   5  15  44  44  74  48  20  22 159  25]\n",
      " [  3   6  15  42  43  73  65  32  49 352 106]\n",
      " [  0   1   2   7  17   7   4   8   8 176 167]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN: \n",
      "[[ 80  96  73  35   9   4   6   0   1   3   0]\n",
      " [ 83 370 337 158  44  33  12   3   9   7   1]\n",
      " [ 64 390 441 233  71  72  36  13  10  19   4]\n",
      " [ 55 290 331 278 127  88  47  13  13  30   4]\n",
      " [ 48 140 203 178 146  96  39  15  13  44   4]\n",
      " [ 23 124 194 147  91  94  52  21  20  41  10]\n",
      " [ 19  87 147 106  75  78  65  19  14  49   6]\n",
      " [ 12  41  74  75  46  49  29  44  25  50   4]\n",
      " [ 16  50  68  65  44  37  41  18  40  64  14]\n",
      " [ 13  56  85  77  70  59  60  33  58 221  54]\n",
      " [  7  15  31  15  25  12  11  18  22 109 132]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   21.5s remaining:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   31.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVC: \n",
      "[[ 88 101  59  33   9   6   5   0   2   3   1]\n",
      " [ 58 428 338 157  34  18  11   3   3   6   1]\n",
      " [ 38 359 446 275  99  65  25  19  10  13   4]\n",
      " [ 25 195 310 356 152 110  47  29  15  31   6]\n",
      " [  9  66 158 199 204 125  72  22  33  30   8]\n",
      " [  7  30  93 145 142 171  90  46  34  54   5]\n",
      " [  5  20  65  88  94 109 120  43  43  66  12]\n",
      " [  0   9  34  56  55  70  45  66  35  73   6]\n",
      " [  2  10  22  43  45  68  50  39  62  96  20]\n",
      " [  0   9  17  52  47  55  74  58  94 284  96]\n",
      " [  0   3   4   8  10  11  16  15  18 124 188]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Decision Tree: \n",
      "[[  8  76 137   0   0  31   0   0   0  51   4]\n",
      " [  2 177 730   0   0 102   0   0   0  45   1]\n",
      " [  2 159 825   0   0 314   0   0   0  53   0]\n",
      " [  4  64 584   0   0 524   0   0   0  97   3]\n",
      " [  1  20 280   0   1 488   0   0   0 129   7]\n",
      " [  3  16 138   0   0 549   0   0   0 101  10]\n",
      " [  4   6 105   0   0 400   0   0   0 136  14]\n",
      " [  1   3  38   0   0 269   0   0   0 123  15]\n",
      " [  4   3  47   0   0 231   0   0   0 149  23]\n",
      " [ 14   3  50   0   0 301   0   0   0 336  82]\n",
      " [  9   3  18   0   0  54   0   0   0 176 137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.9s remaining:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[ 65 130  82  17   3   5   2   0   0   2   1]\n",
      " [ 22 435 456  97  17   7   4   0   3  14   2]\n",
      " [  4 350 607 250  45  53  11   5   2  24   2]\n",
      " [  4 159 441 363 119  92  26   2   7  60   3]\n",
      " [  1  52 201 240 201 108  40   6   9  61   7]\n",
      " [  1  30 139 188 126 162  56  13  12  81   9]\n",
      " [  2  21  70 136  92 113  70  14  10 124  13]\n",
      " [  0   3  39  74  55  66  38  44  13 111   6]\n",
      " [  1   6  30  68  54  58  28  14  30 146  22]\n",
      " [  0   4  32  60  35  59  53  16  38 423  66]\n",
      " [  0   1   3  11  13  12   9   3  11 173 161]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Gradient Boost: \n",
      "[[ 73 124  80  12   4   4   3   1   0   5   1]\n",
      " [ 39 448 412  96  12  18   5   6   5  14   2]\n",
      " [ 18 329 576 254  39  83  23   2   5  21   3]\n",
      " [ 12 132 438 365  88 121  34  15  16  50   5]\n",
      " [  5  52 195 239 120 131  57  25  25  67  10]\n",
      " [  0  30 101 198  92 177  69  21  30  84  15]\n",
      " [  3  14  68 126  76 127  69  24  36  99  23]\n",
      " [  0   5  29  71  47  80  38  32  25 107  15]\n",
      " [  1   7  17  58  38  64  30  20  29 164  29]\n",
      " [  2   4  14  55  53  67  49  20  45 384  93]\n",
      " [  0   1   4   9  10  11   4   7   5 160 186]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   35.8s remaining:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[ 66 134  76  14   3   6   0   0   0   6   2]\n",
      " [ 31 444 458  62  16  17   3   2   0  21   3]\n",
      " [  9 361 611 222  28  80   9   3   2  25   3]\n",
      " [  7 144 476 356  78 111  20   5   4  71   4]\n",
      " [  3  55 223 255 104 152  27   8  13  80   6]\n",
      " [  0  24 117 214  78 208  36  10  20  98  12]\n",
      " [  0  20  68 156  57 139  51  11  19 125  19]\n",
      " [  0   7  25  83  34  86  23  22  11 142  16]\n",
      " [  1   9  23  63  26  75  18   8  16 189  29]\n",
      " [  0   4  17  72  40  72  29   8  20 421 103]\n",
      " [  0   1   4  11   7  10   4   3   5 157 195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[ 55  99 103  22   2   4   1   0   0  14   7]\n",
      " [130 314 443 108  11  14   1   1   0  25  10]\n",
      " [ 98 258 571 249  37  65  18   3   4  34  16]\n",
      " [ 55 139 406 313  78 138  24   8  11  91  13]\n",
      " [ 26  63 182 250  85 155  20   5   6 107  27]\n",
      " [ 15  33 112 214  64 179  37  10  15 108  30]\n",
      " [  6  23  80 137  37 123  35   6   5 170  43]\n",
      " [  3  10  31  74  32  97  26   6   9 136  25]\n",
      " [  5  15  25  54  27  74  19   3   9 180  46]\n",
      " [  7  30  13  57  25 100  30  10  14 348 152]\n",
      " [  0   5   8  10   3  12  10   2   7 171 169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.159364</td>\n",
       "      <td>0.159364</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.043812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.263722</td>\n",
       "      <td>0.263722</td>\n",
       "      <td>0.252461</td>\n",
       "      <td>0.251175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.229258</td>\n",
       "      <td>0.218664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.282050</td>\n",
       "      <td>0.281744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.239458</td>\n",
       "      <td>0.239458</td>\n",
       "      <td>0.260865</td>\n",
       "      <td>0.163596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.301649</td>\n",
       "      <td>0.301649</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.286645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.276851</td>\n",
       "      <td>0.274505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.286248</td>\n",
       "      <td>0.270193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.245465</td>\n",
       "      <td>0.245465</td>\n",
       "      <td>0.225560</td>\n",
       "      <td>0.221782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy    Recall  Precision  F1 Score\n",
       "0        Baseline  0.159364  0.159364   0.025397  0.043812\n",
       "1          LogReg  0.263722  0.263722   0.252461  0.251175\n",
       "2             KNN  0.225088  0.225088   0.229258  0.218664\n",
       "3             SVC  0.284217  0.284217   0.282050  0.281744\n",
       "4   Decision Tree  0.239458  0.239458   0.260865  0.163596\n",
       "5   Random Forest  0.301649  0.301649   0.307399  0.286645\n",
       "6  Gradient Boost  0.289635  0.289635   0.276851  0.274505\n",
       "7         XGBoost  0.293757  0.293757   0.286248  0.270193\n",
       "8        AdaBoost  0.245465  0.245465   0.225560  0.221782"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1 Score'])\n",
    "i = 0\n",
    "for m in clfmodels.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(\n",
    "                y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" +\n",
    "          str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.24546525323910484\n",
      "Recall:  0.24546525323910484\n",
      "Precision:  0.22555966733807414\n",
      "F1 Score:  0.22178198870408516\n"
     ]
    }
   ],
   "source": [
    "# Apply LogReg with OVR\n",
    "lr_ovr_model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "# fit model\n",
    "lr_ovr_model.fit(X_train_prep, y_train)\n",
    "# make predictions\n",
    "y_pred_lr_ovr = lr_ovr_model.predict(X_train_prep)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Recall: ', recall_score(y_train, y_train_pred, average=\"weighted\"))\n",
    "print('Precision: ', precision_score(y_train, y_train_pred, average=\"weighted\"))\n",
    "print('F1 Score: ', f1_score(y_train, y_train_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_lr_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('lr_clf',\n",
    "                             LogisticRegression(penalty='l2',\n",
    "                                                max_iter=100,\n",
    "                                                C=0.9,\n",
    "#                                                multi_class='multinomial',\n",
    "                                                random_state=random_state,\n",
    "                                                l1_ratio=0.5,\n",
    "                                                n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_lr_clf = LogisticRegression()\n",
    "test_lr_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_lr_clf = {\n",
    "    'lr_clf__penalty': ['l1', 'l2'],\n",
    "    'lr_clf__max_iter': randint(low=10, high=100),\n",
    "    'lr_clf__C': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
    "    'lr_clf__l1_ratio': [None, 0.1, 0.2, 0.3, 0.5, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   35.5s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_lr_clf = RandomizedSearchCV(pipeline_lr_clf,\n",
    "                                 param_distribs_lr_clf,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=50,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_lr_clf = rnd_lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.25\n",
      "Best parameters:\n",
      "{'lr_clf__C': 1, 'lr_clf__l1_ratio': 0.9, 'lr_clf__max_iter': 96, 'lr_clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_lr_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_lr_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_lr_clf = {\n",
    "#    'lr_clf__penalty': ['l1', 'l2'],\n",
    "    'lr_clf__max_iter': [85, 100, 125],\n",
    "    'lr_clf__C': [0.1, 0.5, 1, 2],\n",
    "    'lr_clf__l1_ratio': [0.8, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['accommodates',\n",
       "                                                                          'accommodates_per_bed',\n",
       "                                                                          'am_balcony',\n",
       "                                                                          'am_breakfast',\n",
       "                                                                          'am_child_friendly',\n",
       "                                                                          'am_elevator',\n",
       "                                                                          'am_essentials',\n",
       "                                                                          'am_nature_and_views',\n",
       "                                                                          'am_pets_allo...\n",
       "                                                                         ['cancellation_policy',\n",
       "                                                                          'host_response_time',\n",
       "                                                                          'neighbourhood_cleansed',\n",
       "                                                                          'property_type',\n",
       "                                                                          'room_type',\n",
       "                                                                          'zipcode'])])),\n",
       "                                       ('lr_clf',\n",
       "                                        LogisticRegression(C=0.9, l1_ratio=0.5,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr_clf__C': [0.1, 0.5, 1, 2],\n",
       "                         'lr_clf__l1_ratio': [0.8, 0.9, 1],\n",
       "                         'lr_clf__max_iter': [85, 100, 125]},\n",
       "             return_train_score=True, scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_lr_clf = GridSearchCV(pipeline_lr_clf,\n",
    "                            param_grid_lr_clf,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_lr_clf = grid_lr_clf.best_estimator_['lr_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.25\n",
      "Best parameters:\n",
      "{'lr_clf__C': 1, 'lr_clf__l1_ratio': 0.8, 'lr_clf__max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_lr_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_lr_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_lr_clf = best_model_lr_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_lr_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Recall: 0.35\n",
      "Precision: 0.35\n",
      "F1 Score: 0.34\n",
      "Confusion Matrix: \n",
      "[[ 74 120  73  19   4   3   3   0   0   7   4]\n",
      " [ 20 543 350  94  20   7   3   1   1  18   0]\n",
      " [ 12 299 648 225  63  60  19   5   1  18   3]\n",
      " [ 11 144 369 412 112 119  32  11   9  48   9]\n",
      " [  6  45 178 211 209 127  52  17  13  62   6]\n",
      " [  0  27  75 182 112 228  67  20  15  82   9]\n",
      " [  1  10  58  97  84 125 126  15  21 111  17]\n",
      " [  0   7  23  51  54  70  48  42  18 118  18]\n",
      " [  1   8  15  47  42  64  39  13  56 149  23]\n",
      " [  2   2  15  35  38  68  49  23  33 450  71]\n",
      " [  0   1   3   6  14   9   8   6   7 139 204]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the best model\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_lr_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "#print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_clf, multi_class='ovr')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_lr_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_lr_clf = best_model_lr_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_lr_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_rf_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_clf',\n",
    "                             RandomForestClassifier(n_estimators=110,\n",
    "                                                    random_state=random_state,\n",
    "                                                    max_depth=5,\n",
    "                                                    max_features=20,\n",
    "                                                    n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for RandomForestClassifier\n",
    "test_rf_clf = RandomForestClassifier()\n",
    "test_rf_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_rf_clf = {\n",
    "    'rf_clf__n_estimators': randint(low=10, high=500),\n",
    "    'rf_clf__max_depth': randint(low=1, high=30),\n",
    "    'rf_clf__max_features': randint(low=1, high=100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_rf_clf = RandomizedSearchCV(pipeline_rf_clf,\n",
    "                           param_distribs_rf_clf,\n",
    "                           cv=5,\n",
    "                           scoring=scoring,\n",
    "                           return_train_score=True,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1,\n",
    "                         random_state=random_state)\n",
    "\n",
    "rnd_rf_clf.fit(X_train, y_train)\n",
    "best_model_rnd_rf_clf = rnd_rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'rf_clf__max_depth': 21, 'rf_clf__max_features': 33, 'rf_clf__n_estimators': 469}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_rf_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_clf = {\n",
    "    'rf_clf__n_estimators': [450, 500],\n",
    "    'rf_clf__max_depth': [20, 25],\n",
    "    'rf_clf__max_features': [30, 35],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed: 10.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_clf = GridSearchCV(pipeline_rf_clf,\n",
    "                            param_grid_rf_clf,\n",
    "                            cv=4,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_rf_clf = grid_rf_clf.best_estimator_['rf_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'rf_clf__max_depth': 25, 'rf_clf__max_features': 35, 'rf_clf__n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.053475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.052189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len_sqrt</th>\n",
       "      <td>0.049861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_no</th>\n",
       "      <td>0.046906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_days_sqrt</th>\n",
       "      <td>0.045590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_days_sqrt</th>\n",
       "      <td>0.045221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_fees_sqrt</th>\n",
       "      <td>0.041142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm_log</th>\n",
       "      <td>0.039622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>0.034078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating_sqrt</th>\n",
       "      <td>0.032940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_people</th>\n",
       "      <td>0.031769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.031012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.028774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.028069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.020518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.017959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.017844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>0.016925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.010814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.009255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.008948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.008442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.008298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.007610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.007536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0.007456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.007280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.007224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_white_goods</th>\n",
       "      <td>0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.006845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>0.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.005714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0.005443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nb_other</th>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alexanderplatz</th>\n",
       "      <td>0.004197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.004160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_unknown</th>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Sd</th>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Sd FK</th>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhofer Vorstadt</th>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_nature_and_views</th>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sdwest</th>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Reuterstrae</th>\n",
       "      <td>0.002128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sd</th>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_sdliche Luisenstadt</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nordwest</th>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Nord</th>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Rixdorf</th>\n",
       "      <td>0.001610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Nord</th>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neukllner Mitte/Zentrum</th>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schillerpromenade</th>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.001328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nord</th>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nrdliche Luisenstadt</th>\n",
       "      <td>0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit West</th>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Helmholtzplatz</th>\n",
       "      <td>0.001251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Sd</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Wedding Zentrum</th>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit Ost</th>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Sdliche Friedrichstadt</th>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Regierungsviertel</th>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Sd</th>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Osloer Strae</th>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Nord</th>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tiergarten Sd</th>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Dsseldorfer Strae</th>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Ost</th>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Parkviertel</th>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Otto-Suhr-Allee</th>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Friedenau</th>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Nord</th>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhof</th>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kurfrstendamm</th>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Volkspark Wilmersdorf</th>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Weiensee</th>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neu Lichtenberg</th>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt  Treptow</th>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kantstrae</th>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Sd</th>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt-Lichtenberg</th>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Zentrum</th>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neue Kantstrae</th>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schlo Charlottenburg</th>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Westend</th>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Britz</th>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Mierendorffplatz</th>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Halensee</th>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Grunewald</th>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Zehlendorf  Nord</th>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Drakestr.</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Ost 2</th>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Plnterwald</th>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Baumschulenweg</th>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karlshorst</th>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Blankenfelde/Niederschnhausen</th>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Barstrae</th>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      weight\n",
       "latitude                                            0.053475\n",
       "longitude                                           0.052189\n",
       "text_len_sqrt                                       0.049861\n",
       "listing_no                                          0.046906\n",
       "first_review_days_sqrt                              0.045590\n",
       "last_review_days_sqrt                               0.045221\n",
       "availability_90                                     0.043774\n",
       "price_extra_fees_sqrt                               0.041142\n",
       "number_of_reviews_ltm_log                           0.039622\n",
       "host_acceptance_rate                                0.034078\n",
       "review_scores_rating_sqrt                           0.032940\n",
       "price_extra_people                                  0.031769\n",
       "room_type_Private room                              0.031012\n",
       "maximum_nights                                      0.028774\n",
       "minimum_nights_log                                  0.028319\n",
       "accommodates                                        0.028069\n",
       "calc_host_lst_count_sqrt_log                        0.020518\n",
       "accommodates_per_bed                                0.017959\n",
       "bedrooms                                            0.017844\n",
       "host_response_rate                                  0.016925\n",
       "bathrooms_log                                       0.010814\n",
       "review_scores_location                              0.009840\n",
       "am_tv                                               0.009255\n",
       "cancellation_policy_strict                          0.008948\n",
       "am_balcony                                          0.008566\n",
       "am_elevator                                         0.008566\n",
       "cancellation_policy_moderate                        0.008442\n",
       "instant_bookable                                    0.008298\n",
       "host_is_superhost                                   0.007610\n",
       "wk_mth_discount                                     0.007536\n",
       "host_response_time_within an hour                   0.007456\n",
       "am_child_friendly                                   0.007280\n",
       "am_private_entrance                                 0.007224\n",
       "am_white_goods                                      0.006866\n",
       "am_pets_allowed                                     0.006845\n",
       "host_response_time_within a few hours               0.006434\n",
       "am_smoking_allowed                                  0.005714\n",
       "host_response_time_within a day                     0.005443\n",
       "neighbourhood_cleansed_nb_other                     0.004374\n",
       "neighbourhood_cleansed_Alexanderplatz               0.004197\n",
       "zipcode_zip_other                                   0.004160\n",
       "host_response_time_unknown                          0.004015\n",
       "property_type_Boutique hotel                        0.003912\n",
       "neighbourhood_cleansed_Brunnenstr. Sd              0.003231\n",
       "am_breakfast                                        0.003216\n",
       "neighbourhood_cleansed_Frankfurter Allee Sd FK     0.002968\n",
       "neighbourhood_cleansed_Tempelhofer Vorstadt         0.002710\n",
       "zipcode_zip_10119                                   0.002596\n",
       "zipcode_zip_10245                                   0.002543\n",
       "am_essentials                                       0.002475\n",
       "am_nature_and_views                                 0.002362\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sdwest      0.002200\n",
       "neighbourhood_cleansed_Reuterstrae                 0.002128\n",
       "room_type_Shared room                               0.002116\n",
       "zipcode_zip_10405                                   0.002054\n",
       "zipcode_zip_10247                                   0.002015\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sd          0.001905\n",
       "neighbourhood_cleansed_sdliche Luisenstadt         0.001856\n",
       "zipcode_zip_10999                                   0.001827\n",
       "zipcode_zip_10439                                   0.001758\n",
       "zipcode_zip_10437                                   0.001726\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nordwest     0.001707\n",
       "property_type_House                                 0.001691\n",
       "neighbourhood_cleansed_Frankfurter Allee Nord       0.001615\n",
       "neighbourhood_cleansed_Rixdorf                      0.001610\n",
       "neighbourhood_cleansed_Schneberg-Nord              0.001566\n",
       "zipcode_zip_10117                                   0.001520\n",
       "neighbourhood_cleansed_Neukllner Mitte/Zentrum     0.001512\n",
       "zipcode_zip_10997                                   0.001478\n",
       "zipcode_zip_10435                                   0.001472\n",
       "neighbourhood_cleansed_Schillerpromenade            0.001430\n",
       "zipcode_zip_10243                                   0.001430\n",
       "zipcode_zip_10179                                   0.001409\n",
       "zipcode_zip_10249                                   0.001328\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nord         0.001321\n",
       "neighbourhood_cleansed_nrdliche Luisenstadt        0.001290\n",
       "zipcode_zip_10967                                   0.001282\n",
       "neighbourhood_cleansed_Moabit West                  0.001275\n",
       "neighbourhood_cleansed_Helmholtzplatz               0.001251\n",
       "zipcode_zip_nan                                     0.001244\n",
       "zipcode_zip_10407                                   0.001238\n",
       "zipcode_zip_12047                                   0.001230\n",
       "zipcode_zip_10178                                   0.001208\n",
       "neighbourhood_cleansed_Schneberg-Sd               0.001189\n",
       "zipcode_zip_12049                                   0.001149\n",
       "neighbourhood_cleansed_Wedding Zentrum              0.001136\n",
       "neighbourhood_cleansed_Moabit Ost                   0.001133\n",
       "zipcode_zip_10965                                   0.001128\n",
       "neighbourhood_cleansed_Sdliche Friedrichstadt      0.001111\n",
       "zipcode_zip_12051                                   0.001110\n",
       "zipcode_zip_12045                                   0.001086\n",
       "zipcode_zip_10961                                   0.001076\n",
       "neighbourhood_cleansed_Regierungsviertel            0.001068\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Sd          0.001022\n",
       "neighbourhood_cleansed_Osloer Strae                0.000965\n",
       "cancellation_policy_super_strict                    0.000956\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Nord         0.000943\n",
       "neighbourhood_cleansed_Tiergarten Sd               0.000930\n",
       "zipcode_zip_13353                                   0.000923\n",
       "room_type_Hotel room                                0.000914\n",
       "zipcode_zip_10777                                   0.000893\n",
       "zipcode_zip_13359                                   0.000887\n",
       "zipcode_zip_12053                                   0.000870\n",
       "zipcode_zip_12059                                   0.000853\n",
       "neighbourhood_cleansed_Dsseldorfer Strae          0.000844\n",
       "zipcode_zip_10785                                   0.000843\n",
       "zipcode_zip_12043                                   0.000819\n",
       "zipcode_zip_10963                                   0.000807\n",
       "neighbourhood_cleansed_Prenzlauer Berg Ost          0.000798\n",
       "neighbourhood_cleansed_Parkviertel                  0.000767\n",
       "zipcode_zip_12055                                   0.000745\n",
       "neighbourhood_cleansed_Otto-Suhr-Allee              0.000730\n",
       "neighbourhood_cleansed_Friedenau                    0.000724\n",
       "zipcode_zip_10969                                   0.000710\n",
       "neighbourhood_cleansed_Brunnenstr. Nord             0.000703\n",
       "neighbourhood_cleansed_Tempelhof                    0.000697\n",
       "neighbourhood_cleansed_Kurfrstendamm               0.000691\n",
       "neighbourhood_cleansed_Volkspark Wilmersdorf        0.000682\n",
       "zipcode_zip_12435                                   0.000642\n",
       "zipcode_zip_13357                                   0.000626\n",
       "zipcode_zip_10559                                   0.000603\n",
       "neighbourhood_cleansed_Weiensee                    0.000600\n",
       "zipcode_zip_10317                                   0.000592\n",
       "zipcode_zip_13347                                   0.000590\n",
       "property_type_Secondary unit                        0.000588\n",
       "neighbourhood_cleansed_Neu Lichtenberg              0.000570\n",
       "zipcode_zip_10829                                   0.000570\n",
       "zipcode_zip_10551                                   0.000560\n",
       "neighbourhood_cleansed_Alt  Treptow                 0.000539\n",
       "neighbourhood_cleansed_Kantstrae                   0.000520\n",
       "neighbourhood_cleansed_Pankow Sd                   0.000519\n",
       "neighbourhood_cleansed_Alt-Lichtenberg              0.000509\n",
       "zipcode_zip_10719                                   0.000501\n",
       "zipcode_zip_10827                                   0.000498\n",
       "zipcode_zip_13187                                   0.000473\n",
       "zipcode_zip_10555                                   0.000469\n",
       "zipcode_zip_10409                                   0.000453\n",
       "neighbourhood_cleansed_Pankow Zentrum               0.000445\n",
       "neighbourhood_cleansed_Neue Kantstrae              0.000444\n",
       "zipcode_zip_13189                                   0.000441\n",
       "zipcode_zip_10557                                   0.000415\n",
       "zipcode_zip_10585                                   0.000414\n",
       "zipcode_zip_10781                                   0.000410\n",
       "zipcode_zip_13086                                   0.000408\n",
       "neighbourhood_cleansed_Schlo Charlottenburg        0.000401\n",
       "neighbourhood_cleansed_Westend                      0.000396\n",
       "zipcode_zip_10365                                   0.000395\n",
       "neighbourhood_cleansed_Britz                        0.000377\n",
       "zipcode_zip_10553                                   0.000372\n",
       "zipcode_zip_13355                                   0.000368\n",
       "zipcode_zip_14057                                   0.000356\n",
       "zipcode_zip_13088                                   0.000349\n",
       "neighbourhood_cleansed_Mierendorffplatz             0.000348\n",
       "zipcode_zip_14059                                   0.000337\n",
       "zipcode_zip_10707                                   0.000332\n",
       "zipcode_zip_10787                                   0.000332\n",
       "zipcode_zip_10715                                   0.000326\n",
       "zipcode_zip_12157                                   0.000318\n",
       "zipcode_zip_10711                                   0.000314\n",
       "zipcode_zip_10717                                   0.000314\n",
       "zipcode_zip_10589                                   0.000312\n",
       "zipcode_zip_10783                                   0.000307\n",
       "zipcode_zip_10623                                   0.000304\n",
       "neighbourhood_cleansed_Halensee                     0.000304\n",
       "zipcode_zip_10629                                   0.000303\n",
       "neighbourhood_cleansed_Grunewald                    0.000299\n",
       "neighbourhood_cleansed_Zehlendorf  Nord             0.000287\n",
       "zipcode_zip_12161                                   0.000287\n",
       "zipcode_zip_12437                                   0.000281\n",
       "zipcode_zip_13351                                   0.000270\n",
       "zipcode_zip_10625                                   0.000268\n",
       "neighbourhood_cleansed_Drakestr.                    0.000267\n",
       "zipcode_zip_12099                                   0.000262\n",
       "neighbourhood_cleansed_Ost 2                        0.000260\n",
       "zipcode_zip_12163                                   0.000257\n",
       "zipcode_zip_10627                                   0.000252\n",
       "zipcode_zip_12347                                   0.000249\n",
       "zipcode_zip_13407                                   0.000244\n",
       "zipcode_zip_12101                                   0.000233\n",
       "zipcode_zip_10587                                   0.000209\n",
       "neighbourhood_cleansed_Plnterwald                  0.000208\n",
       "zipcode_zip_10315                                   0.000206\n",
       "neighbourhood_cleansed_Baumschulenweg               0.000204\n",
       "zipcode_zip_13156                                   0.000202\n",
       "zipcode_zip_10318                                   0.000202\n",
       "neighbourhood_cleansed_Karlshorst                   0.000199\n",
       "zipcode_zip_10367                                   0.000199\n",
       "zipcode_zip_13409                                   0.000197\n",
       "zipcode_zip_10823                                   0.000195\n",
       "zipcode_zip_12103                                   0.000194\n",
       "property_type_Bed and breakfast                     0.000193\n",
       "neighbourhood_cleansed_Blankenfelde/Niederschn...  0.000175\n",
       "zipcode_zip_14197                                   0.000174\n",
       "zipcode_zip_13349                                   0.000169\n",
       "property_type_Unique space                          0.000107\n",
       "neighbourhood_cleansed_Barstrae                    0.000106\n",
       "zipcode_zip_10713                                   0.000099"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and print feature importances\n",
    "grid_rf_clf_fi = feat_importances(grid_rf_clf, cv_model=True, named_steps='rf_clf', column_names=column_names)\n",
    "grid_rf_clf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_rf_clf = best_model_rf_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: \n",
      "[[ 307    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1057    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1276    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  926    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  817    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  665    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  449    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  457    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  786    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  397]]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_rf_clf, model=\"clf\")\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_rf_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "#print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_clf, multi_class='ovr')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_rf_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_rf_clf = best_model_rf_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_rf_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_xgb_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_clf',\n",
    "                              XGBClassifier(n_estimators=110,\n",
    "                                            random_state=random_state,\n",
    "                                            max_depth=5,\n",
    "                                            max_features=20,\n",
    "                                            scoring=scoring,\n",
    "                                            n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample', 'verbosity'])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_xgb_clf = XGBClassifier()\n",
    "test_xgb_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_clf = {\n",
    "    'xgb_clf__n_estimators': randint(low=10, high=200),\n",
    "    'xgb_clf__max_depth': randint(low=1, high=10),\n",
    "    'xgb_clf__learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 25.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_clf = RandomizedSearchCV(pipeline_xgb_clf,\n",
    "                                 param_distribs_xgb_clf,\n",
    "                                 cv=5,\n",
    "                                 n_iter=20,\n",
    "                                 scoring=scoring,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_clf = rnd_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'xgb_clf__learning_rate': 0.2, 'xgb_clf__max_depth': 8, 'xgb_clf__n_estimators': 126}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_xgb_clf = {\n",
    "    'xgb_clf__n_estimators': [120, 130],\n",
    "    'xgb_clf__max_depth': [8, 10],\n",
    "    'xgb_clf__learning_rate': [0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['accommodates',\n",
       "                                                                          'accommodates_per_bed',\n",
       "                                                                          'am_balcony',\n",
       "                                                                          'am_breakfast',\n",
       "                                                                          'am_child_friendly',\n",
       "                                                                          'am_elevator',\n",
       "                                                                          'am_essentials',\n",
       "                                                                          'am_nature_and_views',\n",
       "                                                                          'am_pets_allo...\n",
       "                                                                          'neighbourhood_cleansed',\n",
       "                                                                          'property_type',\n",
       "                                                                          'room_type',\n",
       "                                                                          'zipcode'])])),\n",
       "                                       ('xgb_clf',\n",
       "                                        XGBClassifier(max_depth=5,\n",
       "                                                      max_features=20,\n",
       "                                                      n_estimators=110,\n",
       "                                                      n_jobs=-1,\n",
       "                                                      random_state=42,\n",
       "                                                      scoring='f1_weighted'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgb_clf__learning_rate': [0.2, 0.3],\n",
       "                         'xgb_clf__max_depth': [8, 10],\n",
       "                         'xgb_clf__n_estimators': [120, 130]},\n",
       "             return_train_score=True, scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_xgb_clf = GridSearchCV(pipeline_xgb_clf,\n",
    "                            param_grid_xgb_clf,\n",
    "                            cv=3,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_xgb_clf = grid_xgb_clf.best_estimator_['xgb_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.29\n",
      "Best parameters:\n",
      "{'xgb_clf__learning_rate': 0.2, 'xgb_clf__max_depth': 10, 'xgb_clf__n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.054966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.018998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.017493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Ost 2</th>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt-Lichtenberg</th>\n",
       "      <td>0.012494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.011030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.010751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.010312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.009451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Friedenau</th>\n",
       "      <td>0.008156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.007994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nb_other</th>\n",
       "      <td>0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Zehlendorf  Nord</th>\n",
       "      <td>0.007563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.007483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Wedding Zentrum</th>\n",
       "      <td>0.007422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.007294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.007289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.007269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.007115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_sdliche Luisenstadt</th>\n",
       "      <td>0.006945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.006924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.006911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.006894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.006793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhof</th>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.006563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.006499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.006387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.006326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Nord</th>\n",
       "      <td>0.006293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alexanderplatz</th>\n",
       "      <td>0.006273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.006212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.006151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.006052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neu Lichtenberg</th>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.005891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sdwest</th>\n",
       "      <td>0.005885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit Ost</th>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Otto-Suhr-Allee</th>\n",
       "      <td>0.005796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Osloer Strae</th>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Parkviertel</th>\n",
       "      <td>0.005724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Helmholtzplatz</th>\n",
       "      <td>0.005640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Rixdorf</th>\n",
       "      <td>0.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.005518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.005502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nrdliche Luisenstadt</th>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.005457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Sd</th>\n",
       "      <td>0.005409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nordwest</th>\n",
       "      <td>0.005187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schillerpromenade</th>\n",
       "      <td>0.005116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.005064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Sd FK</th>\n",
       "      <td>0.005019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>0.004995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.004989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.004960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Dsseldorfer Strae</th>\n",
       "      <td>0.004876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nord</th>\n",
       "      <td>0.004858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Sd</th>\n",
       "      <td>0.004779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kurfrstendamm</th>\n",
       "      <td>0.004750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.004747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_nature_and_views</th>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Westend</th>\n",
       "      <td>0.004666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.004639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Mierendorffplatz</th>\n",
       "      <td>0.004625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_unknown</th>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.004593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_people</th>\n",
       "      <td>0.004534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.004458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Sd</th>\n",
       "      <td>0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.004413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhofer Vorstadt</th>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit West</th>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kantstrae</th>\n",
       "      <td>0.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sd</th>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.004263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neukllner Mitte/Zentrum</th>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Sdliche Friedrichstadt</th>\n",
       "      <td>0.004195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Weiensee</th>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_white_goods</th>\n",
       "      <td>0.004037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.003969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Nord</th>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Nord</th>\n",
       "      <td>0.003901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.003895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.003894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.003889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_no</th>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating_sqrt</th>\n",
       "      <td>0.003872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Plnterwald</th>\n",
       "      <td>0.003850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Regierungsviertel</th>\n",
       "      <td>0.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Reuterstrae</th>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Britz</th>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.003764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_fees_sqrt</th>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Ost</th>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Volkspark Wilmersdorf</th>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt  Treptow</th>\n",
       "      <td>0.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_days_sqrt</th>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.003669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.003663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.003635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0.003629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_days_sqrt</th>\n",
       "      <td>0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.003606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len_sqrt</th>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.003555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.003530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Sd</th>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm_log</th>\n",
       "      <td>0.003498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Drakestr.</th>\n",
       "      <td>0.003492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Grunewald</th>\n",
       "      <td>0.003445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.003388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tiergarten Sd</th>\n",
       "      <td>0.003217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Halensee</th>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.003075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Nord</th>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Baumschulenweg</th>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schlo Charlottenburg</th>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neue Kantstrae</th>\n",
       "      <td>0.002455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Zentrum</th>\n",
       "      <td>0.002389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.001812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Blankenfelde/Niederschnhausen</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Barstrae</th>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karlshorst</th>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      weight\n",
       "room_type_Private room                              0.054966\n",
       "room_type_Shared room                               0.018998\n",
       "property_type_Boutique hotel                        0.017493\n",
       "zipcode_zip_13407                                   0.013383\n",
       "bedrooms                                            0.013143\n",
       "neighbourhood_cleansed_Ost 2                        0.012749\n",
       "neighbourhood_cleansed_Alt-Lichtenberg              0.012494\n",
       "room_type_Hotel room                                0.011030\n",
       "zipcode_zip_13187                                   0.010751\n",
       "zipcode_zip_14057                                   0.010312\n",
       "accommodates                                        0.009451\n",
       "neighbourhood_cleansed_Friedenau                    0.008156\n",
       "zipcode_zip_13359                                   0.007994\n",
       "neighbourhood_cleansed_nb_other                     0.007631\n",
       "neighbourhood_cleansed_Zehlendorf  Nord             0.007563\n",
       "zipcode_zip_10553                                   0.007483\n",
       "neighbourhood_cleansed_Wedding Zentrum              0.007422\n",
       "zipcode_zip_10243                                   0.007294\n",
       "property_type_Secondary unit                        0.007289\n",
       "zipcode_zip_10707                                   0.007269\n",
       "cancellation_policy_super_strict                    0.007202\n",
       "bathrooms_log                                       0.007115\n",
       "neighbourhood_cleansed_sdliche Luisenstadt         0.006945\n",
       "zipcode_zip_10717                                   0.006924\n",
       "zipcode_zip_10119                                   0.006911\n",
       "zipcode_zip_10783                                   0.006894\n",
       "zipcode_zip_12103                                   0.006793\n",
       "zipcode_zip_10587                                   0.006700\n",
       "zipcode_zip_13353                                   0.006660\n",
       "neighbourhood_cleansed_Tempelhof                    0.006578\n",
       "zipcode_zip_13088                                   0.006563\n",
       "zipcode_zip_10623                                   0.006499\n",
       "zipcode_zip_10555                                   0.006387\n",
       "zipcode_zip_10589                                   0.006326\n",
       "neighbourhood_cleansed_Schneberg-Nord              0.006293\n",
       "neighbourhood_cleansed_Alexanderplatz               0.006273\n",
       "zipcode_zip_10178                                   0.006212\n",
       "zipcode_zip_10435                                   0.006151\n",
       "zipcode_zip_10965                                   0.006052\n",
       "neighbourhood_cleansed_Neu Lichtenberg              0.006048\n",
       "zipcode_zip_10629                                   0.005938\n",
       "calc_host_lst_count_sqrt_log                        0.005938\n",
       "zipcode_zip_14059                                   0.005891\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sdwest      0.005885\n",
       "neighbourhood_cleansed_Moabit Ost                   0.005859\n",
       "neighbourhood_cleansed_Otto-Suhr-Allee              0.005796\n",
       "am_essentials                                       0.005793\n",
       "zipcode_zip_10551                                   0.005791\n",
       "neighbourhood_cleansed_Osloer Strae                0.005789\n",
       "neighbourhood_cleansed_Parkviertel                  0.005724\n",
       "neighbourhood_cleansed_Helmholtzplatz               0.005640\n",
       "zipcode_zip_10405                                   0.005610\n",
       "zipcode_zip_10247                                   0.005561\n",
       "neighbourhood_cleansed_Rixdorf                      0.005527\n",
       "zipcode_zip_10409                                   0.005518\n",
       "zipcode_zip_12049                                   0.005502\n",
       "neighbourhood_cleansed_nrdliche Luisenstadt        0.005500\n",
       "am_elevator                                         0.005457\n",
       "zipcode_zip_10249                                   0.005435\n",
       "neighbourhood_cleansed_Brunnenstr. Sd              0.005409\n",
       "zipcode_zip_12045                                   0.005394\n",
       "zipcode_zip_10245                                   0.005228\n",
       "zipcode_zip_12053                                   0.005208\n",
       "zipcode_zip_10439                                   0.005203\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nordwest     0.005187\n",
       "zipcode_zip_10407                                   0.005177\n",
       "neighbourhood_cleansed_Schillerpromenade            0.005116\n",
       "zipcode_zip_13189                                   0.005064\n",
       "neighbourhood_cleansed_Frankfurter Allee Sd FK     0.005019\n",
       "review_scores_location                              0.004995\n",
       "zipcode_zip_other                                   0.004989\n",
       "zipcode_zip_13086                                   0.004960\n",
       "zipcode_zip_12157                                   0.004957\n",
       "zipcode_zip_13351                                   0.004941\n",
       "neighbourhood_cleansed_Dsseldorfer Strae          0.004876\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nord         0.004858\n",
       "zipcode_zip_12043                                   0.004839\n",
       "zipcode_zip_10179                                   0.004794\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Sd          0.004779\n",
       "am_breakfast                                        0.004775\n",
       "neighbourhood_cleansed_Kurfrstendamm               0.004750\n",
       "wk_mth_discount                                     0.004747\n",
       "am_nature_and_views                                 0.004687\n",
       "minimum_nights_log                                  0.004670\n",
       "zipcode_zip_12051                                   0.004667\n",
       "neighbourhood_cleansed_Westend                      0.004666\n",
       "zipcode_zip_10785                                   0.004639\n",
       "neighbourhood_cleansed_Mierendorffplatz             0.004625\n",
       "host_response_time_unknown                          0.004614\n",
       "zipcode_zip_12059                                   0.004593\n",
       "price_extra_people                                  0.004534\n",
       "zipcode_zip_12055                                   0.004458\n",
       "zipcode_zip_10117                                   0.004456\n",
       "neighbourhood_cleansed_Pankow Sd                   0.004432\n",
       "property_type_House                                 0.004413\n",
       "neighbourhood_cleansed_Tempelhofer Vorstadt         0.004400\n",
       "neighbourhood_cleansed_Moabit West                  0.004383\n",
       "zipcode_zip_10777                                   0.004377\n",
       "neighbourhood_cleansed_Kantstrae                   0.004302\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sd          0.004275\n",
       "zipcode_zip_10557                                   0.004265\n",
       "zipcode_zip_10437                                   0.004263\n",
       "neighbourhood_cleansed_Neukllner Mitte/Zentrum     0.004224\n",
       "neighbourhood_cleansed_Sdliche Friedrichstadt      0.004195\n",
       "zipcode_zip_nan                                     0.004192\n",
       "neighbourhood_cleansed_Weiensee                    0.004143\n",
       "host_response_time_within a few hours               0.004107\n",
       "zipcode_zip_12163                                   0.004087\n",
       "am_private_entrance                                 0.004058\n",
       "accommodates_per_bed                                0.004043\n",
       "am_white_goods                                      0.004037\n",
       "host_response_rate                                  0.004012\n",
       "zipcode_zip_13347                                   0.004004\n",
       "zipcode_zip_10787                                   0.003997\n",
       "am_tv                                               0.003970\n",
       "latitude                                            0.003969\n",
       "zipcode_zip_12435                                   0.003965\n",
       "zipcode_zip_10585                                   0.003965\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Nord         0.003935\n",
       "zipcode_zip_12047                                   0.003920\n",
       "longitude                                           0.003906\n",
       "neighbourhood_cleansed_Brunnenstr. Nord             0.003901\n",
       "zipcode_zip_10967                                   0.003895\n",
       "zipcode_zip_10999                                   0.003894\n",
       "zipcode_zip_10719                                   0.003889\n",
       "listing_no                                          0.003883\n",
       "review_scores_rating_sqrt                           0.003872\n",
       "availability_90                                     0.003867\n",
       "neighbourhood_cleansed_Plnterwald                  0.003850\n",
       "neighbourhood_cleansed_Regierungsviertel            0.003842\n",
       "neighbourhood_cleansed_Reuterstrae                 0.003815\n",
       "zipcode_zip_10559                                   0.003788\n",
       "neighbourhood_cleansed_Britz                        0.003767\n",
       "zipcode_zip_12161                                   0.003764\n",
       "price_extra_fees_sqrt                               0.003748\n",
       "neighbourhood_cleansed_Prenzlauer Berg Ost          0.003730\n",
       "neighbourhood_cleansed_Volkspark Wilmersdorf        0.003716\n",
       "neighbourhood_cleansed_Alt  Treptow                 0.003683\n",
       "first_review_days_sqrt                              0.003681\n",
       "zipcode_zip_10715                                   0.003669\n",
       "zipcode_zip_12347                                   0.003664\n",
       "zipcode_zip_10997                                   0.003663\n",
       "am_balcony                                          0.003648\n",
       "cancellation_policy_moderate                        0.003643\n",
       "cancellation_policy_strict                          0.003635\n",
       "host_response_time_within a day                     0.003629\n",
       "zipcode_zip_10627                                   0.003623\n",
       "last_review_days_sqrt                               0.003619\n",
       "am_pets_allowed                                     0.003606\n",
       "host_response_time_within an hour                   0.003597\n",
       "text_len_sqrt                                       0.003577\n",
       "am_child_friendly                                   0.003555\n",
       "host_is_superhost                                   0.003531\n",
       "maximum_nights                                      0.003530\n",
       "host_acceptance_rate                                0.003523\n",
       "neighbourhood_cleansed_Schneberg-Sd               0.003509\n",
       "number_of_reviews_ltm_log                           0.003498\n",
       "neighbourhood_cleansed_Drakestr.                    0.003492\n",
       "zipcode_zip_10781                                   0.003480\n",
       "neighbourhood_cleansed_Grunewald                    0.003445\n",
       "zipcode_zip_10969                                   0.003388\n",
       "zipcode_zip_10365                                   0.003382\n",
       "zipcode_zip_10317                                   0.003353\n",
       "am_smoking_allowed                                  0.003310\n",
       "neighbourhood_cleansed_Tiergarten Sd               0.003217\n",
       "zipcode_zip_14197                                   0.003181\n",
       "neighbourhood_cleansed_Halensee                     0.003176\n",
       "instant_bookable                                    0.003075\n",
       "zipcode_zip_13357                                   0.003074\n",
       "zipcode_zip_10963                                   0.003046\n",
       "zipcode_zip_13355                                   0.002945\n",
       "neighbourhood_cleansed_Frankfurter Allee Nord       0.002911\n",
       "neighbourhood_cleansed_Baumschulenweg               0.002856\n",
       "zipcode_zip_10961                                   0.002832\n",
       "zipcode_zip_12099                                   0.002758\n",
       "neighbourhood_cleansed_Schlo Charlottenburg        0.002734\n",
       "zipcode_zip_10625                                   0.002596\n",
       "zipcode_zip_12101                                   0.002596\n",
       "neighbourhood_cleansed_Neue Kantstrae              0.002455\n",
       "zipcode_zip_10367                                   0.002427\n",
       "zipcode_zip_10829                                   0.002406\n",
       "neighbourhood_cleansed_Pankow Zentrum               0.002389\n",
       "zipcode_zip_10823                                   0.001947\n",
       "zipcode_zip_10711                                   0.001921\n",
       "zipcode_zip_10827                                   0.001878\n",
       "property_type_Bed and breakfast                     0.001812\n",
       "zipcode_zip_10318                                   0.001785\n",
       "zipcode_zip_10315                                   0.001756\n",
       "neighbourhood_cleansed_Blankenfelde/Niederschn...  0.001691\n",
       "neighbourhood_cleansed_Barstrae                    0.001523\n",
       "neighbourhood_cleansed_Karlshorst                   0.001491\n",
       "zipcode_zip_13349                                   0.001258\n",
       "zipcode_zip_12437                                   0.000839\n",
       "zipcode_zip_13156                                   0.000000\n",
       "zipcode_zip_13409                                   0.000000\n",
       "zipcode_zip_10713                                   0.000000\n",
       "property_type_Unique space                          0.000000"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and print feature importances\n",
    "grid_xgb_clf_fi = feat_importances(grid_xgb_clf, cv_model=True, named_steps='xgb_clf', column_names=column_names)\n",
    "grid_xgb_clf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_xgb_clf = best_model_xgb_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: \n",
      "[[ 307    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1057    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1276    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  926    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  817    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  665    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  449    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  457    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  786    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  397]]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_xgb_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_xgb_clf = best_model_xgb_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_xgb_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! NN Model 1: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Regression (\"price_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_LOG\u001b[0m as the target and \u001b[1mneg_median_absolute_error\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_LOG\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'guests_included_calc', 'host_is_superhost', 'instant_bookable', 'maximum_nights', 'minimum_nights_log', 'property_type', 'room_type', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "regmodels = {\n",
    "    'Baseline':\n",
    "    DummyRegressor(strategy='mean'),\n",
    "    'LinReg':\n",
    "    LinearRegression(),\n",
    "    'Passive Aggressive':\n",
    "    PassiveAggressiveRegressor(),\n",
    "    #        'RANSAC' : RANSACRegressor(),\n",
    "    'ElasticNet':\n",
    "    ElasticNet(),\n",
    "    'Stochastic Gradient Descent':\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeRegressor(criterion=\"mse\",\n",
    "                          max_depth=3,\n",
    "                          random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestRegressor(random_state=random_state,\n",
    "                          max_features='sqrt',\n",
    "                          n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingRegressor(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBRegressor(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostRegressor(random_state=random_state),\n",
    "    'SVR':\n",
    "    SVR(),\n",
    "    'CatBoost':\n",
    "    CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.6s remaining:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.1s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.7s remaining:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   19.3s remaining:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   23.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MAPE median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.963293</td>\n",
       "      <td>10.312244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.099945</td>\n",
       "      <td>5.622496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9.588548</td>\n",
       "      <td>7.757167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>11.963293</td>\n",
       "      <td>10.312244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.69</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>12.587933</td>\n",
       "      <td>9.711597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.33</td>\n",
       "      <td>8.384422</td>\n",
       "      <td>6.747336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.849030</td>\n",
       "      <td>5.352247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.033132</td>\n",
       "      <td>5.646463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.026799</td>\n",
       "      <td>5.606353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.001659</td>\n",
       "      <td>6.540991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.27</td>\n",
       "      <td>6.881792</td>\n",
       "      <td>5.302322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.26</td>\n",
       "      <td>6.665453</td>\n",
       "      <td>5.175233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model   MSE  RMSE     R2   MAE       MAPE  \\\n",
       "0                      Baseline  0.35  0.59  -0.00  0.47  11.963293   \n",
       "1                        LinReg  0.13  0.37   0.61  0.28   7.099945   \n",
       "2            Passive Aggressive  0.25  0.50   0.29  0.38   9.588548   \n",
       "3                    ElasticNet  0.35  0.59  -0.00  0.47  11.963293   \n",
       "4   Stochastic Gradient Descent  0.47  0.69  -0.36  0.51  12.587933   \n",
       "5                 Decision Tree  0.19  0.43   0.46  0.33   8.384422   \n",
       "6                 Random Forest  0.12  0.35   0.64  0.27   6.849030   \n",
       "7                Gradient Boost  0.13  0.36   0.63  0.28   7.033132   \n",
       "8                       XGBoost  0.13  0.36   0.63  0.28   7.026799   \n",
       "9                      AdaBoost  0.16  0.41   0.52  0.32   8.001659   \n",
       "10                          SVR  0.13  0.36   0.63  0.27   6.881792   \n",
       "11                     CatBoost  0.12  0.35   0.65  0.26   6.665453   \n",
       "\n",
       "    MAPE median  \n",
       "0     10.312244  \n",
       "1      5.622496  \n",
       "2      7.757167  \n",
       "3     10.312244  \n",
       "4      9.711597  \n",
       "5      6.747336  \n",
       "6      5.352247  \n",
       "7      5.646463  \n",
       "8      5.606353  \n",
       "9      6.540991  \n",
       "10     5.302322  \n",
       "11     5.175233  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'R2', 'MAE', 'MAPE', 'MAPE median'])\n",
    "i = 0\n",
    "for m in regmodels.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model':\n",
    "            m[0],\n",
    "            'MSE':\n",
    "            \"{:.2f}\".format(mean_squared_error(y_train, y_train_pred)),\n",
    "            'RMSE':\n",
    "            \"{:.2f}\".format(\n",
    "                mean_squared_error(y_train, y_train_pred, squared=False)),\n",
    "            'R2':\n",
    "            \"{:.2f}\".format(r2_score(y_train, y_train_pred)),\n",
    "            'MAE':\n",
    "            \"{:.2f}\".format(mean_absolute_error(y_train, y_train_pred)),\n",
    "            'MAPE': mean_absolute_percentage_error(y_train, y_train_pred),\n",
    "            'MAPE median': median_absolute_percentage_error(y_train, y_train_pred)\n",
    "        },\n",
    "        index=[i])\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_xgb_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_reg',\n",
    "                              XGBRegressor(n_estimators=182,\n",
    "                                           learning_rate=0.45,\n",
    "                                           random_state=random_state,\n",
    "                                           max_depth=5,\n",
    "                                           gamma=0.3,\n",
    "                                           bootstrap=True,\n",
    "                                           max_features=21,\n",
    "                                           scoring=scoring,\n",
    "                                           n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'importance_type', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample', 'verbosity'])"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_xgb_reg = XGBRegressor()\n",
    "test_xgb_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for XGBRegressor** (as base for hyperparameter search):\n",
    "\n",
    "max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_reg = {\n",
    "    'xgb_reg__n_estimators': randint(low=80, high=300),\n",
    "    'xgb_reg__bootstrap': [True, False],\n",
    "    'xgb_reg__gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'xgb_reg__max_depth': randint(low=1, high=7),\n",
    "    'xgb_reg__max_features': randint(low=1, high=40),\n",
    "    'xgb_reg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:04:06] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_reg = RandomizedSearchCV(pipeline_xgb_reg,\n",
    "                                 param_distribs_xgb_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=10,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_reg = rnd_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.21\n",
      "Best parameters:\n",
      "{'xgb_reg__bootstrap': True, 'xgb_reg__gamma': 0.3, 'xgb_reg__learning_rate': 0.45, 'xgb_reg__max_features': 8, 'xgb_reg__n_estimators': 268}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_xgb_reg = {\n",
    "#    'xgb_reg__bootstrap': [True, False],\n",
    "#    'xgb_reg__n_estimators': [190, 230, 290],\n",
    "#    'xgb_reg__max_features': [40, 45],\n",
    "    'xgb_reg__max_depth': [4, 5],\n",
    "    'xgb_reg__learning_rate': [0.42, 0.45, 0.48]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    9.2s finished\n",
      "C:\\Users\\Mauricio\\anaconda3\\envs\\airbnb42\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:51:29] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_xgb_reg = GridSearchCV(pipeline_xgb_reg,\n",
    "                            param_grid_xgb_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_xgb_reg = grid_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_xgb_reg = grid_xgb_reg.best_estimator_['xgb_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.22\n",
      "Best parameters:\n",
      "{'xgb_reg__learning_rate': 0.42, 'xgb_reg__max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.354507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.044553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included_calc</th>\n",
       "      <td>0.035743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.032164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.030424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.020782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.017576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.017562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.015473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.014447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.013084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.012070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.011124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.009970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.008305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.008212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.007817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.007721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.007494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.007275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.006612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.006498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.005860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.005854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.005513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.005455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.005297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.005231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.005201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.005082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.004911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.004907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.004882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.004582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.004402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.004348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.004340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.004182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.004092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.004089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.003750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.003742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.003641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.003641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.003593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.003561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.003546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.003513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.003465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.003359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.003345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.003281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.003211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.003179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.003138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.003076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.002860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.002792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.002791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.002749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.002749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.002667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.002565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.002447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.002443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.002317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.002152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.001894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.001870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.001857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.001787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.001551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.001542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.001531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.001489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.001406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.001213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.000984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    weight\n",
       "room_type_Private room            0.354507\n",
       "bedrooms                          0.049805\n",
       "room_type_Shared room             0.044553\n",
       "guests_included_calc              0.035743\n",
       "property_type_Boutique hotel      0.032164\n",
       "room_type_Hotel room              0.030424\n",
       "zipcode_zip_10119                 0.020782\n",
       "zipcode_zip_10117                 0.017576\n",
       "am_elevator                       0.017562\n",
       "bathrooms_log                     0.015473\n",
       "zipcode_zip_10435                 0.014447\n",
       "am_tv                             0.013084\n",
       "zipcode_zip_other                 0.012070\n",
       "calc_host_lst_count_sqrt_log      0.011124\n",
       "zipcode_zip_10245                 0.009970\n",
       "zipcode_zip_13359                 0.008305\n",
       "zipcode_zip_10405                 0.008212\n",
       "am_smoking_allowed                0.007817\n",
       "minimum_nights_log                0.007781\n",
       "am_balcony                        0.007721\n",
       "zipcode_zip_10997                 0.007494\n",
       "am_child_friendly                 0.007275\n",
       "wk_mth_discount                   0.006612\n",
       "host_is_superhost                 0.006498\n",
       "zipcode_zip_10243                 0.005860\n",
       "zipcode_zip_13353                 0.005854\n",
       "zipcode_zip_13407                 0.005513\n",
       "zipcode_zip_10719                 0.005455\n",
       "zipcode_zip_12047                 0.005297\n",
       "am_breakfast                      0.005231\n",
       "zipcode_zip_13409                 0.005201\n",
       "am_private_entrance               0.005082\n",
       "zipcode_zip_10365                 0.004911\n",
       "zipcode_zip_10317                 0.004907\n",
       "zipcode_zip_12347                 0.004882\n",
       "accommodates_per_bed              0.004582\n",
       "zipcode_zip_10553                 0.004454\n",
       "zipcode_zip_10969                 0.004402\n",
       "zipcode_zip_10587                 0.004348\n",
       "zipcode_zip_10589                 0.004340\n",
       "zipcode_zip_13347                 0.004182\n",
       "zipcode_zip_10777                 0.004092\n",
       "zipcode_zip_13086                 0.004089\n",
       "zipcode_zip_10967                 0.003840\n",
       "zipcode_zip_12161                 0.003750\n",
       "zipcode_zip_13189                 0.003742\n",
       "cancellation_policy_strict        0.003724\n",
       "zipcode_zip_13187                 0.003664\n",
       "zipcode_zip_14057                 0.003641\n",
       "maximum_nights                    0.003641\n",
       "zipcode_zip_10409                 0.003593\n",
       "zipcode_zip_10999                 0.003561\n",
       "zipcode_zip_10557                 0.003546\n",
       "zipcode_zip_12437                 0.003513\n",
       "zipcode_zip_13351                 0.003465\n",
       "property_type_Bed and breakfast   0.003400\n",
       "zipcode_zip_13357                 0.003359\n",
       "zipcode_zip_10439                 0.003345\n",
       "zipcode_zip_10247                 0.003309\n",
       "zipcode_zip_12045                 0.003307\n",
       "zipcode_zip_10315                 0.003286\n",
       "zipcode_zip_10179                 0.003281\n",
       "zipcode_zip_10178                 0.003211\n",
       "instant_bookable                  0.003179\n",
       "zipcode_zip_12055                 0.003150\n",
       "zipcode_zip_12043                 0.003138\n",
       "zipcode_zip_12051                 0.003076\n",
       "property_type_House               0.002868\n",
       "zipcode_zip_10715                 0.002860\n",
       "zipcode_zip_10555                 0.002831\n",
       "zipcode_zip_10787                 0.002831\n",
       "zipcode_zip_10963                 0.002792\n",
       "zipcode_zip_12053                 0.002791\n",
       "zipcode_zip_12157                 0.002749\n",
       "property_type_Unique space        0.002749\n",
       "cancellation_policy_moderate      0.002720\n",
       "zipcode_zip_10785                 0.002667\n",
       "zipcode_zip_10559                 0.002637\n",
       "zipcode_zip_13349                 0.002565\n",
       "am_essentials                     0.002516\n",
       "am_pets_allowed                   0.002447\n",
       "zipcode_zip_12049                 0.002443\n",
       "zipcode_zip_10713                 0.002422\n",
       "zipcode_zip_12099                 0.002414\n",
       "zipcode_zip_10965                 0.002317\n",
       "zipcode_zip_12435                 0.002152\n",
       "zipcode_zip_12101                 0.001927\n",
       "zipcode_zip_13156                 0.001894\n",
       "zipcode_zip_10437                 0.001870\n",
       "zipcode_zip_12059                 0.001857\n",
       "zipcode_zip_10318                 0.001787\n",
       "zipcode_zip_10961                 0.001753\n",
       "zipcode_zip_10249                 0.001551\n",
       "zipcode_zip_10783                 0.001542\n",
       "zipcode_zip_13088                 0.001531\n",
       "zipcode_zip_12103                 0.001500\n",
       "property_type_Secondary unit      0.001489\n",
       "zipcode_zip_10367                 0.001406\n",
       "zipcode_zip_14059                 0.001213\n",
       "zipcode_zip_10629                 0.001196\n",
       "zipcode_zip_10827                 0.001091\n",
       "zipcode_zip_10551                 0.000984\n",
       "zipcode_zip_14197                 0.000782\n",
       "zipcode_zip_12163                 0.000693\n",
       "zipcode_zip_10627                 0.000675\n",
       "zipcode_zip_10711                 0.000568\n",
       "zipcode_zip_10717                 0.000517\n",
       "zipcode_zip_13355                 0.000000\n",
       "zipcode_zip_10823                 0.000000\n",
       "zipcode_zip_10407                 0.000000\n",
       "zipcode_zip_10585                 0.000000\n",
       "zipcode_zip_10623                 0.000000\n",
       "zipcode_zip_10707                 0.000000\n",
       "zipcode_zip_10781                 0.000000\n",
       "cancellation_policy_super_strict  0.000000\n",
       "zipcode_zip_10829                 0.000000\n",
       "zipcode_zip_10625                 0.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_xgb_reg = get_feat_importances(best_model_xgb_reg)\n",
    "fi_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_xgb_reg = best_model_xgb_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09\n",
      "RMSE: 0.30\n",
      "MAE: 0.23\n",
      "R2: 0.74\n",
      "MAPE: 5.81\n",
      "MAPE median: 4.56\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_xgb_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_xgb_reg = best_model_xgb_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13\n",
      "RMSE: 0.36\n",
      "MAE: 0.27\n",
      "R2: 0.63\n",
      "MAPE: 6.78\n",
      "MAPE median: 5.18\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_xgb_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34298203, 0.37207619])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_xgb_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_xgb_reg = (median_absolute_percentage_error(y_test, y_test_pred_xgb_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67.34, 106.66),\n",
       " (56.01, 86.95),\n",
       " (41.73, 62.72),\n",
       " (29.38, 42.5),\n",
       " (56.9, 88.48),\n",
       " (33.12, 48.55),\n",
       " (37.71, 56.06),\n",
       " (72.91, 116.48),\n",
       " (92.31, 151.33),\n",
       " (39.06, 58.3),\n",
       " (61.6, 96.61),\n",
       " (44.24, 66.93),\n",
       " (35.15, 51.85),\n",
       " (138.36, 237.07),\n",
       " (34.38, 50.6),\n",
       " (44.02, 66.56),\n",
       " (40.47, 60.63),\n",
       " (123.6, 209.19),\n",
       " (26.51, 37.92),\n",
       " (62.74, 98.59),\n",
       " (66.59, 105.34),\n",
       " (64.94, 102.45),\n",
       " (24.13, 34.16),\n",
       " (71.73, 114.39),\n",
       " (45.55, 69.13),\n",
       " (41.77, 62.79),\n",
       " (72.45, 115.67),\n",
       " (76.33, 122.56),\n",
       " (69.91, 111.17),\n",
       " (46.95, 71.5),\n",
       " (101.6, 168.31),\n",
       " (33.31, 48.86),\n",
       " (35.2, 51.93),\n",
       " (30.72, 44.65),\n",
       " (55.24, 85.61),\n",
       " (131.94, 224.89),\n",
       " (34.53, 50.84),\n",
       " (41.61, 62.52),\n",
       " (26.27, 37.54),\n",
       " (34.61, 50.96),\n",
       " (48.91, 74.81),\n",
       " (40.71, 61.02),\n",
       " (56.73, 88.18),\n",
       " (23.73, 33.53),\n",
       " (74.45, 119.21),\n",
       " (50.95, 78.28),\n",
       " (128.08, 217.61),\n",
       " (110.23, 184.23),\n",
       " (24.41, 34.6),\n",
       " (34.05, 50.05),\n",
       " (50.35, 77.25),\n",
       " (59.33, 92.68),\n",
       " (83.86, 136.04),\n",
       " (68.16, 108.1),\n",
       " (17.73, 24.28),\n",
       " (52.49, 80.9),\n",
       " (115.39, 193.83),\n",
       " (37.34, 55.46),\n",
       " (62.56, 98.28),\n",
       " (45.65, 69.29),\n",
       " (57.81, 90.04),\n",
       " (57.23, 89.04),\n",
       " (187.62, 332.34),\n",
       " (25.49, 36.31),\n",
       " (100.52, 166.32),\n",
       " (66.94, 105.95),\n",
       " (83.93, 136.16),\n",
       " (31.95, 46.65),\n",
       " (28.28, 40.74),\n",
       " (29.08, 42.02),\n",
       " (42.5, 64.01),\n",
       " (51.98, 80.03),\n",
       " (33.14, 48.57),\n",
       " (49.08, 75.1),\n",
       " (27.02, 38.74),\n",
       " (56.67, 88.09),\n",
       " (38.05, 56.63),\n",
       " (74.52, 119.34),\n",
       " (32.26, 47.15),\n",
       " (37.97, 56.48),\n",
       " (44.16, 66.8),\n",
       " (24.21, 34.3),\n",
       " (33.95, 49.89),\n",
       " (46.85, 71.32),\n",
       " (51.55, 79.3),\n",
       " (32.23, 47.09),\n",
       " (65.77, 103.89),\n",
       " (94.21, 154.78),\n",
       " (26.38, 37.72),\n",
       " (33.4, 49.0),\n",
       " (93.4, 153.3),\n",
       " (41.47, 62.3),\n",
       " (60.34, 94.44),\n",
       " (29.04, 41.95),\n",
       " (77.68, 124.96),\n",
       " (55.04, 85.28),\n",
       " (57.38, 89.3),\n",
       " (32.47, 47.49),\n",
       " (54.91, 85.05),\n",
       " (53.49, 82.62),\n",
       " (60.63, 94.93),\n",
       " (38.84, 57.92),\n",
       " (41.87, 62.97),\n",
       " (313.56, 587.48),\n",
       " (59.44, 92.86),\n",
       " (51.85, 79.8),\n",
       " (92.15, 151.04),\n",
       " (85.6, 139.17),\n",
       " (48.25, 73.69),\n",
       " (204.68, 366.02),\n",
       " (43.32, 65.38),\n",
       " (32.0, 46.73),\n",
       " (28.47, 41.04),\n",
       " (35.12, 51.8),\n",
       " (29.91, 43.36),\n",
       " (81.47, 131.74),\n",
       " (40.5, 60.67),\n",
       " (31.23, 45.48),\n",
       " (75.39, 120.89),\n",
       " (32.94, 48.25),\n",
       " (64.31, 101.34),\n",
       " (44.26, 66.96),\n",
       " (56.89, 88.45),\n",
       " (35.65, 52.68),\n",
       " (54.05, 83.58),\n",
       " (31.18, 45.4),\n",
       " (47.75, 72.83),\n",
       " (48.16, 73.54),\n",
       " (41.32, 62.04),\n",
       " (51.15, 78.62),\n",
       " (37.7, 56.04),\n",
       " (97.22, 160.28),\n",
       " (39.38, 58.83),\n",
       " (42.38, 63.82),\n",
       " (42.86, 64.61),\n",
       " (23.48, 33.14),\n",
       " (32.41, 47.38),\n",
       " (58.44, 91.13),\n",
       " (33.79, 49.64),\n",
       " (55.62, 86.28),\n",
       " (32.82, 48.05),\n",
       " (114.43, 192.05),\n",
       " (34.23, 50.36),\n",
       " (32.93, 48.24),\n",
       " (50.72, 77.88),\n",
       " (38.56, 57.46),\n",
       " (54.99, 85.19),\n",
       " (138.41, 237.17),\n",
       " (36.0, 53.25),\n",
       " (39.79, 59.5),\n",
       " (87.96, 143.43),\n",
       " (22.06, 30.93),\n",
       " (65.6, 103.59),\n",
       " (33.1, 48.51),\n",
       " (26.13, 37.32),\n",
       " (27.97, 40.24),\n",
       " (57.49, 89.49),\n",
       " (22.68, 31.9),\n",
       " (22.34, 31.36),\n",
       " (46.95, 71.5),\n",
       " (99.71, 164.84),\n",
       " (42.74, 64.41),\n",
       " (46.96, 71.5),\n",
       " (46.64, 70.96),\n",
       " (26.3, 37.59),\n",
       " (69.44, 110.35),\n",
       " (35.04, 51.68),\n",
       " (30.82, 44.82),\n",
       " (53.52, 82.66),\n",
       " (46.4, 70.57),\n",
       " (68.26, 108.28),\n",
       " (50.83, 78.07),\n",
       " (61.05, 95.67),\n",
       " (44.66, 67.62),\n",
       " (36.46, 54.01),\n",
       " (50.97, 78.3),\n",
       " (42.32, 63.71),\n",
       " (24.65, 34.98),\n",
       " (71.59, 114.15),\n",
       " (67.13, 106.29),\n",
       " (62.14, 97.56),\n",
       " (24.89, 35.35),\n",
       " (50.45, 77.42),\n",
       " (44.4, 67.2),\n",
       " (91.2, 149.3),\n",
       " (173.78, 305.27),\n",
       " (57.77, 89.98),\n",
       " (74.65, 119.57),\n",
       " (30.15, 43.74),\n",
       " (27.83, 40.03),\n",
       " (111.78, 187.11),\n",
       " (57.23, 89.05),\n",
       " (48.42, 73.97),\n",
       " (25.9, 36.95),\n",
       " (49.54, 75.88),\n",
       " (48.46, 74.05),\n",
       " (40.88, 61.32),\n",
       " (60.45, 94.62),\n",
       " (142.46, 244.88),\n",
       " (38.73, 57.74),\n",
       " (105.38, 175.27),\n",
       " (62.18, 97.63),\n",
       " (59.94, 93.74),\n",
       " (54.76, 84.79),\n",
       " (65.11, 102.74),\n",
       " (57.45, 89.42),\n",
       " (31.97, 46.68),\n",
       " (42.61, 64.2),\n",
       " (45.66, 69.32),\n",
       " (58.39, 91.05),\n",
       " (48.6, 74.28),\n",
       " (33.43, 49.05),\n",
       " (24.69, 35.04),\n",
       " (89.49, 146.21),\n",
       " (57.36, 89.28),\n",
       " (56.14, 87.16),\n",
       " (37.12, 55.1),\n",
       " (30.78, 44.75),\n",
       " (22.16, 31.09),\n",
       " (51.44, 79.12),\n",
       " (78.08, 125.67),\n",
       " (36.56, 54.16),\n",
       " (33.84, 49.71),\n",
       " (63.71, 100.3),\n",
       " (24.14, 34.17),\n",
       " (48.25, 73.69),\n",
       " (29.38, 42.51),\n",
       " (48.71, 74.47),\n",
       " (48.13, 73.48),\n",
       " (59.68, 93.29),\n",
       " (48.24, 73.67),\n",
       " (29.26, 42.3),\n",
       " (27.86, 40.06),\n",
       " (57.09, 88.8),\n",
       " (56.33, 87.49),\n",
       " (25.3, 36.01),\n",
       " (115.75, 194.51),\n",
       " (39.74, 59.42),\n",
       " (45.12, 68.4),\n",
       " (32.15, 46.98),\n",
       " (116.67, 196.21),\n",
       " (57.57, 89.64),\n",
       " (47.65, 72.67),\n",
       " (59.48, 92.93),\n",
       " (50.04, 76.73),\n",
       " (13.87, 18.49),\n",
       " (60.53, 94.77),\n",
       " (27.27, 39.13),\n",
       " (28.93, 41.78),\n",
       " (61.12, 95.78),\n",
       " (132.19, 225.37),\n",
       " (63.34, 99.65),\n",
       " (18.99, 26.19),\n",
       " (59.33, 92.68),\n",
       " (40.23, 60.23),\n",
       " (39.56, 59.12),\n",
       " (76.02, 122.0),\n",
       " (56.29, 87.42),\n",
       " (40.06, 59.95),\n",
       " (24.76, 35.15),\n",
       " (74.08, 118.55),\n",
       " (34.4, 50.63),\n",
       " (26.57, 38.02),\n",
       " (175.31, 308.25),\n",
       " (38.38, 57.17),\n",
       " (32.18, 47.02),\n",
       " (30.45, 44.22),\n",
       " (26.99, 38.69),\n",
       " (51.41, 79.06),\n",
       " (58.43, 91.12),\n",
       " (59.67, 93.27),\n",
       " (31.82, 46.43),\n",
       " (27.4, 39.34),\n",
       " (93.51, 153.51),\n",
       " (40.13, 60.06),\n",
       " (50.01, 76.68),\n",
       " (41.3, 62.01),\n",
       " (29.75, 43.09),\n",
       " (55.66, 86.33),\n",
       " (94.82, 155.9),\n",
       " (95.27, 156.72),\n",
       " (58.91, 91.95),\n",
       " (36.74, 54.46),\n",
       " (52.09, 80.23),\n",
       " (107.75, 179.64),\n",
       " (44.83, 67.92),\n",
       " (37.76, 56.14),\n",
       " (101.19, 167.55),\n",
       " (61.15, 95.83),\n",
       " (31.16, 45.37),\n",
       " (26.66, 38.16),\n",
       " (90.79, 148.57),\n",
       " (28.78, 41.54),\n",
       " (31.77, 46.36),\n",
       " (95.49, 157.12),\n",
       " (116.32, 195.56),\n",
       " (81.54, 131.87),\n",
       " (39.27, 58.64),\n",
       " (84.86, 137.85),\n",
       " (113.53, 190.37),\n",
       " (41.19, 61.83),\n",
       " (84.29, 136.82),\n",
       " (36.94, 54.79),\n",
       " (26.42, 37.78),\n",
       " (56.27, 87.39),\n",
       " (30.67, 44.58),\n",
       " (37.31, 55.4),\n",
       " (25.33, 36.06),\n",
       " (54.79, 84.85),\n",
       " (24.28, 34.41),\n",
       " (62.91, 98.9),\n",
       " (27.98, 40.25),\n",
       " (132.82, 226.57),\n",
       " (92.95, 152.5),\n",
       " (63.34, 99.64),\n",
       " (33.27, 48.78),\n",
       " (109.2, 182.32),\n",
       " (26.55, 37.98),\n",
       " (43.51, 65.7),\n",
       " (44.97, 68.15),\n",
       " (89.12, 145.54),\n",
       " (58.92, 91.96),\n",
       " (12.79, 16.9),\n",
       " (74.75, 119.74),\n",
       " (14.94, 20.07),\n",
       " (85.37, 138.75),\n",
       " (52.96, 81.7),\n",
       " (38.44, 57.27),\n",
       " (33.88, 49.79),\n",
       " (26.96, 38.64),\n",
       " (98.64, 162.87),\n",
       " (37.66, 55.98),\n",
       " (59.13, 92.33),\n",
       " (54.3, 84.01),\n",
       " (35.69, 52.74),\n",
       " (18.61, 25.62),\n",
       " (28.78, 41.54),\n",
       " (39.16, 58.46),\n",
       " (27.81, 39.99),\n",
       " (58.16, 90.66),\n",
       " (22.53, 31.66),\n",
       " (110.78, 185.26),\n",
       " (16.09, 21.79),\n",
       " (52.43, 80.8),\n",
       " (54.09, 83.65),\n",
       " (47.63, 72.63),\n",
       " (38.77, 57.82),\n",
       " (32.72, 47.89),\n",
       " (39.11, 58.38),\n",
       " (56.94, 88.54),\n",
       " (30.8, 44.79),\n",
       " (83.33, 135.08),\n",
       " (27.19, 39.01),\n",
       " (31.53, 45.96),\n",
       " (30.71, 44.64),\n",
       " (53.39, 82.44),\n",
       " (37.53, 55.76),\n",
       " (56.03, 86.98),\n",
       " (58.54, 91.32),\n",
       " (32.85, 48.11),\n",
       " (122.85, 207.77),\n",
       " (36.7, 54.4),\n",
       " (184.85, 326.91),\n",
       " (30.54, 44.37),\n",
       " (64.49, 101.67),\n",
       " (53.54, 82.7),\n",
       " (70.27, 111.82),\n",
       " (66.33, 104.88),\n",
       " (73.79, 118.04),\n",
       " (26.63, 38.12),\n",
       " (59.07, 92.23),\n",
       " (59.4, 92.81),\n",
       " (73.63, 117.75),\n",
       " (39.61, 59.2),\n",
       " (30.47, 44.25),\n",
       " (152.37, 263.83),\n",
       " (115.41, 193.87),\n",
       " (30.72, 44.66),\n",
       " (23.86, 33.73),\n",
       " (92.13, 150.99),\n",
       " (32.73, 47.91),\n",
       " (120.77, 203.88),\n",
       " (36.49, 54.05),\n",
       " (42.34, 63.74),\n",
       " (28.72, 41.44),\n",
       " (54.65, 84.6),\n",
       " (35.28, 52.07),\n",
       " (28.73, 41.46),\n",
       " (34.69, 51.11),\n",
       " (67.58, 107.07),\n",
       " (36.76, 54.5),\n",
       " (50.26, 77.1),\n",
       " (70.56, 112.32),\n",
       " (27.26, 39.12),\n",
       " (54.23, 83.88),\n",
       " (110.12, 184.03),\n",
       " (31.03, 45.16),\n",
       " (93.1, 152.77),\n",
       " (57.63, 89.74),\n",
       " (61.06, 95.67),\n",
       " (21.85, 30.6),\n",
       " (30.56, 44.4),\n",
       " (84.19, 136.62),\n",
       " (38.65, 57.62),\n",
       " (38.16, 56.8),\n",
       " (39.86, 59.62),\n",
       " (20.42, 28.38),\n",
       " (90.98, 148.91),\n",
       " (28.14, 40.51),\n",
       " (46.69, 71.05),\n",
       " (114.43, 192.05),\n",
       " (66.85, 105.8),\n",
       " (50.45, 77.43),\n",
       " (21.16, 29.54),\n",
       " (31.54, 45.98),\n",
       " (64.2, 101.15),\n",
       " (63.62, 100.14),\n",
       " (111.67, 186.91),\n",
       " (82.78, 134.1),\n",
       " (34.32, 50.5),\n",
       " (58.82, 91.79),\n",
       " (49.48, 75.78),\n",
       " (70.76, 112.68),\n",
       " (67.56, 107.04),\n",
       " (45.71, 69.4),\n",
       " (29.34, 42.44),\n",
       " (33.85, 49.73),\n",
       " (42.59, 64.17),\n",
       " (68.04, 107.88),\n",
       " (66.52, 105.21),\n",
       " (62.42, 98.05),\n",
       " (102.62, 170.18),\n",
       " (72.96, 116.58),\n",
       " (183.72, 324.7),\n",
       " (53.9, 83.31),\n",
       " (52.67, 81.2),\n",
       " (34.96, 51.54),\n",
       " (58.51, 91.26),\n",
       " (32.47, 47.49),\n",
       " (68.16, 108.1),\n",
       " (29.56, 42.79),\n",
       " (59.7, 93.32),\n",
       " (24.13, 34.16),\n",
       " (55.29, 85.69),\n",
       " (60.78, 95.2),\n",
       " (34.0, 49.97),\n",
       " (39.86, 59.62),\n",
       " (46.05, 69.97),\n",
       " (28.53, 41.13),\n",
       " (37.43, 55.6),\n",
       " (42.94, 64.74),\n",
       " (92.0, 150.76),\n",
       " (36.08, 53.38),\n",
       " (26.37, 37.69),\n",
       " (34.92, 51.48),\n",
       " (70.72, 112.6),\n",
       " (28.07, 40.41),\n",
       " (32.66, 47.8),\n",
       " (77.31, 124.3),\n",
       " (27.3, 39.18),\n",
       " (74.47, 119.25),\n",
       " (60.89, 95.38),\n",
       " (45.92, 69.74),\n",
       " (57.01, 88.67),\n",
       " (121.34, 204.94),\n",
       " (36.0, 53.25),\n",
       " (32.4, 47.37),\n",
       " (30.84, 44.85),\n",
       " (53.36, 82.39),\n",
       " (52.44, 80.81),\n",
       " (99.31, 164.1),\n",
       " (44.93, 68.08),\n",
       " (96.94, 159.77),\n",
       " (31.45, 45.84),\n",
       " (61.52, 96.49),\n",
       " (59.53, 93.03),\n",
       " (77.94, 125.43),\n",
       " (30.46, 44.24),\n",
       " (37.05, 54.98),\n",
       " (31.17, 45.39),\n",
       " (40.0, 59.84),\n",
       " (44.74, 67.76),\n",
       " (60.4, 94.54),\n",
       " (64.35, 101.42),\n",
       " (28.56, 41.2),\n",
       " (57.59, 89.67),\n",
       " (28.94, 41.8),\n",
       " (70.18, 111.66),\n",
       " (31.91, 46.58),\n",
       " (56.89, 88.45),\n",
       " (66.49, 105.16),\n",
       " (53.0, 81.78),\n",
       " (34.23, 50.35),\n",
       " (56.69, 88.11),\n",
       " (47.27, 72.03),\n",
       " (35.33, 52.15),\n",
       " (68.95, 109.49),\n",
       " (55.98, 86.9),\n",
       " (42.82, 64.54),\n",
       " (91.76, 150.33),\n",
       " (39.55, 59.11),\n",
       " (23.73, 33.53),\n",
       " (47.27, 72.02),\n",
       " (44.43, 67.24),\n",
       " (72.29, 115.39),\n",
       " (36.61, 54.24),\n",
       " (44.97, 68.14),\n",
       " (26.75, 38.3),\n",
       " (31.82, 46.43),\n",
       " (74.21, 118.79),\n",
       " (63.96, 100.73),\n",
       " (33.11, 48.52),\n",
       " (44.12, 66.73),\n",
       " (51.69, 79.54),\n",
       " (154.84, 268.59),\n",
       " (21.64, 30.27),\n",
       " (42.53, 64.06),\n",
       " (33.01, 48.37),\n",
       " (29.84, 43.24),\n",
       " (120.14, 202.7),\n",
       " (44.71, 67.71),\n",
       " (35.97, 53.19),\n",
       " (64.84, 102.27),\n",
       " (25.53, 36.36),\n",
       " (32.75, 47.94),\n",
       " (34.6, 50.95),\n",
       " (51.48, 79.18),\n",
       " (40.07, 59.96),\n",
       " (24.19, 34.26),\n",
       " (34.43, 50.67),\n",
       " (47.29, 72.06),\n",
       " (43.31, 65.36),\n",
       " (60.18, 94.15),\n",
       " (27.56, 39.6),\n",
       " (56.95, 88.56),\n",
       " (112.66, 188.75),\n",
       " (46.38, 70.53),\n",
       " (28.08, 40.42),\n",
       " (40.95, 61.43),\n",
       " (87.73, 143.01),\n",
       " (29.88, 43.3),\n",
       " (77.94, 125.43),\n",
       " (63.96, 100.73),\n",
       " (30.74, 44.69),\n",
       " (90.18, 147.46),\n",
       " (30.45, 44.22),\n",
       " (31.47, 45.87),\n",
       " (28.49, 41.07),\n",
       " (87.76, 143.08),\n",
       " (51.39, 79.02),\n",
       " (116.59, 196.07),\n",
       " (87.72, 143.0),\n",
       " (53.21, 82.13),\n",
       " (56.7, 88.13),\n",
       " (33.75, 49.58),\n",
       " (26.36, 37.69),\n",
       " (56.83, 88.35),\n",
       " (33.7, 49.49),\n",
       " (30.45, 44.23),\n",
       " (33.95, 49.9),\n",
       " (37.22, 55.24),\n",
       " (47.0, 71.58),\n",
       " (105.42, 175.35),\n",
       " (53.08, 81.91),\n",
       " (150.75, 260.73),\n",
       " (62.58, 98.32),\n",
       " (48.81, 74.63),\n",
       " (59.06, 92.21),\n",
       " (45.87, 69.66),\n",
       " (38.87, 57.97),\n",
       " (78.48, 126.4),\n",
       " (49.65, 76.06),\n",
       " (35.79, 52.9),\n",
       " (33.21, 48.69),\n",
       " (39.07, 58.3),\n",
       " (38.45, 57.28),\n",
       " (130.82, 222.78),\n",
       " (27.2, 39.01),\n",
       " (53.19, 82.1),\n",
       " (96.08, 158.2),\n",
       " (57.28, 89.14),\n",
       " (24.28, 34.4),\n",
       " (66.97, 106.01),\n",
       " (28.82, 41.61),\n",
       " (35.46, 52.37),\n",
       " (53.39, 82.44),\n",
       " (69.05, 109.67),\n",
       " (34.41, 50.64),\n",
       " (50.05, 76.74),\n",
       " (96.24, 158.5),\n",
       " (45.91, 69.74),\n",
       " (26.46, 37.84),\n",
       " (38.21, 56.89),\n",
       " (61.24, 95.99),\n",
       " (58.73, 91.64),\n",
       " (67.18, 106.37),\n",
       " (57.37, 89.28),\n",
       " (55.05, 85.29),\n",
       " (42.46, 63.95),\n",
       " (92.49, 151.66),\n",
       " (52.85, 81.51),\n",
       " (36.76, 54.49),\n",
       " (41.24, 61.92),\n",
       " (20.46, 28.45),\n",
       " (58.27, 90.84),\n",
       " (59.08, 92.25),\n",
       " (47.78, 72.89),\n",
       " (263.97, 485.35),\n",
       " (22.68, 31.9),\n",
       " (76.36, 122.61),\n",
       " (52.25, 80.49),\n",
       " (48.08, 73.4),\n",
       " (41.29, 62.0),\n",
       " (35.48, 52.4),\n",
       " (45.31, 68.73),\n",
       " (32.85, 48.11),\n",
       " (22.85, 32.16),\n",
       " (25.37, 36.12),\n",
       " (24.85, 35.3),\n",
       " (80.83, 130.6),\n",
       " (46.9, 71.41),\n",
       " (69.53, 110.5),\n",
       " (43.37, 65.46),\n",
       " (61.09, 95.73),\n",
       " (64.08, 100.94),\n",
       " (37.17, 55.18),\n",
       " (106.74, 177.78),\n",
       " (23.51, 33.2),\n",
       " (92.38, 151.45),\n",
       " (44.62, 67.56),\n",
       " (42.79, 64.5),\n",
       " (38.56, 57.47),\n",
       " (103.26, 171.36),\n",
       " (75.97, 121.92),\n",
       " (59.6, 93.14),\n",
       " (56.02, 86.96),\n",
       " (87.52, 142.65),\n",
       " (30.55, 44.39),\n",
       " (46.25, 70.3),\n",
       " (30.67, 44.58),\n",
       " (64.56, 101.78),\n",
       " (60.0, 93.84),\n",
       " (59.3, 92.62),\n",
       " (41.51, 62.36),\n",
       " (32.49, 47.52),\n",
       " (27.68, 39.78),\n",
       " (31.41, 45.77),\n",
       " (23.0, 32.4),\n",
       " (34.43, 50.68),\n",
       " (34.72, 51.15),\n",
       " (100.47, 166.24),\n",
       " (45.03, 68.25),\n",
       " (49.53, 75.85),\n",
       " (67.42, 106.79),\n",
       " (160.06, 278.65),\n",
       " (19.53, 27.02),\n",
       " (58.3, 90.89),\n",
       " (32.23, 47.1),\n",
       " (42.51, 64.02),\n",
       " (33.34, 48.9),\n",
       " (33.69, 49.47),\n",
       " (66.34, 104.9),\n",
       " (27.99, 40.28),\n",
       " (29.14, 42.12),\n",
       " (54.19, 83.81),\n",
       " (37.27, 55.33),\n",
       " (61.31, 96.1),\n",
       " (69.93, 111.21),\n",
       " (47.64, 72.65),\n",
       " (59.66, 93.25),\n",
       " (103.77, 172.3),\n",
       " (32.71, 47.88),\n",
       " (25.23, 35.9),\n",
       " (80.02, 129.15),\n",
       " (47.58, 72.55),\n",
       " (77.96, 125.47),\n",
       " (36.38, 53.86),\n",
       " (54.03, 83.54),\n",
       " (56.55, 87.88),\n",
       " (62.4, 98.02),\n",
       " (110.96, 185.59),\n",
       " (59.85, 93.58),\n",
       " (77.93, 125.4),\n",
       " (65.55, 103.51),\n",
       " (29.81, 43.19),\n",
       " (60.12, 94.04),\n",
       " (30.01, 43.52),\n",
       " (59.82, 93.53),\n",
       " (27.1, 38.86),\n",
       " (27.82, 40.0),\n",
       " (49.07, 75.08),\n",
       " (52.01, 80.07),\n",
       " (59.22, 92.48),\n",
       " (168.34, 294.67),\n",
       " (82.7, 133.96),\n",
       " (29.42, 42.57),\n",
       " (33.72, 49.52),\n",
       " (37.77, 56.16),\n",
       " (99.83, 165.06),\n",
       " (36.31, 53.75),\n",
       " (56.66, 88.06),\n",
       " (38.68, 57.66),\n",
       " (74.07, 118.55),\n",
       " (86.49, 140.78),\n",
       " (36.09, 53.4),\n",
       " (50.44, 77.41),\n",
       " (96.27, 158.53),\n",
       " (67.93, 107.69),\n",
       " (73.21, 117.01),\n",
       " (100.95, 167.11),\n",
       " (35.3, 52.1),\n",
       " (116.03, 195.02),\n",
       " (34.39, 50.62),\n",
       " (55.18, 85.52),\n",
       " (87.25, 142.15),\n",
       " (54.9, 85.03),\n",
       " (34.39, 50.61),\n",
       " (32.36, 47.31),\n",
       " (52.92, 81.64),\n",
       " (28.99, 41.87),\n",
       " (30.67, 44.57),\n",
       " (34.15, 50.23),\n",
       " (119.25, 201.02),\n",
       " (36.02, 53.27),\n",
       " (83.08, 134.64),\n",
       " (55.09, 85.35),\n",
       " (59.06, 92.21),\n",
       " (25.42, 36.19),\n",
       " (47.17, 71.85),\n",
       " (68.84, 109.29),\n",
       " (38.04, 56.6),\n",
       " (112.23, 187.96),\n",
       " (61.04, 95.65),\n",
       " (104.57, 173.77),\n",
       " (60.38, 94.5),\n",
       " (50.94, 78.26),\n",
       " (37.14, 55.13),\n",
       " (147.97, 255.4),\n",
       " (123.54, 209.07),\n",
       " (57.93, 90.26),\n",
       " (30.6, 44.46),\n",
       " (27.54, 39.57),\n",
       " (43.81, 66.21),\n",
       " (25.72, 36.67),\n",
       " (22.61, 31.79),\n",
       " (44.27, 66.98),\n",
       " (29.26, 42.3),\n",
       " (45.71, 69.4),\n",
       " (54.63, 84.57),\n",
       " (35.19, 51.91),\n",
       " (47.9, 73.1),\n",
       " (35.76, 52.86),\n",
       " (62.99, 99.04),\n",
       " (43.76, 66.12),\n",
       " (35.77, 52.87),\n",
       " (46.8, 71.23),\n",
       " (27.13, 38.91),\n",
       " (29.47, 42.65),\n",
       " (60.1, 94.01),\n",
       " (24.73, 35.1),\n",
       " (44.55, 67.45),\n",
       " (36.32, 53.77),\n",
       " (34.45, 50.71),\n",
       " (116.67, 196.21),\n",
       " (48.0, 73.26),\n",
       " (26.22, 37.47),\n",
       " (42.77, 64.45),\n",
       " (54.02, 83.53),\n",
       " (94.86, 155.98),\n",
       " (92.73, 152.09),\n",
       " (50.33, 77.22),\n",
       " (30.53, 44.35),\n",
       " (37.58, 55.84),\n",
       " (94.64, 155.57),\n",
       " (47.64, 72.65),\n",
       " (55.94, 86.82),\n",
       " (68.87, 109.34),\n",
       " (125.25, 212.29),\n",
       " (35.69, 52.74),\n",
       " (52.96, 81.7),\n",
       " (59.26, 92.56),\n",
       " (40.87, 61.29),\n",
       " (27.62, 39.69),\n",
       " (58.15, 90.64),\n",
       " (71.52, 114.03),\n",
       " (55.0, 85.21),\n",
       " (38.04, 56.6),\n",
       " (26.33, 37.63),\n",
       " (22.7, 31.92),\n",
       " (49.09, 75.11),\n",
       " (50.52, 77.55),\n",
       " (53.39, 82.45),\n",
       " (49.42, 75.67),\n",
       " (48.66, 74.38),\n",
       " (23.72, 33.52),\n",
       " (30.36, 44.08),\n",
       " (38.91, 58.05),\n",
       " (31.35, 45.67),\n",
       " (101.54, 168.19),\n",
       " (30.56, 44.4),\n",
       " (25.73, 36.68),\n",
       " (23.93, 33.85),\n",
       " (30.34, 44.05),\n",
       " (63.23, 99.45),\n",
       " (64.15, 101.07),\n",
       " (41.51, 62.35),\n",
       " (67.88, 107.59),\n",
       " (37.01, 54.91),\n",
       " (194.82, 346.51),\n",
       " (20.32, 28.24),\n",
       " (47.52, 72.45),\n",
       " (53.22, 82.15),\n",
       " (125.46, 212.67),\n",
       " (26.24, 37.5),\n",
       " (87.83, 143.21),\n",
       " (57.53, 89.57),\n",
       " (27.48, 39.46),\n",
       " (51.36, 78.97),\n",
       " (29.54, 42.76),\n",
       " (36.71, 54.42),\n",
       " (50.65, 77.76),\n",
       " (28.47, 41.04),\n",
       " (61.19, 95.91),\n",
       " (51.36, 78.97),\n",
       " (148.46, 256.34),\n",
       " (33.1, 48.51),\n",
       " (52.55, 81.01),\n",
       " (59.75, 93.41),\n",
       " (50.61, 77.69),\n",
       " (37.99, 56.52),\n",
       " (33.98, 49.95),\n",
       " (54.64, 84.58),\n",
       " (87.38, 142.39),\n",
       " (30.12, 43.69),\n",
       " (39.11, 58.38),\n",
       " (31.7, 46.23),\n",
       " (75.95, 121.87),\n",
       " (26.15, 37.36),\n",
       " (39.82, 59.55),\n",
       " (31.52, 45.94),\n",
       " (56.61, 87.98),\n",
       " (50.34, 77.24),\n",
       " (96.5, 158.96),\n",
       " (48.7, 74.44),\n",
       " (55.89, 86.74),\n",
       " (220.37, 397.28),\n",
       " (69.78, 110.94),\n",
       " (48.31, 73.79),\n",
       " (47.65, 72.66),\n",
       " (50.23, 77.04),\n",
       " (32.11, 46.9),\n",
       " (52.32, 80.61),\n",
       " (88.01, 143.52),\n",
       " (52.55, 81.0),\n",
       " (52.1, 80.23),\n",
       " (73.72, 117.93),\n",
       " (103.72, 172.2),\n",
       " (56.17, 87.21),\n",
       " (54.0, 83.49),\n",
       " (26.79, 38.37),\n",
       " (32.7, 47.86),\n",
       " (54.86, 84.96),\n",
       " (35.04, 51.68),\n",
       " (49.1, 75.12),\n",
       " (24.85, 35.3),\n",
       " (27.47, 39.44),\n",
       " (98.63, 162.86),\n",
       " (50.75, 77.93),\n",
       " (59.34, 92.7),\n",
       " (28.02, 40.32),\n",
       " (26.46, 37.84),\n",
       " (102.71, 170.35),\n",
       " (35.43, 52.32),\n",
       " (70.48, 112.18),\n",
       " (26.26, 37.52),\n",
       " (64.14, 101.05),\n",
       " (38.4, 57.19),\n",
       " (43.42, 65.55),\n",
       " (48.44, 74.01),\n",
       " (149.37, 258.08),\n",
       " (61.25, 96.0),\n",
       " (87.55, 142.69),\n",
       " (65.31, 103.09),\n",
       " (34.67, 51.07),\n",
       " (72.63, 115.98),\n",
       " (34.92, 51.47),\n",
       " (29.14, 42.12),\n",
       " (100.04, 165.44),\n",
       " (44.3, 67.02),\n",
       " (35.43, 52.31),\n",
       " (44.61, 67.55),\n",
       " (32.25, 47.13),\n",
       " (41.34, 62.08),\n",
       " (73.15, 116.91),\n",
       " (51.57, 79.34),\n",
       " (57.2, 89.0),\n",
       " (114.38, 191.94),\n",
       " (183.7, 324.66),\n",
       " (61.37, 96.23),\n",
       " (86.28, 140.4),\n",
       " (35.89, 53.07),\n",
       " (34.51, 50.81),\n",
       " (92.65, 151.95),\n",
       " (56.35, 87.52),\n",
       " (26.65, 38.14),\n",
       " (43.44, 65.58),\n",
       " (39.99, 59.83),\n",
       " (34.13, 50.19),\n",
       " (66.56, 105.28),\n",
       " (68.91, 109.42),\n",
       " (65.79, 103.93),\n",
       " (77.27, 124.22),\n",
       " (65.38, 103.21),\n",
       " (85.52, 139.03),\n",
       " (41.9, 63.0),\n",
       " (42.14, 63.41),\n",
       " (19.73, 27.33),\n",
       " (58.8, 91.76),\n",
       " (36.56, 54.17),\n",
       " (38.52, 57.4),\n",
       " (31.87, 46.52),\n",
       " (28.84, 41.63),\n",
       " (27.29, 39.17),\n",
       " (25.19, 35.83),\n",
       " (58.22, 90.75),\n",
       " (31.72, 46.27),\n",
       " (33.52, 49.19),\n",
       " (47.91, 73.11),\n",
       " (17.19, 23.46),\n",
       " (30.28, 43.94),\n",
       " (51.81, 79.73),\n",
       " (30.83, 44.84),\n",
       " (110.38, 184.51),\n",
       " (72.21, 115.23),\n",
       " (146.08, 251.79),\n",
       " (55.97, 86.86),\n",
       " (60.17, 94.13),\n",
       " (45.92, 69.76),\n",
       " (41.47, 62.29),\n",
       " (50.33, 77.23),\n",
       " (78.09, 125.7),\n",
       " (59.38, 92.77),\n",
       " (29.14, 42.12),\n",
       " (34.98, 51.57),\n",
       " (46.81, 71.24),\n",
       " (52.06, 80.17),\n",
       " (42.92, 64.72),\n",
       " (36.78, 54.53),\n",
       " (31.94, 46.63),\n",
       " (69.68, 110.77),\n",
       " (47.68, 72.71),\n",
       " (50.8, 78.01),\n",
       " (22.93, 32.29),\n",
       " (68.88, 109.36),\n",
       " (105.11, 174.76),\n",
       " (43.96, 66.45),\n",
       " (24.26, 34.37),\n",
       " (28.65, 41.33),\n",
       " (31.78, 46.37),\n",
       " (26.8, 38.38),\n",
       " (44.26, 66.95),\n",
       " (145.96, 251.56),\n",
       " (23.97, 33.92),\n",
       " (69.0, 109.57),\n",
       " (15.8, 21.36),\n",
       " (50.82, 78.05),\n",
       " (24.98, 35.5),\n",
       " (27.75, 39.89),\n",
       " (43.92, 66.38),\n",
       " (27.44, 39.4),\n",
       " (65.11, 102.74),\n",
       " (21.77, 30.47),\n",
       " (31.61, 46.09),\n",
       " (50.49, 77.49),\n",
       " (33.7, 49.48),\n",
       " (55.71, 86.43),\n",
       " (23.84, 33.71),\n",
       " (43.47, 65.63),\n",
       " (26.1, 37.28),\n",
       " (41.95, 63.09),\n",
       " (25.29, 36.0),\n",
       " (57.38, 89.3),\n",
       " (80.01, 129.12),\n",
       " (38.89, 58.01),\n",
       " (120.16, 202.74),\n",
       " (26.39, 37.74),\n",
       " (23.45, 33.09),\n",
       " (64.2, 101.15),\n",
       " (76.51, 122.88),\n",
       " (27.86, 40.07),\n",
       " (61.5, 96.45),\n",
       " (42.72, 64.38),\n",
       " (35.55, 52.51),\n",
       " (118.61, 199.83),\n",
       " (56.41, 87.63),\n",
       " (33.08, 48.48),\n",
       " (96.07, 158.18),\n",
       " (31.41, 45.78),\n",
       " (54.39, 84.15),\n",
       " (46.34, 70.47),\n",
       " ...)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_xgb_reg = tuple([(round(math.exp(el-el*MAPE_median_xgb_reg),2),round(math.exp(el+el*MAPE_median_xgb_reg),2)) for el in y_test_pred_xgb_reg])\n",
    "y_pred_interval_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_xgb_reg, title=\"best_model_xgb_reg_02\", save=\"joblib\")\n",
    "save_model(grid_xgb_reg, title=\"best_cv_xgb_reg_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 2: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_svm_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('svm_reg',\n",
    "                              SVR(kernel='rbf',\n",
    "                                  C=50,\n",
    "                                  degree=4,\n",
    "                                  gamma=0.005,\n",
    "                                  epsilon=0.3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for Support Vector Machine\n",
    "test_svr_reg = SVR()\n",
    "test_svr_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Support Vector Machine** (as base for hyperparameter search):\n",
    "\n",
    "kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_svm_reg = {\n",
    "#    'svm_reg__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm_reg__C': [0.1, 0.5, 0.8, 1, 1.5, 2, 3, 5, 10, 50, 100],        # initial: [0.1, 0.5, 1, 2, 5, 10, 50, 100, 500, 1000]\n",
    "    'svm_reg__gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1],   # initial: [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 1]\n",
    "    'svm_reg__epsilon': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.9],            # initial: [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.9]\n",
    "    'svm_reg__degree': randint(low=1, high=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   26.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_svm_reg = RandomizedSearchCV(pipeline_svm_reg,\n",
    "                                 param_distribs_svm_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=10,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_svm_reg = rnd_svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.22\n",
      "Best parameters:\n",
      "{'svm_reg__C': 50, 'svm_reg__degree': 4, 'svm_reg__epsilon': 0.3, 'svm_reg__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_svm_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_svm_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_svm_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_svm_reg = {\n",
    "#    'svm_reg__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm_reg__gamma': [0.003, 0.005, 0.007],\n",
    "    'svm_reg__C': [40, 50, 60],\n",
    "    'svm_reg__degree': [3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   31.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_svm_reg = GridSearchCV(pipeline_svm_reg,\n",
    "                            param_grid_svm_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_svm_reg = grid_svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_svm_reg = grid_svm_reg.best_estimator_[\"svm_reg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.22\n",
      "Best parameters:\n",
      "{'svm_reg__C': 50, 'svm_reg__degree': 3, 'svm_reg__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_svm_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_svm_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_svm_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "#fi_svm_reg = get_feat_importances(best_model_svm_reg)\n",
    "#fi_svm_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_svm_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_svm_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_svm_reg = best_model_svm_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09\n",
      "RMSE: 0.31\n",
      "MAE: 0.24\n",
      "R2: 0.73\n",
      "MAPE: 6.10\n",
      "MAPE median: 5.43\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_svm_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_svm_reg = best_model_svm_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13\n",
      "RMSE: 0.36\n",
      "MAE: 0.27\n",
      "R2: 0.64\n",
      "MAPE: 6.81\n",
      "MAPE median: 5.33\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_svm_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34191936, 0.36906891])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_svm_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_svm_reg = (median_absolute_percentage_error(y_test, y_test_pred_svm_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70.78, 114.35),\n",
       " (53.15, 83.13),\n",
       " (40.03, 60.64),\n",
       " (32.39, 47.92),\n",
       " (54.4, 85.32),\n",
       " (35.24, 52.63),\n",
       " (40.94, 62.19),\n",
       " (89.25, 148.0),\n",
       " (108.69, 184.27),\n",
       " (37.11, 55.74),\n",
       " (51.95, 81.05),\n",
       " (53.21, 83.25),\n",
       " (36.17, 54.18),\n",
       " (120.27, 206.23),\n",
       " (35.64, 53.29),\n",
       " (62.12, 98.89),\n",
       " (34.2, 50.9),\n",
       " (112.62, 191.7),\n",
       " (24.49, 35.11),\n",
       " (64.86, 103.76),\n",
       " (82.26, 135.16),\n",
       " (51.58, 80.41),\n",
       " (27.05, 39.21),\n",
       " (63.41, 101.18),\n",
       " (36.54, 54.79),\n",
       " (40.69, 61.75),\n",
       " (77.7, 126.85),\n",
       " (83.29, 137.05),\n",
       " (67.83, 109.05),\n",
       " (43.07, 65.79),\n",
       " (74.43, 120.93),\n",
       " (32.47, 48.05),\n",
       " (35.69, 53.38),\n",
       " (31.79, 46.93),\n",
       " (56.51, 89.01),\n",
       " (143.54, 251.1),\n",
       " (31.36, 46.22),\n",
       " (39.16, 59.18),\n",
       " (24.67, 35.4),\n",
       " (33.29, 49.41),\n",
       " (43.14, 65.91),\n",
       " (41.17, 62.57),\n",
       " (48.8, 75.6),\n",
       " (25.84, 37.27),\n",
       " (82.56, 135.7),\n",
       " (53.87, 84.39),\n",
       " (115.69, 197.51),\n",
       " (103.1, 173.75),\n",
       " (22.71, 32.28),\n",
       " (35.07, 52.35),\n",
       " (49.66, 77.08),\n",
       " (45.35, 69.68),\n",
       " (77.99, 127.37),\n",
       " (49.34, 76.53),\n",
       " (22.45, 31.88),\n",
       " (60.56, 96.13),\n",
       " (108.07, 183.1),\n",
       " (42.47, 64.78),\n",
       " (65.98, 105.75),\n",
       " (43.64, 66.76),\n",
       " (60.12, 95.36),\n",
       " (64.25, 102.66),\n",
       " (257.38, 480.84),\n",
       " (23.22, 33.08),\n",
       " (106.42, 180.0),\n",
       " (63.38, 101.12),\n",
       " (70.83, 114.44),\n",
       " (31.05, 45.72),\n",
       " (31.68, 46.75),\n",
       " (34.0, 50.58),\n",
       " (47.94, 74.13),\n",
       " (43.9, 67.21),\n",
       " (45.38, 69.73),\n",
       " (58.23, 92.03),\n",
       " (25.75, 37.12),\n",
       " (49.77, 77.28),\n",
       " (37.74, 56.8),\n",
       " (60.92, 96.77),\n",
       " (30.88, 45.44),\n",
       " (34.76, 51.84),\n",
       " (44.29, 67.87),\n",
       " (23.49, 33.52),\n",
       " (36.34, 54.46),\n",
       " (53.37, 83.52),\n",
       " (44.15, 67.64),\n",
       " (31.64, 46.68),\n",
       " (75.38, 122.63),\n",
       " (86.13, 142.25),\n",
       " (32.13, 47.49),\n",
       " (30.47, 44.76),\n",
       " (98.52, 165.2),\n",
       " (43.11, 65.85),\n",
       " (62.31, 99.23),\n",
       " (27.54, 40.0),\n",
       " (66.18, 106.1),\n",
       " (56.38, 88.78),\n",
       " (55.95, 88.02),\n",
       " (40.2, 60.93),\n",
       " (50.98, 79.37),\n",
       " (55.8, 87.76),\n",
       " (57.22, 90.25),\n",
       " (37.87, 57.01),\n",
       " (41.13, 62.5),\n",
       " (249.05, 463.56),\n",
       " (63.35, 101.08),\n",
       " (58.95, 93.29),\n",
       " (78.8, 128.85),\n",
       " (78.11, 127.59),\n",
       " (47.95, 74.14),\n",
       " (138.08, 240.5),\n",
       " (40.15, 60.86),\n",
       " (28.23, 41.12),\n",
       " (27.28, 39.59),\n",
       " (33.26, 49.35),\n",
       " (29.29, 42.85),\n",
       " (66.04, 105.86),\n",
       " (39.14, 59.15),\n",
       " (34.37, 51.19),\n",
       " (79.4, 129.95),\n",
       " (30.04, 44.06),\n",
       " (54.09, 84.77),\n",
       " (51.36, 80.03),\n",
       " (61.73, 98.2),\n",
       " (33.69, 50.07),\n",
       " (47.6, 73.53),\n",
       " (33.73, 50.12),\n",
       " (45.07, 69.21),\n",
       " (47.79, 73.86),\n",
       " (39.92, 60.46),\n",
       " (53.69, 84.08),\n",
       " (43.23, 66.07),\n",
       " (86.26, 142.49),\n",
       " (38.7, 58.41),\n",
       " (35.86, 53.66),\n",
       " (42.55, 64.91),\n",
       " (23.12, 32.93),\n",
       " (32.56, 48.19),\n",
       " (54.71, 85.85),\n",
       " (31.31, 46.14),\n",
       " (49.88, 77.47),\n",
       " (28.78, 42.01),\n",
       " (95.87, 160.25),\n",
       " (41.11, 62.47),\n",
       " (35.21, 52.58),\n",
       " (47.16, 72.77),\n",
       " (50.3, 78.2),\n",
       " (51.62, 80.47),\n",
       " (137.17, 238.74),\n",
       " (36.97, 55.52),\n",
       " (39.81, 60.28),\n",
       " (100.26, 168.44),\n",
       " (23.57, 33.65),\n",
       " (58.93, 93.25),\n",
       " (33.95, 50.48),\n",
       " (25.95, 37.44),\n",
       " (32.66, 48.37),\n",
       " (64.87, 103.77),\n",
       " (23.51, 33.55),\n",
       " (30.93, 45.52),\n",
       " (47.15, 72.77),\n",
       " (80.97, 132.8),\n",
       " (41.81, 63.65),\n",
       " (45.03, 69.13),\n",
       " (48.27, 74.69),\n",
       " (25.58, 36.85),\n",
       " (72.23, 116.95),\n",
       " (34.52, 51.44),\n",
       " (26.41, 38.18),\n",
       " (61.08, 97.05),\n",
       " (44.91, 68.92),\n",
       " (71.72, 116.03),\n",
       " (50.16, 77.95),\n",
       " (59.02, 93.42),\n",
       " (43.86, 67.13),\n",
       " (36.05, 53.97),\n",
       " (52.72, 82.39),\n",
       " (52.83, 82.59),\n",
       " (25.83, 37.25),\n",
       " (71.56, 115.75),\n",
       " (67.38, 108.25),\n",
       " (63.21, 100.82),\n",
       " (26.13, 37.74),\n",
       " (48.04, 74.3),\n",
       " (54.73, 85.9),\n",
       " (78.06, 127.51),\n",
       " (191.82, 346.69),\n",
       " (59.8, 94.79),\n",
       " (81.52, 133.8),\n",
       " (32.08, 47.41),\n",
       " (27.32, 39.65),\n",
       " (118.52, 202.9),\n",
       " (51.86, 80.9),\n",
       " (43.23, 66.06),\n",
       " (24.6, 35.28),\n",
       " (48.0, 74.23),\n",
       " (43.5, 66.53),\n",
       " (41.46, 63.05),\n",
       " (51.99, 81.12),\n",
       " (143.93, 251.86),\n",
       " (41.74, 63.53),\n",
       " (93.41, 155.69),\n",
       " (61.06, 97.01),\n",
       " (62.07, 98.81),\n",
       " (54.21, 84.98),\n",
       " (62.02, 98.72),\n",
       " (62.27, 99.15),\n",
       " (35.17, 52.52),\n",
       " (51.25, 79.84),\n",
       " (38.61, 58.26),\n",
       " (61.1, 97.09),\n",
       " (57.66, 91.01),\n",
       " (32.5, 48.1),\n",
       " (31.53, 46.5),\n",
       " (104.75, 176.85),\n",
       " (52.48, 81.98),\n",
       " (55.59, 87.38),\n",
       " (30.52, 44.85),\n",
       " (29.7, 43.52),\n",
       " (28.28, 41.19),\n",
       " (50.32, 78.23),\n",
       " (81.34, 133.48),\n",
       " (47.38, 73.16),\n",
       " (42.17, 64.27),\n",
       " (65.22, 104.4),\n",
       " (25.26, 36.34),\n",
       " (46.71, 72.01),\n",
       " (29.44, 43.08),\n",
       " (52.36, 81.75),\n",
       " (52.43, 81.88),\n",
       " (56.07, 88.24),\n",
       " (52.56, 82.1),\n",
       " (27.87, 40.54),\n",
       " (28.43, 41.45),\n",
       " (67.72, 108.85),\n",
       " (58.35, 92.24),\n",
       " (26.28, 37.97),\n",
       " (83.48, 137.39),\n",
       " (36.45, 54.64),\n",
       " (44.99, 69.07),\n",
       " (24.32, 34.83),\n",
       " (105.06, 177.44),\n",
       " (52.8, 82.53),\n",
       " (50.25, 78.11),\n",
       " (60.18, 95.46),\n",
       " (58.12, 91.83),\n",
       " (16.36, 22.42),\n",
       " (71.07, 114.86),\n",
       " (28.03, 40.8),\n",
       " (36.28, 54.36),\n",
       " (56.23, 88.51),\n",
       " (122.51, 210.53),\n",
       " (55.57, 87.36),\n",
       " (22.96, 32.67),\n",
       " (58.17, 91.93),\n",
       " (39.24, 59.32),\n",
       " (41.88, 63.78),\n",
       " (91.36, 151.9),\n",
       " (58.87, 93.14),\n",
       " (35.43, 52.94),\n",
       " (25.55, 36.8),\n",
       " (81.34, 133.48),\n",
       " (36.01, 53.9),\n",
       " (24.81, 35.62),\n",
       " (176.91, 316.84),\n",
       " (30.76, 45.25),\n",
       " (29.48, 43.15),\n",
       " (23.16, 32.99),\n",
       " (30.59, 44.97),\n",
       " (53.74, 84.17),\n",
       " (48.99, 75.94),\n",
       " (66.39, 106.48),\n",
       " (28.94, 42.28),\n",
       " (25.72, 37.07),\n",
       " (83.84, 138.05),\n",
       " (41.92, 63.84),\n",
       " (54.14, 84.86),\n",
       " (42.52, 64.86),\n",
       " (25.43, 36.61),\n",
       " (45.37, 69.71),\n",
       " (67.26, 108.02),\n",
       " (76.89, 125.38),\n",
       " (80.99, 132.83),\n",
       " (36.56, 54.83),\n",
       " (55.85, 87.85),\n",
       " (80.98, 132.82),\n",
       " (45.54, 70.0),\n",
       " (41.29, 62.78),\n",
       " (108.16, 183.28),\n",
       " (92.01, 153.1),\n",
       " (29.33, 42.91),\n",
       " (26.54, 38.39),\n",
       " (70.87, 114.5),\n",
       " (31.39, 46.27),\n",
       " (36.75, 55.15),\n",
       " (81.79, 134.29),\n",
       " (111.3, 189.21),\n",
       " (82.01, 134.7),\n",
       " (43.36, 66.29),\n",
       " (80.37, 131.71),\n",
       " (100.73, 169.32),\n",
       " (35.46, 53.0),\n",
       " (84.53, 139.32),\n",
       " (37.62, 56.59),\n",
       " (27.86, 40.53),\n",
       " (59.53, 94.31),\n",
       " (27.26, 39.56),\n",
       " (35.39, 52.88),\n",
       " (26.77, 38.76),\n",
       " (50.7, 78.89),\n",
       " (25.53, 36.77),\n",
       " (68.48, 110.22),\n",
       " (25.4, 36.57),\n",
       " (134.99, 234.51),\n",
       " (77.33, 126.18),\n",
       " (57.14, 90.11),\n",
       " (32.79, 48.57),\n",
       " (96.02, 160.54),\n",
       " (23.68, 33.81),\n",
       " (46.86, 72.26),\n",
       " (49.12, 76.15),\n",
       " (87.14, 144.1),\n",
       " (54.31, 85.15),\n",
       " (12.6, 16.76),\n",
       " (63.58, 101.47),\n",
       " (22.06, 31.26),\n",
       " (86.23, 142.42),\n",
       " (57.07, 89.98),\n",
       " (23.88, 34.14),\n",
       " (29.86, 43.77),\n",
       " (25.88, 37.33),\n",
       " (86.54, 143.01),\n",
       " (39.29, 59.4),\n",
       " (51.68, 80.59),\n",
       " (59.99, 95.13),\n",
       " (32.96, 48.86),\n",
       " (19.93, 27.91),\n",
       " (33.63, 49.96),\n",
       " (35.83, 53.61),\n",
       " (46.7, 71.98),\n",
       " (64.16, 102.51),\n",
       " (21.71, 30.7),\n",
       " (87.19, 144.2),\n",
       " (15.21, 20.66),\n",
       " (51.09, 79.56),\n",
       " (59.26, 93.84),\n",
       " (42.24, 64.38),\n",
       " (36.84, 55.3),\n",
       " (34.41, 51.25),\n",
       " (42.16, 64.25),\n",
       " (60.63, 96.24),\n",
       " (29.74, 43.57),\n",
       " (99.77, 167.52),\n",
       " (28.53, 41.61),\n",
       " (29.27, 42.81),\n",
       " (26.79, 38.8),\n",
       " (60.32, 95.7),\n",
       " (41.03, 62.34),\n",
       " (54.4, 85.31),\n",
       " (74.28, 120.65),\n",
       " (31.64, 46.68),\n",
       " (111.01, 188.65),\n",
       " (37.16, 55.84),\n",
       " (146.67, 257.19),\n",
       " (31.86, 47.05),\n",
       " (68.36, 110.0),\n",
       " (93.03, 154.98),\n",
       " (75.02, 121.99),\n",
       " (66.87, 107.34),\n",
       " (72.98, 118.3),\n",
       " (24.19, 34.62),\n",
       " (59.03, 93.42),\n",
       " (60.78, 96.51),\n",
       " (67.27, 108.06),\n",
       " (44.18, 67.69),\n",
       " (31.9, 47.11),\n",
       " (171.4, 305.89),\n",
       " (83.88, 138.11),\n",
       " (25.63, 36.94),\n",
       " (30.28, 44.46),\n",
       " (92.69, 154.36),\n",
       " (36.21, 54.25),\n",
       " (144.48, 252.92),\n",
       " (36.43, 54.6),\n",
       " (43.13, 65.89),\n",
       " (26.64, 38.55),\n",
       " (55.08, 86.5),\n",
       " (33.41, 49.6),\n",
       " (29.86, 43.77),\n",
       " (33.61, 49.92),\n",
       " (57.78, 91.23),\n",
       " (38.25, 57.65),\n",
       " (53.27, 83.34),\n",
       " (64.16, 102.5),\n",
       " (26.98, 39.09),\n",
       " (54.0, 84.63),\n",
       " (100.27, 168.47),\n",
       " (30.69, 45.13),\n",
       " (86.95, 143.75),\n",
       " (60.68, 96.34),\n",
       " (66.12, 106.0),\n",
       " (22.81, 32.44),\n",
       " (33.11, 49.11),\n",
       " (79.65, 130.38),\n",
       " (33.45, 49.67),\n",
       " (29.03, 42.42),\n",
       " (40.92, 62.15),\n",
       " (21.21, 29.92),\n",
       " (84.39, 139.06),\n",
       " (27.76, 40.35),\n",
       " (52.18, 81.46),\n",
       " (95.87, 160.25),\n",
       " (77.92, 127.25),\n",
       " (40.39, 61.26),\n",
       " (23.04, 32.8),\n",
       " (34.26, 51.0),\n",
       " (70.11, 113.13),\n",
       " (64.17, 102.53),\n",
       " (101.75, 171.23),\n",
       " (92.13, 153.31),\n",
       " (35.02, 52.26),\n",
       " (57.61, 90.94),\n",
       " (51.72, 80.65),\n",
       " (77.77, 126.98),\n",
       " (69.46, 111.96),\n",
       " (46.68, 71.96),\n",
       " (34.04, 50.65),\n",
       " (31.28, 46.09),\n",
       " (34.59, 51.56),\n",
       " (82.95, 136.43),\n",
       " (66.88, 107.36),\n",
       " (60.33, 95.72),\n",
       " (93.77, 156.36),\n",
       " (77.55, 126.57),\n",
       " (147.18, 258.19),\n",
       " (58.59, 92.65),\n",
       " (60.69, 96.35),\n",
       " (39.41, 59.6),\n",
       " (69.99, 112.93),\n",
       " (35.09, 52.38),\n",
       " (68.86, 110.89),\n",
       " (29.04, 42.43),\n",
       " (59.75, 94.7),\n",
       " (32.13, 47.48),\n",
       " (67.71, 108.84),\n",
       " (55.39, 87.05),\n",
       " (33.01, 48.95),\n",
       " (41.83, 63.68),\n",
       " (49.76, 77.25),\n",
       " (29.01, 42.38),\n",
       " (43.98, 67.34),\n",
       " (48.49, 75.06),\n",
       " (89.37, 148.22),\n",
       " (37.89, 57.04),\n",
       " (29.65, 43.43),\n",
       " (33.89, 50.4),\n",
       " (60.41, 95.87),\n",
       " (30.22, 44.36),\n",
       " (34.0, 50.58),\n",
       " (73.82, 119.83),\n",
       " (29.05, 42.45),\n",
       " (61.43, 97.66),\n",
       " (45.72, 70.31),\n",
       " (47.03, 72.55),\n",
       " (50.68, 78.84),\n",
       " (87.04, 143.92),\n",
       " (33.43, 49.63),\n",
       " (36.91, 55.42),\n",
       " (30.64, 45.04),\n",
       " (50.54, 78.61),\n",
       " (49.22, 76.32),\n",
       " (95.09, 158.81),\n",
       " (41.73, 63.52),\n",
       " (102.01, 171.72),\n",
       " (29.06, 42.46),\n",
       " (61.28, 97.4),\n",
       " (61.23, 97.31),\n",
       " (98.11, 164.42),\n",
       " (28.54, 41.62),\n",
       " (38.54, 58.15),\n",
       " (33.3, 49.41),\n",
       " (39.72, 60.12),\n",
       " (43.05, 65.75),\n",
       " (72.99, 118.31),\n",
       " (55.28, 86.85),\n",
       " (26.48, 38.3),\n",
       " (58.1, 91.8),\n",
       " (25.63, 36.93),\n",
       " (67.12, 107.78),\n",
       " (31.22, 46.0),\n",
       " (61.73, 98.2),\n",
       " (65.49, 104.88),\n",
       " (50.38, 78.32),\n",
       " (31.21, 45.98),\n",
       " (56.42, 88.84),\n",
       " (34.99, 52.22),\n",
       " (35.44, 52.97),\n",
       " (71.12, 114.96),\n",
       " (60.44, 95.93),\n",
       " (39.91, 60.44),\n",
       " (77.96, 127.32),\n",
       " (35.88, 53.69),\n",
       " (26.06, 37.61),\n",
       " (52.56, 82.12),\n",
       " (34.83, 51.95),\n",
       " (67.85, 109.08),\n",
       " (36.13, 54.11),\n",
       " (43.92, 67.24),\n",
       " (29.19, 42.68),\n",
       " (26.97, 39.09),\n",
       " (75.61, 123.05),\n",
       " (72.4, 117.25),\n",
       " (29.47, 43.14),\n",
       " (36.33, 54.45),\n",
       " (55.54, 87.31),\n",
       " (147.69, 259.18),\n",
       " (20.73, 29.16),\n",
       " (33.86, 50.35),\n",
       " (28.53, 41.6),\n",
       " (30.7, 45.14),\n",
       " (101.67, 171.07),\n",
       " (39.31, 59.43),\n",
       " (43.5, 66.52),\n",
       " (61.9, 98.49),\n",
       " (22.33, 31.68),\n",
       " (32.17, 47.55),\n",
       " (41.41, 62.97),\n",
       " (49.33, 76.52),\n",
       " (42.08, 64.12),\n",
       " (23.14, 32.96),\n",
       " (34.66, 51.66),\n",
       " (40.24, 61.0),\n",
       " (33.41, 49.6),\n",
       " (66.53, 106.74),\n",
       " (27.72, 40.29),\n",
       " (63.52, 101.37),\n",
       " (81.85, 134.4),\n",
       " (41.6, 63.3),\n",
       " (21.3, 30.06),\n",
       " (35.89, 53.72),\n",
       " (75.22, 122.34),\n",
       " (31.39, 46.28),\n",
       " (66.35, 106.41),\n",
       " (72.56, 117.55),\n",
       " (29.4, 43.02),\n",
       " (115.73, 197.61),\n",
       " (31.43, 46.34),\n",
       " (29.18, 42.67),\n",
       " (26.4, 38.16),\n",
       " (108.7, 184.29),\n",
       " (44.06, 67.48),\n",
       " (119.73, 205.22),\n",
       " (85.92, 141.86),\n",
       " (48.83, 75.65),\n",
       " (48.59, 75.24),\n",
       " (32.53, 48.15),\n",
       " (24.7, 35.43),\n",
       " (56.58, 89.13),\n",
       " (37.36, 56.17),\n",
       " (25.64, 36.94),\n",
       " (44.05, 67.45),\n",
       " (33.07, 49.04),\n",
       " (48.44, 74.97),\n",
       " (86.33, 142.61),\n",
       " (48.64, 75.33),\n",
       " (139.97, 244.16),\n",
       " (59.58, 94.41),\n",
       " (45.64, 70.18),\n",
       " (48.43, 74.96),\n",
       " (47.55, 73.45),\n",
       " (42.16, 64.25),\n",
       " (77.05, 125.67),\n",
       " (49.78, 77.3),\n",
       " (33.56, 49.84),\n",
       " (32.47, 48.05),\n",
       " (39.66, 60.02),\n",
       " (35.98, 53.86),\n",
       " (177.75, 318.51),\n",
       " (26.7, 38.64),\n",
       " (57.28, 90.35),\n",
       " (99.81, 167.6),\n",
       " (57.11, 90.06),\n",
       " (26.71, 38.66),\n",
       " (70.24, 113.37),\n",
       " (33.81, 50.26),\n",
       " (36.27, 54.35),\n",
       " (52.37, 81.78),\n",
       " (69.82, 112.62),\n",
       " (35.87, 53.67),\n",
       " (65.53, 104.94),\n",
       " (97.92, 164.07),\n",
       " (47.24, 72.92),\n",
       " (24.53, 35.17),\n",
       " (43.22, 66.05),\n",
       " (62.39, 99.37),\n",
       " (46.48, 71.61),\n",
       " (72.57, 117.56),\n",
       " (46.36, 71.41),\n",
       " (56.02, 88.14),\n",
       " (43.44, 66.42),\n",
       " (95.39, 159.37),\n",
       " (53.23, 83.28),\n",
       " (34.31, 51.08),\n",
       " (40.32, 61.14),\n",
       " (20.47, 28.76),\n",
       " (44.3, 67.89),\n",
       " (66.62, 106.89),\n",
       " (46.49, 71.63),\n",
       " (220.53, 404.88),\n",
       " (26.27, 37.95),\n",
       " (52.74, 82.43),\n",
       " (50.06, 77.77),\n",
       " (51.89, 80.94),\n",
       " (42.64, 65.07),\n",
       " (33.61, 49.93),\n",
       " (53.2, 83.22),\n",
       " (30.44, 44.72),\n",
       " (22.31, 31.65),\n",
       " (21.84, 30.91),\n",
       " (26.41, 38.18),\n",
       " (107.57, 182.16),\n",
       " (45.53, 69.98),\n",
       " (75.16, 122.25),\n",
       " (41.4, 62.96),\n",
       " (58.15, 91.88),\n",
       " (63.86, 101.97),\n",
       " (37.09, 55.72),\n",
       " (83.2, 136.87),\n",
       " (24.14, 34.54),\n",
       " (82.66, 135.89),\n",
       " (44.47, 68.17),\n",
       " (40.65, 61.7),\n",
       " (39.27, 59.37),\n",
       " (113.52, 193.4),\n",
       " (79.34, 129.82),\n",
       " (61.1, 97.09),\n",
       " (71.9, 116.35),\n",
       " (85.73, 141.52),\n",
       " (28.28, 41.2),\n",
       " (42.32, 64.52),\n",
       " (27.26, 39.55),\n",
       " (59.43, 94.14),\n",
       " (56.01, 88.14),\n",
       " (54.87, 86.14),\n",
       " (35.23, 52.61),\n",
       " (34.37, 51.18),\n",
       " (30.82, 45.34),\n",
       " (30.86, 45.4),\n",
       " (19.72, 27.58),\n",
       " (35.52, 53.09),\n",
       " (33.16, 49.18),\n",
       " (103.29, 174.11),\n",
       " (45.11, 69.27),\n",
       " (52.55, 82.08),\n",
       " (71.81, 116.19),\n",
       " (117.98, 201.88),\n",
       " (18.11, 25.1),\n",
       " (54.55, 85.57),\n",
       " (27.49, 39.92),\n",
       " (50.24, 78.08),\n",
       " (34.03, 50.62),\n",
       " (35.88, 53.69),\n",
       " (87.26, 144.32),\n",
       " (24.81, 35.62),\n",
       " (27.43, 39.83),\n",
       " (52.16, 81.42),\n",
       " (35.31, 52.74),\n",
       " (59.41, 94.11),\n",
       " (63.77, 101.81),\n",
       " (40.31, 61.11),\n",
       " (55.43, 87.11),\n",
       " (76.19, 124.1),\n",
       " (26.25, 37.93),\n",
       " (24.71, 35.46),\n",
       " (73.11, 118.53),\n",
       " (58.1, 91.8),\n",
       " (78.32, 127.97),\n",
       " (34.57, 51.52),\n",
       " (53.63, 83.97),\n",
       " (58.46, 92.43),\n",
       " (65.26, 104.47),\n",
       " (102.37, 172.4),\n",
       " (59.58, 94.4),\n",
       " (72.08, 116.68),\n",
       " (72.3, 117.08),\n",
       " (28.23, 41.12),\n",
       " (48.5, 75.09),\n",
       " (29.19, 42.67),\n",
       " (63.98, 102.18),\n",
       " (27.59, 40.08),\n",
       " (29.14, 42.6),\n",
       " (53.66, 84.02),\n",
       " (46.79, 72.15),\n",
       " (81.46, 133.69),\n",
       " (158.12, 279.64),\n",
       " (75.73, 123.28),\n",
       " (24.02, 34.35),\n",
       " (35.54, 53.12),\n",
       " (35.51, 53.07),\n",
       " (85.6, 141.28),\n",
       " (38.83, 58.62),\n",
       " (58.36, 92.26),\n",
       " (40.56, 61.54),\n",
       " (71.04, 114.81),\n",
       " (91.84, 152.78),\n",
       " (33.01, 48.94),\n",
       " (44.74, 68.63),\n",
       " (108.0, 182.96),\n",
       " (68.45, 110.17),\n",
       " (64.42, 102.97),\n",
       " (94.22, 157.19),\n",
       " (39.48, 59.72),\n",
       " (90.57, 150.44),\n",
       " (32.99, 48.9),\n",
       " (61.85, 98.42),\n",
       " (87.1, 144.02),\n",
       " (57.75, 91.17),\n",
       " (29.29, 42.84),\n",
       " (28.5, 41.56),\n",
       " (57.78, 91.23),\n",
       " (27.44, 39.83),\n",
       " (29.63, 43.4),\n",
       " (37.5, 56.41),\n",
       " (131.19, 227.19),\n",
       " (35.91, 53.75),\n",
       " (71.04, 114.82),\n",
       " (55.97, 88.07),\n",
       " (57.95, 91.53),\n",
       " (29.53, 43.23),\n",
       " (47.38, 73.16),\n",
       " (89.63, 148.7),\n",
       " (37.36, 56.16),\n",
       " (164.25, 291.72),\n",
       " (60.92, 96.76),\n",
       " (82.8, 136.14),\n",
       " (64.88, 103.8),\n",
       " (48.56, 75.18),\n",
       " (42.38, 64.61),\n",
       " (105.83, 178.89),\n",
       " (132.13, 228.99),\n",
       " (52.17, 81.44),\n",
       " (36.83, 55.27),\n",
       " (29.19, 42.68),\n",
       " (55.2, 86.71),\n",
       " (22.13, 31.37),\n",
       " (20.87, 29.38),\n",
       " (41.68, 63.43),\n",
       " (28.74, 41.94),\n",
       " (46.68, 71.96),\n",
       " (63.9, 102.05),\n",
       " (32.7, 48.43),\n",
       " (57.04, 89.93),\n",
       " (32.88, 48.72),\n",
       " (57.87, 91.4),\n",
       " (45.78, 70.41),\n",
       " (37.65, 56.66),\n",
       " (39.15, 59.16),\n",
       " (26.12, 37.71),\n",
       " (28.74, 41.95),\n",
       " (68.79, 110.77),\n",
       " (25.94, 37.43),\n",
       " (49.79, 77.31),\n",
       " (28.3, 41.24),\n",
       " (35.38, 52.86),\n",
       " (104.16, 175.74),\n",
       " (52.5, 82.0),\n",
       " (26.66, 38.59),\n",
       " (27.93, 40.63),\n",
       " (55.81, 87.78),\n",
       " (93.94, 156.67),\n",
       " (83.04, 136.59),\n",
       " (48.2, 74.58),\n",
       " (31.16, 45.9),\n",
       " (39.11, 59.1),\n",
       " (89.21, 147.92),\n",
       " (48.27, 74.69),\n",
       " (52.28, 81.62),\n",
       " (59.71, 94.63),\n",
       " (117.07, 200.15),\n",
       " (33.69, 50.06),\n",
       " (59.21, 93.74),\n",
       " (59.18, 93.7),\n",
       " (37.1, 55.74),\n",
       " (26.32, 38.04),\n",
       " (55.77, 87.71),\n",
       " (73.71, 119.63),\n",
       " (55.22, 86.74),\n",
       " (38.57, 58.2),\n",
       " (26.43, 38.21),\n",
       " (22.64, 32.17),\n",
       " (45.8, 70.44),\n",
       " (58.76, 92.95),\n",
       " (45.89, 70.6),\n",
       " (60.6, 96.2),\n",
       " (38.77, 58.53),\n",
       " (22.48, 31.91),\n",
       " (35.66, 53.33),\n",
       " (37.69, 56.71),\n",
       " (29.88, 43.81),\n",
       " (111.25, 189.11),\n",
       " (29.77, 43.62),\n",
       " (26.89, 38.95),\n",
       " (25.63, 36.93),\n",
       " (32.74, 48.49),\n",
       " (68.27, 109.84),\n",
       " (69.27, 111.64),\n",
       " (40.2, 60.94),\n",
       " (71.36, 115.38),\n",
       " (35.36, 52.83),\n",
       " (146.84, 257.52),\n",
       " (18.13, 25.12),\n",
       " (50.7, 78.88),\n",
       " (55.04, 86.43),\n",
       " (110.72, 188.1),\n",
       " (26.63, 38.53),\n",
       " (70.14, 113.18),\n",
       " (66.26, 106.24),\n",
       " (24.6, 35.28),\n",
       " (54.3, 85.14),\n",
       " (28.21, 41.09),\n",
       " (39.14, 59.15),\n",
       " (50.89, 79.2),\n",
       " (23.71, 33.86),\n",
       " (55.21, 86.72),\n",
       " (55.32, 86.91),\n",
       " (168.57, 300.26),\n",
       " (33.56, 49.84),\n",
       " (55.56, 87.34),\n",
       " (62.12, 98.88),\n",
       " (44.57, 68.35),\n",
       " (36.27, 54.34),\n",
       " (36.17, 54.17),\n",
       " (62.44, 99.46),\n",
       " (119.53, 204.84),\n",
       " (29.49, 43.17),\n",
       " (52.32, 81.7),\n",
       " (33.78, 50.21),\n",
       " (77.97, 127.33),\n",
       " (25.66, 36.97),\n",
       " (37.3, 56.06),\n",
       " (31.67, 46.73),\n",
       " (62.66, 99.84),\n",
       " (44.42, 68.09),\n",
       " (95.87, 160.25),\n",
       " (41.5, 63.13),\n",
       " (50.58, 78.68),\n",
       " (194.42, 351.91),\n",
       " (62.05, 98.76),\n",
       " (63.85, 101.96),\n",
       " (54.99, 86.34),\n",
       " (48.36, 74.85),\n",
       " (28.16, 41.0),\n",
       " (53.56, 83.85),\n",
       " (109.95, 186.65),\n",
       " (49.23, 76.34),\n",
       " (50.21, 78.04),\n",
       " (60.78, 96.52),\n",
       " (109.5, 185.79),\n",
       " (55.2, 86.72),\n",
       " (44.95, 68.99),\n",
       " (27.92, 40.62),\n",
       " (41.67, 63.42),\n",
       " (60.47, 95.97),\n",
       " (34.52, 51.44),\n",
       " (47.41, 73.21),\n",
       " (27.01, 39.15),\n",
       " (26.28, 37.97),\n",
       " (79.25, 129.67),\n",
       " (56.75, 89.42),\n",
       " (64.19, 102.57),\n",
       " (27.91, 40.6),\n",
       " (31.2, 45.96),\n",
       " (84.25, 138.8),\n",
       " (32.63, 48.31),\n",
       " (56.71, 89.35),\n",
       " (25.16, 36.18),\n",
       " (65.47, 104.83),\n",
       " (40.04, 60.67),\n",
       " (48.59, 75.24),\n",
       " (56.8, 89.51),\n",
       " (148.78, 261.32),\n",
       " (67.04, 107.64),\n",
       " (64.65, 103.38),\n",
       " (70.48, 113.8),\n",
       " (28.31, 41.25),\n",
       " (72.73, 117.85),\n",
       " (35.67, 53.34),\n",
       " (26.55, 38.4),\n",
       " (91.13, 151.47),\n",
       " (40.92, 62.15),\n",
       " (34.33, 51.11),\n",
       " (50.19, 78.0),\n",
       " (38.25, 57.66),\n",
       " (54.54, 85.56),\n",
       " (65.1, 104.19),\n",
       " (48.84, 75.67),\n",
       " (56.5, 88.99),\n",
       " (127.21, 219.53),\n",
       " (166.83, 296.82),\n",
       " (60.87, 96.67),\n",
       " (82.94, 136.39),\n",
       " (35.99, 53.87),\n",
       " (37.2, 55.9),\n",
       " (84.61, 139.46),\n",
       " (59.7, 94.61),\n",
       " (27.6, 40.11),\n",
       " (40.58, 61.57),\n",
       " (44.52, 68.26),\n",
       " (38.56, 58.17),\n",
       " (57.01, 89.88),\n",
       " (56.91, 89.7),\n",
       " (74.1, 120.33),\n",
       " (67.65, 108.72),\n",
       " (58.76, 92.95),\n",
       " (107.03, 181.14),\n",
       " (36.87, 55.35),\n",
       " (37.07, 55.67),\n",
       " (23.53, 33.58),\n",
       " (56.06, 88.21),\n",
       " (34.74, 51.81),\n",
       " (39.17, 59.21),\n",
       " (31.38, 46.26),\n",
       " (30.31, 44.51),\n",
       " (29.75, 43.59),\n",
       " (23.19, 33.03),\n",
       " (57.39, 90.55),\n",
       " (29.1, 42.53),\n",
       " (37.89, 57.05),\n",
       " (46.04, 70.87),\n",
       " (23.26, 33.15),\n",
       " (25.73, 37.09),\n",
       " (54.77, 85.96),\n",
       " (32.53, 48.14),\n",
       " (143.73, 251.47),\n",
       " (68.37, 110.03),\n",
       " (170.45, 303.99),\n",
       " (61.39, 97.6),\n",
       " (61.49, 97.77),\n",
       " (39.5, 59.76),\n",
       " (42.77, 65.29),\n",
       " (60.08, 95.28),\n",
       " (88.47, 146.55),\n",
       " (58.78, 93.0),\n",
       " (35.89, 53.71),\n",
       " (35.54, 53.13),\n",
       " (44.92, 68.95),\n",
       " (46.42, 71.52),\n",
       " (42.45, 64.74),\n",
       " (33.89, 50.39),\n",
       " (40.36, 61.21),\n",
       " (60.28, 95.64),\n",
       " (49.72, 77.18),\n",
       " (58.02, 91.66),\n",
       " (25.3, 36.41),\n",
       " (69.05, 111.23),\n",
       " (117.65, 201.25),\n",
       " (41.56, 63.23),\n",
       " (25.06, 36.02),\n",
       " (28.92, 42.25),\n",
       " (29.87, 43.79),\n",
       " (27.76, 40.36),\n",
       " (49.69, 77.14),\n",
       " (151.34, 266.33),\n",
       " (27.24, 39.51),\n",
       " (73.83, 119.84),\n",
       " (17.88, 24.74),\n",
       " (48.55, 75.17),\n",
       " (25.72, 37.08),\n",
       " (28.3, 41.23),\n",
       " (54.96, 86.3),\n",
       " (32.12, 47.47),\n",
       " (64.18, 102.54),\n",
       " (23.49, 33.51),\n",
       " (29.65, 43.43),\n",
       " (48.59, 75.23),\n",
       " (33.03, 48.96),\n",
       " (45.52, 69.97),\n",
       " (24.08, 34.46),\n",
       " (43.0, 65.67),\n",
       " (25.99, 37.51),\n",
       " (36.34, 54.46),\n",
       " (23.61, 33.71),\n",
       " (54.78, 85.97),\n",
       " (75.09, 122.12),\n",
       " (37.86, 57.0),\n",
       " (126.29, 217.75),\n",
       " (25.5, 36.72),\n",
       " (27.51, 39.96),\n",
       " (70.11, 113.13),\n",
       " (84.65, 139.54),\n",
       " (30.93, 45.52),\n",
       " (64.1, 102.4),\n",
       " (43.51, 66.54),\n",
       " (29.43, 43.07),\n",
       " (96.41, 161.26),\n",
       " (61.67, 98.1),\n",
       " (30.76, 45.25),\n",
       " (77.72, 126.88),\n",
       " (34.48, 51.36),\n",
       " (89.03, 147.59),\n",
       " (44.7, 68.57),\n",
       " ...)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_svm_reg = tuple([(round(math.exp(el-el*MAPE_median_svm_reg),2),round(math.exp(el+el*MAPE_median_svm_reg),2)) for el in y_test_pred_svm_reg])\n",
    "y_pred_interval_svm_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_svm_reg, title=\"best_model_svm_reg_02\", save=\"joblib\")\n",
    "save_model(grid_svm_reg, title=\"best_cv_svm_reg_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_rf_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_reg',\n",
    "                             RandomForestRegressor(n_estimators=1500,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   random_state=random_state,\n",
    "                                                   max_depth=4,\n",
    "                                                   min_samples_split=10,\n",
    "                                                   min_samples_leaf=1,\n",
    "                                                   bootstrap=False,\n",
    "                                                   n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_rf_reg = RandomForestRegressor()\n",
    "test_rf_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Random Forest Regressor** (as base for hyperparameter search):\n",
    "\n",
    "n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_rf_reg = {\n",
    "    'rf_reg__n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "    'rf_reg__max_features': ['auto', 'sqrt'],\n",
    "    'rf_reg__max_depth': [None, 1, 2, 3, 4, 5, 7, 10, 15, 20, 30, 40, 50, 75, 100],\n",
    "    'rf_reg__min_samples_split': [2, 5, 10],\n",
    "    'rf_reg__min_samples_leaf': [1, 2, 4],\n",
    "    'rf_reg__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 45.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_rf_reg = RandomizedSearchCV(pipeline_rf_reg,\n",
    "                                 param_distribs_rf_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=10,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_rf_reg = rnd_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.23\n",
      "Best parameters:\n",
      "{'rf_reg__n_estimators': 1000, 'rf_reg__min_samples_split': 10, 'rf_reg__min_samples_leaf': 1, 'rf_reg__max_features': 'sqrt', 'rf_reg__max_depth': 100, 'rf_reg__bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_reg = {\n",
    "#    'rf_reg__n_estimators': [1200, 2000],\n",
    "#    'rf_reg__max_features': ['auto', 'sqrt'],\n",
    "    'rf_reg__max_depth': [10, 15],\n",
    "    'rf_reg__min_samples_split': [6, 10],\n",
    "#    'rf_reg__min_samples_leaf': [1, 2],\n",
    "#    'rf_reg__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_reg = GridSearchCV(pipeline_rf_reg,\n",
    "                            param_grid_rf_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_rf_reg = grid_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_rf_reg = grid_rf_reg.best_estimator_['rf_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.24\n",
      "Best parameters:\n",
      "{'rf_reg__max_depth': 15, 'rf_reg__min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.227147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.138154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.113998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.045111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.042288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.037592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.033099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.032034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.027565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.023683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.020177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.017680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.016305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.011836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.009851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.008482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.008462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.008287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.006347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.005314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.002769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.002229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.001928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    weight\n",
       "room_type_Private room            0.227147\n",
       "accommodates                      0.138154\n",
       "bedrooms                          0.113998\n",
       "calc_host_lst_count_sqrt_log      0.045111\n",
       "am_tv                             0.042288\n",
       "bathrooms_log                     0.037592\n",
       "availability_90                   0.033099\n",
       "accommodates_per_bed              0.032034\n",
       "am_elevator                       0.027565\n",
       "minimum_nights_log                0.023683\n",
       "maximum_nights                    0.023266\n",
       "am_private_entrance               0.020177\n",
       "am_child_friendly                 0.017680\n",
       "property_type_Boutique hotel      0.017303\n",
       "room_type_Shared room             0.016305\n",
       "zipcode_zip_other                 0.011836\n",
       "room_type_Hotel room              0.009851\n",
       "zipcode_zip_10117                 0.009247\n",
       "am_smoking_allowed                0.008488\n",
       "am_balcony                        0.008482\n",
       "wk_mth_discount                   0.008462\n",
       "cancellation_policy_super_strict  0.008288\n",
       "zipcode_zip_10119                 0.008287\n",
       "host_is_superhost                 0.006347\n",
       "cancellation_policy_strict        0.005638\n",
       "zipcode_zip_13359                 0.005633\n",
       "instant_bookable                  0.005314\n",
       "am_pets_allowed                   0.004192\n",
       "zipcode_zip_10179                 0.003971\n",
       "cancellation_policy_moderate      0.003840\n",
       "am_breakfast                      0.003534\n",
       "am_essentials                     0.003280\n",
       "property_type_House               0.002769\n",
       "zipcode_zip_10245                 0.002275\n",
       "zipcode_zip_10435                 0.002229\n",
       "zipcode_zip_10405                 0.002156\n",
       "zipcode_zip_10719                 0.002057\n",
       "zipcode_zip_10247                 0.001955\n",
       "zipcode_zip_10559                 0.001928\n",
       "zipcode_zip_10243                 0.001922\n",
       "zipcode_zip_10999                 0.001875\n",
       "zipcode_zip_10178                 0.001856\n",
       "zipcode_zip_10439                 0.001837\n",
       "zipcode_zip_10997                 0.001799\n",
       "zipcode_zip_10969                 0.001592\n",
       "zipcode_zip_10785                 0.001322\n",
       "zipcode_zip_13407                 0.001236\n",
       "zipcode_zip_13353                 0.001232\n",
       "zipcode_zip_10437                 0.001177\n",
       "zipcode_zip_12047                 0.001153\n",
       "zipcode_zip_10963                 0.001140\n",
       "zipcode_zip_13357                 0.001138\n",
       "zipcode_zip_10965                 0.001124\n",
       "zipcode_zip_12049                 0.001007\n",
       "zipcode_zip_13347                 0.000954\n",
       "zipcode_zip_nan                   0.000943\n",
       "zipcode_zip_10553                 0.000939\n",
       "zipcode_zip_12347                 0.000888\n",
       "zipcode_zip_12053                 0.000886\n",
       "zipcode_zip_12051                 0.000848\n",
       "zipcode_zip_12437                 0.000818\n",
       "zipcode_zip_13349                 0.000812\n",
       "zipcode_zip_10407                 0.000761\n",
       "zipcode_zip_12059                 0.000754\n",
       "property_type_Secondary unit      0.000736\n",
       "zipcode_zip_13086                 0.000736\n",
       "zipcode_zip_12043                 0.000731\n",
       "zipcode_zip_10777                 0.000691\n",
       "zipcode_zip_12045                 0.000688\n",
       "zipcode_zip_10557                 0.000680\n",
       "zipcode_zip_10967                 0.000667\n",
       "zipcode_zip_10249                 0.000666\n",
       "zipcode_zip_10589                 0.000646\n",
       "zipcode_zip_12055                 0.000645\n",
       "zipcode_zip_12099                 0.000626\n",
       "zipcode_zip_10317                 0.000620\n",
       "zipcode_zip_10787                 0.000617\n",
       "zipcode_zip_10555                 0.000603\n",
       "zipcode_zip_10707                 0.000590\n",
       "zipcode_zip_12103                 0.000575\n",
       "zipcode_zip_10551                 0.000574\n",
       "zipcode_zip_12435                 0.000572\n",
       "zipcode_zip_10315                 0.000562\n",
       "zipcode_zip_13187                 0.000560\n",
       "zipcode_zip_14057                 0.000537\n",
       "zipcode_zip_12157                 0.000517\n",
       "zipcode_zip_13189                 0.000501\n",
       "zipcode_zip_10783                 0.000495\n",
       "zipcode_zip_14197                 0.000491\n",
       "zipcode_zip_10711                 0.000475\n",
       "zipcode_zip_10715                 0.000471\n",
       "property_type_Bed and breakfast   0.000457\n",
       "zipcode_zip_10623                 0.000451\n",
       "zipcode_zip_10409                 0.000438\n",
       "zipcode_zip_10365                 0.000430\n",
       "zipcode_zip_10629                 0.000407\n",
       "zipcode_zip_10829                 0.000388\n",
       "zipcode_zip_10585                 0.000384\n",
       "zipcode_zip_10961                 0.000384\n",
       "zipcode_zip_10781                 0.000368\n",
       "zipcode_zip_10827                 0.000357\n",
       "zipcode_zip_13088                 0.000344\n",
       "zipcode_zip_13355                 0.000343\n",
       "zipcode_zip_13409                 0.000340\n",
       "property_type_Unique space        0.000334\n",
       "zipcode_zip_10367                 0.000279\n",
       "zipcode_zip_10587                 0.000279\n",
       "zipcode_zip_14059                 0.000275\n",
       "zipcode_zip_12161                 0.000272\n",
       "zipcode_zip_10625                 0.000243\n",
       "zipcode_zip_13351                 0.000229\n",
       "zipcode_zip_10717                 0.000227\n",
       "zipcode_zip_12163                 0.000218\n",
       "zipcode_zip_10318                 0.000203\n",
       "zipcode_zip_10823                 0.000177\n",
       "zipcode_zip_13156                 0.000133\n",
       "zipcode_zip_10627                 0.000114\n",
       "zipcode_zip_12101                 0.000108\n",
       "zipcode_zip_10713                 0.000073"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_rf_reg = get_feat_importances(best_model_rf_reg)\n",
    "fi_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_rf_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_rf_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_rf_reg = best_model_rf_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10\n",
      "RMSE: 0.31\n",
      "MAE: 0.25\n",
      "R2: 0.70\n",
      "MAPE: 6.31\n",
      "MAPE median: 5.07\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_rf_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_rf_reg = best_model_rf_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.15\n",
      "RMSE: 0.38\n",
      "MAE: 0.29\n",
      "R2: 0.54\n",
      "MAPE: 7.61\n",
      "MAPE median: 5.83\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_rf_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36322871, 0.39248337])"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_rf_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_rf_reg = (median_absolute_percentage_error(y_test, y_test_pred_rf_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52.49, 84.34),\n",
       " (63.69, 104.73),\n",
       " (48.79, 77.71),\n",
       " (31.74, 48.02),\n",
       " (37.33, 57.58),\n",
       " (31.18, 47.07),\n",
       " (40.96, 63.88),\n",
       " (39.19, 60.8),\n",
       " (50.29, 80.39),\n",
       " (43.01, 67.48),\n",
       " (25.4, 37.42),\n",
       " (40.63, 63.31),\n",
       " (60.1, 98.14),\n",
       " (26.03, 38.45),\n",
       " (34.87, 53.35),\n",
       " (65.81, 108.65),\n",
       " (68.9, 114.37),\n",
       " (52.99, 85.24),\n",
       " (57.08, 92.64),\n",
       " (47.3, 75.06),\n",
       " (85.92, 146.45),\n",
       " (50.15, 80.13),\n",
       " (42.29, 66.21),\n",
       " (76.92, 129.38),\n",
       " (25.16, 37.02),\n",
       " (50.02, 79.91),\n",
       " (76.51, 128.6),\n",
       " (33.78, 51.48),\n",
       " (28.21, 42.09),\n",
       " (45.88, 72.54),\n",
       " (26.96, 40.0),\n",
       " (56.11, 90.88),\n",
       " (55.91, 90.52),\n",
       " (29.42, 44.11),\n",
       " (44.83, 70.68),\n",
       " (58.97, 96.07),\n",
       " (36.57, 56.26),\n",
       " (51.65, 82.83),\n",
       " (33.59, 51.16),\n",
       " (32.83, 49.87),\n",
       " (31.65, 47.86),\n",
       " (25.48, 37.55),\n",
       " (38.19, 59.07),\n",
       " (35.32, 54.12),\n",
       " (30.45, 45.84),\n",
       " (46.57, 73.76),\n",
       " (47.55, 75.5),\n",
       " (72.92, 121.87),\n",
       " (59.19, 96.49),\n",
       " (90.86, 155.9),\n",
       " (34.06, 51.96),\n",
       " (66.47, 109.87),\n",
       " (52.47, 84.3),\n",
       " (48.38, 76.98),\n",
       " (35.34, 54.15),\n",
       " (46.65, 73.9),\n",
       " (57.55, 93.5),\n",
       " (33.75, 51.44),\n",
       " (53.35, 85.89),\n",
       " (34.6, 52.89),\n",
       " (54.31, 87.61),\n",
       " (55.14, 89.13),\n",
       " (59.51, 97.07),\n",
       " (46.6, 73.82),\n",
       " (53.62, 86.38),\n",
       " (45.53, 71.91),\n",
       " (27.74, 41.3),\n",
       " (30.72, 46.29),\n",
       " (45.95, 72.67),\n",
       " (42.77, 67.05),\n",
       " (49.66, 79.26),\n",
       " (87.26, 149.01),\n",
       " (38.47, 59.55),\n",
       " (55.25, 89.31),\n",
       " (121.63, 216.12),\n",
       " (42.85, 67.21),\n",
       " (17.95, 25.37),\n",
       " (62.71, 102.94),\n",
       " (41.25, 64.39),\n",
       " (28.8, 43.07),\n",
       " (27.48, 40.85),\n",
       " (23.99, 35.1),\n",
       " (37.71, 58.24),\n",
       " (26.3, 38.9),\n",
       " (58.84, 95.84),\n",
       " (54.84, 88.57),\n",
       " (44.0, 69.22),\n",
       " (67.78, 112.29),\n",
       " (39.91, 62.05),\n",
       " (54.44, 87.86),\n",
       " (66.76, 110.4),\n",
       " (47.89, 76.11),\n",
       " (41.24, 64.38),\n",
       " (112.29, 197.63),\n",
       " (53.12, 85.47),\n",
       " (30.66, 46.19),\n",
       " (93.65, 161.27),\n",
       " (54.66, 88.26),\n",
       " (29.75, 44.65),\n",
       " (23.08, 33.61),\n",
       " (31.18, 47.07),\n",
       " (38.07, 58.86),\n",
       " (31.47, 47.56),\n",
       " (42.53, 66.64),\n",
       " (28.53, 42.61),\n",
       " (58.21, 94.7),\n",
       " (28.95, 43.31),\n",
       " (39.94, 62.11),\n",
       " (37.78, 58.35),\n",
       " (49.03, 78.13),\n",
       " (32.86, 49.92),\n",
       " (23.76, 34.72),\n",
       " (76.03, 127.7),\n",
       " (27.51, 40.91),\n",
       " (65.8, 108.63),\n",
       " (66.77, 110.42),\n",
       " (39.11, 60.67),\n",
       " (80.84, 136.78),\n",
       " (45.15, 71.24),\n",
       " (34.31, 52.39),\n",
       " (30.76, 46.36),\n",
       " (50.02, 79.92),\n",
       " (33.47, 50.96),\n",
       " (42.84, 67.18),\n",
       " (31.64, 47.84),\n",
       " (61.75, 101.17),\n",
       " (34.81, 53.25),\n",
       " (49.21, 78.46),\n",
       " (34.1, 52.03),\n",
       " (29.19, 43.72),\n",
       " (81.92, 138.82),\n",
       " (23.88, 34.92),\n",
       " (31.96, 48.38),\n",
       " (26.51, 39.26),\n",
       " (35.77, 54.9),\n",
       " (32.85, 49.89),\n",
       " (31.63, 47.83),\n",
       " (48.22, 76.7),\n",
       " (98.87, 171.37),\n",
       " (90.77, 155.73),\n",
       " (32.49, 49.29),\n",
       " (41.82, 65.4),\n",
       " (47.77, 75.9),\n",
       " (29.12, 43.6),\n",
       " (46.52, 73.67),\n",
       " (78.43, 132.23),\n",
       " (44.43, 69.98),\n",
       " (36.16, 55.56),\n",
       " (53.67, 86.47),\n",
       " (63.78, 104.89),\n",
       " (68.88, 114.33),\n",
       " (54.77, 88.44),\n",
       " (56.04, 90.74),\n",
       " (31.73, 48.01),\n",
       " (70.59, 117.52),\n",
       " (90.86, 155.9),\n",
       " (25.83, 38.13),\n",
       " (49.19, 78.43),\n",
       " (32.11, 48.65),\n",
       " (85.8, 146.22),\n",
       " (34.55, 52.81),\n",
       " (32.0, 48.45),\n",
       " (59.38, 96.83),\n",
       " (44.69, 70.44),\n",
       " (44.25, 69.67),\n",
       " (81.24, 137.55),\n",
       " (46.12, 72.96),\n",
       " (30.02, 45.12),\n",
       " (27.17, 40.35),\n",
       " (31.23, 47.15),\n",
       " (50.48, 80.73),\n",
       " (130.48, 233.8),\n",
       " (37.67, 58.17),\n",
       " (45.77, 72.34),\n",
       " (31.96, 48.39),\n",
       " (70.45, 117.26),\n",
       " (28.98, 43.37),\n",
       " (56.65, 91.87),\n",
       " (30.37, 45.7),\n",
       " (39.5, 61.34),\n",
       " (49.77, 79.46),\n",
       " (65.53, 108.13),\n",
       " (53.46, 86.09),\n",
       " (51.13, 81.9),\n",
       " (29.23, 43.78),\n",
       " (52.46, 84.28),\n",
       " (42.53, 66.64),\n",
       " (63.03, 103.52),\n",
       " (50.64, 81.01),\n",
       " (45.32, 71.55),\n",
       " (55.74, 90.21),\n",
       " (28.94, 43.3),\n",
       " (62.06, 101.74),\n",
       " (64.78, 106.73),\n",
       " (55.53, 89.82),\n",
       " (57.0, 92.5),\n",
       " (63.56, 104.48),\n",
       " (31.26, 47.21),\n",
       " (54.01, 87.07),\n",
       " (29.38, 44.04),\n",
       " (59.81, 97.62),\n",
       " (33.14, 50.4),\n",
       " (100.23, 174.02),\n",
       " (45.51, 71.89),\n",
       " (52.69, 84.71),\n",
       " (43.08, 67.61),\n",
       " (56.44, 91.47),\n",
       " (78.76, 132.86),\n",
       " (48.18, 76.62),\n",
       " (31.66, 47.88),\n",
       " (114.42, 201.82),\n",
       " (28.9, 43.23),\n",
       " (36.71, 56.51),\n",
       " (67.74, 112.22),\n",
       " (29.97, 45.03),\n",
       " (51.16, 81.95),\n",
       " (29.8, 44.74),\n",
       " (46.32, 73.33),\n",
       " (40.79, 63.59),\n",
       " (57.18, 92.83),\n",
       " (91.48, 157.09),\n",
       " (24.06, 35.21),\n",
       " (57.99, 94.29),\n",
       " (30.98, 46.74),\n",
       " (72.06, 120.26),\n",
       " (32.24, 48.86),\n",
       " (19.75, 28.22),\n",
       " (29.23, 43.79),\n",
       " (57.08, 92.64),\n",
       " (67.35, 111.49),\n",
       " (60.38, 98.66),\n",
       " (62.73, 102.97),\n",
       " (46.97, 74.48),\n",
       " (36.62, 56.36),\n",
       " (43.12, 67.66),\n",
       " (48.29, 76.82),\n",
       " (52.56, 84.47),\n",
       " (62.52, 102.58),\n",
       " (45.95, 72.66),\n",
       " (43.43, 68.22),\n",
       " (58.79, 95.75),\n",
       " (62.12, 101.85),\n",
       " (53.78, 86.67),\n",
       " (93.86, 161.68),\n",
       " (33.71, 51.37),\n",
       " (33.07, 50.27),\n",
       " (30.68, 46.23),\n",
       " (44.14, 69.46),\n",
       " (47.64, 75.66),\n",
       " (45.73, 72.27),\n",
       " (33.83, 51.58),\n",
       " (56.66, 91.88),\n",
       " (52.52, 84.4),\n",
       " (71.55, 119.31),\n",
       " (55.83, 90.38),\n",
       " (48.44, 77.09),\n",
       " (57.72, 93.8),\n",
       " (44.65, 70.36),\n",
       " (31.51, 47.64),\n",
       " (32.75, 49.73),\n",
       " (29.58, 44.37),\n",
       " (33.37, 50.79),\n",
       " (48.78, 77.7),\n",
       " (30.56, 46.03),\n",
       " (41.87, 65.48),\n",
       " (33.4, 50.84),\n",
       " (53.92, 86.91),\n",
       " (33.7, 51.35),\n",
       " (65.52, 108.11),\n",
       " (44.2, 69.57),\n",
       " (26.27, 38.85),\n",
       " (50.12, 80.08),\n",
       " (50.22, 80.26),\n",
       " (59.45, 96.95),\n",
       " (94.49, 162.9),\n",
       " (72.74, 121.53),\n",
       " (79.48, 134.22),\n",
       " (36.68, 56.47),\n",
       " (57.93, 94.18),\n",
       " (50.13, 80.1),\n",
       " (25.4, 37.41),\n",
       " (60.69, 99.23),\n",
       " (39.13, 60.7),\n",
       " (96.93, 167.62),\n",
       " (52.78, 84.87),\n",
       " (47.18, 74.85),\n",
       " (32.0, 48.46),\n",
       " (25.7, 37.91),\n",
       " (63.95, 105.21),\n",
       " (51.36, 82.3),\n",
       " (30.51, 45.93),\n",
       " (53.13, 85.48),\n",
       " (83.98, 142.74),\n",
       " (43.6, 68.52),\n",
       " (68.87, 114.32),\n",
       " (29.93, 44.95),\n",
       " (33.54, 51.08),\n",
       " (49.01, 78.11),\n",
       " (30.88, 46.56),\n",
       " (56.52, 91.62),\n",
       " (29.05, 43.49),\n",
       " (49.98, 79.84),\n",
       " (32.22, 48.83),\n",
       " (49.81, 79.52),\n",
       " (54.53, 88.01),\n",
       " (35.92, 55.16),\n",
       " (55.77, 90.26),\n",
       " (54.04, 87.13),\n",
       " (56.11, 90.87),\n",
       " (58.68, 95.56),\n",
       " (73.15, 122.3),\n",
       " (50.25, 80.32),\n",
       " (73.74, 123.41),\n",
       " (70.39, 117.14),\n",
       " (87.76, 149.95),\n",
       " (31.55, 47.7),\n",
       " (25.28, 37.21),\n",
       " (27.53, 40.95),\n",
       " (47.04, 74.59),\n",
       " (64.63, 106.47),\n",
       " (46.01, 72.76),\n",
       " (70.9, 118.1),\n",
       " (59.61, 97.25),\n",
       " (29.68, 44.54),\n",
       " (94.4, 162.71),\n",
       " (48.48, 77.15),\n",
       " (45.5, 71.87),\n",
       " (52.89, 85.06),\n",
       " (24.1, 35.27),\n",
       " (50.83, 81.37),\n",
       " (65.9, 108.81),\n",
       " (46.2, 73.1),\n",
       " (27.4, 40.73),\n",
       " (57.4, 93.22),\n",
       " (58.98, 96.1),\n",
       " (33.09, 50.3),\n",
       " (29.24, 43.81),\n",
       " (43.24, 67.89),\n",
       " (30.49, 45.91),\n",
       " (44.85, 70.71),\n",
       " (41.83, 65.41),\n",
       " (108.48, 190.14),\n",
       " (29.7, 44.58),\n",
       " (26.28, 38.87),\n",
       " (51.92, 83.31),\n",
       " (29.96, 45.02),\n",
       " (32.69, 49.63),\n",
       " (48.12, 76.52),\n",
       " (52.76, 84.82),\n",
       " (86.83, 148.17),\n",
       " (59.82, 97.63),\n",
       " (49.78, 79.48),\n",
       " (27.7, 41.22),\n",
       " (70.19, 116.77),\n",
       " (25.44, 37.48),\n",
       " (27.53, 40.95),\n",
       " (51.89, 83.26),\n",
       " (53.63, 86.4),\n",
       " (80.82, 136.75),\n",
       " (30.13, 45.31),\n",
       " (33.22, 50.53),\n",
       " (40.74, 63.51),\n",
       " (31.98, 48.42),\n",
       " (31.07, 46.89),\n",
       " (52.76, 84.83),\n",
       " (36.18, 55.6),\n",
       " (55.49, 89.75),\n",
       " (30.63, 46.15),\n",
       " (53.68, 86.48),\n",
       " (66.79, 110.45),\n",
       " (31.39, 47.42),\n",
       " (26.11, 38.59),\n",
       " (45.55, 71.96),\n",
       " (56.64, 91.85),\n",
       " (26.39, 39.04),\n",
       " (41.88, 65.5),\n",
       " (61.0, 99.8),\n",
       " (30.52, 45.96),\n",
       " (39.18, 60.79),\n",
       " (28.51, 42.58),\n",
       " (54.03, 87.11),\n",
       " (62.49, 102.52),\n",
       " (94.06, 162.06),\n",
       " (33.61, 51.19),\n",
       " (34.12, 52.07),\n",
       " (48.32, 76.87),\n",
       " (58.53, 95.29),\n",
       " (30.95, 46.68),\n",
       " (27.43, 40.78),\n",
       " (53.3, 85.8),\n",
       " (84.71, 144.14),\n",
       " (54.03, 87.11),\n",
       " (30.0, 45.07),\n",
       " (36.11, 55.48),\n",
       " (30.37, 45.7),\n",
       " (99.9, 173.36),\n",
       " (46.49, 73.62),\n",
       " (58.94, 96.02),\n",
       " (60.03, 98.01),\n",
       " (28.26, 42.16),\n",
       " (30.38, 45.73),\n",
       " (77.84, 131.12),\n",
       " (29.18, 43.7),\n",
       " (47.71, 75.78),\n",
       " (51.41, 82.39),\n",
       " (31.46, 47.54),\n",
       " (46.16, 73.04),\n",
       " (35.29, 54.07),\n",
       " (32.96, 50.08),\n",
       " (31.49, 47.59),\n",
       " (32.02, 48.49),\n",
       " (66.55, 110.02),\n",
       " (73.24, 122.46),\n",
       " (64.16, 105.61),\n",
       " (28.57, 42.69),\n",
       " (52.73, 84.78),\n",
       " (22.25, 32.26),\n",
       " (50.13, 80.1),\n",
       " (48.4, 77.02),\n",
       " (78.8, 132.92),\n",
       " (38.62, 59.82),\n",
       " (24.79, 36.41),\n",
       " (36.16, 55.57),\n",
       " (60.17, 98.27),\n",
       " (39.52, 61.37),\n",
       " (42.43, 66.45),\n",
       " (46.82, 74.2),\n",
       " (65.69, 108.42),\n",
       " (32.88, 49.96),\n",
       " (47.44, 75.31),\n",
       " (47.88, 76.09),\n",
       " (57.57, 93.53),\n",
       " (44.67, 70.39),\n",
       " (33.09, 50.31),\n",
       " (50.4, 80.59),\n",
       " (31.05, 46.85),\n",
       " (29.05, 43.49),\n",
       " (41.83, 65.41),\n",
       " (27.75, 41.31),\n",
       " (72.35, 120.79),\n",
       " (49.92, 79.73),\n",
       " (45.13, 71.22),\n",
       " (30.12, 45.29),\n",
       " (67.33, 111.46),\n",
       " (44.5, 70.1),\n",
       " (23.55, 34.38),\n",
       " (73.12, 122.24),\n",
       " (26.27, 38.85),\n",
       " (27.56, 40.99),\n",
       " (40.98, 63.93),\n",
       " (57.93, 94.19),\n",
       " (45.93, 72.63),\n",
       " (47.31, 75.07),\n",
       " (32.26, 48.91),\n",
       " (32.0, 48.45),\n",
       " (86.1, 146.79),\n",
       " (62.51, 102.56),\n",
       " (62.56, 102.65),\n",
       " (46.33, 73.34),\n",
       " (48.79, 77.72),\n",
       " (28.99, 43.39),\n",
       " (32.42, 49.18),\n",
       " (46.68, 73.95),\n",
       " (62.86, 103.21),\n",
       " (53.63, 86.39),\n",
       " (25.01, 36.77),\n",
       " (32.76, 49.74),\n",
       " (66.96, 110.76),\n",
       " (27.9, 41.56),\n",
       " (22.83, 33.2),\n",
       " (32.1, 48.63),\n",
       " (56.54, 91.66),\n",
       " (59.2, 96.51),\n",
       " (59.18, 96.47),\n",
       " (43.73, 68.74),\n",
       " (32.87, 49.93),\n",
       " (100.62, 174.77),\n",
       " (29.5, 44.25),\n",
       " (33.99, 51.85),\n",
       " (29.19, 43.72),\n",
       " (38.21, 59.1),\n",
       " (52.21, 83.83),\n",
       " (68.7, 113.99),\n",
       " (37.22, 57.39),\n",
       " (27.6, 41.07),\n",
       " (51.34, 82.28),\n",
       " (26.34, 38.97),\n",
       " (35.28, 54.05),\n",
       " (107.64, 188.48),\n",
       " (48.45, 77.1),\n",
       " (33.23, 50.54),\n",
       " (30.37, 45.7),\n",
       " (28.58, 42.7),\n",
       " (83.18, 141.22),\n",
       " (33.5, 51.01),\n",
       " (31.16, 47.04),\n",
       " (44.04, 69.3),\n",
       " (37.02, 57.05),\n",
       " (54.32, 87.64),\n",
       " (65.65, 108.34),\n",
       " (49.35, 78.7),\n",
       " (80.94, 136.98),\n",
       " (43.19, 67.79),\n",
       " (30.96, 46.69),\n",
       " (25.49, 37.56),\n",
       " (31.58, 47.75),\n",
       " (68.32, 113.3),\n",
       " (47.82, 75.98),\n",
       " (47.14, 74.77),\n",
       " (77.14, 129.79),\n",
       " (35.27, 54.03),\n",
       " (51.47, 82.5),\n",
       " (37.23, 57.42),\n",
       " (56.78, 92.1),\n",
       " (30.77, 46.39),\n",
       " (37.7, 58.23),\n",
       " (77.75, 130.95),\n",
       " (26.45, 39.15),\n",
       " (30.25, 45.49),\n",
       " (30.59, 46.07),\n",
       " (68.64, 113.88),\n",
       " (30.6, 46.09),\n",
       " (53.8, 86.7),\n",
       " (55.78, 90.29),\n",
       " (30.97, 46.71),\n",
       " (54.71, 88.35),\n",
       " (28.24, 42.13),\n",
       " (66.22, 109.41),\n",
       " (63.68, 104.72),\n",
       " (74.8, 125.4),\n",
       " (26.46, 39.17),\n",
       " (45.73, 72.28),\n",
       " (31.66, 47.88),\n",
       " (100.83, 175.18),\n",
       " (25.73, 37.96),\n",
       " (30.52, 45.95),\n",
       " (50.11, 80.06),\n",
       " (35.17, 53.87),\n",
       " (31.07, 46.89),\n",
       " (34.87, 53.36),\n",
       " (82.03, 139.05),\n",
       " (47.46, 75.34),\n",
       " (90.86, 155.9),\n",
       " (59.27, 96.64),\n",
       " (24.64, 36.16),\n",
       " (37.21, 57.37),\n",
       " (47.08, 74.66),\n",
       " (44.03, 69.28),\n",
       " (42.91, 67.3),\n",
       " (45.37, 71.63),\n",
       " (30.92, 46.62),\n",
       " (33.01, 50.17),\n",
       " (44.91, 70.82),\n",
       " (39.39, 61.15),\n",
       " (30.1, 45.25),\n",
       " (129.4, 231.65),\n",
       " (43.78, 68.84),\n",
       " (53.54, 86.24),\n",
       " (46.6, 73.82),\n",
       " (26.37, 39.02),\n",
       " (44.43, 69.97),\n",
       " (35.61, 54.62),\n",
       " (26.68, 39.53),\n",
       " (74.6, 125.02),\n",
       " (69.1, 114.74),\n",
       " (34.95, 53.49),\n",
       " (43.94, 69.11),\n",
       " (53.37, 85.92),\n",
       " (45.91, 72.59),\n",
       " (36.26, 55.75),\n",
       " (51.95, 83.37),\n",
       " (50.39, 80.57),\n",
       " (37.62, 58.09),\n",
       " (39.37, 61.12),\n",
       " (53.58, 86.3),\n",
       " (53.91, 86.89),\n",
       " (29.09, 43.56),\n",
       " (18.94, 26.93),\n",
       " (42.85, 67.2),\n",
       " (37.93, 58.63),\n",
       " (56.69, 91.94),\n",
       " (49.7, 79.33),\n",
       " (51.29, 82.18),\n",
       " (44.33, 69.81),\n",
       " (52.37, 84.13),\n",
       " (44.71, 70.47),\n",
       " (80.25, 135.67),\n",
       " (54.17, 87.36),\n",
       " (45.65, 72.14),\n",
       " (56.8, 92.13),\n",
       " (38.65, 59.87),\n",
       " (41.1, 64.14),\n",
       " (38.77, 60.07),\n",
       " (30.69, 46.24),\n",
       " (54.62, 88.19),\n",
       " (63.17, 103.78),\n",
       " (33.92, 51.73),\n",
       " (48.76, 77.66),\n",
       " (27.52, 40.93),\n",
       " (30.67, 46.21),\n",
       " (52.37, 84.12),\n",
       " (41.25, 64.4),\n",
       " (32.82, 49.84),\n",
       " (48.73, 77.6),\n",
       " (33.34, 50.74),\n",
       " (56.28, 91.18),\n",
       " (48.05, 76.4),\n",
       " (29.18, 43.7),\n",
       " (41.58, 64.97),\n",
       " (56.55, 91.69),\n",
       " (36.07, 55.41),\n",
       " (53.98, 87.02),\n",
       " (50.53, 80.82),\n",
       " (48.58, 77.34),\n",
       " (46.67, 73.94),\n",
       " (29.8, 44.74),\n",
       " (23.59, 34.45),\n",
       " (52.14, 83.71),\n",
       " (52.49, 84.34),\n",
       " (20.74, 29.82),\n",
       " (56.48, 91.55),\n",
       " (32.72, 49.68),\n",
       " (54.79, 88.49),\n",
       " (32.3, 48.96),\n",
       " (35.39, 54.24),\n",
       " (39.89, 62.02),\n",
       " (40.85, 63.69),\n",
       " (29.83, 44.79),\n",
       " (24.71, 36.28),\n",
       " (31.4, 47.44),\n",
       " (57.61, 93.6),\n",
       " (35.25, 54.01),\n",
       " (33.9, 51.68),\n",
       " (32.81, 49.84),\n",
       " (45.25, 71.43),\n",
       " (62.86, 103.21),\n",
       " (89.69, 153.66),\n",
       " (61.11, 100.0),\n",
       " (32.76, 49.74),\n",
       " (31.63, 47.83),\n",
       " (33.07, 50.27),\n",
       " (47.76, 75.88),\n",
       " (45.8, 72.4),\n",
       " (33.77, 51.47),\n",
       " (29.21, 43.76),\n",
       " (50.06, 79.99),\n",
       " (41.79, 65.34),\n",
       " (54.55, 88.05),\n",
       " (38.98, 60.44),\n",
       " (36.37, 55.93),\n",
       " (32.62, 49.51),\n",
       " (53.03, 85.32),\n",
       " (34.3, 52.37),\n",
       " (46.94, 74.42),\n",
       " (62.53, 102.6),\n",
       " (67.83, 112.39),\n",
       " (26.32, 38.94),\n",
       " (24.21, 35.46),\n",
       " (34.25, 52.29),\n",
       " (50.15, 80.14),\n",
       " (25.57, 37.69),\n",
       " (50.27, 80.36),\n",
       " (29.24, 43.81),\n",
       " (43.59, 68.49),\n",
       " (37.54, 57.94),\n",
       " (62.24, 102.07),\n",
       " (33.96, 51.79),\n",
       " (49.03, 78.13),\n",
       " (29.67, 44.52),\n",
       " (30.52, 45.96),\n",
       " (50.83, 81.35),\n",
       " (54.34, 87.67),\n",
       " (72.22, 120.57),\n",
       " (117.85, 208.62),\n",
       " (31.82, 48.15),\n",
       " (45.69, 72.21),\n",
       " (36.84, 56.73),\n",
       " (31.64, 47.86),\n",
       " (84.15, 143.06),\n",
       " (31.28, 47.24),\n",
       " (59.76, 97.52),\n",
       " (55.17, 89.18),\n",
       " (32.56, 49.4),\n",
       " (25.76, 38.01),\n",
       " (30.74, 46.32),\n",
       " (36.89, 56.82),\n",
       " (28.37, 42.35),\n",
       " (56.6, 91.76),\n",
       " (36.5, 56.14),\n",
       " (36.3, 55.81),\n",
       " (42.32, 66.27),\n",
       " (38.56, 59.7),\n",
       " (39.84, 61.94),\n",
       " (35.39, 54.25),\n",
       " (29.31, 43.92),\n",
       " (51.47, 82.51),\n",
       " (32.73, 49.7),\n",
       " (41.69, 65.16),\n",
       " (39.48, 61.31),\n",
       " (28.44, 42.47),\n",
       " (32.56, 49.41),\n",
       " (52.0, 83.45),\n",
       " (42.16, 65.99),\n",
       " (60.98, 99.76),\n",
       " (53.56, 86.26),\n",
       " (30.27, 45.53),\n",
       " (31.55, 47.7),\n",
       " (53.07, 85.39),\n",
       " (45.09, 71.15),\n",
       " (33.28, 50.64),\n",
       " (37.41, 57.72),\n",
       " (54.63, 88.2),\n",
       " (75.67, 127.03),\n",
       " (65.61, 108.27),\n",
       " (32.26, 48.9),\n",
       " (47.33, 75.11),\n",
       " (27.66, 41.17),\n",
       " (28.08, 41.86),\n",
       " (32.79, 49.79),\n",
       " (32.25, 48.88),\n",
       " (50.44, 80.66),\n",
       " (58.69, 95.56),\n",
       " (90.04, 154.33),\n",
       " (51.73, 82.97),\n",
       " (47.24, 74.95),\n",
       " (47.83, 76.01),\n",
       " (52.51, 84.37),\n",
       " (47.23, 74.94),\n",
       " (29.91, 44.93),\n",
       " (43.23, 67.87),\n",
       " (97.85, 169.39),\n",
       " (43.71, 68.71),\n",
       " (32.22, 48.83),\n",
       " (58.61, 95.42),\n",
       " (18.76, 26.65),\n",
       " (32.86, 49.93),\n",
       " (67.99, 112.67),\n",
       " (48.94, 77.98),\n",
       " (55.61, 89.98),\n",
       " (29.44, 44.14),\n",
       " (36.32, 55.85),\n",
       " (24.81, 36.44),\n",
       " (30.66, 46.2),\n",
       " (59.91, 97.79),\n",
       " (88.28, 150.95),\n",
       " (25.83, 38.13),\n",
       " (28.71, 42.92),\n",
       " (33.91, 51.7),\n",
       " (44.11, 69.41),\n",
       " (38.29, 59.24),\n",
       " (63.4, 104.2),\n",
       " (47.4, 75.23),\n",
       " (31.1, 46.93),\n",
       " (32.07, 48.57),\n",
       " (95.72, 165.27),\n",
       " (98.1, 169.88),\n",
       " (70.52, 117.39),\n",
       " (57.97, 94.25),\n",
       " (26.11, 38.59),\n",
       " (34.08, 52.0),\n",
       " (40.57, 63.21),\n",
       " (36.69, 56.48),\n",
       " (49.12, 78.31),\n",
       " (33.19, 50.49),\n",
       " (57.82, 93.98),\n",
       " (48.84, 77.79),\n",
       " (50.47, 80.72),\n",
       " (44.44, 70.0),\n",
       " (50.39, 80.58),\n",
       " (27.03, 40.11),\n",
       " (64.92, 107.0),\n",
       " (33.29, 50.65),\n",
       " (41.73, 65.23),\n",
       " (35.6, 54.6),\n",
       " (29.44, 44.14),\n",
       " (35.08, 53.71),\n",
       " (65.8, 108.63),\n",
       " (23.96, 35.04),\n",
       " (32.53, 49.36),\n",
       " (31.22, 47.14),\n",
       " (48.06, 76.41),\n",
       " (29.01, 43.41),\n",
       " (24.82, 36.45),\n",
       " (76.54, 128.66),\n",
       " (44.75, 70.54),\n",
       " (61.17, 100.1),\n",
       " (47.73, 75.83),\n",
       " (30.79, 46.42),\n",
       " (42.88, 67.26),\n",
       " (52.14, 83.7),\n",
       " (29.18, 43.71),\n",
       " (62.52, 102.58),\n",
       " (54.62, 88.19),\n",
       " (53.78, 86.67),\n",
       " (29.86, 44.85),\n",
       " (46.98, 74.5),\n",
       " (37.25, 57.45),\n",
       " (31.62, 47.82),\n",
       " (29.66, 44.51),\n",
       " (69.51, 115.5),\n",
       " (53.45, 86.07),\n",
       " (33.38, 50.8),\n",
       " (29.5, 44.24),\n",
       " (41.92, 65.56),\n",
       " (31.49, 47.59),\n",
       " (39.15, 60.73),\n",
       " (27.35, 40.65),\n",
       " (52.7, 84.72),\n",
       " (47.03, 74.57),\n",
       " (29.74, 44.64),\n",
       " (41.24, 64.38),\n",
       " (82.69, 140.3),\n",
       " (49.36, 78.72),\n",
       " (28.85, 43.16),\n",
       " (42.51, 66.6),\n",
       " (34.34, 52.45),\n",
       " (40.11, 62.41),\n",
       " (47.74, 75.84),\n",
       " (31.8, 48.11),\n",
       " (45.32, 71.54),\n",
       " (66.86, 110.58),\n",
       " (24.49, 35.92),\n",
       " (28.54, 42.62),\n",
       " (56.39, 91.38),\n",
       " (81.4, 137.84),\n",
       " (61.49, 100.69),\n",
       " (48.43, 77.06),\n",
       " (52.07, 83.58),\n",
       " (47.94, 76.2),\n",
       " (63.11, 103.67),\n",
       " (37.89, 58.56),\n",
       " (48.9, 77.92),\n",
       " (48.86, 77.84),\n",
       " (41.53, 64.88),\n",
       " (27.54, 40.95),\n",
       " (50.19, 80.22),\n",
       " (90.8, 155.8),\n",
       " (37.09, 57.16),\n",
       " (32.8, 49.81),\n",
       " (55.67, 90.08),\n",
       " (39.65, 61.6),\n",
       " (26.45, 39.16),\n",
       " (34.65, 52.98),\n",
       " (49.9, 79.69),\n",
       " (29.13, 43.61),\n",
       " (46.76, 74.1),\n",
       " (24.08, 35.25),\n",
       " (56.25, 91.13),\n",
       " (51.17, 81.97),\n",
       " (52.48, 84.33),\n",
       " (54.29, 87.59),\n",
       " (47.97, 76.25),\n",
       " (49.36, 78.72),\n",
       " (31.77, 48.07),\n",
       " (30.39, 45.74),\n",
       " (34.21, 52.22),\n",
       " (79.76, 134.74),\n",
       " (31.83, 48.18),\n",
       " (70.05, 116.52),\n",
       " (33.69, 51.34),\n",
       " (56.07, 90.8),\n",
       " (46.16, 73.04),\n",
       " (48.48, 77.15),\n",
       " (24.85, 36.5),\n",
       " (52.1, 83.65),\n",
       " (58.33, 94.92),\n",
       " (30.52, 45.95),\n",
       " (27.5, 40.89),\n",
       " (29.44, 44.13),\n",
       " (44.33, 69.81),\n",
       " (62.11, 101.83),\n",
       " (61.37, 100.46),\n",
       " (66.56, 110.04),\n",
       " (61.44, 100.6),\n",
       " (30.28, 45.56),\n",
       " (26.93, 39.95),\n",
       " (56.91, 92.33),\n",
       " (31.81, 48.14),\n",
       " (36.1, 55.47),\n",
       " (22.73, 33.04),\n",
       " (54.81, 88.53),\n",
       " (30.71, 46.28),\n",
       " (53.84, 86.78),\n",
       " (46.93, 74.4),\n",
       " (99.33, 172.27),\n",
       " (35.01, 53.59),\n",
       " (51.71, 82.94),\n",
       " (57.49, 93.38),\n",
       " (30.51, 45.93),\n",
       " (47.0, 74.53),\n",
       " (54.88, 88.64),\n",
       " (64.2, 105.68),\n",
       " (30.19, 45.39),\n",
       " (44.61, 70.3),\n",
       " (34.2, 52.21),\n",
       " (31.57, 47.73),\n",
       " (51.21, 82.05),\n",
       " (49.91, 79.7),\n",
       " (35.74, 54.84),\n",
       " (42.31, 66.25),\n",
       " (74.3, 124.46),\n",
       " (30.62, 46.12),\n",
       " (26.1, 38.56),\n",
       " (30.49, 45.9),\n",
       " (57.78, 93.91),\n",
       " (70.97, 118.23),\n",
       " (42.17, 66.0),\n",
       " (73.24, 122.46),\n",
       " (64.71, 106.61),\n",
       " (27.51, 40.91),\n",
       " (32.0, 48.46),\n",
       " (38.21, 59.11),\n",
       " (57.79, 93.93),\n",
       " (88.52, 151.41),\n",
       " (47.27, 75.01),\n",
       " (53.45, 86.07),\n",
       " (30.62, 46.12),\n",
       " (34.96, 53.5),\n",
       " (62.05, 101.72),\n",
       " (27.05, 40.15),\n",
       " (29.06, 43.51),\n",
       " (27.61, 41.08),\n",
       " (34.51, 52.74),\n",
       " (30.28, 45.55),\n",
       " (60.61, 99.07),\n",
       " (64.27, 105.8),\n",
       " (73.7, 123.33),\n",
       " (50.77, 81.25),\n",
       " (47.26, 74.99),\n",
       " (68.65, 113.91),\n",
       " (41.55, 64.91),\n",
       " (26.19, 38.72),\n",
       " (102.07, 177.6),\n",
       " (29.69, 44.55),\n",
       " (35.25, 54.01),\n",
       " (29.85, 44.82),\n",
       " (68.56, 113.74),\n",
       " (35.58, 54.56),\n",
       " (62.96, 103.4),\n",
       " (29.07, 43.51),\n",
       " (62.79, 103.08),\n",
       " (107.73, 188.67),\n",
       " (42.79, 67.08),\n",
       " (46.26, 73.22),\n",
       " (29.32, 43.94),\n",
       " (42.17, 66.0),\n",
       " (58.84, 95.84),\n",
       " (30.29, 45.57),\n",
       " (55.49, 89.76),\n",
       " (69.77, 115.98),\n",
       " (25.91, 38.26),\n",
       " (26.48, 39.2),\n",
       " (25.5, 37.57),\n",
       " (33.18, 50.47),\n",
       " (30.21, 45.43),\n",
       " (58.36, 94.97),\n",
       " (42.99, 67.44),\n",
       " (31.62, 47.81),\n",
       " (56.25, 91.13),\n",
       " (40.78, 63.57),\n",
       " (51.85, 83.18),\n",
       " (25.12, 36.96),\n",
       " (30.38, 45.72),\n",
       " (63.32, 104.04),\n",
       " (30.7, 46.26),\n",
       " (33.92, 51.73),\n",
       " (31.15, 47.02),\n",
       " (54.98, 88.82),\n",
       " (17.36, 24.44),\n",
       " (61.67, 101.01),\n",
       " (42.89, 67.27),\n",
       " (44.52, 70.14),\n",
       " (26.1, 38.58),\n",
       " (56.58, 91.73),\n",
       " (31.77, 48.06),\n",
       " (62.7, 102.91),\n",
       " (29.56, 44.34),\n",
       " (23.95, 35.03),\n",
       " (33.53, 51.06),\n",
       " (30.89, 46.58),\n",
       " (31.8, 48.13),\n",
       " (58.65, 95.49),\n",
       " (45.97, 72.69),\n",
       " (43.58, 68.48),\n",
       " (45.13, 71.22),\n",
       " (48.54, 77.27),\n",
       " (36.8, 56.66),\n",
       " (30.76, 46.36),\n",
       " (42.6, 66.76),\n",
       " (46.12, 72.97),\n",
       " (71.6, 119.41),\n",
       " (30.19, 45.4),\n",
       " (34.67, 53.01),\n",
       " (53.37, 85.93),\n",
       " (98.77, 171.18),\n",
       " (50.99, 81.65),\n",
       " (89.19, 152.7),\n",
       " (34.84, 53.3),\n",
       " (49.07, 78.21),\n",
       " (35.2, 53.91),\n",
       " ...)"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_rf_reg = tuple([(round(math.exp(el-el*MAPE_median_rf_reg),2),round(math.exp(el+el*MAPE_median_rf_reg),2)) for el in y_test_pred_rf_reg])\n",
    "y_pred_interval_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_rf_reg, title=\"best_model_rf_reg_02\", save=\"joblib\")\n",
    "save_model(grid_rf_reg, title=\"best_cv_rf_reg_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 4: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_cat_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('cat_reg',\n",
    "                              CatBoostRegressor(n_estimators=150,\n",
    "                                                learning_rate=0.3,\n",
    "                                                l2_leaf_reg=4,\n",
    "                                                loss_function=\"RMSE\",\n",
    "                                                random_state=random_state,\n",
    "                                                depth=4))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss_function'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_cat_reg = CatBoostRegressor()\n",
    "test_cat_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for CatBoostRegressor** (as base for hyperparameter search):\n",
    "\n",
    "iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, boost_from_average=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_cat_reg = {\n",
    "    'cat_reg__n_estimators': randint(low=130, high=180),    # initial: randint(low=10, high=200)\n",
    "    'cat_reg__l2_leaf_reg': randint(low=2, high=11),       # initial: randint(low=1, high=15)\n",
    "    'cat_reg__depth': randint(low=4, high=6),             # initial: randint(low=1, high=15)\n",
    "    'cat_reg__learning_rate': [0.15, 0.18, 0.2, 0.22, 0.25, 0.27, 0.3] # initial: [0.01, 0.02, 0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   32.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5156745\ttotal: 56.2ms\tremaining: 8.38s\n",
      "1:\tlearn: 0.4715264\ttotal: 59.1ms\tremaining: 4.38s\n",
      "2:\tlearn: 0.4446813\ttotal: 61.6ms\tremaining: 3.02s\n",
      "3:\tlearn: 0.4253420\ttotal: 63.3ms\tremaining: 2.31s\n",
      "4:\tlearn: 0.4137535\ttotal: 65ms\tremaining: 1.88s\n",
      "5:\tlearn: 0.4061849\ttotal: 66.6ms\tremaining: 1.6s\n",
      "6:\tlearn: 0.3988524\ttotal: 68.2ms\tremaining: 1.39s\n",
      "7:\tlearn: 0.3923261\ttotal: 70.5ms\tremaining: 1.25s\n",
      "8:\tlearn: 0.3884186\ttotal: 72.6ms\tremaining: 1.14s\n",
      "9:\tlearn: 0.3844157\ttotal: 74.9ms\tremaining: 1.05s\n",
      "10:\tlearn: 0.3792050\ttotal: 76.5ms\tremaining: 967ms\n",
      "11:\tlearn: 0.3759227\ttotal: 78.2ms\tremaining: 899ms\n",
      "12:\tlearn: 0.3738849\ttotal: 79.8ms\tremaining: 841ms\n",
      "13:\tlearn: 0.3711826\ttotal: 84.6ms\tremaining: 822ms\n",
      "14:\tlearn: 0.3690398\ttotal: 86.8ms\tremaining: 782ms\n",
      "15:\tlearn: 0.3676172\ttotal: 90.2ms\tremaining: 756ms\n",
      "16:\tlearn: 0.3664609\ttotal: 93.6ms\tremaining: 732ms\n",
      "17:\tlearn: 0.3652486\ttotal: 96.9ms\tremaining: 711ms\n",
      "18:\tlearn: 0.3636378\ttotal: 102ms\tremaining: 701ms\n",
      "19:\tlearn: 0.3626866\ttotal: 105ms\tremaining: 683ms\n",
      "20:\tlearn: 0.3615922\ttotal: 108ms\tremaining: 666ms\n",
      "21:\tlearn: 0.3606316\ttotal: 111ms\tremaining: 648ms\n",
      "22:\tlearn: 0.3599045\ttotal: 114ms\tremaining: 629ms\n",
      "23:\tlearn: 0.3588181\ttotal: 116ms\tremaining: 608ms\n",
      "24:\tlearn: 0.3578041\ttotal: 118ms\tremaining: 589ms\n",
      "25:\tlearn: 0.3571799\ttotal: 120ms\tremaining: 574ms\n",
      "26:\tlearn: 0.3567110\ttotal: 122ms\tremaining: 557ms\n",
      "27:\tlearn: 0.3562614\ttotal: 124ms\tremaining: 540ms\n",
      "28:\tlearn: 0.3556330\ttotal: 126ms\tremaining: 525ms\n",
      "29:\tlearn: 0.3547122\ttotal: 134ms\tremaining: 536ms\n",
      "30:\tlearn: 0.3538362\ttotal: 136ms\tremaining: 523ms\n",
      "31:\tlearn: 0.3532727\ttotal: 138ms\tremaining: 508ms\n",
      "32:\tlearn: 0.3525632\ttotal: 139ms\tremaining: 494ms\n",
      "33:\tlearn: 0.3519219\ttotal: 141ms\tremaining: 482ms\n",
      "34:\tlearn: 0.3515075\ttotal: 143ms\tremaining: 469ms\n",
      "35:\tlearn: 0.3504554\ttotal: 144ms\tremaining: 457ms\n",
      "36:\tlearn: 0.3499939\ttotal: 146ms\tremaining: 446ms\n",
      "37:\tlearn: 0.3495363\ttotal: 148ms\tremaining: 436ms\n",
      "38:\tlearn: 0.3488971\ttotal: 150ms\tremaining: 427ms\n",
      "39:\tlearn: 0.3482987\ttotal: 152ms\tremaining: 417ms\n",
      "40:\tlearn: 0.3478623\ttotal: 153ms\tremaining: 407ms\n",
      "41:\tlearn: 0.3474393\ttotal: 155ms\tremaining: 398ms\n",
      "42:\tlearn: 0.3470653\ttotal: 157ms\tremaining: 390ms\n",
      "43:\tlearn: 0.3467111\ttotal: 158ms\tremaining: 381ms\n",
      "44:\tlearn: 0.3463205\ttotal: 160ms\tremaining: 373ms\n",
      "45:\tlearn: 0.3456799\ttotal: 161ms\tremaining: 365ms\n",
      "46:\tlearn: 0.3451785\ttotal: 163ms\tremaining: 357ms\n",
      "47:\tlearn: 0.3446600\ttotal: 165ms\tremaining: 350ms\n",
      "48:\tlearn: 0.3442779\ttotal: 166ms\tremaining: 343ms\n",
      "49:\tlearn: 0.3438892\ttotal: 168ms\tremaining: 336ms\n",
      "50:\tlearn: 0.3435264\ttotal: 171ms\tremaining: 332ms\n",
      "51:\tlearn: 0.3432239\ttotal: 173ms\tremaining: 325ms\n",
      "52:\tlearn: 0.3430411\ttotal: 174ms\tremaining: 319ms\n",
      "53:\tlearn: 0.3427924\ttotal: 176ms\tremaining: 312ms\n",
      "54:\tlearn: 0.3423100\ttotal: 177ms\tremaining: 306ms\n",
      "55:\tlearn: 0.3419919\ttotal: 179ms\tremaining: 300ms\n",
      "56:\tlearn: 0.3415895\ttotal: 180ms\tremaining: 294ms\n",
      "57:\tlearn: 0.3412937\ttotal: 182ms\tremaining: 289ms\n",
      "58:\tlearn: 0.3409619\ttotal: 184ms\tremaining: 284ms\n",
      "59:\tlearn: 0.3405364\ttotal: 186ms\tremaining: 278ms\n",
      "60:\tlearn: 0.3403101\ttotal: 187ms\tremaining: 273ms\n",
      "61:\tlearn: 0.3398384\ttotal: 189ms\tremaining: 268ms\n",
      "62:\tlearn: 0.3394284\ttotal: 190ms\tremaining: 263ms\n",
      "63:\tlearn: 0.3392517\ttotal: 192ms\tremaining: 258ms\n",
      "64:\tlearn: 0.3387710\ttotal: 195ms\tremaining: 255ms\n",
      "65:\tlearn: 0.3385583\ttotal: 197ms\tremaining: 251ms\n",
      "66:\tlearn: 0.3382639\ttotal: 199ms\tremaining: 247ms\n",
      "67:\tlearn: 0.3380193\ttotal: 201ms\tremaining: 242ms\n",
      "68:\tlearn: 0.3376276\ttotal: 203ms\tremaining: 238ms\n",
      "69:\tlearn: 0.3373411\ttotal: 204ms\tremaining: 233ms\n",
      "70:\tlearn: 0.3369830\ttotal: 206ms\tremaining: 229ms\n",
      "71:\tlearn: 0.3368016\ttotal: 207ms\tremaining: 225ms\n",
      "72:\tlearn: 0.3365521\ttotal: 209ms\tremaining: 220ms\n",
      "73:\tlearn: 0.3362814\ttotal: 211ms\tremaining: 216ms\n",
      "74:\tlearn: 0.3359669\ttotal: 212ms\tremaining: 212ms\n",
      "75:\tlearn: 0.3355368\ttotal: 214ms\tremaining: 208ms\n",
      "76:\tlearn: 0.3351935\ttotal: 216ms\tremaining: 205ms\n",
      "77:\tlearn: 0.3349827\ttotal: 217ms\tremaining: 201ms\n",
      "78:\tlearn: 0.3347002\ttotal: 219ms\tremaining: 197ms\n",
      "79:\tlearn: 0.3344475\ttotal: 221ms\tremaining: 193ms\n",
      "80:\tlearn: 0.3341828\ttotal: 223ms\tremaining: 190ms\n",
      "81:\tlearn: 0.3339178\ttotal: 224ms\tremaining: 186ms\n",
      "82:\tlearn: 0.3336587\ttotal: 226ms\tremaining: 182ms\n",
      "83:\tlearn: 0.3334073\ttotal: 228ms\tremaining: 179ms\n",
      "84:\tlearn: 0.3332704\ttotal: 229ms\tremaining: 175ms\n",
      "85:\tlearn: 0.3329615\ttotal: 231ms\tremaining: 172ms\n",
      "86:\tlearn: 0.3327695\ttotal: 233ms\tremaining: 169ms\n",
      "87:\tlearn: 0.3324548\ttotal: 234ms\tremaining: 165ms\n",
      "88:\tlearn: 0.3322399\ttotal: 236ms\tremaining: 162ms\n",
      "89:\tlearn: 0.3321300\ttotal: 238ms\tremaining: 159ms\n",
      "90:\tlearn: 0.3318427\ttotal: 239ms\tremaining: 155ms\n",
      "91:\tlearn: 0.3315394\ttotal: 242ms\tremaining: 152ms\n",
      "92:\tlearn: 0.3313981\ttotal: 244ms\tremaining: 150ms\n",
      "93:\tlearn: 0.3311907\ttotal: 246ms\tremaining: 147ms\n",
      "94:\tlearn: 0.3308942\ttotal: 249ms\tremaining: 144ms\n",
      "95:\tlearn: 0.3307364\ttotal: 251ms\tremaining: 141ms\n",
      "96:\tlearn: 0.3304872\ttotal: 254ms\tremaining: 139ms\n",
      "97:\tlearn: 0.3302972\ttotal: 256ms\tremaining: 136ms\n",
      "98:\tlearn: 0.3301278\ttotal: 257ms\tremaining: 133ms\n",
      "99:\tlearn: 0.3299816\ttotal: 259ms\tremaining: 130ms\n",
      "100:\tlearn: 0.3298081\ttotal: 261ms\tremaining: 127ms\n",
      "101:\tlearn: 0.3296680\ttotal: 262ms\tremaining: 124ms\n",
      "102:\tlearn: 0.3294748\ttotal: 264ms\tremaining: 121ms\n",
      "103:\tlearn: 0.3291933\ttotal: 266ms\tremaining: 118ms\n",
      "104:\tlearn: 0.3288998\ttotal: 268ms\tremaining: 115ms\n",
      "105:\tlearn: 0.3284417\ttotal: 269ms\tremaining: 112ms\n",
      "106:\tlearn: 0.3282112\ttotal: 271ms\tremaining: 109ms\n",
      "107:\tlearn: 0.3279579\ttotal: 273ms\tremaining: 106ms\n",
      "108:\tlearn: 0.3276945\ttotal: 275ms\tremaining: 103ms\n",
      "109:\tlearn: 0.3274346\ttotal: 276ms\tremaining: 100ms\n",
      "110:\tlearn: 0.3273218\ttotal: 278ms\tremaining: 97.7ms\n",
      "111:\tlearn: 0.3270449\ttotal: 280ms\tremaining: 94.8ms\n",
      "112:\tlearn: 0.3269065\ttotal: 281ms\tremaining: 92.1ms\n",
      "113:\tlearn: 0.3267576\ttotal: 283ms\tremaining: 89.3ms\n",
      "114:\tlearn: 0.3265349\ttotal: 285ms\tremaining: 86.6ms\n",
      "115:\tlearn: 0.3262570\ttotal: 286ms\tremaining: 83.9ms\n",
      "116:\tlearn: 0.3260782\ttotal: 288ms\tremaining: 81.2ms\n",
      "117:\tlearn: 0.3258121\ttotal: 290ms\tremaining: 78.5ms\n",
      "118:\tlearn: 0.3255299\ttotal: 291ms\tremaining: 75.9ms\n",
      "119:\tlearn: 0.3254062\ttotal: 293ms\tremaining: 73.2ms\n",
      "120:\tlearn: 0.3251153\ttotal: 295ms\tremaining: 70.6ms\n",
      "121:\tlearn: 0.3249024\ttotal: 296ms\tremaining: 68ms\n",
      "122:\tlearn: 0.3246833\ttotal: 298ms\tremaining: 65.4ms\n",
      "123:\tlearn: 0.3245288\ttotal: 300ms\tremaining: 62.8ms\n",
      "124:\tlearn: 0.3243083\ttotal: 301ms\tremaining: 60.2ms\n",
      "125:\tlearn: 0.3241110\ttotal: 303ms\tremaining: 57.7ms\n",
      "126:\tlearn: 0.3240175\ttotal: 305ms\tremaining: 55.3ms\n",
      "127:\tlearn: 0.3239073\ttotal: 307ms\tremaining: 52.8ms\n",
      "128:\tlearn: 0.3237592\ttotal: 310ms\tremaining: 50.4ms\n",
      "129:\tlearn: 0.3235187\ttotal: 311ms\tremaining: 47.9ms\n",
      "130:\tlearn: 0.3233032\ttotal: 313ms\tremaining: 45.4ms\n",
      "131:\tlearn: 0.3231295\ttotal: 315ms\tremaining: 42.9ms\n",
      "132:\tlearn: 0.3230112\ttotal: 316ms\tremaining: 40.4ms\n",
      "133:\tlearn: 0.3229219\ttotal: 318ms\tremaining: 37.9ms\n",
      "134:\tlearn: 0.3227752\ttotal: 320ms\tremaining: 35.5ms\n",
      "135:\tlearn: 0.3226258\ttotal: 321ms\tremaining: 33.1ms\n",
      "136:\tlearn: 0.3223883\ttotal: 323ms\tremaining: 30.6ms\n",
      "137:\tlearn: 0.3221469\ttotal: 324ms\tremaining: 28.2ms\n",
      "138:\tlearn: 0.3219916\ttotal: 326ms\tremaining: 25.8ms\n",
      "139:\tlearn: 0.3217714\ttotal: 328ms\tremaining: 23.4ms\n",
      "140:\tlearn: 0.3216569\ttotal: 330ms\tremaining: 21ms\n",
      "141:\tlearn: 0.3214718\ttotal: 331ms\tremaining: 18.7ms\n",
      "142:\tlearn: 0.3212085\ttotal: 333ms\tremaining: 16.3ms\n",
      "143:\tlearn: 0.3210752\ttotal: 335ms\tremaining: 13.9ms\n",
      "144:\tlearn: 0.3209054\ttotal: 336ms\tremaining: 11.6ms\n",
      "145:\tlearn: 0.3207443\ttotal: 338ms\tremaining: 9.26ms\n",
      "146:\tlearn: 0.3205706\ttotal: 340ms\tremaining: 6.93ms\n",
      "147:\tlearn: 0.3203032\ttotal: 341ms\tremaining: 4.61ms\n",
      "148:\tlearn: 0.3201629\ttotal: 343ms\tremaining: 2.3ms\n",
      "149:\tlearn: 0.3200266\ttotal: 344ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_cat_reg = RandomizedSearchCV(pipeline_cat_reg,\n",
    "                                 param_distribs_cat_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=15,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_cat_reg = rnd_cat_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.21\n",
      "Best parameters:\n",
      "{'cat_reg__depth': 4, 'cat_reg__l2_leaf_reg': 4, 'cat_reg__learning_rate': 0.3, 'cat_reg__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_cat_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_cat_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_cat_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_cat_reg = {\n",
    "#    'cat_reg__n_estimators': [150, 155],\n",
    "#    'cat_reg__l2_leaf_reg': [3, 4],\n",
    "    'cat_reg__depth': [4, 5],\n",
    "#    'cat_reg__learning_rate': [0.15, 0.2, 0.25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    6.7s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5156745\ttotal: 2.05ms\tremaining: 306ms\n",
      "1:\tlearn: 0.4715264\ttotal: 3.86ms\tremaining: 286ms\n",
      "2:\tlearn: 0.4446813\ttotal: 5.6ms\tremaining: 274ms\n",
      "3:\tlearn: 0.4253420\ttotal: 7.27ms\tremaining: 266ms\n",
      "4:\tlearn: 0.4137535\ttotal: 8.93ms\tremaining: 259ms\n",
      "5:\tlearn: 0.4061849\ttotal: 10.5ms\tremaining: 253ms\n",
      "6:\tlearn: 0.3988524\ttotal: 12.2ms\tremaining: 249ms\n",
      "7:\tlearn: 0.3923261\ttotal: 13.8ms\tremaining: 245ms\n",
      "8:\tlearn: 0.3884186\ttotal: 15.5ms\tremaining: 243ms\n",
      "9:\tlearn: 0.3844157\ttotal: 17.2ms\tremaining: 241ms\n",
      "10:\tlearn: 0.3792050\ttotal: 18.8ms\tremaining: 238ms\n",
      "11:\tlearn: 0.3759227\ttotal: 20.5ms\tremaining: 236ms\n",
      "12:\tlearn: 0.3738849\ttotal: 22.1ms\tremaining: 233ms\n",
      "13:\tlearn: 0.3711826\ttotal: 23.8ms\tremaining: 231ms\n",
      "14:\tlearn: 0.3690398\ttotal: 25.4ms\tremaining: 229ms\n",
      "15:\tlearn: 0.3676172\ttotal: 27ms\tremaining: 226ms\n",
      "16:\tlearn: 0.3664609\ttotal: 28.9ms\tremaining: 226ms\n",
      "17:\tlearn: 0.3652486\ttotal: 31.7ms\tremaining: 232ms\n",
      "18:\tlearn: 0.3636378\ttotal: 34.4ms\tremaining: 237ms\n",
      "19:\tlearn: 0.3626866\ttotal: 36.1ms\tremaining: 234ms\n",
      "20:\tlearn: 0.3615922\ttotal: 37.8ms\tremaining: 232ms\n",
      "21:\tlearn: 0.3606316\ttotal: 39.5ms\tremaining: 230ms\n",
      "22:\tlearn: 0.3599045\ttotal: 41.1ms\tremaining: 227ms\n",
      "23:\tlearn: 0.3588181\ttotal: 42.6ms\tremaining: 224ms\n",
      "24:\tlearn: 0.3578041\ttotal: 44.3ms\tremaining: 222ms\n",
      "25:\tlearn: 0.3571799\ttotal: 45.9ms\tremaining: 219ms\n",
      "26:\tlearn: 0.3567110\ttotal: 47.6ms\tremaining: 217ms\n",
      "27:\tlearn: 0.3562614\ttotal: 49.1ms\tremaining: 214ms\n",
      "28:\tlearn: 0.3556330\ttotal: 50.8ms\tremaining: 212ms\n",
      "29:\tlearn: 0.3547122\ttotal: 52.5ms\tremaining: 210ms\n",
      "30:\tlearn: 0.3538362\ttotal: 54.1ms\tremaining: 208ms\n",
      "31:\tlearn: 0.3532727\ttotal: 55.6ms\tremaining: 205ms\n",
      "32:\tlearn: 0.3525632\ttotal: 57.2ms\tremaining: 203ms\n",
      "33:\tlearn: 0.3519219\ttotal: 58.8ms\tremaining: 200ms\n",
      "34:\tlearn: 0.3515075\ttotal: 60.2ms\tremaining: 198ms\n",
      "35:\tlearn: 0.3504554\ttotal: 61.7ms\tremaining: 195ms\n",
      "36:\tlearn: 0.3499939\ttotal: 63.3ms\tremaining: 193ms\n",
      "37:\tlearn: 0.3495363\ttotal: 64.8ms\tremaining: 191ms\n",
      "38:\tlearn: 0.3488971\ttotal: 66.3ms\tremaining: 189ms\n",
      "39:\tlearn: 0.3482987\ttotal: 67.9ms\tremaining: 187ms\n",
      "40:\tlearn: 0.3478623\ttotal: 69.4ms\tremaining: 185ms\n",
      "41:\tlearn: 0.3474393\ttotal: 71ms\tremaining: 183ms\n",
      "42:\tlearn: 0.3470653\ttotal: 72.6ms\tremaining: 181ms\n",
      "43:\tlearn: 0.3467111\ttotal: 74ms\tremaining: 178ms\n",
      "44:\tlearn: 0.3463205\ttotal: 75.6ms\tremaining: 176ms\n",
      "45:\tlearn: 0.3456799\ttotal: 77.1ms\tremaining: 174ms\n",
      "46:\tlearn: 0.3451785\ttotal: 78.8ms\tremaining: 173ms\n",
      "47:\tlearn: 0.3446600\ttotal: 80.2ms\tremaining: 170ms\n",
      "48:\tlearn: 0.3442779\ttotal: 81.9ms\tremaining: 169ms\n",
      "49:\tlearn: 0.3438892\ttotal: 83.5ms\tremaining: 167ms\n",
      "50:\tlearn: 0.3435264\ttotal: 85.1ms\tremaining: 165ms\n",
      "51:\tlearn: 0.3432239\ttotal: 86.7ms\tremaining: 163ms\n",
      "52:\tlearn: 0.3430411\ttotal: 88.3ms\tremaining: 162ms\n",
      "53:\tlearn: 0.3427924\ttotal: 89.8ms\tremaining: 160ms\n",
      "54:\tlearn: 0.3423100\ttotal: 91.5ms\tremaining: 158ms\n",
      "55:\tlearn: 0.3419919\ttotal: 93.1ms\tremaining: 156ms\n",
      "56:\tlearn: 0.3415895\ttotal: 94.7ms\tremaining: 154ms\n",
      "57:\tlearn: 0.3412937\ttotal: 96.2ms\tremaining: 153ms\n",
      "58:\tlearn: 0.3409619\ttotal: 97.6ms\tremaining: 151ms\n",
      "59:\tlearn: 0.3405364\ttotal: 99.1ms\tremaining: 149ms\n",
      "60:\tlearn: 0.3403101\ttotal: 101ms\tremaining: 147ms\n",
      "61:\tlearn: 0.3398384\ttotal: 102ms\tremaining: 145ms\n",
      "62:\tlearn: 0.3394284\ttotal: 104ms\tremaining: 143ms\n",
      "63:\tlearn: 0.3392517\ttotal: 105ms\tremaining: 141ms\n",
      "64:\tlearn: 0.3387710\ttotal: 107ms\tremaining: 140ms\n",
      "65:\tlearn: 0.3385583\ttotal: 108ms\tremaining: 138ms\n",
      "66:\tlearn: 0.3382639\ttotal: 110ms\tremaining: 136ms\n",
      "67:\tlearn: 0.3380193\ttotal: 112ms\tremaining: 135ms\n",
      "68:\tlearn: 0.3376276\ttotal: 113ms\tremaining: 133ms\n",
      "69:\tlearn: 0.3373411\ttotal: 115ms\tremaining: 131ms\n",
      "70:\tlearn: 0.3369830\ttotal: 116ms\tremaining: 129ms\n",
      "71:\tlearn: 0.3368016\ttotal: 119ms\tremaining: 129ms\n",
      "72:\tlearn: 0.3365521\ttotal: 121ms\tremaining: 128ms\n",
      "73:\tlearn: 0.3362814\ttotal: 125ms\tremaining: 128ms\n",
      "74:\tlearn: 0.3359669\ttotal: 127ms\tremaining: 127ms\n",
      "75:\tlearn: 0.3355368\ttotal: 130ms\tremaining: 127ms\n",
      "76:\tlearn: 0.3351935\ttotal: 133ms\tremaining: 126ms\n",
      "77:\tlearn: 0.3349827\ttotal: 135ms\tremaining: 125ms\n",
      "78:\tlearn: 0.3347002\ttotal: 138ms\tremaining: 124ms\n",
      "79:\tlearn: 0.3344475\ttotal: 141ms\tremaining: 123ms\n",
      "80:\tlearn: 0.3341828\ttotal: 143ms\tremaining: 122ms\n",
      "81:\tlearn: 0.3339178\ttotal: 146ms\tremaining: 121ms\n",
      "82:\tlearn: 0.3336587\ttotal: 149ms\tremaining: 120ms\n",
      "83:\tlearn: 0.3334073\ttotal: 152ms\tremaining: 119ms\n",
      "84:\tlearn: 0.3332704\ttotal: 154ms\tremaining: 118ms\n",
      "85:\tlearn: 0.3329615\ttotal: 157ms\tremaining: 117ms\n",
      "86:\tlearn: 0.3327695\ttotal: 160ms\tremaining: 116ms\n",
      "87:\tlearn: 0.3324548\ttotal: 162ms\tremaining: 114ms\n",
      "88:\tlearn: 0.3322399\ttotal: 165ms\tremaining: 113ms\n",
      "89:\tlearn: 0.3321300\ttotal: 168ms\tremaining: 112ms\n",
      "90:\tlearn: 0.3318427\ttotal: 171ms\tremaining: 111ms\n",
      "91:\tlearn: 0.3315394\ttotal: 173ms\tremaining: 109ms\n",
      "92:\tlearn: 0.3313981\ttotal: 176ms\tremaining: 108ms\n",
      "93:\tlearn: 0.3311907\ttotal: 179ms\tremaining: 107ms\n",
      "94:\tlearn: 0.3308942\ttotal: 182ms\tremaining: 105ms\n",
      "95:\tlearn: 0.3307364\ttotal: 184ms\tremaining: 104ms\n",
      "96:\tlearn: 0.3304872\ttotal: 193ms\tremaining: 105ms\n",
      "97:\tlearn: 0.3302972\ttotal: 196ms\tremaining: 104ms\n",
      "98:\tlearn: 0.3301278\ttotal: 199ms\tremaining: 102ms\n",
      "99:\tlearn: 0.3299816\ttotal: 201ms\tremaining: 101ms\n",
      "100:\tlearn: 0.3298081\ttotal: 205ms\tremaining: 99.3ms\n",
      "101:\tlearn: 0.3296680\ttotal: 208ms\tremaining: 97.7ms\n",
      "102:\tlearn: 0.3294748\ttotal: 211ms\tremaining: 96.1ms\n",
      "103:\tlearn: 0.3291933\ttotal: 213ms\tremaining: 94.2ms\n",
      "104:\tlearn: 0.3288998\ttotal: 220ms\tremaining: 94.3ms\n",
      "105:\tlearn: 0.3284417\ttotal: 240ms\tremaining: 99.6ms\n",
      "106:\tlearn: 0.3282112\ttotal: 249ms\tremaining: 100ms\n",
      "107:\tlearn: 0.3279579\ttotal: 252ms\tremaining: 97.9ms\n",
      "108:\tlearn: 0.3276945\ttotal: 255ms\tremaining: 95.8ms\n",
      "109:\tlearn: 0.3274346\ttotal: 258ms\tremaining: 93.7ms\n",
      "110:\tlearn: 0.3273218\ttotal: 260ms\tremaining: 91.4ms\n",
      "111:\tlearn: 0.3270449\ttotal: 263ms\tremaining: 89.3ms\n",
      "112:\tlearn: 0.3269065\ttotal: 266ms\tremaining: 87.1ms\n",
      "113:\tlearn: 0.3267576\ttotal: 268ms\tremaining: 84.8ms\n",
      "114:\tlearn: 0.3265349\ttotal: 271ms\tremaining: 82.5ms\n",
      "115:\tlearn: 0.3262570\ttotal: 274ms\tremaining: 80.2ms\n",
      "116:\tlearn: 0.3260782\ttotal: 276ms\tremaining: 77.9ms\n",
      "117:\tlearn: 0.3258121\ttotal: 279ms\tremaining: 75.6ms\n",
      "118:\tlearn: 0.3255299\ttotal: 281ms\tremaining: 73.3ms\n",
      "119:\tlearn: 0.3254062\ttotal: 284ms\tremaining: 70.9ms\n",
      "120:\tlearn: 0.3251153\ttotal: 286ms\tremaining: 68.6ms\n",
      "121:\tlearn: 0.3249024\ttotal: 289ms\tremaining: 66.3ms\n",
      "122:\tlearn: 0.3246833\ttotal: 292ms\tremaining: 64ms\n",
      "123:\tlearn: 0.3245288\ttotal: 294ms\tremaining: 61.7ms\n",
      "124:\tlearn: 0.3243083\ttotal: 297ms\tremaining: 59.4ms\n",
      "125:\tlearn: 0.3241110\ttotal: 299ms\tremaining: 57ms\n",
      "126:\tlearn: 0.3240175\ttotal: 302ms\tremaining: 54.7ms\n",
      "127:\tlearn: 0.3239073\ttotal: 305ms\tremaining: 52.4ms\n",
      "128:\tlearn: 0.3237592\ttotal: 308ms\tremaining: 50.1ms\n",
      "129:\tlearn: 0.3235187\ttotal: 310ms\tremaining: 47.7ms\n",
      "130:\tlearn: 0.3233032\ttotal: 313ms\tremaining: 45.4ms\n",
      "131:\tlearn: 0.3231295\ttotal: 315ms\tremaining: 43ms\n",
      "132:\tlearn: 0.3230112\ttotal: 318ms\tremaining: 40.6ms\n",
      "133:\tlearn: 0.3229219\ttotal: 320ms\tremaining: 38.2ms\n",
      "134:\tlearn: 0.3227752\ttotal: 325ms\tremaining: 36.1ms\n",
      "135:\tlearn: 0.3226258\ttotal: 328ms\tremaining: 33.8ms\n",
      "136:\tlearn: 0.3223883\ttotal: 332ms\tremaining: 31.5ms\n",
      "137:\tlearn: 0.3221469\ttotal: 335ms\tremaining: 29.2ms\n",
      "138:\tlearn: 0.3219916\ttotal: 338ms\tremaining: 26.8ms\n",
      "139:\tlearn: 0.3217714\ttotal: 342ms\tremaining: 24.4ms\n",
      "140:\tlearn: 0.3216569\ttotal: 345ms\tremaining: 22.1ms\n",
      "141:\tlearn: 0.3214718\ttotal: 348ms\tremaining: 19.6ms\n",
      "142:\tlearn: 0.3212085\ttotal: 350ms\tremaining: 17.1ms\n",
      "143:\tlearn: 0.3210752\ttotal: 353ms\tremaining: 14.7ms\n",
      "144:\tlearn: 0.3209054\ttotal: 355ms\tremaining: 12.2ms\n",
      "145:\tlearn: 0.3207443\ttotal: 357ms\tremaining: 9.79ms\n",
      "146:\tlearn: 0.3205706\ttotal: 359ms\tremaining: 7.33ms\n",
      "147:\tlearn: 0.3203032\ttotal: 361ms\tremaining: 4.87ms\n",
      "148:\tlearn: 0.3201629\ttotal: 362ms\tremaining: 2.43ms\n",
      "149:\tlearn: 0.3200266\ttotal: 364ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_cat_reg = GridSearchCV(pipeline_cat_reg,\n",
    "                            param_grid_cat_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_cat_reg = grid_cat_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_cat_reg = grid_cat_reg.best_estimator_['cat_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.21\n",
      "Best parameters:\n",
      "{'cat_reg__depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_cat_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_cat_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>26.286565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guests_included_calc</th>\n",
       "      <td>16.531309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>8.930682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>7.459091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>4.374038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>3.976968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>3.644855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>3.116251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>2.742996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>2.285218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>2.086127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>2.044384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>1.295996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>1.199323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>1.029342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.979650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.914955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.799838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.635093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.609731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.519959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.446088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.418396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.382304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.352048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.339346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.317086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.289523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.274139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.250104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.220446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.212931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.211363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.208315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.207173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.186717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.174545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.165627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.156364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.147665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.142440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.140259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.140064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.127645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.122959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.118526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.117447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.116138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.111415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.110128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.097169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.092408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.091821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.090102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.089251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.088703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.084653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.082553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.082079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.080125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.080096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.079670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.072279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.070528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.069041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.068826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.067492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.067416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.060743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.055726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.050831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.049768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.046901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.046462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.040891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.040370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.038390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.035851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.033664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.032196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.031547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.030952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.028832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.027474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.026787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.022666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.022045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.018978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.017703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.014574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.008796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.007173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.006850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     weight\n",
       "room_type_Private room            26.286565\n",
       "guests_included_calc              16.531309\n",
       "bedrooms                           8.930682\n",
       "calc_host_lst_count_sqrt_log       7.459091\n",
       "minimum_nights_log                 4.374038\n",
       "am_elevator                        3.976968\n",
       "property_type_Boutique hotel       3.644855\n",
       "room_type_Shared room              3.116251\n",
       "bathrooms_log                      2.742996\n",
       "accommodates_per_bed               2.285218\n",
       "am_tv                              2.086127\n",
       "zipcode_zip_other                  2.044384\n",
       "maximum_nights                     1.295996\n",
       "wk_mth_discount                    1.199323\n",
       "am_balcony                         1.029342\n",
       "zipcode_zip_10119                  0.979650\n",
       "host_is_superhost                  0.914955\n",
       "zipcode_zip_10179                  0.799838\n",
       "am_child_friendly                  0.635093\n",
       "zipcode_zip_10117                  0.609731\n",
       "am_breakfast                       0.519959\n",
       "am_smoking_allowed                 0.446088\n",
       "cancellation_policy_strict         0.418396\n",
       "zipcode_zip_13359                  0.382304\n",
       "am_private_entrance                0.352048\n",
       "instant_bookable                   0.339346\n",
       "zipcode_zip_10435                  0.317086\n",
       "zipcode_zip_10245                  0.289523\n",
       "zipcode_zip_10997                  0.274139\n",
       "zipcode_zip_10999                  0.250104\n",
       "zipcode_zip_13353                  0.220446\n",
       "property_type_House                0.212931\n",
       "zipcode_zip_13407                  0.211363\n",
       "zipcode_zip_10405                  0.208315\n",
       "cancellation_policy_moderate       0.207173\n",
       "zipcode_zip_10969                  0.186717\n",
       "zipcode_zip_12347                  0.174545\n",
       "zipcode_zip_10317                  0.165627\n",
       "am_essentials                      0.156364\n",
       "zipcode_zip_13086                  0.147665\n",
       "zipcode_zip_13347                  0.142440\n",
       "zipcode_zip_10365                  0.140259\n",
       "zipcode_zip_12047                  0.140064\n",
       "am_pets_allowed                    0.127645\n",
       "zipcode_zip_13409                  0.122959\n",
       "zipcode_zip_10553                  0.118526\n",
       "zipcode_zip_10315                  0.117447\n",
       "zipcode_zip_10589                  0.116138\n",
       "zipcode_zip_12051                  0.111415\n",
       "zipcode_zip_10719                  0.110128\n",
       "zipcode_zip_10587                  0.097169\n",
       "zipcode_zip_13189                  0.092408\n",
       "zipcode_zip_12437                  0.091821\n",
       "zipcode_zip_10318                  0.090102\n",
       "zipcode_zip_10967                  0.089251\n",
       "zipcode_zip_13351                  0.088703\n",
       "zipcode_zip_13357                  0.084653\n",
       "zipcode_zip_10785                  0.082553\n",
       "zipcode_zip_10409                  0.082079\n",
       "zipcode_zip_12055                  0.080125\n",
       "zipcode_zip_10178                  0.080096\n",
       "zipcode_zip_12435                  0.079670\n",
       "zipcode_zip_10965                  0.072279\n",
       "zipcode_zip_10555                  0.070528\n",
       "zipcode_zip_13187                  0.069041\n",
       "zipcode_zip_10243                  0.068826\n",
       "zipcode_zip_12099                  0.067492\n",
       "zipcode_zip_12059                  0.067416\n",
       "zipcode_zip_12157                  0.060743\n",
       "zipcode_zip_12043                  0.055726\n",
       "zipcode_zip_10715                  0.050831\n",
       "zipcode_zip_13349                  0.049768\n",
       "zipcode_zip_13088                  0.046901\n",
       "zipcode_zip_10777                  0.046462\n",
       "zipcode_zip_14197                  0.044444\n",
       "zipcode_zip_10963                  0.040891\n",
       "zipcode_zip_10557                  0.040370\n",
       "property_type_Bed and breakfast    0.038390\n",
       "property_type_Secondary unit       0.035851\n",
       "zipcode_zip_12101                  0.033664\n",
       "zipcode_zip_10787                  0.032196\n",
       "zipcode_zip_10367                  0.031547\n",
       "zipcode_zip_10713                  0.030952\n",
       "zipcode_zip_14059                  0.028832\n",
       "zipcode_zip_10961                  0.027474\n",
       "room_type_Hotel room               0.026787\n",
       "zipcode_zip_10827                  0.022666\n",
       "zipcode_zip_10783                  0.022045\n",
       "zipcode_zip_12103                  0.018978\n",
       "zipcode_zip_12161                  0.018600\n",
       "zipcode_zip_10629                  0.017703\n",
       "zipcode_zip_10437                  0.017000\n",
       "zipcode_zip_10249                  0.014574\n",
       "zipcode_zip_10551                  0.008796\n",
       "zipcode_zip_14057                  0.007173\n",
       "zipcode_zip_13156                  0.006850\n",
       "zipcode_zip_10585                  0.000000\n",
       "zipcode_zip_10247                  0.000000\n",
       "zipcode_zip_10829                  0.000000\n",
       "zipcode_zip_10781                  0.000000\n",
       "cancellation_policy_super_strict   0.000000\n",
       "zipcode_zip_10717                  0.000000\n",
       "zipcode_zip_10711                  0.000000\n",
       "property_type_Unique space         0.000000\n",
       "zipcode_zip_13355                  0.000000\n",
       "zipcode_zip_12045                  0.000000\n",
       "zipcode_zip_12049                  0.000000\n",
       "zipcode_zip_10707                  0.000000\n",
       "zipcode_zip_10623                  0.000000\n",
       "zipcode_zip_10407                  0.000000\n",
       "zipcode_zip_10439                  0.000000\n",
       "zipcode_zip_12053                  0.000000\n",
       "zipcode_zip_12163                  0.000000\n",
       "zipcode_zip_10823                  0.000000\n",
       "zipcode_zip_10559                  0.000000\n",
       "zipcode_zip_10627                  0.000000\n",
       "zipcode_zip_10625                  0.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_cat_reg = get_feat_importances(best_model_cat_reg)\n",
    "fi_cat_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_cat_reg = best_model_cat_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10\n",
      "RMSE: 0.32\n",
      "MAE: 0.25\n",
      "R2: 0.70\n",
      "MAPE: 6.24\n",
      "MAPE median: 4.87\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_cat_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_cat_reg = best_model_cat_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13\n",
      "RMSE: 0.35\n",
      "MAE: 0.27\n",
      "R2: 0.64\n",
      "MAPE: 6.69\n",
      "MAPE median: 5.07\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_cat_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.34024543, 0.36782985])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_cat_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_cat_reg = (median_absolute_percentage_error(y_test, y_test_pred_cat_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((74.42, 117.88),\n",
       " (54.15, 82.91),\n",
       " (42.66, 63.68),\n",
       " (26.86, 38.16),\n",
       " (53.28, 81.45),\n",
       " (39.16, 57.93),\n",
       " (38.41, 56.69),\n",
       " (75.17, 119.21),\n",
       " (93.75, 152.21),\n",
       " (39.94, 59.2),\n",
       " (64.4, 100.44),\n",
       " (38.96, 57.59),\n",
       " (34.15, 49.79),\n",
       " (128.14, 215.1),\n",
       " (35.39, 51.79),\n",
       " (72.16, 113.93),\n",
       " (35.11, 51.32),\n",
       " (130.84, 220.13),\n",
       " (26.92, 38.26),\n",
       " (62.3, 96.83),\n",
       " (68.14, 106.92),\n",
       " (67.52, 105.86),\n",
       " (23.91, 33.55),\n",
       " (76.4, 121.37),\n",
       " (42.98, 64.22),\n",
       " (38.72, 57.2),\n",
       " (78.43, 124.93),\n",
       " (68.56, 107.65),\n",
       " (74.62, 118.23),\n",
       " (48.12, 72.76),\n",
       " (103.45, 169.73),\n",
       " (34.28, 49.98),\n",
       " (35.23, 51.53),\n",
       " (28.96, 41.47),\n",
       " (52.23, 79.66),\n",
       " (120.61, 201.15),\n",
       " (37.03, 54.45),\n",
       " (36.65, 53.83),\n",
       " (27.67, 39.44),\n",
       " (37.01, 54.42),\n",
       " (48.75, 73.81),\n",
       " (41.6, 61.93),\n",
       " (53.93, 82.54),\n",
       " (24.34, 34.22),\n",
       " (80.08, 127.85),\n",
       " (55.95, 85.97),\n",
       " (116.33, 193.27),\n",
       " (103.88, 170.52),\n",
       " (26.92, 38.25),\n",
       " (35.16, 51.41),\n",
       " (51.75, 78.85),\n",
       " (51.3, 78.1),\n",
       " (83.59, 134.06),\n",
       " (57.98, 89.42),\n",
       " (23.16, 32.38),\n",
       " (61.07, 94.73),\n",
       " (124.19, 207.77),\n",
       " (37.23, 54.78),\n",
       " (62.31, 96.85),\n",
       " (46.5, 70.05),\n",
       " (55.54, 85.28),\n",
       " (61.64, 95.69),\n",
       " (163.53, 281.74),\n",
       " (24.73, 34.83),\n",
       " (114.97, 190.77),\n",
       " (55.3, 84.87),\n",
       " (64.79, 101.12),\n",
       " (32.6, 47.29),\n",
       " (32.57, 47.24),\n",
       " (34.28, 49.99),\n",
       " (47.12, 71.09),\n",
       " (49.31, 74.75),\n",
       " (36.76, 54.01),\n",
       " (45.87, 69.01),\n",
       " (27.67, 39.44),\n",
       " (53.65, 82.07),\n",
       " (38.55, 56.92),\n",
       " (74.71, 118.39),\n",
       " (33.94, 49.44),\n",
       " (35.94, 52.68),\n",
       " (44.76, 67.16),\n",
       " (23.73, 33.28),\n",
       " (35.29, 51.62),\n",
       " (49.04, 74.29),\n",
       " (49.45, 75.0),\n",
       " (32.24, 46.71),\n",
       " (70.24, 110.59),\n",
       " (69.85, 109.9),\n",
       " (29.2, 41.87),\n",
       " (34.68, 50.64),\n",
       " (97.69, 159.31),\n",
       " (41.83, 62.3),\n",
       " (55.84, 85.78),\n",
       " (29.09, 41.68),\n",
       " (68.58, 107.7),\n",
       " (59.35, 91.77),\n",
       " (59.51, 92.04),\n",
       " (31.88, 46.14),\n",
       " (55.5, 85.21),\n",
       " (51.02, 77.63),\n",
       " (61.13, 94.82),\n",
       " (42.04, 62.65),\n",
       " (42.88, 64.04),\n",
       " (297.4, 546.16),\n",
       " (59.43, 91.9),\n",
       " (63.61, 99.08),\n",
       " (89.89, 145.29),\n",
       " (70.22, 110.55),\n",
       " (47.84, 72.29),\n",
       " (176.87, 307.29),\n",
       " (41.31, 61.45),\n",
       " (31.65, 45.76),\n",
       " (28.48, 40.72),\n",
       " (33.33, 48.46),\n",
       " (29.4, 42.18),\n",
       " (72.11, 113.85),\n",
       " (42.48, 63.38),\n",
       " (31.01, 44.75),\n",
       " (76.51, 121.55),\n",
       " (32.46, 47.07),\n",
       " (64.36, 100.38),\n",
       " (43.53, 65.12),\n",
       " (60.03, 92.93),\n",
       " (33.71, 49.06),\n",
       " (46.36, 69.82),\n",
       " (31.53, 45.56),\n",
       " (45.42, 68.25),\n",
       " (46.57, 70.17),\n",
       " (43.73, 65.44),\n",
       " (53.93, 82.54),\n",
       " (38.35, 56.6),\n",
       " (77.66, 123.58),\n",
       " (38.24, 56.42),\n",
       " (39.88, 59.1),\n",
       " (40.89, 60.76),\n",
       " (24.56, 34.57),\n",
       " (33.06, 48.03),\n",
       " (57.37, 88.39),\n",
       " (33.2, 48.25),\n",
       " (53.13, 81.18),\n",
       " (31.44, 45.43),\n",
       " (116.7, 193.95),\n",
       " (35.92, 52.64),\n",
       " (32.06, 46.42),\n",
       " (47.64, 71.95),\n",
       " (42.83, 63.96),\n",
       " (52.38, 79.92),\n",
       " (135.88, 229.53),\n",
       " (34.06, 49.63),\n",
       " (51.98, 79.25),\n",
       " (82.96, 132.94),\n",
       " (22.28, 31.03),\n",
       " (68.66, 107.82),\n",
       " (33.14, 48.15),\n",
       " (27.23, 38.74),\n",
       " (28.34, 40.49),\n",
       " (67.76, 106.27),\n",
       " (23.61, 33.09),\n",
       " (28.58, 40.87),\n",
       " (50.75, 77.17),\n",
       " (91.37, 147.93),\n",
       " (47.0, 70.89),\n",
       " (43.77, 65.52),\n",
       " (46.61, 70.23),\n",
       " (27.45, 39.09),\n",
       " (66.79, 104.58),\n",
       " (36.91, 54.24),\n",
       " (31.6, 45.68),\n",
       " (55.22, 84.73),\n",
       " (47.79, 72.21),\n",
       " (81.54, 130.42),\n",
       " (52.63, 80.34),\n",
       " (56.68, 87.21),\n",
       " (45.65, 68.64),\n",
       " (36.51, 53.59),\n",
       " (52.3, 79.79),\n",
       " (48.11, 72.73),\n",
       " (26.38, 37.41),\n",
       " (80.78, 129.09),\n",
       " (68.74, 107.96),\n",
       " (55.77, 85.66),\n",
       " (23.0, 32.14),\n",
       " (49.79, 75.55),\n",
       " (49.83, 75.62),\n",
       " (91.41, 148.0),\n",
       " (147.77, 251.85),\n",
       " (57.71, 88.96),\n",
       " (75.05, 118.98),\n",
       " (33.79, 49.2),\n",
       " (28.09, 40.11),\n",
       " (102.77, 168.49),\n",
       " (56.26, 86.5),\n",
       " (41.51, 61.79),\n",
       " (27.88, 39.76),\n",
       " (45.03, 67.61),\n",
       " (45.93, 69.11),\n",
       " (39.27, 58.11),\n",
       " (56.49, 86.89),\n",
       " (132.6, 223.4),\n",
       " (34.63, 50.55),\n",
       " (103.11, 169.12),\n",
       " (57.94, 89.36),\n",
       " (58.21, 89.83),\n",
       " (54.2, 83.0),\n",
       " (62.12, 96.53),\n",
       " (57.79, 89.1),\n",
       " (33.42, 48.6),\n",
       " (48.84, 73.97),\n",
       " (41.33, 61.48),\n",
       " (58.5, 90.32),\n",
       " (55.75, 85.62),\n",
       " (31.03, 44.77),\n",
       " (25.18, 35.52),\n",
       " (99.83, 163.18),\n",
       " (56.07, 86.17),\n",
       " (54.82, 84.05),\n",
       " (36.33, 53.32),\n",
       " (31.4, 45.36),\n",
       " (23.91, 33.55),\n",
       " (51.02, 77.62),\n",
       " (77.02, 122.45),\n",
       " (41.89, 62.41),\n",
       " (42.52, 63.45),\n",
       " (60.47, 93.69),\n",
       " (25.55, 36.11),\n",
       " (49.57, 75.19),\n",
       " (28.57, 40.87),\n",
       " (48.3, 73.06),\n",
       " (47.44, 71.62),\n",
       " (67.64, 106.06),\n",
       " (55.01, 84.38),\n",
       " (29.12, 41.73),\n",
       " (26.92, 38.26),\n",
       " (63.8, 99.41),\n",
       " (52.42, 79.99),\n",
       " (28.8, 41.22),\n",
       " (100.98, 165.26),\n",
       " (40.47, 60.07),\n",
       " (43.03, 64.29),\n",
       " (26.57, 37.7),\n",
       " (126.83, 212.67),\n",
       " (59.12, 91.39),\n",
       " (51.49, 78.42),\n",
       " (57.0, 87.76),\n",
       " (50.0, 75.91),\n",
       " (13.19, 17.37),\n",
       " (61.14, 94.85),\n",
       " (27.23, 38.74),\n",
       " (32.3, 46.8),\n",
       " (54.07, 82.78),\n",
       " (126.42, 211.91),\n",
       " (69.07, 108.54),\n",
       " (24.45, 34.39),\n",
       " (59.5, 92.03),\n",
       " (40.15, 59.55),\n",
       " (32.13, 46.53),\n",
       " (90.29, 146.0),\n",
       " (57.38, 88.41),\n",
       " (39.14, 57.9),\n",
       " (28.69, 41.05),\n",
       " (83.87, 134.56),\n",
       " (32.9, 47.77),\n",
       " (27.26, 38.79),\n",
       " (155.96, 267.34),\n",
       " (33.59, 48.88),\n",
       " (32.03, 46.37),\n",
       " (28.72, 41.1),\n",
       " (28.14, 40.18),\n",
       " (52.09, 79.43),\n",
       " (56.68, 87.21),\n",
       " (61.97, 96.26),\n",
       " (33.16, 48.18),\n",
       " (28.92, 41.41),\n",
       " (92.08, 149.21),\n",
       " (43.89, 65.71),\n",
       " (50.47, 76.71),\n",
       " (42.3, 63.09),\n",
       " (27.47, 39.12),\n",
       " (51.56, 78.54),\n",
       " (66.75, 104.52),\n",
       " (97.79, 159.49),\n",
       " (67.28, 105.43),\n",
       " (35.23, 51.53),\n",
       " (51.46, 78.37),\n",
       " (106.63, 175.51),\n",
       " (51.35, 78.17),\n",
       " (42.31, 63.1),\n",
       " (104.0, 170.73),\n",
       " (87.32, 140.7),\n",
       " (30.08, 43.26),\n",
       " (26.71, 37.92),\n",
       " (81.56, 130.46),\n",
       " (28.88, 41.36),\n",
       " (34.7, 50.66),\n",
       " (82.98, 132.98),\n",
       " (82.24, 131.68),\n",
       " (85.34, 137.17),\n",
       " (39.34, 58.22),\n",
       " (79.41, 126.66),\n",
       " (112.76, 186.72),\n",
       " (34.85, 50.91),\n",
       " (89.21, 144.07),\n",
       " (37.78, 55.67),\n",
       " (26.16, 37.06),\n",
       " (58.72, 90.7),\n",
       " (29.7, 42.65),\n",
       " (34.59, 50.5),\n",
       " (26.43, 37.48),\n",
       " (56.46, 86.83),\n",
       " (21.11, 29.23),\n",
       " (62.64, 97.42),\n",
       " (29.24, 41.92),\n",
       " (123.99, 207.41),\n",
       " (86.84, 139.85),\n",
       " (60.5, 93.75),\n",
       " (33.01, 47.94),\n",
       " (106.02, 174.4),\n",
       " (27.81, 39.66),\n",
       " (43.31, 64.75),\n",
       " (46.52, 70.08),\n",
       " (89.78, 145.09),\n",
       " (55.76, 85.65),\n",
       " (15.51, 20.79),\n",
       " (74.64, 118.27),\n",
       " (18.31, 24.98),\n",
       " (87.71, 141.4),\n",
       " (54.37, 83.3),\n",
       " (27.68, 39.46),\n",
       " (28.83, 41.27),\n",
       " (22.99, 32.12),\n",
       " (97.07, 158.18),\n",
       " (39.75, 58.88),\n",
       " (59.07, 91.3),\n",
       " (51.58, 78.57),\n",
       " (34.95, 51.08),\n",
       " (20.82, 28.79),\n",
       " (27.14, 38.61),\n",
       " (33.68, 49.02),\n",
       " (46.04, 69.28),\n",
       " (59.05, 91.25),\n",
       " (23.41, 32.78),\n",
       " (95.54, 155.43),\n",
       " (16.44, 22.16),\n",
       " (58.39, 90.12),\n",
       " (53.21, 81.32),\n",
       " (48.86, 74.0),\n",
       " (37.88, 55.82),\n",
       " (30.59, 44.08),\n",
       " (39.83, 59.02),\n",
       " (60.7, 94.08),\n",
       " (32.75, 47.52),\n",
       " (95.2, 154.82),\n",
       " (27.17, 38.66),\n",
       " (31.25, 45.12),\n",
       " (28.74, 41.13),\n",
       " (54.12, 82.86),\n",
       " (44.05, 65.98),\n",
       " (59.16, 91.45),\n",
       " (62.99, 98.01),\n",
       " (32.25, 46.73),\n",
       " (106.6, 175.47),\n",
       " (38.7, 57.16),\n",
       " (178.8, 311.0),\n",
       " (30.01, 43.15),\n",
       " (62.46, 97.1),\n",
       " (95.57, 155.48),\n",
       " (71.17, 112.2),\n",
       " (68.32, 107.24),\n",
       " (73.32, 115.96),\n",
       " (27.56, 39.26),\n",
       " (63.94, 99.65),\n",
       " (63.25, 98.46),\n",
       " (69.05, 108.51),\n",
       " (41.13, 61.16),\n",
       " (30.32, 43.64),\n",
       " (133.28, 224.68),\n",
       " (90.22, 145.89),\n",
       " (28.99, 41.52),\n",
       " (29.42, 42.2),\n",
       " (85.47, 137.4),\n",
       " (36.62, 53.77),\n",
       " (127.32, 213.57),\n",
       " (35.91, 52.62),\n",
       " (47.52, 71.76),\n",
       " (27.58, 39.3),\n",
       " (54.76, 83.95),\n",
       " (32.87, 47.71),\n",
       " (31.42, 45.4),\n",
       " (33.89, 49.37),\n",
       " (58.93, 91.05),\n",
       " (36.13, 52.98),\n",
       " (55.04, 84.42),\n",
       " (67.99, 106.66),\n",
       " (26.49, 37.58),\n",
       " (53.85, 82.4),\n",
       " (103.12, 169.13),\n",
       " (33.46, 48.66),\n",
       " (88.36, 142.55),\n",
       " (63.03, 98.09),\n",
       " (59.33, 91.73),\n",
       " (25.45, 35.96),\n",
       " (29.92, 43.0),\n",
       " (83.34, 133.62),\n",
       " (35.18, 51.44),\n",
       " (39.14, 57.89),\n",
       " (40.77, 60.57),\n",
       " (22.5, 31.36),\n",
       " (85.28, 137.06),\n",
       " (26.77, 38.02),\n",
       " (50.24, 76.32),\n",
       " (116.7, 193.95),\n",
       " (69.83, 109.86),\n",
       " (48.66, 73.67),\n",
       " (22.34, 31.12),\n",
       " (36.15, 53.02),\n",
       " (67.55, 105.91),\n",
       " (62.72, 97.55),\n",
       " (107.1, 176.37),\n",
       " (79.13, 126.18),\n",
       " (33.92, 49.4),\n",
       " (73.33, 115.98),\n",
       " (49.89, 75.73),\n",
       " (67.94, 106.58),\n",
       " (68.49, 107.53),\n",
       " (54.96, 84.29),\n",
       " (32.1, 46.48),\n",
       " (33.36, 48.5),\n",
       " (40.84, 60.68),\n",
       " (70.77, 111.5),\n",
       " (66.07, 103.34),\n",
       " (70.08, 110.29),\n",
       " (92.97, 150.8),\n",
       " (83.64, 134.14),\n",
       " (166.66, 287.73),\n",
       " (53.91, 82.5),\n",
       " (43.46, 65.01),\n",
       " (36.88, 54.2),\n",
       " (62.7, 97.51),\n",
       " (33.12, 48.13),\n",
       " (66.36, 103.83),\n",
       " (28.88, 41.36),\n",
       " (59.82, 92.58),\n",
       " (23.91, 33.55),\n",
       " (65.16, 101.77),\n",
       " (57.12, 87.97),\n",
       " (34.73, 50.72),\n",
       " (41.23, 61.33),\n",
       " (51.68, 78.74),\n",
       " (32.62, 47.32),\n",
       " (36.06, 52.87),\n",
       " (43.22, 64.61),\n",
       " (89.52, 144.63),\n",
       " (35.26, 51.57),\n",
       " (26.29, 37.26),\n",
       " (35.92, 52.64),\n",
       " (62.17, 96.6),\n",
       " (30.75, 44.33),\n",
       " (35.13, 51.37),\n",
       " (78.88, 125.74),\n",
       " (28.35, 40.51),\n",
       " (64.85, 101.23),\n",
       " (57.8, 89.12),\n",
       " (44.65, 66.97),\n",
       " (58.74, 90.72),\n",
       " (120.86, 201.62),\n",
       " (34.14, 49.77),\n",
       " (33.67, 49.0),\n",
       " (28.51, 40.77),\n",
       " (56.33, 86.61),\n",
       " (49.41, 74.92),\n",
       " (103.54, 169.9),\n",
       " (40.38, 59.93),\n",
       " (95.01, 154.47),\n",
       " (31.32, 45.24),\n",
       " (58.78, 90.8),\n",
       " (59.26, 91.62),\n",
       " (100.64, 164.65),\n",
       " (31.4, 45.37),\n",
       " (35.7, 52.28),\n",
       " (32.64, 47.35),\n",
       " (41.49, 61.74),\n",
       " (44.56, 66.82),\n",
       " (52.88, 80.76),\n",
       " (57.63, 88.82),\n",
       " (27.71, 39.51),\n",
       " (54.32, 83.2),\n",
       " (27.96, 39.89),\n",
       " (80.99, 129.46),\n",
       " (30.28, 43.58),\n",
       " (60.03, 92.93),\n",
       " (74.86, 118.65),\n",
       " (55.19, 84.68),\n",
       " (40.15, 59.54),\n",
       " (61.35, 95.2),\n",
       " (44.75, 67.13),\n",
       " (36.71, 53.92),\n",
       " (63.1, 98.21),\n",
       " (56.41, 86.75),\n",
       " (41.29, 61.41),\n",
       " (68.13, 106.9),\n",
       " (42.03, 62.64),\n",
       " (24.8, 34.94),\n",
       " (48.6, 73.56),\n",
       " (38.64, 57.07),\n",
       " (68.68, 107.86),\n",
       " (34.65, 50.6),\n",
       " (45.8, 68.89),\n",
       " (30.3, 43.6),\n",
       " (30.13, 43.34),\n",
       " (77.06, 122.53),\n",
       " (69.32, 108.97),\n",
       " (27.93, 39.85),\n",
       " (43.99, 65.88),\n",
       " (52.54, 80.19),\n",
       " (121.79, 203.33),\n",
       " (24.36, 34.25),\n",
       " (41.38, 61.56),\n",
       " (30.47, 43.87),\n",
       " (30.14, 43.35),\n",
       " (116.35, 193.3),\n",
       " (43.46, 65.0),\n",
       " (36.23, 53.15),\n",
       " (66.31, 103.76),\n",
       " (26.54, 37.65),\n",
       " (34.48, 50.3),\n",
       " (33.77, 49.16),\n",
       " (55.66, 85.48),\n",
       " (42.89, 64.06),\n",
       " (25.14, 35.47),\n",
       " (35.11, 51.33),\n",
       " (40.79, 60.59),\n",
       " (39.28, 58.13),\n",
       " (64.03, 99.81),\n",
       " (28.71, 41.08),\n",
       " (61.18, 94.91),\n",
       " (117.0, 194.5),\n",
       " (41.76, 62.19),\n",
       " (25.15, 35.48),\n",
       " (39.33, 58.2),\n",
       " (82.12, 131.46),\n",
       " (29.89, 42.96),\n",
       " (70.99, 111.9),\n",
       " (69.32, 108.97),\n",
       " (31.35, 45.28),\n",
       " (99.99, 163.46),\n",
       " (34.13, 49.75),\n",
       " (31.94, 46.23),\n",
       " (28.95, 41.46),\n",
       " (89.97, 145.44),\n",
       " (48.11, 72.73),\n",
       " (117.57, 195.56),\n",
       " (84.37, 135.45),\n",
       " (48.67, 73.68),\n",
       " (57.68, 88.91),\n",
       " (32.59, 47.28),\n",
       " (28.11, 40.13),\n",
       " (54.57, 83.63),\n",
       " (35.57, 52.07),\n",
       " (29.93, 43.02),\n",
       " (34.4, 50.18),\n",
       " (36.42, 53.45),\n",
       " (45.76, 68.82),\n",
       " (92.7, 150.33),\n",
       " (55.92, 85.91),\n",
       " (140.63, 238.43),\n",
       " (64.34, 100.35),\n",
       " (50.05, 76.0),\n",
       " (50.76, 77.19),\n",
       " (43.81, 65.59),\n",
       " (37.22, 54.76),\n",
       " (67.71, 106.18),\n",
       " (46.4, 69.89),\n",
       " (35.93, 52.66),\n",
       " (34.4, 50.18),\n",
       " (37.59, 55.36),\n",
       " (39.71, 58.82),\n",
       " (133.64, 225.35),\n",
       " (24.59, 34.61),\n",
       " (50.98, 77.56),\n",
       " (88.65, 143.08),\n",
       " (58.49, 90.3),\n",
       " (25.91, 36.66),\n",
       " (71.19, 112.24),\n",
       " (30.55, 44.0),\n",
       " (37.44, 55.11),\n",
       " (53.65, 82.07),\n",
       " (66.94, 104.85),\n",
       " (32.88, 47.74),\n",
       " (66.47, 104.03),\n",
       " (85.28, 137.07),\n",
       " (48.22, 72.93),\n",
       " (23.29, 32.58),\n",
       " (44.65, 66.98),\n",
       " (66.05, 103.3),\n",
       " (52.07, 79.39),\n",
       " (67.36, 105.58),\n",
       " (57.04, 87.83),\n",
       " (56.64, 87.15),\n",
       " (44.28, 66.36),\n",
       " (94.3, 153.19),\n",
       " (48.88, 74.03),\n",
       " (36.02, 52.81),\n",
       " (40.73, 60.49),\n",
       " (22.49, 31.35),\n",
       " (51.92, 79.14),\n",
       " (60.76, 94.18),\n",
       " (47.08, 71.03),\n",
       " (206.62, 364.98),\n",
       " (20.97, 29.02),\n",
       " (62.56, 97.29),\n",
       " (54.12, 82.86),\n",
       " (53.46, 81.75),\n",
       " (42.96, 64.17),\n",
       " (34.64, 50.57),\n",
       " (47.06, 70.99),\n",
       " (36.07, 52.89),\n",
       " (23.92, 33.57),\n",
       " (25.24, 35.63),\n",
       " (26.44, 37.5),\n",
       " (82.77, 132.61),\n",
       " (42.25, 63.01),\n",
       " (72.64, 114.76),\n",
       " (47.2, 71.23),\n",
       " (63.2, 98.38),\n",
       " (55.89, 85.87),\n",
       " (34.73, 50.72),\n",
       " (90.94, 147.17),\n",
       " (27.04, 38.44),\n",
       " (86.66, 139.52),\n",
       " (49.19, 74.55),\n",
       " (40.2, 59.63),\n",
       " (35.34, 51.71),\n",
       " (119.55, 199.2),\n",
       " (88.06, 142.02),\n",
       " (65.37, 102.12),\n",
       " (58.94, 91.06),\n",
       " (83.81, 134.45),\n",
       " (28.55, 40.83),\n",
       " (46.84, 70.63),\n",
       " (29.51, 42.34),\n",
       " (65.5, 102.35),\n",
       " (59.1, 91.34),\n",
       " (54.29, 83.15),\n",
       " (38.18, 56.32),\n",
       " (33.17, 48.2),\n",
       " (28.08, 40.09),\n",
       " (29.63, 42.55),\n",
       " (24.34, 34.22),\n",
       " (34.94, 51.06),\n",
       " (31.6, 45.67),\n",
       " (100.15, 163.74),\n",
       " (40.16, 59.56),\n",
       " (49.33, 74.78),\n",
       " (68.87, 108.2),\n",
       " (160.37, 275.73),\n",
       " (17.71, 24.07),\n",
       " (49.83, 75.63),\n",
       " (27.04, 38.44),\n",
       " (39.25, 58.06),\n",
       " (33.29, 48.4),\n",
       " (37.01, 54.41),\n",
       " (74.0, 117.14),\n",
       " (28.31, 40.45),\n",
       " (28.75, 41.15),\n",
       " (54.14, 82.89),\n",
       " (36.29, 53.25),\n",
       " (58.51, 90.33),\n",
       " (68.98, 108.39),\n",
       " (47.24, 71.28),\n",
       " (66.18, 103.53),\n",
       " (79.83, 127.41),\n",
       " (31.31, 45.21),\n",
       " (26.06, 36.91),\n",
       " (60.69, 94.06),\n",
       " (54.55, 83.6),\n",
       " (84.96, 136.49),\n",
       " (36.28, 53.22),\n",
       " (49.69, 75.38),\n",
       " (56.13, 86.28),\n",
       " (67.1, 105.12),\n",
       " (98.33, 160.46),\n",
       " (59.81, 92.57),\n",
       " (80.72, 128.98),\n",
       " (69.45, 109.2),\n",
       " (29.48, 42.3),\n",
       " (56.24, 86.46),\n",
       " (30.45, 43.85),\n",
       " (59.8, 92.54),\n",
       " (31.52, 45.55),\n",
       " (28.72, 41.1),\n",
       " (49.67, 75.35),\n",
       " (58.41, 90.17),\n",
       " (56.0, 86.06),\n",
       " (193.36, 339.16),\n",
       " (79.18, 126.26),\n",
       " (28.84, 41.28),\n",
       " (31.53, 45.58),\n",
       " (35.1, 51.31),\n",
       " (87.49, 141.0),\n",
       " (39.76, 58.91),\n",
       " (60.0, 92.89),\n",
       " (37.74, 55.6),\n",
       " (73.77, 116.75),\n",
       " (87.74, 141.45),\n",
       " (33.39, 48.56),\n",
       " (47.55, 71.8),\n",
       " (92.95, 150.77),\n",
       " (66.55, 104.16),\n",
       " (70.0, 110.17),\n",
       " (87.3, 140.67),\n",
       " (36.94, 54.3),\n",
       " (112.81, 186.8),\n",
       " (34.19, 49.84),\n",
       " (57.73, 89.0),\n",
       " (94.41, 153.39),\n",
       " (54.83, 84.06),\n",
       " (31.21, 45.05),\n",
       " (31.15, 44.97),\n",
       " (64.33, 100.33),\n",
       " (27.71, 39.5),\n",
       " (29.17, 41.82),\n",
       " (32.78, 47.58),\n",
       " (134.14, 226.28),\n",
       " (37.66, 55.47),\n",
       " (85.49, 137.44),\n",
       " (48.2, 72.89),\n",
       " (55.43, 85.09),\n",
       " (26.38, 37.41),\n",
       " (43.51, 65.09),\n",
       " (71.09, 112.07),\n",
       " (36.27, 53.2),\n",
       " (139.9, 237.05),\n",
       " (72.44, 114.42),\n",
       " (86.59, 139.41),\n",
       " (64.36, 100.39),\n",
       " (47.64, 71.96),\n",
       " (40.19, 59.62),\n",
       " (132.32, 222.87),\n",
       " (134.58, 227.1),\n",
       " (65.37, 102.13),\n",
       " (35.8, 52.45),\n",
       " (28.06, 40.06),\n",
       " (48.47, 73.35),\n",
       " (25.06, 35.34),\n",
       " (23.26, 32.55),\n",
       " (42.36, 63.18),\n",
       " (28.98, 41.51),\n",
       " (54.96, 84.29),\n",
       " (62.09, 96.47),\n",
       " (35.98, 52.74),\n",
       " (56.52, 86.94),\n",
       " (35.45, 51.88),\n",
       " (58.9, 91.0),\n",
       " (44.02, 65.93),\n",
       " (41.59, 61.92),\n",
       " (44.29, 66.37),\n",
       " (26.96, 38.32),\n",
       " (28.86, 41.32),\n",
       " (61.47, 95.4),\n",
       " (25.63, 36.23),\n",
       " (53.99, 82.64),\n",
       " (34.62, 50.54),\n",
       " (34.25, 49.94),\n",
       " (126.83, 212.67),\n",
       " (51.79, 78.93),\n",
       " (25.13, 35.45),\n",
       " (35.26, 51.58),\n",
       " (54.74, 83.91),\n",
       " (79.62, 127.04),\n",
       " (94.55, 153.65),\n",
       " (50.58, 76.88),\n",
       " (30.94, 44.63),\n",
       " (38.28, 56.48),\n",
       " (97.13, 158.29),\n",
       " (46.5, 70.06),\n",
       " (59.19, 91.49),\n",
       " (71.93, 113.53),\n",
       " (128.17, 215.15),\n",
       " (34.18, 49.83),\n",
       " (57.7, 88.95),\n",
       " (53.48, 81.78),\n",
       " (37.38, 55.02),\n",
       " (24.74, 34.84),\n",
       " (59.48, 92.0),\n",
       " (66.81, 104.61),\n",
       " (55.69, 85.53),\n",
       " (38.6, 57.0),\n",
       " (27.27, 38.8),\n",
       " (22.59, 31.51),\n",
       " (49.42, 74.93),\n",
       " (50.48, 76.72),\n",
       " (49.58, 75.21),\n",
       " (50.29, 76.39),\n",
       " (47.82, 72.26),\n",
       " (21.83, 30.34),\n",
       " (34.24, 49.92),\n",
       " (36.09, 52.92),\n",
       " (29.99, 43.12),\n",
       " (95.77, 155.84),\n",
       " (31.62, 45.72),\n",
       " (25.25, 35.64),\n",
       " (24.88, 35.06),\n",
       " (30.88, 44.53),\n",
       " (63.53, 98.95),\n",
       " (65.58, 102.49),\n",
       " (42.91, 64.09),\n",
       " (56.11, 86.25),\n",
       " (31.91, 46.19),\n",
       " (154.35, 264.3),\n",
       " (20.35, 28.07),\n",
       " (60.75, 94.17),\n",
       " (56.91, 87.61),\n",
       " (101.14, 165.54),\n",
       " (27.56, 39.27),\n",
       " (97.61, 159.16),\n",
       " (62.9, 97.87),\n",
       " (25.46, 35.96),\n",
       " (49.95, 75.83),\n",
       " (29.31, 42.04),\n",
       " (35.22, 51.51),\n",
       " (51.6, 78.61),\n",
       " (26.25, 37.2),\n",
       " (54.32, 83.19),\n",
       " (50.77, 77.21),\n",
       " (150.92, 257.8),\n",
       " (31.62, 45.71),\n",
       " (51.66, 78.7),\n",
       " (59.97, 92.83),\n",
       " (48.88, 74.03),\n",
       " (38.99, 57.64),\n",
       " (36.56, 53.69),\n",
       " (49.82, 75.62),\n",
       " (89.55, 144.68),\n",
       " (29.17, 41.8),\n",
       " (40.77, 60.56),\n",
       " (33.24, 48.32),\n",
       " (78.65, 125.32),\n",
       " (26.05, 36.89),\n",
       " (40.02, 59.34),\n",
       " (31.63, 45.73),\n",
       " (59.6, 92.2),\n",
       " (50.06, 76.02),\n",
       " (91.81, 148.72),\n",
       " (37.03, 54.45),\n",
       " (55.44, 85.11),\n",
       " (161.5, 277.89),\n",
       " (66.93, 104.83),\n",
       " (57.04, 87.83),\n",
       " (43.92, 65.76),\n",
       " (50.51, 76.78),\n",
       " (32.17, 46.59),\n",
       " (55.14, 84.6),\n",
       " (96.45, 157.06),\n",
       " (55.0, 84.36),\n",
       " (54.87, 84.14),\n",
       " (70.58, 111.17),\n",
       " (119.84, 199.74),\n",
       " (58.51, 90.33),\n",
       " (78.68, 125.38),\n",
       " (26.73, 37.96),\n",
       " (37.03, 54.44),\n",
       " (54.22, 83.04),\n",
       " (36.91, 54.24),\n",
       " (50.96, 77.52),\n",
       " (27.88, 39.77),\n",
       " (26.91, 38.25),\n",
       " (85.27, 137.06),\n",
       " (51.62, 78.63),\n",
       " (62.45, 97.08),\n",
       " (29.41, 42.19),\n",
       " (27.99, 39.95),\n",
       " (94.76, 154.02),\n",
       " (35.13, 51.36),\n",
       " (63.98, 99.73),\n",
       " (26.21, 37.14),\n",
       " (72.43, 114.41),\n",
       " (40.27, 59.75),\n",
       " (44.61, 66.9),\n",
       " (53.43, 81.7),\n",
       " (149.01, 254.19),\n",
       " (59.16, 91.45),\n",
       " (86.97, 140.07),\n",
       " (60.26, 93.33),\n",
       " (30.88, 44.52),\n",
       " (73.8, 116.8),\n",
       " (32.13, 46.53),\n",
       " (28.19, 40.26),\n",
       " (79.83, 127.41),\n",
       " (43.08, 64.38),\n",
       " (36.81, 54.08),\n",
       " (43.4, 64.9),\n",
       " (32.5, 47.12),\n",
       " (45.97, 69.17),\n",
       " (69.82, 109.84),\n",
       " (49.49, 75.06),\n",
       " (60.91, 94.44),\n",
       " (118.37, 197.03),\n",
       " (205.95, 363.67),\n",
       " (60.71, 94.1),\n",
       " (79.72, 127.21),\n",
       " (45.32, 68.09),\n",
       " (35.67, 52.24),\n",
       " (85.12, 136.79),\n",
       " (58.56, 90.42),\n",
       " (29.45, 42.25),\n",
       " (42.79, 63.89),\n",
       " (44.59, 66.87),\n",
       " (35.37, 51.76),\n",
       " (66.71, 104.45),\n",
       " (59.92, 92.75),\n",
       " (69.38, 109.08),\n",
       " (69.07, 108.55),\n",
       " (64.43, 100.5),\n",
       " (87.16, 140.41),\n",
       " (41.78, 62.23),\n",
       " (41.72, 62.13),\n",
       " (21.99, 30.59),\n",
       " (57.38, 88.4),\n",
       " (36.57, 53.71),\n",
       " (38.0, 56.03),\n",
       " (31.29, 45.18),\n",
       " (29.81, 42.83),\n",
       " (30.27, 43.55),\n",
       " (22.97, 32.09),\n",
       " (59.11, 91.35),\n",
       " (31.61, 45.7),\n",
       " (38.29, 56.5),\n",
       " (48.12, 72.75),\n",
       " (16.6, 22.4),\n",
       " (26.83, 38.11),\n",
       " (56.26, 86.5),\n",
       " (32.65, 47.36),\n",
       " (78.73, 125.47),\n",
       " (66.91, 104.8),\n",
       " (163.64, 281.96),\n",
       " (60.4, 93.57),\n",
       " (62.96, 97.98),\n",
       " (44.06, 65.99),\n",
       " (43.12, 64.44),\n",
       " (59.66, 92.3),\n",
       " (78.41, 124.89),\n",
       " (60.78, 94.21),\n",
       " (32.91, 47.79),\n",
       " (35.53, 52.01),\n",
       " (46.57, 70.17),\n",
       " (54.42, 83.37),\n",
       " (43.96, 65.83),\n",
       " (32.7, 47.45),\n",
       " (33.76, 49.16),\n",
       " (61.33, 95.16),\n",
       " (47.14, 71.13),\n",
       " (61.75, 95.88),\n",
       " (29.08, 41.67),\n",
       " (79.12, 126.16),\n",
       " (96.78, 157.67),\n",
       " (43.3, 64.74),\n",
       " (26.35, 37.36),\n",
       " (27.86, 39.74),\n",
       " (29.25, 41.94),\n",
       " (27.98, 39.92),\n",
       " (42.73, 63.8),\n",
       " (140.7, 238.56),\n",
       " (26.54, 37.65),\n",
       " (71.22, 112.29),\n",
       " (18.91, 25.88),\n",
       " (51.77, 78.89),\n",
       " (25.86, 36.6),\n",
       " (26.85, 38.15),\n",
       " (51.72, 78.81),\n",
       " (30.48, 43.9),\n",
       " (66.79, 104.58),\n",
       " (24.94, 35.15),\n",
       " (28.94, 41.45),\n",
       " (49.86, 75.68),\n",
       " (35.71, 52.3),\n",
       " (48.91, 74.08),\n",
       " (22.96, 32.08),\n",
       " (40.75, 60.52),\n",
       " (28.41, 40.61),\n",
       " (35.19, 51.47),\n",
       " (30.86, 44.5),\n",
       " (65.01, 101.51),\n",
       " (76.46, 121.46),\n",
       " (35.98, 52.73),\n",
       " (126.12, 211.36),\n",
       " (25.81, 36.51),\n",
       " (28.2, 40.27),\n",
       " (67.55, 105.91),\n",
       " (75.48, 119.74),\n",
       " (28.41, 40.6),\n",
       " (65.67, 102.64),\n",
       " (45.3, 68.06),\n",
       " (35.84, 52.51),\n",
       " (95.42, 155.21),\n",
       " (55.73, 85.59),\n",
       " (32.45, 47.04),\n",
       " (88.79, 143.33),\n",
       " (30.8, 44.4),\n",
       " (94.64, 153.82),\n",
       " (47.33, 71.45),\n",
       " ...)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_cat_reg = tuple([(round(math.exp(el-el*MAPE_median_cat_reg),2),round(math.exp(el+el*MAPE_median_cat_reg),2)) for el in y_test_pred_cat_reg])\n",
    "y_pred_interval_cat_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_cat_reg, title=\"best_model_cat_reg_02\", save=\"joblib\")\n",
    "save_model(grid_cat_reg, title=\"best_cv_cat_reg_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model 1: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               15104     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 246,017\n",
      "Trainable params: 246,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model_nn_seq = models.Sequential()\n",
    "\n",
    "# Input Layer\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(128,\n",
    "                 input_shape=(X_train_prep.shape[1], ),\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "\n",
    "# Hidden Layers\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(256,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(256,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(512,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model_nn_seq.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model_nn_seq.compile(loss='mean_absolute_percentage_error',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['mean_absolute_percentage_error'])\n",
    "\n",
    "# Model summary\n",
    "print(model_nn_seq.summary())\n",
    "\n",
    "# Visualize the neural network\n",
    "#SVG(model_to_dot(model_nn_seq, show_layer_names=False, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline with preprocessing\n",
    "#pipeline_nn_reg = Pipeline([('preprocessor', preprocessor),\n",
    "#                             ('nn_reg',\n",
    "#                              KerasRegressor(build_fn=model_nn_seq, epochs=20, batch_size=250))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "#param_grid_nn_reg = {\n",
    "#    'xgb_reg__bootstrap': [True, False],\n",
    "#    'nn_reg__epochs': [10, 20]\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "#grid_nn_reg = GridSearchCV(pipeline_nn_reg,\n",
    "#                            param_grid_nn_reg,\n",
    "#                            cv=5,\n",
    "#                            scoring=scoring,\n",
    "#                            return_train_score=True,\n",
    "#                            verbose=4,\n",
    "#                            n_jobs=-1)\n",
    "\n",
    "#grid_nn_reg = grid_nn_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6687 samples, validate on 1672 samples\n",
      "Epoch 1/20\n",
      "6687/6687 [==============================] - 2s 314us/step - loss: 89.7828 - mean_absolute_percentage_error: 31.1804 - val_loss: 66.8553 - val_mean_absolute_percentage_error: 13.3454\n",
      "Epoch 2/20\n",
      "6687/6687 [==============================] - 1s 111us/step - loss: 60.5978 - mean_absolute_percentage_error: 11.3438 - val_loss: 55.4232 - val_mean_absolute_percentage_error: 10.7918\n",
      "Epoch 3/20\n",
      "6687/6687 [==============================] - 1s 102us/step - loss: 50.6808 - mean_absolute_percentage_error: 9.4313 - val_loss: 47.3532 - val_mean_absolute_percentage_error: 9.5435\n",
      "Epoch 4/20\n",
      "6687/6687 [==============================] - 1s 109us/step - loss: 43.7905 - mean_absolute_percentage_error: 8.2567 - val_loss: 42.2621 - val_mean_absolute_percentage_error: 9.0747\n",
      "Epoch 5/20\n",
      "6687/6687 [==============================] - 1s 110us/step - loss: 39.3247 - mean_absolute_percentage_error: 7.8196 - val_loss: 38.0525 - val_mean_absolute_percentage_error: 8.3513\n",
      "Epoch 6/20\n",
      "6687/6687 [==============================] - 1s 110us/step - loss: 35.5606 - mean_absolute_percentage_error: 7.2036 - val_loss: 34.8667 - val_mean_absolute_percentage_error: 7.9664\n",
      "Epoch 7/20\n",
      "6687/6687 [==============================] - 1s 99us/step - loss: 32.6521 - mean_absolute_percentage_error: 6.8749 - val_loss: 33.0051 - val_mean_absolute_percentage_error: 8.4440\n",
      "Epoch 8/20\n",
      "6687/6687 [==============================] - 1s 100us/step - loss: 30.4208 - mean_absolute_percentage_error: 6.8164 - val_loss: 30.2952 - val_mean_absolute_percentage_error: 7.7356\n",
      "Epoch 9/20\n",
      "6687/6687 [==============================] - 1s 95us/step - loss: 28.3000 - mean_absolute_percentage_error: 6.5524 - val_loss: 28.6824 - val_mean_absolute_percentage_error: 7.8333\n",
      "Epoch 10/20\n",
      "6687/6687 [==============================] - 1s 116us/step - loss: 26.8280 - mean_absolute_percentage_error: 6.6674 - val_loss: 27.2086 - val_mean_absolute_percentage_error: 7.8219\n",
      "Epoch 11/20\n",
      "6687/6687 [==============================] - 1s 103us/step - loss: 25.2882 - mean_absolute_percentage_error: 6.5236 - val_loss: 26.1195 - val_mean_absolute_percentage_error: 8.0444\n",
      "Epoch 12/20\n",
      "6687/6687 [==============================] - 1s 102us/step - loss: 24.1456 - mean_absolute_percentage_error: 6.6012 - val_loss: 24.4075 - val_mean_absolute_percentage_error: 7.4627\n",
      "Epoch 13/20\n",
      "6687/6687 [==============================] - 1s 105us/step - loss: 22.6931 - mean_absolute_percentage_error: 6.2169 - val_loss: 23.2822 - val_mean_absolute_percentage_error: 7.3380\n",
      "Epoch 14/20\n",
      "6687/6687 [==============================] - 1s 97us/step - loss: 21.6560 - mean_absolute_percentage_error: 6.1299 - val_loss: 22.4436 - val_mean_absolute_percentage_error: 7.3964\n",
      "Epoch 15/20\n",
      "6687/6687 [==============================] - 1s 101us/step - loss: 20.7303 - mean_absolute_percentage_error: 6.0530 - val_loss: 22.0483 - val_mean_absolute_percentage_error: 7.7939\n",
      "Epoch 16/20\n",
      "6687/6687 [==============================] - 1s 198us/step - loss: 20.0724 - mean_absolute_percentage_error: 6.1583 - val_loss: 21.2673 - val_mean_absolute_percentage_error: 7.7404\n",
      "Epoch 17/20\n",
      "6687/6687 [==============================] - 1s 99us/step - loss: 19.4878 - mean_absolute_percentage_error: 6.2767 - val_loss: 20.4185 - val_mean_absolute_percentage_error: 7.5630\n",
      "Epoch 18/20\n",
      "6687/6687 [==============================] - 1s 99us/step - loss: 18.6123 - mean_absolute_percentage_error: 6.0369 - val_loss: 19.6813 - val_mean_absolute_percentage_error: 7.4314\n",
      "Epoch 19/20\n",
      "6687/6687 [==============================] - 1s 99us/step - loss: 18.0597 - mean_absolute_percentage_error: 6.0666 - val_loss: 19.3766 - val_mean_absolute_percentage_error: 7.6821\n",
      "Epoch 20/20\n",
      "6687/6687 [==============================] - 1s 103us/step - loss: 17.4197 - mean_absolute_percentage_error: 5.9538 - val_loss: 18.4909 - val_mean_absolute_percentage_error: 7.2951\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "#model_nn_seq_start = time.time()\n",
    "\n",
    "best_model_nn_reg = model_nn_seq.fit(X_train_prep,\n",
    "                                        y_train,\n",
    "                                        epochs=20,\n",
    "                                        batch_size=256,\n",
    "                                        validation_split=0.2)\n",
    "\n",
    "#model_nn_seq_end = time.time()\n",
    "\n",
    "#print(f\"Time taken to run: {round((model_nn_seq_end - model_nn_seq_start)/60,1)} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_nn_reg = model_nn_seq.predict(X_train_prep).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.12\n",
      "RMSE: 0.35\n",
      "MAE: 0.24\n",
      "R2: 0.65\n",
      "MAPE: 6.00\n",
      "MAPE median: 4.32\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_nn_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_nn_reg = model_nn_seq.predict(X_test_prep).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19\n",
      "RMSE: 0.43\n",
      "MAE: 0.30\n",
      "R2: 0.46\n",
      "MAPE: 7.28\n",
      "MAPE median: 5.71\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_nn_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33338371, 0.5163427 ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_nn_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_nn_reg = (median_absolute_percentage_error(y_test, y_test_pred_nn_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76.21, 128.78),\n",
       " (47.52, 75.83),\n",
       " (42.57, 67.03),\n",
       " (35.37, 54.47),\n",
       " (52.86, 85.45),\n",
       " (31.0, 46.99),\n",
       " (49.25, 78.93),\n",
       " (58.77, 96.22),\n",
       " (88.07, 151.45),\n",
       " (35.64, 54.93),\n",
       " (49.49, 79.36),\n",
       " (42.4, 66.73),\n",
       " (25.6, 37.91),\n",
       " (119.62, 213.46),\n",
       " (39.5, 61.65),\n",
       " (49.85, 80.01),\n",
       " (40.22, 62.91),\n",
       " (121.34, 216.91),\n",
       " (23.29, 34.09),\n",
       " (54.51, 88.45),\n",
       " (64.33, 106.49),\n",
       " (59.03, 96.71),\n",
       " (19.32, 27.65),\n",
       " (60.08, 98.63),\n",
       " (33.06, 50.49),\n",
       " (37.39, 57.97),\n",
       " (82.24, 140.25),\n",
       " (66.38, 110.3),\n",
       " (61.23, 100.76),\n",
       " (42.61, 67.12),\n",
       " (89.37, 153.95),\n",
       " (32.02, 48.72),\n",
       " (33.87, 51.88),\n",
       " (33.27, 50.85),\n",
       " (58.86, 96.39),\n",
       " (82.13, 140.04),\n",
       " (27.08, 40.36),\n",
       " (37.42, 58.02),\n",
       " (22.35, 32.56),\n",
       " (29.78, 44.91),\n",
       " (36.74, 56.84),\n",
       " (43.94, 69.46),\n",
       " (51.04, 82.15),\n",
       " (24.64, 36.32),\n",
       " (63.25, 104.49),\n",
       " (47.15, 75.17),\n",
       " (100.33, 175.28),\n",
       " (117.78, 209.79),\n",
       " (24.19, 35.57),\n",
       " (33.99, 52.08),\n",
       " (45.11, 71.53),\n",
       " (47.77, 76.29),\n",
       " (80.43, 136.8),\n",
       " (50.81, 81.74),\n",
       " (25.09, 37.07),\n",
       " (60.44, 99.3),\n",
       " (134.47, 243.4),\n",
       " (36.31, 56.09),\n",
       " (67.44, 112.29),\n",
       " (33.44, 51.15),\n",
       " (45.57, 72.36),\n",
       " (47.63, 76.03),\n",
       " (378.0, 775.36),\n",
       " (20.98, 30.33),\n",
       " (99.15, 172.96),\n",
       " (39.84, 62.24),\n",
       " (57.45, 93.81),\n",
       " (28.7, 43.08),\n",
       " (32.16, 48.95),\n",
       " (27.63, 41.29),\n",
       " (38.35, 59.63),\n",
       " (44.81, 71.01),\n",
       " (43.98, 69.53),\n",
       " (42.01, 66.04),\n",
       " (22.57, 32.92),\n",
       " (47.3, 75.44),\n",
       " (43.2, 68.16),\n",
       " (83.99, 143.59),\n",
       " (28.42, 42.62),\n",
       " (40.18, 62.83),\n",
       " (42.31, 66.58),\n",
       " (21.92, 31.85),\n",
       " (25.47, 37.69),\n",
       " (40.76, 63.85),\n",
       " (43.9, 69.39),\n",
       " (27.09, 40.39),\n",
       " (83.14, 141.97),\n",
       " (55.35, 89.98),\n",
       " (28.34, 42.48),\n",
       " (23.74, 34.84),\n",
       " (105.12, 184.69),\n",
       " (44.43, 70.33),\n",
       " (54.81, 88.99),\n",
       " (23.6, 34.6),\n",
       " (85.59, 146.68),\n",
       " (47.85, 76.43),\n",
       " (59.07, 96.79),\n",
       " (29.28, 44.07),\n",
       " (43.13, 68.02),\n",
       " (48.24, 77.12),\n",
       " (63.18, 104.35),\n",
       " (39.31, 61.3),\n",
       " (40.72, 63.78),\n",
       " (364.38, 744.11),\n",
       " (43.72, 69.08),\n",
       " (53.5, 86.61),\n",
       " (99.99, 174.61),\n",
       " (68.07, 113.47),\n",
       " (50.36, 80.94),\n",
       " (191.73, 362.26),\n",
       " (35.28, 54.31),\n",
       " (24.67, 36.37),\n",
       " (19.76, 28.36),\n",
       " (31.68, 48.14),\n",
       " (27.11, 40.43),\n",
       " (76.06, 128.49),\n",
       " (34.95, 53.74),\n",
       " (29.06, 43.7),\n",
       " (78.19, 132.54),\n",
       " (32.78, 50.02),\n",
       " (44.96, 71.28),\n",
       " (38.21, 59.38),\n",
       " (45.37, 72.0),\n",
       " (39.44, 61.54),\n",
       " (35.56, 54.79),\n",
       " (24.65, 36.33),\n",
       " (40.0, 62.53),\n",
       " (52.44, 84.7),\n",
       " (36.45, 56.33),\n",
       " (43.64, 68.94),\n",
       " (34.07, 52.22),\n",
       " (86.49, 148.41),\n",
       " (35.45, 54.61),\n",
       " (31.71, 48.19),\n",
       " (43.34, 68.39),\n",
       " (22.8, 33.29),\n",
       " (26.91, 40.08),\n",
       " (58.85, 96.38),\n",
       " (29.21, 43.94),\n",
       " (46.03, 73.17),\n",
       " (23.98, 35.23),\n",
       " (94.76, 164.41),\n",
       " (39.36, 61.4),\n",
       " (26.08, 38.71),\n",
       " (50.18, 80.61),\n",
       " (39.64, 61.89),\n",
       " (48.72, 77.98),\n",
       " (102.97, 180.45),\n",
       " (38.36, 59.66),\n",
       " (37.29, 57.79),\n",
       " (78.56, 133.24),\n",
       " (26.07, 38.68),\n",
       " (50.93, 81.97),\n",
       " (29.68, 44.75),\n",
       " (24.45, 36.0),\n",
       " (31.58, 47.96),\n",
       " (46.59, 74.18),\n",
       " (21.43, 31.05),\n",
       " (25.17, 37.19),\n",
       " (57.55, 93.99),\n",
       " (88.94, 153.12),\n",
       " (42.55, 67.0),\n",
       " (40.1, 62.68),\n",
       " (43.66, 68.96),\n",
       " (24.41, 35.94),\n",
       " (71.14, 119.21),\n",
       " (31.05, 47.06),\n",
       " (24.95, 36.83),\n",
       " (46.12, 73.34),\n",
       " (34.27, 52.56),\n",
       " (68.17, 113.64),\n",
       " (73.8, 124.23),\n",
       " (54.91, 89.18),\n",
       " (39.47, 61.59),\n",
       " (33.59, 51.41),\n",
       " (51.16, 82.37),\n",
       " (58.75, 96.19),\n",
       " (25.45, 37.66),\n",
       " (70.17, 117.4),\n",
       " (69.18, 115.54),\n",
       " (41.46, 65.08),\n",
       " (20.31, 29.24),\n",
       " (52.99, 85.69),\n",
       " (46.04, 73.19),\n",
       " (53.31, 86.26),\n",
       " (179.31, 336.05),\n",
       " (55.04, 89.41),\n",
       " (55.56, 90.36),\n",
       " (24.18, 35.56),\n",
       " (24.24, 35.66),\n",
       " (118.44, 211.1),\n",
       " (56.61, 92.27),\n",
       " (42.22, 66.42),\n",
       " (33.54, 51.31),\n",
       " (36.06, 55.65),\n",
       " (38.14, 59.27),\n",
       " (33.52, 51.28),\n",
       " (50.21, 80.66),\n",
       " (137.06, 248.64),\n",
       " (35.86, 55.31),\n",
       " (74.62, 125.77),\n",
       " (56.26, 91.64),\n",
       " (44.16, 69.86),\n",
       " (50.82, 81.77),\n",
       " (70.4, 117.83),\n",
       " (65.27, 108.24),\n",
       " (32.45, 49.46),\n",
       " (43.25, 68.24),\n",
       " (38.12, 59.23),\n",
       " (53.49, 86.6),\n",
       " (56.24, 91.61),\n",
       " (31.21, 47.34),\n",
       " (23.5, 34.44),\n",
       " (92.55, 160.1),\n",
       " (48.82, 78.16),\n",
       " (55.97, 91.1),\n",
       " (27.78, 41.55),\n",
       " (25.19, 37.23),\n",
       " (20.15, 28.99),\n",
       " (52.1, 84.07),\n",
       " (64.87, 107.5),\n",
       " (39.45, 61.56),\n",
       " (40.11, 62.71),\n",
       " (59.82, 98.16),\n",
       " (23.05, 33.71),\n",
       " (41.95, 65.95),\n",
       " (26.51, 39.42),\n",
       " (54.23, 87.95),\n",
       " (50.31, 80.84),\n",
       " (46.12, 73.34),\n",
       " (53.57, 86.74),\n",
       " (25.58, 37.87),\n",
       " (31.26, 47.42),\n",
       " (60.53, 99.48),\n",
       " (49.54, 79.46),\n",
       " (24.64, 36.32),\n",
       " (108.7, 191.74),\n",
       " (26.55, 39.48),\n",
       " (50.33, 80.87),\n",
       " (24.42, 35.95),\n",
       " (96.66, 168.11),\n",
       " (53.29, 86.23),\n",
       " (49.55, 79.48),\n",
       " (58.98, 96.62),\n",
       " (51.1, 82.26),\n",
       " (19.44, 27.85),\n",
       " (50.05, 80.38),\n",
       " (25.79, 38.22),\n",
       " (31.45, 47.74),\n",
       " (36.56, 56.52),\n",
       " (162.88, 301.73),\n",
       " (68.75, 114.73),\n",
       " (21.15, 30.6),\n",
       " (53.77, 87.09),\n",
       " (38.72, 60.29),\n",
       " (35.57, 54.81),\n",
       " (93.96, 162.84),\n",
       " (44.2, 69.92),\n",
       " (32.57, 49.66),\n",
       " (23.62, 34.64),\n",
       " (92.85, 160.68),\n",
       " (21.86, 31.76),\n",
       " (19.25, 27.53),\n",
       " (213.73, 409.18),\n",
       " (23.34, 34.18),\n",
       " (28.69, 43.07),\n",
       " (18.94, 27.05),\n",
       " (23.39, 34.25),\n",
       " (48.81, 78.14),\n",
       " (36.27, 56.02),\n",
       " (54.08, 87.66),\n",
       " (22.98, 33.58),\n",
       " (35.39, 54.5),\n",
       " (76.75, 129.8),\n",
       " (28.75, 43.18),\n",
       " (42.48, 66.88),\n",
       " (37.9, 58.85),\n",
       " (23.13, 33.84),\n",
       " (43.29, 68.31),\n",
       " (66.73, 110.95),\n",
       " (75.72, 127.84),\n",
       " (73.39, 123.45),\n",
       " (28.68, 43.06),\n",
       " (52.66, 85.1),\n",
       " (99.07, 172.8),\n",
       " (37.96, 58.96),\n",
       " (34.33, 52.66),\n",
       " (119.75, 213.73),\n",
       " (100.87, 176.33),\n",
       " (28.84, 43.32),\n",
       " (23.85, 35.01),\n",
       " (90.9, 156.91),\n",
       " (31.1, 47.15),\n",
       " (32.16, 48.96),\n",
       " (66.7, 110.9),\n",
       " (105.27, 184.98),\n",
       " (70.34, 117.72),\n",
       " (50.76, 81.65),\n",
       " (81.72, 139.26),\n",
       " (131.41, 237.18),\n",
       " (37.95, 58.94),\n",
       " (80.97, 137.83),\n",
       " (37.88, 58.81),\n",
       " (21.91, 31.84),\n",
       " (59.15, 96.93),\n",
       " (31.82, 48.38),\n",
       " (26.84, 39.96),\n",
       " (30.77, 46.58),\n",
       " (40.59, 63.55),\n",
       " (22.21, 32.33),\n",
       " (76.03, 128.43),\n",
       " (28.05, 42.0),\n",
       " (141.44, 257.57),\n",
       " (79.47, 134.96),\n",
       " (48.13, 76.93),\n",
       " (28.8, 43.26),\n",
       " (67.33, 112.07),\n",
       " (25.86, 38.33),\n",
       " (45.76, 72.7),\n",
       " (39.18, 61.08),\n",
       " (82.66, 141.06),\n",
       " (52.39, 84.6),\n",
       " (11.56, 15.55),\n",
       " (51.67, 83.29),\n",
       " (23.11, 33.79),\n",
       " (76.46, 129.25),\n",
       " (39.57, 61.76),\n",
       " (23.33, 34.16),\n",
       " (33.19, 50.71),\n",
       " (22.08, 32.12),\n",
       " (83.56, 142.78),\n",
       " (35.38, 54.49),\n",
       " (52.62, 85.02),\n",
       " (37.07, 57.41),\n",
       " (30.37, 45.9),\n",
       " (23.0, 33.61),\n",
       " (23.33, 34.17),\n",
       " (29.07, 43.71),\n",
       " (31.19, 47.3),\n",
       " (55.63, 90.48),\n",
       " (20.83, 30.09),\n",
       " (85.91, 147.29),\n",
       " (13.88, 19.09),\n",
       " (46.12, 73.33),\n",
       " (53.77, 87.11),\n",
       " (51.87, 83.66),\n",
       " (28.68, 43.06),\n",
       " (34.04, 52.18),\n",
       " (40.05, 62.61),\n",
       " (61.39, 101.05),\n",
       " (30.17, 45.58),\n",
       " (80.46, 136.86),\n",
       " (20.43, 29.44),\n",
       " (27.17, 40.53),\n",
       " (24.27, 35.7),\n",
       " (51.47, 82.93),\n",
       " (38.96, 60.7),\n",
       " (59.91, 98.34),\n",
       " (47.6, 75.98),\n",
       " (31.17, 47.27),\n",
       " (76.48, 129.28),\n",
       " (31.74, 48.23),\n",
       " (144.42, 263.67),\n",
       " (29.15, 43.85),\n",
       " (56.91, 92.82),\n",
       " (101.71, 177.98),\n",
       " (65.73, 109.09),\n",
       " (66.4, 110.34),\n",
       " (65.27, 108.23),\n",
       " (26.69, 39.72),\n",
       " (66.51, 110.54),\n",
       " (42.55, 67.01),\n",
       " (49.59, 79.55),\n",
       " (40.86, 64.02),\n",
       " (24.64, 36.32),\n",
       " (182.17, 342.06),\n",
       " (81.25, 138.37),\n",
       " (27.77, 41.52),\n",
       " (28.51, 42.77),\n",
       " (67.47, 112.35),\n",
       " (43.85, 69.31),\n",
       " (186.38, 350.94),\n",
       " (30.02, 45.32),\n",
       " (44.97, 71.29),\n",
       " (27.7, 41.41),\n",
       " (52.78, 85.31),\n",
       " (28.26, 42.36),\n",
       " (31.29, 47.47),\n",
       " (32.36, 49.29),\n",
       " (51.68, 83.32),\n",
       " (35.9, 55.37),\n",
       " (57.51, 93.91),\n",
       " (55.97, 91.11),\n",
       " (30.26, 45.73),\n",
       " (50.99, 82.07),\n",
       " (88.25, 151.79),\n",
       " (28.66, 43.03),\n",
       " (81.14, 138.16),\n",
       " (47.32, 75.47),\n",
       " (54.01, 87.53),\n",
       " (22.19, 32.29),\n",
       " (29.25, 44.01),\n",
       " (65.09, 107.91),\n",
       " (29.14, 43.83),\n",
       " (27.35, 40.82),\n",
       " (33.75, 51.68),\n",
       " (22.82, 33.32),\n",
       " (92.75, 160.5),\n",
       " (23.83, 34.97),\n",
       " (45.37, 72.01),\n",
       " (94.76, 164.41),\n",
       " (59.91, 98.33),\n",
       " (44.31, 70.11),\n",
       " (23.34, 34.17),\n",
       " (32.8, 50.05),\n",
       " (60.04, 98.56),\n",
       " (63.66, 105.25),\n",
       " (87.76, 150.84),\n",
       " (69.34, 115.84),\n",
       " (39.53, 61.7),\n",
       " (45.6, 72.4),\n",
       " (46.95, 74.82),\n",
       " (60.63, 99.65),\n",
       " (64.93, 107.6),\n",
       " (36.91, 57.12),\n",
       " (35.58, 54.82),\n",
       " (31.96, 48.62),\n",
       " (34.5, 52.96),\n",
       " (48.66, 77.88),\n",
       " (70.46, 117.94),\n",
       " (52.84, 85.42),\n",
       " (84.71, 144.98),\n",
       " (67.85, 113.04),\n",
       " (201.33, 382.64),\n",
       " (43.94, 69.47),\n",
       " (49.26, 78.95),\n",
       " (29.24, 44.01),\n",
       " (66.22, 110.0),\n",
       " (31.09, 47.14),\n",
       " (62.46, 103.02),\n",
       " (26.21, 38.93),\n",
       " (42.17, 66.33),\n",
       " (18.78, 26.78),\n",
       " (59.17, 96.97),\n",
       " (44.04, 69.63),\n",
       " (29.68, 44.74),\n",
       " (38.23, 59.42),\n",
       " (41.63, 65.37),\n",
       " (24.63, 36.3),\n",
       " (35.96, 55.48),\n",
       " (38.36, 59.65),\n",
       " (106.69, 187.77),\n",
       " (35.69, 55.01),\n",
       " (29.14, 43.83),\n",
       " (34.06, 52.2),\n",
       " (58.24, 95.26),\n",
       " (26.98, 40.2),\n",
       " (38.88, 60.55),\n",
       " (64.93, 107.61),\n",
       " (26.32, 39.1),\n",
       " (67.42, 112.24),\n",
       " (56.33, 91.77),\n",
       " (38.64, 60.13),\n",
       " (45.44, 72.12),\n",
       " (81.79, 139.39),\n",
       " (30.1, 45.46),\n",
       " (29.7, 44.78),\n",
       " (21.83, 31.7),\n",
       " (49.44, 79.29),\n",
       " (51.51, 83.01),\n",
       " (91.85, 158.74),\n",
       " (40.13, 62.75),\n",
       " (92.91, 160.82),\n",
       " (28.6, 42.92),\n",
       " (42.49, 66.89),\n",
       " (77.0, 130.26),\n",
       " (126.83, 227.94),\n",
       " (27.05, 40.33),\n",
       " (37.75, 58.59),\n",
       " (25.4, 37.58),\n",
       " (34.6, 53.14),\n",
       " (46.83, 74.6),\n",
       " (66.39, 110.33),\n",
       " (63.91, 105.72),\n",
       " (24.42, 35.95),\n",
       " (53.17, 86.01),\n",
       " (25.9, 38.4),\n",
       " (80.43, 136.8),\n",
       " (28.05, 42.0),\n",
       " (45.37, 72.0),\n",
       " (64.6, 106.99),\n",
       " (51.04, 82.16),\n",
       " (28.81, 43.27),\n",
       " (61.74, 101.7),\n",
       " (36.56, 56.52),\n",
       " (27.5, 41.07),\n",
       " (66.57, 110.66),\n",
       " (44.78, 70.94),\n",
       " (34.81, 53.5),\n",
       " (55.78, 90.76),\n",
       " (36.08, 55.68),\n",
       " (22.65, 33.04),\n",
       " (53.4, 86.43),\n",
       " (44.22, 69.95),\n",
       " (55.91, 91.01),\n",
       " (33.8, 51.76),\n",
       " (36.54, 56.48),\n",
       " (32.51, 49.55),\n",
       " (25.86, 38.34),\n",
       " (71.81, 120.47),\n",
       " (46.07, 73.24),\n",
       " (30.06, 45.39),\n",
       " (37.09, 57.45),\n",
       " (50.08, 80.42),\n",
       " (141.31, 257.3),\n",
       " (21.86, 31.75),\n",
       " (43.12, 68.0),\n",
       " (33.02, 50.42),\n",
       " (29.08, 43.73),\n",
       " (82.73, 141.18),\n",
       " (44.13, 69.8),\n",
       " (34.69, 53.3),\n",
       " (76.36, 129.06),\n",
       " (21.33, 30.89),\n",
       " (30.6, 46.29),\n",
       " (44.28, 70.07),\n",
       " (44.29, 70.08),\n",
       " (37.11, 57.47),\n",
       " (24.55, 36.17),\n",
       " (36.54, 56.48),\n",
       " (32.21, 49.04),\n",
       " (34.47, 52.92),\n",
       " (42.9, 67.62),\n",
       " (25.87, 38.35),\n",
       " (71.0, 118.95),\n",
       " (85.22, 145.97),\n",
       " (34.86, 53.58),\n",
       " (26.16, 38.83),\n",
       " (40.3, 63.04),\n",
       " (89.92, 155.02),\n",
       " (26.87, 40.02),\n",
       " (77.1, 130.47),\n",
       " (46.28, 73.63),\n",
       " (27.32, 40.78),\n",
       " (152.21, 279.65),\n",
       " (29.81, 44.96),\n",
       " (23.83, 34.98),\n",
       " (23.49, 34.43),\n",
       " (81.77, 139.36),\n",
       " (39.11, 60.97),\n",
       " (160.72, 297.26),\n",
       " (105.49, 185.41),\n",
       " (41.15, 64.54),\n",
       " (59.08, 96.81),\n",
       " (32.2, 49.03),\n",
       " (25.05, 36.99),\n",
       " (50.91, 81.92),\n",
       " (41.58, 65.29),\n",
       " (26.97, 40.19),\n",
       " (38.74, 60.31),\n",
       " (38.51, 59.91),\n",
       " (45.82, 72.79),\n",
       " (79.8, 135.59),\n",
       " (40.86, 64.02),\n",
       " (130.79, 235.94),\n",
       " (53.81, 87.17),\n",
       " (43.54, 68.76),\n",
       " (51.52, 83.03),\n",
       " (41.35, 64.89),\n",
       " (37.85, 58.76),\n",
       " (71.48, 119.86),\n",
       " (44.25, 70.0),\n",
       " (29.32, 44.13),\n",
       " (32.26, 49.12),\n",
       " (39.69, 61.97),\n",
       " (31.62, 48.04),\n",
       " (129.56, 233.44),\n",
       " (25.8, 38.25),\n",
       " (52.93, 85.57),\n",
       " (68.45, 114.16),\n",
       " (43.56, 68.78),\n",
       " (25.72, 38.11),\n",
       " (69.3, 115.75),\n",
       " (37.48, 58.12),\n",
       " (30.17, 45.57),\n",
       " (54.67, 88.74),\n",
       " (58.65, 96.0),\n",
       " (30.17, 45.56),\n",
       " (70.43, 117.88),\n",
       " (74.73, 125.97),\n",
       " (39.75, 62.08),\n",
       " (26.77, 39.86),\n",
       " (35.0, 53.82),\n",
       " (52.23, 84.31),\n",
       " (49.86, 80.03),\n",
       " (87.78, 150.88),\n",
       " (40.11, 62.71),\n",
       " (58.16, 95.1),\n",
       " (50.02, 80.32),\n",
       " (86.89, 149.16),\n",
       " (45.29, 71.86),\n",
       " (46.56, 74.12),\n",
       " (37.97, 58.97),\n",
       " (24.03, 35.3),\n",
       " (30.43, 46.02),\n",
       " (58.05, 94.91),\n",
       " (39.42, 61.49),\n",
       " (144.74, 264.33),\n",
       " (28.32, 42.45),\n",
       " (55.79, 90.78),\n",
       " (53.87, 87.29),\n",
       " (49.75, 79.83),\n",
       " (34.15, 52.36),\n",
       " (31.12, 47.18),\n",
       " (37.95, 58.94),\n",
       " (29.91, 45.13),\n",
       " (19.35, 27.69),\n",
       " (23.27, 34.06),\n",
       " (23.0, 33.61),\n",
       " (74.41, 125.38),\n",
       " (38.68, 60.21),\n",
       " (82.44, 140.63),\n",
       " (45.94, 73.01),\n",
       " (49.51, 79.4),\n",
       " (60.6, 99.6),\n",
       " (25.85, 38.32),\n",
       " (72.91, 122.55),\n",
       " (27.94, 41.81),\n",
       " (82.89, 141.5),\n",
       " (44.53, 70.5),\n",
       " (30.15, 45.54),\n",
       " (44.71, 70.83),\n",
       " (132.88, 240.16),\n",
       " (84.16, 143.93),\n",
       " (63.91, 105.72),\n",
       " (50.88, 81.87),\n",
       " (74.65, 125.83),\n",
       " (25.71, 38.1),\n",
       " (40.67, 63.7),\n",
       " (24.45, 36.0),\n",
       " (60.93, 100.2),\n",
       " (49.29, 79.01),\n",
       " (65.14, 108.0),\n",
       " (34.93, 53.7),\n",
       " (37.68, 58.47),\n",
       " (26.78, 39.88),\n",
       " (29.98, 45.26),\n",
       " (18.76, 26.76),\n",
       " (31.19, 47.3),\n",
       " (33.5, 51.25),\n",
       " (114.85, 203.95),\n",
       " (37.7, 58.51),\n",
       " (45.88, 72.91),\n",
       " (83.87, 143.38),\n",
       " (158.46, 292.56),\n",
       " (20.66, 29.82),\n",
       " (48.07, 76.82),\n",
       " (27.0, 40.24),\n",
       " (34.83, 53.52),\n",
       " (34.35, 52.7),\n",
       " (33.11, 50.58),\n",
       " (112.76, 199.79),\n",
       " (28.96, 43.53),\n",
       " (28.63, 42.98),\n",
       " (42.09, 66.19),\n",
       " (29.12, 43.79),\n",
       " (60.99, 100.31),\n",
       " (58.91, 96.49),\n",
       " (44.32, 70.13),\n",
       " (45.19, 71.68),\n",
       " (53.88, 87.3),\n",
       " (24.46, 36.02),\n",
       " (21.47, 31.13),\n",
       " (68.92, 115.04),\n",
       " (46.14, 73.37),\n",
       " (111.02, 196.33),\n",
       " (32.22, 49.06),\n",
       " (46.84, 74.61),\n",
       " (67.54, 112.46),\n",
       " (65.54, 108.75),\n",
       " (59.51, 97.59),\n",
       " (69.44, 116.01),\n",
       " (61.11, 100.55),\n",
       " (52.25, 84.34),\n",
       " (25.12, 37.11),\n",
       " (52.29, 84.41),\n",
       " (32.38, 49.32),\n",
       " (58.58, 95.88),\n",
       " (36.23, 55.95),\n",
       " (23.93, 35.15),\n",
       " (47.62, 76.01),\n",
       " (59.93, 98.36),\n",
       " (57.22, 93.4),\n",
       " (106.32, 187.05),\n",
       " (67.98, 113.3),\n",
       " (22.65, 33.05),\n",
       " (33.4, 51.07),\n",
       " (34.35, 52.7),\n",
       " (79.18, 134.42),\n",
       " (36.88, 57.08),\n",
       " (51.48, 82.95),\n",
       " (33.6, 51.42),\n",
       " (68.14, 113.59),\n",
       " (109.81, 193.95),\n",
       " (37.8, 58.68),\n",
       " (44.63, 70.69),\n",
       " (80.74, 137.38),\n",
       " (55.65, 90.53),\n",
       " (55.28, 89.86),\n",
       " (102.44, 179.41),\n",
       " (38.67, 60.2),\n",
       " (110.43, 195.16),\n",
       " (28.66, 43.02),\n",
       " (40.8, 63.92),\n",
       " (92.21, 159.44),\n",
       " (60.4, 99.22),\n",
       " (27.5, 41.08),\n",
       " (31.94, 48.58),\n",
       " (44.55, 70.53),\n",
       " (25.46, 37.68),\n",
       " (20.64, 29.78),\n",
       " (32.18, 48.99),\n",
       " (118.97, 212.17),\n",
       " (31.43, 47.72),\n",
       " (75.64, 127.69),\n",
       " (44.12, 69.78),\n",
       " (62.44, 103.0),\n",
       " (25.71, 38.09),\n",
       " (40.32, 63.08),\n",
       " (65.92, 109.45),\n",
       " (33.81, 51.77),\n",
       " (172.42, 321.62),\n",
       " (48.58, 77.73),\n",
       " (57.36, 93.64),\n",
       " (65.37, 108.43),\n",
       " (48.34, 77.3),\n",
       " (34.11, 52.29),\n",
       " (184.96, 347.94),\n",
       " (120.14, 214.51),\n",
       " (38.65, 60.15),\n",
       " (35.16, 54.1),\n",
       " (28.3, 42.42),\n",
       " (51.2, 82.46),\n",
       " (20.57, 29.66),\n",
       " (23.74, 34.83),\n",
       " (40.43, 63.27),\n",
       " (27.67, 41.35),\n",
       " (36.91, 57.12),\n",
       " (69.51, 116.15),\n",
       " (29.05, 43.68),\n",
       " (55.83, 90.85),\n",
       " (22.68, 33.1),\n",
       " (55.33, 89.94),\n",
       " (43.39, 68.49),\n",
       " (37.66, 58.42),\n",
       " (38.96, 60.7),\n",
       " (25.42, 37.61),\n",
       " (29.1, 43.76),\n",
       " (60.65, 99.68),\n",
       " (18.54, 26.41),\n",
       " (41.85, 65.77),\n",
       " (23.85, 35.02),\n",
       " (36.85, 57.02),\n",
       " (95.81, 166.45),\n",
       " (45.82, 72.79),\n",
       " (24.38, 35.89),\n",
       " (48.11, 76.88),\n",
       " (47.89, 76.5),\n",
       " (69.38, 115.91),\n",
       " (85.24, 146.0),\n",
       " (53.64, 86.87),\n",
       " (25.88, 38.37),\n",
       " (36.76, 56.87),\n",
       " (80.5, 136.93),\n",
       " (42.96, 67.72),\n",
       " (48.66, 77.88),\n",
       " (53.71, 86.99),\n",
       " (106.65, 187.69),\n",
       " (31.27, 47.44),\n",
       " (58.95, 96.57),\n",
       " (46.38, 73.8),\n",
       " (38.42, 59.76),\n",
       " (23.37, 34.22),\n",
       " (51.19, 82.43),\n",
       " (66.14, 109.86),\n",
       " (40.21, 62.89),\n",
       " (35.45, 54.6),\n",
       " (25.62, 37.93),\n",
       " (23.05, 33.7),\n",
       " (51.23, 82.51),\n",
       " (47.89, 76.5),\n",
       " (45.99, 73.1),\n",
       " (45.3, 71.88),\n",
       " (41.38, 64.94),\n",
       " (21.9, 31.81),\n",
       " (41.63, 65.38),\n",
       " (27.88, 41.72),\n",
       " (26.66, 39.67),\n",
       " (82.92, 141.56),\n",
       " (29.52, 44.47),\n",
       " (25.17, 37.19),\n",
       " (23.41, 34.29),\n",
       " (36.35, 56.16),\n",
       " (76.38, 129.1),\n",
       " (58.77, 96.24),\n",
       " (36.46, 56.35),\n",
       " (66.84, 111.16),\n",
       " (31.25, 47.41),\n",
       " (116.65, 207.54),\n",
       " (18.82, 26.85),\n",
       " (42.47, 66.86),\n",
       " (51.66, 83.28),\n",
       " (89.96, 155.09),\n",
       " (34.62, 53.16),\n",
       " (54.83, 89.03),\n",
       " (63.44, 104.84),\n",
       " (22.79, 33.28),\n",
       " (49.77, 79.87),\n",
       " (25.59, 37.9),\n",
       " (42.39, 66.72),\n",
       " (52.78, 85.31),\n",
       " (26.94, 40.14),\n",
       " (59.93, 98.36),\n",
       " (42.65, 67.18),\n",
       " (127.66, 229.61),\n",
       " (29.85, 45.04),\n",
       " (54.36, 88.17),\n",
       " (48.84, 78.19),\n",
       " (45.38, 72.02),\n",
       " (37.15, 57.55),\n",
       " (29.29, 44.09),\n",
       " (51.36, 82.74),\n",
       " (113.94, 202.14),\n",
       " (28.73, 43.14),\n",
       " (35.86, 55.31),\n",
       " (25.91, 38.42),\n",
       " (82.01, 139.81),\n",
       " (26.28, 39.03),\n",
       " (40.92, 64.13),\n",
       " (28.51, 42.77),\n",
       " (67.23, 111.9),\n",
       " (44.07, 69.68),\n",
       " (75.17, 126.81),\n",
       " (32.4, 49.36),\n",
       " (44.81, 71.0),\n",
       " (268.47, 528.34),\n",
       " (76.62, 129.55),\n",
       " (37.15, 57.55),\n",
       " (46.33, 73.71),\n",
       " (41.81, 65.69),\n",
       " (25.87, 38.35),\n",
       " (46.27, 73.6),\n",
       " (86.54, 148.5),\n",
       " (40.93, 64.15),\n",
       " (53.88, 87.3),\n",
       " (60.86, 100.08),\n",
       " (130.38, 235.11),\n",
       " (46.74, 74.44),\n",
       " (26.17, 38.86),\n",
       " (27.31, 40.76),\n",
       " (47.48, 75.76),\n",
       " (43.42, 68.54),\n",
       " (31.05, 47.06),\n",
       " (43.74, 69.1),\n",
       " (29.49, 44.42),\n",
       " (26.64, 39.64),\n",
       " (60.92, 100.18),\n",
       " (48.94, 78.38),\n",
       " (60.02, 98.53),\n",
       " (26.68, 39.71),\n",
       " (31.43, 47.72),\n",
       " (88.48, 152.24),\n",
       " (26.0, 38.56),\n",
       " (46.45, 73.93),\n",
       " (26.85, 39.99),\n",
       " (89.35, 153.91),\n",
       " (39.14, 61.01),\n",
       " (44.57, 70.58),\n",
       " (50.46, 81.11),\n",
       " (141.85, 258.41),\n",
       " (74.4, 125.34),\n",
       " (77.84, 131.86),\n",
       " (56.67, 92.38),\n",
       " (29.09, 43.75),\n",
       " (62.06, 102.29),\n",
       " (29.11, 43.78),\n",
       " (24.26, 35.69),\n",
       " (120.73, 215.68),\n",
       " (45.19, 71.68),\n",
       " (35.48, 54.65),\n",
       " (44.27, 70.05),\n",
       " (29.42, 44.29),\n",
       " (41.83, 65.74),\n",
       " (67.79, 112.94),\n",
       " (41.47, 65.09),\n",
       " (58.46, 95.67),\n",
       " (121.35, 216.94),\n",
       " (296.33, 590.2),\n",
       " (56.39, 91.87),\n",
       " (76.72, 129.74),\n",
       " (39.09, 60.93),\n",
       " (40.63, 63.62),\n",
       " (80.55, 137.03),\n",
       " (63.87, 105.63),\n",
       " (30.28, 45.76),\n",
       " (44.89, 71.14),\n",
       " (44.67, 70.76),\n",
       " (35.27, 54.3),\n",
       " (53.58, 86.75),\n",
       " (47.75, 76.25),\n",
       " (62.34, 102.82),\n",
       " (66.87, 111.23),\n",
       " (77.16, 130.58),\n",
       " (71.6, 120.07),\n",
       " (28.16, 42.18),\n",
       " (26.02, 38.61),\n",
       " (21.03, 30.41),\n",
       " (52.53, 84.85),\n",
       " (34.65, 53.23),\n",
       " (31.06, 47.08),\n",
       " (28.45, 42.66),\n",
       " (28.55, 42.83),\n",
       " (27.5, 41.08),\n",
       " (25.26, 37.34),\n",
       " (54.54, 88.51),\n",
       " (25.77, 38.19),\n",
       " (36.74, 56.84),\n",
       " (47.38, 75.58),\n",
       " (18.1, 25.7),\n",
       " (25.22, 37.28),\n",
       " (50.0, 80.28),\n",
       " (34.24, 52.52),\n",
       " (83.48, 142.63),\n",
       " (79.82, 135.64),\n",
       " (130.48, 235.3),\n",
       " (47.3, 75.43),\n",
       " (73.13, 122.96),\n",
       " (37.29, 57.79),\n",
       " (48.23, 77.1),\n",
       " (58.43, 95.6),\n",
       " (87.33, 150.01),\n",
       " (54.18, 87.85),\n",
       " (31.88, 48.47),\n",
       " (32.91, 50.23),\n",
       " (44.79, 70.96),\n",
       " (41.06, 64.37),\n",
       " (41.65, 65.42),\n",
       " (25.23, 37.29),\n",
       " (29.59, 44.59),\n",
       " (48.97, 78.44),\n",
       " (42.6, 67.09),\n",
       " (42.33, 66.61),\n",
       " (30.48, 46.1),\n",
       " (65.86, 109.35),\n",
       " (108.71, 191.77),\n",
       " (36.53, 56.47),\n",
       " (19.82, 28.45),\n",
       " (23.69, 34.75),\n",
       " (31.12, 47.18),\n",
       " (31.88, 48.48),\n",
       " (41.68, 65.47),\n",
       " (118.36, 210.96),\n",
       " (28.67, 43.04),\n",
       " (63.46, 104.88),\n",
       " (16.81, 23.65),\n",
       " (41.49, 65.14),\n",
       " (25.13, 37.13),\n",
       " (26.77, 39.85),\n",
       " (40.52, 63.43),\n",
       " (28.7, 43.1),\n",
       " (62.35, 102.83),\n",
       " (19.71, 28.27),\n",
       " (25.37, 37.52),\n",
       " (54.95, 89.24),\n",
       " (34.45, 52.88),\n",
       " (32.86, 50.15),\n",
       " (23.18, 33.92),\n",
       " (40.66, 63.68),\n",
       " (26.2, 38.9),\n",
       " (29.42, 44.3),\n",
       " (26.63, 39.62),\n",
       " (53.96, 87.45),\n",
       " (91.52, 158.12),\n",
       " (32.19, 49.01),\n",
       " (160.62, 297.04),\n",
       " (25.85, 38.32),\n",
       " (31.48, 47.79),\n",
       " (60.04, 98.56),\n",
       " (76.15, 128.66),\n",
       " (22.6, 32.96),\n",
       " (43.54, 68.76),\n",
       " (35.68, 54.99),\n",
       " (27.94, 41.81),\n",
       " (100.43, 175.46),\n",
       " (48.73, 78.01),\n",
       " (33.63, 51.47),\n",
       " (63.28, 104.55),\n",
       " (33.39, 51.05),\n",
       " (84.36, 144.31),\n",
       " (42.55, 67.01),\n",
       " ...)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_nn_reg = tuple([(round(math.exp(el-el*MAPE_median_nn_reg),2),round(math.exp(el+el*MAPE_median_nn_reg),2)) for el in y_test_pred_nn_reg])\n",
    "y_pred_interval_nn_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#model_nn_seq.model_evaluation(model_nn_seq, skip_epochs=2, X_train=X_train, X_test=X_test)\n",
    "\n",
    "#score_nn_seq = model_nn_seq.evaluate(X_train_prep, y_train,verbose=1)\n",
    "#print(score_nn_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_nn_reg, title=\"best_model_nn_reg_02\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation with Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_reg = [best_model_xgb_reg, best_model_svm_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_test for final evaluation\n",
    "#X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "#y_pred_rf_reg = best_model_rf_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "#print(\"MSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"RMSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg, squared=False))),\n",
    "#print(\"MAE: {:.2f}\".format(mean_absolute_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"R2: {:.2f}\".format(r2_score(y_test, y_pred_rf_reg))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Illustrate best model\n",
    "#fig, axes = plt.subplots(1, 2, figsize = (14, 6))\n",
    "#axes = axes.flatten()\n",
    "\n",
    "#y_pred = best_model.predict(X_test_prep)\n",
    "#axes[0].scatter(y_test, y_pred)\n",
    "#axes[0].set_xlabel('y_test')\n",
    "#axes[0].set_ylabel('y_pred')\n",
    "\n",
    "#coef = best_model.best_estimator_.named_steps['xgb'].coef_\n",
    "#mean_coef = np.mean(coef)\n",
    "#axes[1].plot(coef, 'o')\n",
    "#axes[1].set_xlabel('coefficient index')\n",
    "#axes[1].set_ylabel('coefficient size')\n",
    "#axes[1].axhline(y = mean_coef, color = 'red', linestyle = '--', alpha = 0.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "#confidence = 0.95\n",
    "#squared_errors = (y_pred_rf_reg - y_test) ** 2\n",
    "#np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "#                         loc=squared_errors.mean(),\n",
    "#                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictive modeling**\n",
    "- Apply further models and adapt current ones (e.g. NN)\n",
    "- Examine other prediction targets (e.g. occupancy rate)\n",
    "\n",
    "**Feature engineering**\n",
    "- Explore NLP for text fields (descriptions, reviews, ...)\n",
    "- Scrape listing photos and analyze quality\n",
    "- Enhance current feature set\n",
    "\n",
    "**Lean structure**\n",
    "- Remove remaining redundancies wherever possible (e.g. pack repeated steps into functions, apply more pipelines, ...)\n",
    "\n",
    "**Cloud**\n",
    "- Move both model creation and app into the cloud (GCP)\n",
    "\n",
    "**Automatization and replicability**\n",
    "- Build a workflow to automatically retrain model monthly with new datasets\n",
    "- Use automated outlier detection\n",
    "- Use automated feature engineering\n",
    "\n",
    "**Replicability**\n",
    "- Reduce redundancies wherever possible (e.g. pack repeated steps into functions, apply more pipelines, ...)\n",
    "- Apply analysis to other cities and compare results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
