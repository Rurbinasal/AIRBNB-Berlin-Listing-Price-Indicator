{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains predictive modeling for various distinct target options, namely:\n",
    "\n",
    "3 Modeling: Binary Classification (**PRICE_BINARY**)\n",
    "- Binary split is set as a USD Price amount in the Dashboard\n",
    "\n",
    "4 Modeling: Multi-Class Classification (**PRICE_CLASS**)\n",
    "- TBD\n",
    "\n",
    "5 Modeling: Regression (**PRICE_LOG**)\n",
    "- TBD\n",
    "\n",
    "**As a consequence, the respective targets need to be selected via the Dashboard BEFORE running the corresponding section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import math\n",
    "import joblib\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline  # Same, but with the latter it is not necessary to name estimator and transformer\n",
    "#from imblearn.pipeline import Pipeline as Imb_Pipe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, GenericUnivariateSelect, mutual_info_classif\n",
    "import eli5\n",
    "\n",
    "# Predictive Modeling (Models)\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score, cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, NuSVC, SVR\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PassiveAggressiveRegressor, ElasticNet, SGDRegressor, RANSACRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor, VotingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from scipy.stats import randint\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer, fbeta_score, accuracy_score, confusion_matrix, f1_score, precision_recall_curve, recall_score, precision_score, roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Neural Networks\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import data_engineered\n",
    "data = pd.read_pickle(f\"saves/{dataset_loc}_{dataset_date}/data_engineered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "\n",
    "#... by removing certain features\n",
    "all_features = [\n",
    "    el for el in data.columns if el not in [\n",
    "        'occupancy_rate', 'occupancy_class', 'listing_no', 'price_log', 'price_class',\n",
    "        'price_binary', \"review_scores_class_new\", \"review_scores_class\",\n",
    "        \"review_scores_calc\", \"neighbourhood_cleansed\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "#... by only considering certain features\n",
    "key_features = [\n",
    "    \"accommodates\", \"accommodates_per_bed\", \"am_balcony\", \"am_breakfast\",\n",
    "    \"am_child_friendly\", \"am_elevator\", \"am_essentials\", \"am_pets_allowed\",\n",
    "    \"am_private_entrance\", \"am_smoking_allowed\", \"am_tv\", \"availability_90\", \"bathrooms_log\", \"bedrooms\",\n",
    "    \"calc_host_lst_count_sqrt_log\", \"cancellation_policy\", \"host_is_superhost\", \"instant_bookable\",\n",
    "    \"maximum_nights\", \"minimum_nights_log\", \"property_type\", \"room_type\", \"wk_mth_discount\",\n",
    "    \"zipcode\"\n",
    "]\n",
    "\n",
    "#Display columns:\n",
    "#all_features\n",
    "#key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dashboard (Global Variables)\n",
    "dataset_loc = \"berlin\"              # \"berlin\", \"paris\", \"amsterdam\"\n",
    "dataset_date = \"2020-03-17\"         # \"2019-12-11\", \"2020-01-10\", \"2020-02-18\", \"2020-03-17\", \"2020-05-14\"\n",
    "target = 'price_log'             # for regression: 'occupancy_rate', 'price_log' | for classification: 'price_class', 'occupancy_class'\n",
    "binary_split = 50                   # price at which \"price_binary\" will be split\n",
    "pred_features = key_features        # select from cell \"feature selection\" above: [all_features, key_features]\n",
    "scoring = 'neg_median_absolute_error'  # for regression: 'neg_mean_squared_error', 'r2', 'neg_mean_poisson_deviance', 'neg_median_absolute_error' | for classification: \"f1(_micro, _macro, _weighted for multiclass)\", \"recall\", \"precision\", \"accuracy\", \"roc_auc\"\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_LOG\u001b[0m as the target and \u001b[1mneg_median_absolute_error\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'availability_90', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'host_is_superhost', 'instant_bookable', 'maximum_nights', 'minimum_nights_log', 'property_type', 'room_type', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n",
      "No issues with your selection of pred_features have been detected. Please make sure to manually check for correctness nevertheless.\n"
     ]
    }
   ],
   "source": [
    "# Display target and used features\n",
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "print(f\"You are currently using \\033[1m{target_upper}\\033[0m as the target and \\033[1m{scoring}\\033[0m for scoring to predict prices for \\033[1m{dataset_loc}\\033[0m on \\033[1m{dataset_date}\\033[0m\\n\")\n",
    "print(f\"You are currently using these features for its prediction:\\n\\033[1m{pred_features}\\033[0m\\n\")\n",
    "\n",
    "if target in pred_features:\n",
    "    print(f\"WARNING: You are using \\033[1m{target_upper}\\033[0m as predictor. Please remove before proceeding.\\n\")\n",
    "\n",
    "if target == 'price_binary':\n",
    "    if 'price_class' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_class'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_log' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_log'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "if target == 'price_class':\n",
    "    if 'price_binary' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_binary'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_log' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_log'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "if target == 'price_log':\n",
    "    if 'price_class' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_class'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "    if 'price_binary' in pred_features:\n",
    "        print(f\"WARNING: Please remove \\033[1m'price_binary'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "        \n",
    "if \"occupancy_class\" in pred_features and \"occupancy_rate\" in pred_features:\n",
    "    print(f\"WARNING: Please remove \\033[1m'ocupancy_class'\\033[0m or \\033[1m'ocupancy_rate'\\033[0m from features before proceeding with target \\033[1m{target_upper}\\033[0m\")\n",
    "\n",
    "else:\n",
    "    print(\"No issues with your selection of pred_features have been detected. Please make sure to manually check for correctness nevertheless.\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Functions and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create \"price_binary\" at given split\n",
    "price_binary = []\n",
    "for price in data.price_log:\n",
    "    if math.exp(price) <= binary_split:\n",
    "        price_binary.append(1)\n",
    "    else:\n",
    "        price_binary.append(2)\n",
    "data[\"price_binary\"] = price_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"mean_absolute_percentage_error\": Function for mean absolute percentage error (MAPE)\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"median_absolute_percentage_error\": Function for median absolute percentage error (MAPE median)\n",
    "def median_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.median(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"print_target_setting\": Function for printing current setting for TARGET and the corresponding features\n",
    "def print_target_setting():\n",
    "    target_upper = target.upper()\n",
    "    y_upper = y_train.name.upper()\n",
    "    print(f\"You are currently using \\033[1m{target_upper}\\033[0m as the target and \\033[1m{scoring}\\033[0m for scoring to predict prices for \\033[1m{dataset_loc}\\033[0m on \\033[1m{dataset_date}\\033[0m\\n\")\n",
    "    print(f\"The target variable y is set to \\033[1m{y_upper}\\033[0m\\n\")\n",
    "    print(f\"You are currently using these features for its prediction:\\n\\033[1m{pred_features}\\033[0m\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"get_feat_importances\": Function for retrieving feature importances\n",
    "def get_feat_importances(model, column_names=column_names):\n",
    "    model=model\n",
    "    feat_importances = pd.DataFrame(model.feature_importances_,\n",
    "                 columns=['weight'],\n",
    "                 index=column_names)\n",
    "    feat_importances.sort_values('weight', inplace=True, ascending=False)\n",
    "    return feat_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"model_eval\": Function for final evaluation of \"best model\"\n",
    "def model_eval(y, y_pred, model=\"reg\"):\n",
    "    \"\"\"\n",
    "    Please always specify the type of model:\n",
    "    Regression: model=\"reg\"\n",
    "    Binary Classification: model=\"bclf\"\n",
    "    Multiclass Classification: model=\"clf\"\n",
    "    \"\"\"\n",
    "    if model==\"reg\":\n",
    "        print(\"MSE: {:.2f}\".format(mean_squared_error(y, y_pred)))\n",
    "        print(\"RMSE: {:.2f}\".format(\n",
    "        mean_squared_error(y, y_pred, squared=False)))\n",
    "        print(\"MAE: {:.2f}\".format(mean_absolute_error(y, y_pred)))\n",
    "        print(\"R2: {:.2f}\".format(r2_score(y, y_pred)))\n",
    "        print(\"MAPE: {:.2f}\".format(mean_absolute_percentage_error(y, y_pred)))\n",
    "        print(\"MAPE median: {:.2f}\".format(median_absolute_percentage_error(y, y_pred)))\n",
    "\n",
    "    elif model==\"bclf\":\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy_score(y, y_pred)))\n",
    "        print(\"Recall: {:.2f}\".format(recall_score(y, y_pred)))\n",
    "        print(\"Precision: {:.2f}\".format(precision_score(y, y_pred)))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred)))\n",
    "        print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y, y_pred)))\n",
    "        print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y, y_pred)))\n",
    "\n",
    "    elif model==\"clf\":\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy_score(y, y_pred)))\n",
    "        print(\"Recall: {:.2f}\".format(recall_score(y, y_pred, average='weighted')))\n",
    "        print(\"Precision: {:.2f}\".format(precision_score(y, y_pred, average='weighted')))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1_score(y, y_pred, average='weighted')))\n",
    "        print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y, y_pred)))\n",
    "    \n",
    "    else:\n",
    "        print(\"Please revise your parameters (e.g. provide a valid model).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"save_model\": Function for saving model (pickle or joblib)\n",
    "def save_model(model, title=\"unknown\", save=\"joblib\"):\n",
    "    if save==\"joblib\":\n",
    "        joblib.dump(model, f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")\n",
    "    elif save==\"pickle\":\n",
    "        model.to_pickle(f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")\n",
    "#        save also evaluation (from y_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"load_model\": Function for loading model (pickle or joblib)\n",
    "def load_model(title=\"unknown\", dataset_loc=dataset_loc, dataset_date=dataset_date, load=\"joblib\"):\n",
    "    if load==\"joblib\":\n",
    "        return joblib.load(f\"saves/{dataset_loc}_{dataset_date}/{title}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \"clf_learning_curves\": Function to evaluate classification model based on learning curves\n",
    "def clf_learning_curves(model):\n",
    "# Fit model on training data\n",
    "    model = model\n",
    "    eval_set = [(X_train_prep, y_train), (X_test_prep, y_test)]\n",
    "    model.fit(X_train_prep, y_train, eval_metric=[\"error\", \"logloss\"], eval_set=eval_set, verbose=True)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    y_pred = model.predict(X_test_prep)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # Evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    \n",
    "    # Retrieve performance metrics\n",
    "    results = model.evals_result()\n",
    "    epochs = len(results['validation_0']['error'])\n",
    "    x_axis = range(0, epochs)\n",
    "    \n",
    "    # Plot log loss\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['logloss'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Log Loss')\n",
    "    pyplot.title('XGBoost Log Loss')\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Plot classification error\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.plot(x_axis, results['validation_0']['error'], label='Train')\n",
    "    ax.plot(x_axis, results['validation_1']['error'], label='Test')\n",
    "    ax.legend()\n",
    "    pyplot.ylabel('Classification Error')\n",
    "    pyplot.title('XGBoost Classification Error')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (Train/Test Split and Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "drop_columns = [el for el in data.columns if el not in pred_features]\n",
    "drop_columns.remove(target)\n",
    "data.drop(labels=drop_columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Drop rows (optional, just temporary)\n",
    "#data = data[data.number_of_reviews_ltm_log>1.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancellation_policy', 'property_type', 'room_type', 'zipcode']"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\")\n",
    "cat_features = list(data.columns[data.dtypes == object])\n",
    "#cat_features.remove(\"neighbourhood\")\n",
    "#cat_features.remove(\"zipcode\")\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates',\n",
       " 'accommodates_per_bed',\n",
       " 'am_balcony',\n",
       " 'am_breakfast',\n",
       " 'am_child_friendly',\n",
       " 'am_elevator',\n",
       " 'am_essentials',\n",
       " 'am_pets_allowed',\n",
       " 'am_private_entrance',\n",
       " 'am_smoking_allowed',\n",
       " 'am_tv',\n",
       " 'availability_90',\n",
       " 'bathrooms_log',\n",
       " 'bedrooms',\n",
       " 'calc_host_lst_count_sqrt_log',\n",
       " 'host_is_superhost',\n",
       " 'instant_bookable',\n",
       " 'maximum_nights',\n",
       " 'minimum_nights_log',\n",
       " 'wk_mth_discount']"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "num_features = list(data.columns[data.dtypes != object])\n",
    "num_features.remove(target)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Build preprocessor pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([('imputer_num', SimpleImputer(strategy='median')),\n",
    "                         ('std_scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([('num', num_pipeline, num_features),\n",
    "                                  ('cat', cat_pipeline, cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state,\n",
    "                                                    shuffle=True)\n",
    "#                                                   stratify=y) # Use stratify=y if labels are inbalanced (e.g. most wines are 5 or 6; check with value_counts()!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving preprocessed X_train and X_test\n",
    "X_train_prep_preprocessor = preprocessor.fit(X_train)\n",
    "\n",
    "X_train_prep = X_train_prep_preprocessor.transform(X_train)\n",
    "X_train_num_prep = num_pipeline.fit_transform(X_train[num_features])\n",
    "X_test_prep = X_train_prep_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get feature names from pipeline after one-hot encoding as \"column_names\"\n",
    "onehot_columns = list(preprocessor.named_transformers_['cat']['1hot'].get_feature_names(cat_features))\n",
    "column_names = num_features + onehot_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "train_outl = num_pipeline.fit_transform(X_train[num_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Fit DBSCAN model\n",
    "outl_model = DBSCAN(eps=3.0, min_samples=10).fit(train_outl)\n",
    "outl_labels = outl_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8456\n",
       "1      34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display results (# of outliers)\n",
    "pd.Series(outl_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Illustrate results\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "unique_labels = set(outl_labels)\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "for color,label in zip(colors, unique_labels):\n",
    "    sample_mask = [True if l == label else False for l in outl_labels]\n",
    "    plt.plot(train_outl[:,0][sample_mask], train_outl[:, 1][sample_mask], 'o', color=color);\n",
    "plt.xlabel('accommodates_per_bed');\n",
    "plt.ylabel('accommodates_per_room');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "- https://www.kaggle.com/kevinarvai/outlier-detection-practice-uni-multivariate\n",
    "- https://datascience.stackexchange.com/questions/46092/how-do-we-interpret-the-outputs-of-dbscan-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Feature Selection (add most useful to modeling pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set X_fs to desired variable\n",
    "X_fs = X_train[\n",
    "    num_features]  # X_train_prep, X_train_num_prep, X_train[num_features]\n",
    "#X_fs = pd.DataFrame(X_fs, columns = X_train_prep_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GenericUnivariateSelect** (Classification and Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply GenericUnivariateSelect\n",
    "trans_GUS = GenericUnivariateSelect(score_func=lambda X, y: X.mean(axis=0),\n",
    "                                    mode='k_best',\n",
    "                                    param=15)  #mode='percentile', 'k_best'\n",
    "X_train_GUS = trans_GUS.fit_transform(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mutual_info_classif** (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit mutual_info_classif\n",
    "#X_train_mic = mutual_info_classif(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "#plt.subplots(1, figsize=(26, 1))\n",
    "#sns.heatmap(X_train_mic[:, np.newaxis].T, cmap='Blues', cbar=False, linewidths=1, annot=True)\n",
    "#plt.yticks([], [])\n",
    "#plt.gca().set_xticklabels(X_fs.columns, rotation=45, ha='right', fontsize=12)\n",
    "#plt.suptitle(\"Feature Importance (mutual_info_classif)\", fontsize=18, y=1.2)\n",
    "#plt.gcf().subplots_adjust(wspace=0.2)\n",
    "#pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply GenericUnivariateSelect to reduce features (optional)\n",
    "#trans_mic = GenericUnivariateSelect(score_func=mutual_info_classif, mode='k_best', param=15) #mode='percentile', 'k_best',\n",
    "#X_train_mic_GUS = trans_mic.fit_transform(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Print kept features\n",
    "#print(\"We started with {0} features but retained only {1} of them!\".format(\n",
    "#    X_fs.shape[1] - 1, X_train_mic_GUS.shape[1]))\n",
    "\n",
    "#columns_retained_Select = X_fs.columns[trans_mic.get_support()].values\n",
    "#pd.DataFrame(X_train_mic_GUS, columns=columns_retained_Select).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chi2** (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mutual_info_regression** (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Binary Classification (\"price_binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_BINARY\u001b[0m as the target and \u001b[1mroc_auc\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_BINARY\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'bathrooms_log', 'host_is_superhost', 'property_type', 'room_type', 'zipcode']\u001b[0m\n",
      "\n",
      "Binary Split:  \u001b[1mUSD 50\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()\n",
    "print(f\"Binary Split:  \\033[1mUSD {binary_split}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "models = {\n",
    "    'Baseline':\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    'LogReg':\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    'KNN':\n",
    "    KNeighborsClassifier(),\n",
    "    'SVC':\n",
    "    SVC(kernel='rbf', C=1E6),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeClassifier(criterion=\"gini\",\n",
    "                           max_depth=3,\n",
    "                           random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestClassifier(random_state=random_state,\n",
    "                           max_features='sqrt',\n",
    "                           n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBClassifier(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostClassifier(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.6s remaining:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.6s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[   0 3993]\n",
      " [   0 4497]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[2941 1052]\n",
      " [ 793 3704]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.3s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN: \n",
      "[[2837 1156]\n",
      " [ 962 3535]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.3min remaining:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVC: \n",
      "[[2926 1067]\n",
      " [ 938 3559]]\n",
      "Confusion Matrix Decision Tree: \n",
      "[[2775 1218]\n",
      " [ 693 3804]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[2906 1087]\n",
      " [ 867 3630]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Gradient Boost: \n",
      "[[2871 1122]\n",
      " [ 666 3831]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[2860 1133]\n",
      " [ 667 3830]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.5s remaining:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[2904 1089]\n",
      " [ 792 3705]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>ROC/AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.529682</td>\n",
       "      <td>0.280563</td>\n",
       "      <td>0.366825</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>0.782686</td>\n",
       "      <td>0.782955</td>\n",
       "      <td>0.782085</td>\n",
       "      <td>0.780100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.750530</td>\n",
       "      <td>0.750375</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>0.748286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.763840</td>\n",
       "      <td>0.763656</td>\n",
       "      <td>0.763571</td>\n",
       "      <td>0.762099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.774912</td>\n",
       "      <td>0.777552</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.770432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.769847</td>\n",
       "      <td>0.769864</td>\n",
       "      <td>0.769335</td>\n",
       "      <td>0.767489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.791453</td>\n",
       "      <td>0.788104</td>\n",
       "      <td>0.785455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.787986</td>\n",
       "      <td>0.790136</td>\n",
       "      <td>0.786639</td>\n",
       "      <td>0.783966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.778445</td>\n",
       "      <td>0.778896</td>\n",
       "      <td>0.777707</td>\n",
       "      <td>0.775578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy    Recall  Precision  F1 Score   ROC/AUC\n",
       "0        Baseline  0.529682  0.529682   0.280563  0.366825  0.500000\n",
       "1          LogReg  0.782686  0.782686   0.782955  0.782085  0.780100\n",
       "2             KNN  0.750530  0.750530   0.750375  0.750058  0.748286\n",
       "3             SVC  0.763840  0.763840   0.763656  0.763571  0.762099\n",
       "4   Decision Tree  0.774912  0.774912   0.777552  0.773200  0.770432\n",
       "5   Random Forest  0.769847  0.769847   0.769864  0.769335  0.767489\n",
       "6  Gradient Boost  0.789399  0.789399   0.791453  0.788104  0.785455\n",
       "7         XGBoost  0.787986  0.787986   0.790136  0.786639  0.783966\n",
       "8        AdaBoost  0.778445  0.778445   0.778896  0.777707  0.775578"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1 Score', 'ROC/AUC'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(\n",
    "                y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'ROC/AUC': roc_auc_score(y_train, y_train_pred)\n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" +\n",
    "          str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_lr_bclf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('lr_bclf',\n",
    "                             LogisticRegression(penalty='l2',\n",
    "                                                max_iter=100,\n",
    "                                                C=0.9,\n",
    "                                                random_state=random_state,\n",
    "                                                l1_ratio=0.5,\n",
    "                                                n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_lr_bclf = LogisticRegression()\n",
    "test_lr_bclf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_lr_bclf = {\n",
    "    'lr_bclf__penalty': ['l1', 'l2'],\n",
    "    'lr_bclf__max_iter': randint(low=10, high=100),\n",
    "    'lr_bclf__C': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
    "    'lr_bclf__l1_ratio': [None, 0.1, 0.2, 0.3, 0.5, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    5.5s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_lr_bclf = RandomizedSearchCV(pipeline_lr_bclf,\n",
    "                                 param_distribs_lr_bclf,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=50,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_lr_bclf = rnd_lr_bclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.85\n",
      "Best parameters:\n",
      "{'lr_bclf__C': 20, 'lr_bclf__l1_ratio': 0.1, 'lr_bclf__max_iter': 83, 'lr_bclf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_lr_bclf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_lr_bclf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_lr_bclf = {\n",
    "    'lr_bclf__penalty': ['l1', 'l2'],\n",
    "    'lr_bclf__max_iter': [100, 125, 150, 200],\n",
    "    'lr_bclf__C': [10, 20, 30],\n",
    "    'lr_bclf__l1_ratio': [None, 0.05, 0.1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:   18.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_lr_bclf = GridSearchCV(pipeline_lr_bclf,\n",
    "                            param_grid_lr_bclf,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_lr_bclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_lr_bclf = grid_lr_bclf.best_estimator_['lr_bclf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.85\n",
      "Best parameters:\n",
      "{'lr_bclf__C': 20, 'lr_bclf__l1_ratio': None, 'lr_bclf__max_iter': 150, 'lr_bclf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_lr_bclf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_lr_bclf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get and print feature importances\n",
    "#grid_lr_bclf_fi = feat_importances(grid_lr_bclf, cv_model=True, named_steps='lr_bclf', column_names=column_names)\n",
    "#grid_lr_bclf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_lr_bclf = best_model_lr_bclf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_lr_bclf, model=\"bclf\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-567-ddc2260eef86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_grid_lr_bclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision: {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_lr_bclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 91\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the best model\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_bclf)))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_lr_bclf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_lr_bclf = best_model_lr_bclf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_lr_bclf, model=\"bclf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! NN Model 1: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Evaluation with Testing Set and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bclf_best_model = best_model_grid_lr_bclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export best model at given binary_split\n",
    "bclf_best_model.to_pickle(f\"saves/{dataset_loc}_{dataset_date}/{target}_{binary_split}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Multi-Class Classification (\"price_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_CLASS\u001b[0m as the target and \u001b[1mf1\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_CLASS\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_nature_and_views', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'am_white_goods', 'availability_90', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'first_review_days_sqrt', 'host_acceptance_rate', 'host_is_superhost', 'host_response_rate', 'host_response_time', 'instant_bookable', 'last_review_days_sqrt', 'latitude', 'listing_no', 'longitude', 'maximum_nights', 'minimum_nights_log', 'neighbourhood_cleansed', 'number_of_reviews_ltm_log', 'price_extra_fees_sqrt', 'price_extra_people', 'property_type', 'review_scores_location', 'review_scores_rating_sqrt', 'room_type', 'text_len_sqrt', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "models = {\n",
    "    'Baseline':\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    'LogReg':\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    'KNN':\n",
    "    KNeighborsClassifier(),\n",
    "    'SVC':\n",
    "    SVC(kernel='rbf', C=1E6),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeClassifier(criterion=\"gini\",\n",
    "                           max_depth=3,\n",
    "                           random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestClassifier(random_state=random_state,\n",
    "                           max_features='sqrt',\n",
    "                           n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBClassifier(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostClassifier(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.2s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[   0    0  307    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1057    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1276    0    0    0    0    0    0    0    0]\n",
      " [   0    0  926    0    0    0    0    0    0    0    0]\n",
      " [   0    0  817    0    0    0    0    0    0    0    0]\n",
      " [   0    0  665    0    0    0    0    0    0    0    0]\n",
      " [   0    0  449    0    0    0    0    0    0    0    0]\n",
      " [   0    0  457    0    0    0    0    0    0    0    0]\n",
      " [   0    0  786    0    0    0    0    0    0    0    0]\n",
      " [   0    0  397    0    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.7s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[ 55 125  78  21   4   4   3   0   1  11   5]\n",
      " [ 27 447 404 121  25   9   3   0   0  18   3]\n",
      " [ 12 347 497 301  81  61  22  10   1  18   3]\n",
      " [ 15 167 401 297 150 125  39  12  14  47   9]\n",
      " [  3  54 177 217 167 130  61  21  26  61   9]\n",
      " [  1  30  86 196 129 143  94  23  22  80  13]\n",
      " [  1  15  53 105  99 139  71  17  25 122  18]\n",
      " [  1   8  25  51  63  79  47  21  19 116  19]\n",
      " [  1   5  15  44  44  74  48  20  22 159  25]\n",
      " [  3   6  15  42  43  73  65  32  49 352 106]\n",
      " [  0   1   2   7  17   7   4   8   8 176 167]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.9s remaining:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN: \n",
      "[[ 80  96  73  35   9   4   6   0   1   3   0]\n",
      " [ 83 370 337 158  44  33  12   3   9   7   1]\n",
      " [ 64 390 441 233  71  72  36  13  10  19   4]\n",
      " [ 55 290 331 278 127  88  47  13  13  30   4]\n",
      " [ 48 140 203 178 146  96  39  15  13  44   4]\n",
      " [ 23 124 194 147  91  94  52  21  20  41  10]\n",
      " [ 19  87 147 106  75  78  65  19  14  49   6]\n",
      " [ 12  41  74  75  46  49  29  44  25  50   4]\n",
      " [ 16  50  68  65  44  37  41  18  40  64  14]\n",
      " [ 13  56  85  77  70  59  60  33  58 221  54]\n",
      " [  7  15  31  15  25  12  11  18  22 109 132]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   21.5s remaining:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   31.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVC: \n",
      "[[ 88 101  59  33   9   6   5   0   2   3   1]\n",
      " [ 58 428 338 157  34  18  11   3   3   6   1]\n",
      " [ 38 359 446 275  99  65  25  19  10  13   4]\n",
      " [ 25 195 310 356 152 110  47  29  15  31   6]\n",
      " [  9  66 158 199 204 125  72  22  33  30   8]\n",
      " [  7  30  93 145 142 171  90  46  34  54   5]\n",
      " [  5  20  65  88  94 109 120  43  43  66  12]\n",
      " [  0   9  34  56  55  70  45  66  35  73   6]\n",
      " [  2  10  22  43  45  68  50  39  62  96  20]\n",
      " [  0   9  17  52  47  55  74  58  94 284  96]\n",
      " [  0   3   4   8  10  11  16  15  18 124 188]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Decision Tree: \n",
      "[[  8  76 137   0   0  31   0   0   0  51   4]\n",
      " [  2 177 730   0   0 102   0   0   0  45   1]\n",
      " [  2 159 825   0   0 314   0   0   0  53   0]\n",
      " [  4  64 584   0   0 524   0   0   0  97   3]\n",
      " [  1  20 280   0   1 488   0   0   0 129   7]\n",
      " [  3  16 138   0   0 549   0   0   0 101  10]\n",
      " [  4   6 105   0   0 400   0   0   0 136  14]\n",
      " [  1   3  38   0   0 269   0   0   0 123  15]\n",
      " [  4   3  47   0   0 231   0   0   0 149  23]\n",
      " [ 14   3  50   0   0 301   0   0   0 336  82]\n",
      " [  9   3  18   0   0  54   0   0   0 176 137]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.9s remaining:   17.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[ 65 130  82  17   3   5   2   0   0   2   1]\n",
      " [ 22 435 456  97  17   7   4   0   3  14   2]\n",
      " [  4 350 607 250  45  53  11   5   2  24   2]\n",
      " [  4 159 441 363 119  92  26   2   7  60   3]\n",
      " [  1  52 201 240 201 108  40   6   9  61   7]\n",
      " [  1  30 139 188 126 162  56  13  12  81   9]\n",
      " [  2  21  70 136  92 113  70  14  10 124  13]\n",
      " [  0   3  39  74  55  66  38  44  13 111   6]\n",
      " [  1   6  30  68  54  58  28  14  30 146  22]\n",
      " [  0   4  32  60  35  59  53  16  38 423  66]\n",
      " [  0   1   3  11  13  12   9   3  11 173 161]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.0min remaining:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.6min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Gradient Boost: \n",
      "[[ 73 124  80  12   4   4   3   1   0   5   1]\n",
      " [ 39 448 412  96  12  18   5   6   5  14   2]\n",
      " [ 18 329 576 254  39  83  23   2   5  21   3]\n",
      " [ 12 132 438 365  88 121  34  15  16  50   5]\n",
      " [  5  52 195 239 120 131  57  25  25  67  10]\n",
      " [  0  30 101 198  92 177  69  21  30  84  15]\n",
      " [  3  14  68 126  76 127  69  24  36  99  23]\n",
      " [  0   5  29  71  47  80  38  32  25 107  15]\n",
      " [  1   7  17  58  38  64  30  20  29 164  29]\n",
      " [  2   4  14  55  53  67  49  20  45 384  93]\n",
      " [  0   1   4   9  10  11   4   7   5 160 186]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   35.8s remaining:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   52.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[ 66 134  76  14   3   6   0   0   0   6   2]\n",
      " [ 31 444 458  62  16  17   3   2   0  21   3]\n",
      " [  9 361 611 222  28  80   9   3   2  25   3]\n",
      " [  7 144 476 356  78 111  20   5   4  71   4]\n",
      " [  3  55 223 255 104 152  27   8  13  80   6]\n",
      " [  0  24 117 214  78 208  36  10  20  98  12]\n",
      " [  0  20  68 156  57 139  51  11  19 125  19]\n",
      " [  0   7  25  83  34  86  23  22  11 142  16]\n",
      " [  1   9  23  63  26  75  18   8  16 189  29]\n",
      " [  0   4  17  72  40  72  29   8  20 421 103]\n",
      " [  0   1   4  11   7  10   4   3   5 157 195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.0s remaining:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[ 55  99 103  22   2   4   1   0   0  14   7]\n",
      " [130 314 443 108  11  14   1   1   0  25  10]\n",
      " [ 98 258 571 249  37  65  18   3   4  34  16]\n",
      " [ 55 139 406 313  78 138  24   8  11  91  13]\n",
      " [ 26  63 182 250  85 155  20   5   6 107  27]\n",
      " [ 15  33 112 214  64 179  37  10  15 108  30]\n",
      " [  6  23  80 137  37 123  35   6   5 170  43]\n",
      " [  3  10  31  74  32  97  26   6   9 136  25]\n",
      " [  5  15  25  54  27  74  19   3   9 180  46]\n",
      " [  7  30  13  57  25 100  30  10  14 348 152]\n",
      " [  0   5   8  10   3  12  10   2   7 171 169]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.159364</td>\n",
       "      <td>0.159364</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.043812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.263722</td>\n",
       "      <td>0.263722</td>\n",
       "      <td>0.252461</td>\n",
       "      <td>0.251175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.225088</td>\n",
       "      <td>0.229258</td>\n",
       "      <td>0.218664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.284217</td>\n",
       "      <td>0.282050</td>\n",
       "      <td>0.281744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.239458</td>\n",
       "      <td>0.239458</td>\n",
       "      <td>0.260865</td>\n",
       "      <td>0.163596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.301649</td>\n",
       "      <td>0.301649</td>\n",
       "      <td>0.307399</td>\n",
       "      <td>0.286645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.289635</td>\n",
       "      <td>0.276851</td>\n",
       "      <td>0.274505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.293757</td>\n",
       "      <td>0.286248</td>\n",
       "      <td>0.270193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.245465</td>\n",
       "      <td>0.245465</td>\n",
       "      <td>0.225560</td>\n",
       "      <td>0.221782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy    Recall  Precision  F1 Score\n",
       "0        Baseline  0.159364  0.159364   0.025397  0.043812\n",
       "1          LogReg  0.263722  0.263722   0.252461  0.251175\n",
       "2             KNN  0.225088  0.225088   0.229258  0.218664\n",
       "3             SVC  0.284217  0.284217   0.282050  0.281744\n",
       "4   Decision Tree  0.239458  0.239458   0.260865  0.163596\n",
       "5   Random Forest  0.301649  0.301649   0.307399  0.286645\n",
       "6  Gradient Boost  0.289635  0.289635   0.276851  0.274505\n",
       "7         XGBoost  0.293757  0.293757   0.286248  0.270193\n",
       "8        AdaBoost  0.245465  0.245465   0.225560  0.221782"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'Accuracy', 'Recall', 'Precision', 'F1 Score'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(\n",
    "                y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" +\n",
    "          str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.24546525323910484\n",
      "Recall:  0.24546525323910484\n",
      "Precision:  0.22555966733807414\n",
      "F1 Score:  0.22178198870408516\n"
     ]
    }
   ],
   "source": [
    "# Apply LogReg with OVR\n",
    "lr_ovr_model = LogisticRegression(multi_class='ovr', max_iter=200)\n",
    "# fit model\n",
    "lr_ovr_model.fit(X_train_prep, y_train)\n",
    "# make predictions\n",
    "y_pred_lr_ovr = lr_ovr_model.predict(X_train_prep)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "print('Recall: ', recall_score(y_train, y_train_pred, average=\"weighted\"))\n",
    "print('Precision: ', precision_score(y_train, y_train_pred, average=\"weighted\"))\n",
    "print('F1 Score: ', f1_score(y_train, y_train_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_lr_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('lr_clf',\n",
    "                             LogisticRegression(penalty='l2',\n",
    "                                                max_iter=100,\n",
    "                                                C=0.9,\n",
    "#                                                multi_class='multinomial',\n",
    "                                                random_state=random_state,\n",
    "                                                l1_ratio=0.5,\n",
    "                                                n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_lr_clf = LogisticRegression()\n",
    "test_lr_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_lr_clf = {\n",
    "    'lr_clf__penalty': ['l1', 'l2'],\n",
    "    'lr_clf__max_iter': randint(low=10, high=100),\n",
    "    'lr_clf__C': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
    "    'lr_clf__l1_ratio': [None, 0.1, 0.2, 0.3, 0.5, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed:   29.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   35.5s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_lr_clf = RandomizedSearchCV(pipeline_lr_clf,\n",
    "                                 param_distribs_lr_clf,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=50,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_lr_clf = rnd_lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.25\n",
      "Best parameters:\n",
      "{'lr_clf__C': 1, 'lr_clf__l1_ratio': 0.9, 'lr_clf__max_iter': 96, 'lr_clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_lr_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_lr_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_lr_clf = {\n",
    "#    'lr_clf__penalty': ['l1', 'l2'],\n",
    "    'lr_clf__max_iter': [85, 100, 125],\n",
    "    'lr_clf__C': [0.1, 0.5, 1, 2],\n",
    "    'lr_clf__l1_ratio': [0.8, 0.9, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:1317: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  \"(penalty={})\".format(self.penalty))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['accommodates',\n",
       "                                                                          'accommodates_per_bed',\n",
       "                                                                          'am_balcony',\n",
       "                                                                          'am_breakfast',\n",
       "                                                                          'am_child_friendly',\n",
       "                                                                          'am_elevator',\n",
       "                                                                          'am_essentials',\n",
       "                                                                          'am_nature_and_views',\n",
       "                                                                          'am_pets_allo...\n",
       "                                                                         ['cancellation_policy',\n",
       "                                                                          'host_response_time',\n",
       "                                                                          'neighbourhood_cleansed',\n",
       "                                                                          'property_type',\n",
       "                                                                          'room_type',\n",
       "                                                                          'zipcode'])])),\n",
       "                                       ('lr_clf',\n",
       "                                        LogisticRegression(C=0.9, l1_ratio=0.5,\n",
       "                                                           n_jobs=-1,\n",
       "                                                           random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'lr_clf__C': [0.1, 0.5, 1, 2],\n",
       "                         'lr_clf__l1_ratio': [0.8, 0.9, 1],\n",
       "                         'lr_clf__max_iter': [85, 100, 125]},\n",
       "             return_train_score=True, scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_lr_clf = GridSearchCV(pipeline_lr_clf,\n",
    "                            param_grid_lr_clf,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_lr_clf = grid_lr_clf.best_estimator_['lr_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.25\n",
      "Best parameters:\n",
      "{'lr_clf__C': 1, 'lr_clf__l1_ratio': 0.8, 'lr_clf__max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_lr_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_lr_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_lr_clf = best_model_lr_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_lr_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35\n",
      "Recall: 0.35\n",
      "Precision: 0.35\n",
      "F1 Score: 0.34\n",
      "Confusion Matrix: \n",
      "[[ 74 120  73  19   4   3   3   0   0   7   4]\n",
      " [ 20 543 350  94  20   7   3   1   1  18   0]\n",
      " [ 12 299 648 225  63  60  19   5   1  18   3]\n",
      " [ 11 144 369 412 112 119  32  11   9  48   9]\n",
      " [  6  45 178 211 209 127  52  17  13  62   6]\n",
      " [  0  27  75 182 112 228  67  20  15  82   9]\n",
      " [  1  10  58  97  84 125 126  15  21 111  17]\n",
      " [  0   7  23  51  54  70  48  42  18 118  18]\n",
      " [  1   8  15  47  42  64  39  13  56 149  23]\n",
      " [  2   2  15  35  38  68  49  23  33 450  71]\n",
      " [  0   1   3   6  14   9   8   6   7 139 204]]\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy, recall and precision for the test set with the best model\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_lr_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_lr_clf, average='weighted')))\n",
    "#print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_clf, multi_class='ovr')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_lr_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_lr_clf = best_model_lr_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_lr_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_rf_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_clf',\n",
    "                             RandomForestClassifier(n_estimators=110,\n",
    "                                                    random_state=random_state,\n",
    "                                                    max_depth=5,\n",
    "                                                    max_features=20,\n",
    "                                                    n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for RandomForestClassifier\n",
    "test_rf_clf = RandomForestClassifier()\n",
    "test_rf_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_rf_clf = {\n",
    "    'rf_clf__n_estimators': randint(low=10, high=500),\n",
    "    'rf_clf__max_depth': randint(low=1, high=30),\n",
    "    'rf_clf__max_features': randint(low=1, high=100),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_rf_clf = RandomizedSearchCV(pipeline_rf_clf,\n",
    "                           param_distribs_rf_clf,\n",
    "                           cv=5,\n",
    "                           scoring=scoring,\n",
    "                           return_train_score=True,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1,\n",
    "                         random_state=random_state)\n",
    "\n",
    "rnd_rf_clf.fit(X_train, y_train)\n",
    "best_model_rnd_rf_clf = rnd_rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'rf_clf__max_depth': 21, 'rf_clf__max_features': 33, 'rf_clf__n_estimators': 469}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_rf_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_clf = {\n",
    "    'rf_clf__n_estimators': [450, 500],\n",
    "    'rf_clf__max_depth': [20, 25],\n",
    "    'rf_clf__max_features': [30, 35],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed: 10.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_clf = GridSearchCV(pipeline_rf_clf,\n",
    "                            param_grid_rf_clf,\n",
    "                            cv=4,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_rf_clf = grid_rf_clf.best_estimator_['rf_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'rf_clf__max_depth': 25, 'rf_clf__max_features': 35, 'rf_clf__n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.053475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.052189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len_sqrt</th>\n",
       "      <td>0.049861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_no</th>\n",
       "      <td>0.046906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_days_sqrt</th>\n",
       "      <td>0.045590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_days_sqrt</th>\n",
       "      <td>0.045221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_fees_sqrt</th>\n",
       "      <td>0.041142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm_log</th>\n",
       "      <td>0.039622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>0.034078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating_sqrt</th>\n",
       "      <td>0.032940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_people</th>\n",
       "      <td>0.031769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.031012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.028774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.028319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.028069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.020518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.017959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.017844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>0.016925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.010814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>0.009840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.009255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.008948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.008442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.008298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.007610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.007536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0.007456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.007280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.007224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_white_goods</th>\n",
       "      <td>0.006866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.006845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>0.006434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.005714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0.005443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nb_other</th>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alexanderplatz</th>\n",
       "      <td>0.004197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.004160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_unknown</th>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.003912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Sd</th>\n",
       "      <td>0.003231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.003216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Sd FK</th>\n",
       "      <td>0.002968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhofer Vorstadt</th>\n",
       "      <td>0.002710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.002543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_nature_and_views</th>\n",
       "      <td>0.002362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sdwest</th>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Reuterstrae</th>\n",
       "      <td>0.002128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.002116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.002015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sd</th>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_sdliche Luisenstadt</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.001758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.001726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nordwest</th>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Nord</th>\n",
       "      <td>0.001615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Rixdorf</th>\n",
       "      <td>0.001610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Nord</th>\n",
       "      <td>0.001566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.001520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neukllner Mitte/Zentrum</th>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.001478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.001472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schillerpromenade</th>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.001430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.001409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.001328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nord</th>\n",
       "      <td>0.001321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nrdliche Luisenstadt</th>\n",
       "      <td>0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.001282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit West</th>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Helmholtzplatz</th>\n",
       "      <td>0.001251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.001244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.001230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.001208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Sd</th>\n",
       "      <td>0.001189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.001149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Wedding Zentrum</th>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit Ost</th>\n",
       "      <td>0.001133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.001128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Sdliche Friedrichstadt</th>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.001086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.001076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Regierungsviertel</th>\n",
       "      <td>0.001068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Sd</th>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Osloer Strae</th>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Nord</th>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tiergarten Sd</th>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.000914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.000887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.000870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.000853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Dsseldorfer Strae</th>\n",
       "      <td>0.000844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Ost</th>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Parkviertel</th>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.000745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Otto-Suhr-Allee</th>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Friedenau</th>\n",
       "      <td>0.000724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Nord</th>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhof</th>\n",
       "      <td>0.000697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kurfrstendamm</th>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Volkspark Wilmersdorf</th>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.000642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Weiensee</th>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.000588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neu Lichtenberg</th>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt  Treptow</th>\n",
       "      <td>0.000539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kantstrae</th>\n",
       "      <td>0.000520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Sd</th>\n",
       "      <td>0.000519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt-Lichtenberg</th>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.000498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.000473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Zentrum</th>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neue Kantstrae</th>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.000415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schlo Charlottenburg</th>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Westend</th>\n",
       "      <td>0.000396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Britz</th>\n",
       "      <td>0.000377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.000356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.000349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Mierendorffplatz</th>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.000318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Halensee</th>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Grunewald</th>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Zehlendorf  Nord</th>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Drakestr.</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.000262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Ost 2</th>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.000209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Plnterwald</th>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Baumschulenweg</th>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karlshorst</th>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Blankenfelde/Niederschnhausen</th>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Barstrae</th>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      weight\n",
       "latitude                                            0.053475\n",
       "longitude                                           0.052189\n",
       "text_len_sqrt                                       0.049861\n",
       "listing_no                                          0.046906\n",
       "first_review_days_sqrt                              0.045590\n",
       "last_review_days_sqrt                               0.045221\n",
       "availability_90                                     0.043774\n",
       "price_extra_fees_sqrt                               0.041142\n",
       "number_of_reviews_ltm_log                           0.039622\n",
       "host_acceptance_rate                                0.034078\n",
       "review_scores_rating_sqrt                           0.032940\n",
       "price_extra_people                                  0.031769\n",
       "room_type_Private room                              0.031012\n",
       "maximum_nights                                      0.028774\n",
       "minimum_nights_log                                  0.028319\n",
       "accommodates                                        0.028069\n",
       "calc_host_lst_count_sqrt_log                        0.020518\n",
       "accommodates_per_bed                                0.017959\n",
       "bedrooms                                            0.017844\n",
       "host_response_rate                                  0.016925\n",
       "bathrooms_log                                       0.010814\n",
       "review_scores_location                              0.009840\n",
       "am_tv                                               0.009255\n",
       "cancellation_policy_strict                          0.008948\n",
       "am_balcony                                          0.008566\n",
       "am_elevator                                         0.008566\n",
       "cancellation_policy_moderate                        0.008442\n",
       "instant_bookable                                    0.008298\n",
       "host_is_superhost                                   0.007610\n",
       "wk_mth_discount                                     0.007536\n",
       "host_response_time_within an hour                   0.007456\n",
       "am_child_friendly                                   0.007280\n",
       "am_private_entrance                                 0.007224\n",
       "am_white_goods                                      0.006866\n",
       "am_pets_allowed                                     0.006845\n",
       "host_response_time_within a few hours               0.006434\n",
       "am_smoking_allowed                                  0.005714\n",
       "host_response_time_within a day                     0.005443\n",
       "neighbourhood_cleansed_nb_other                     0.004374\n",
       "neighbourhood_cleansed_Alexanderplatz               0.004197\n",
       "zipcode_zip_other                                   0.004160\n",
       "host_response_time_unknown                          0.004015\n",
       "property_type_Boutique hotel                        0.003912\n",
       "neighbourhood_cleansed_Brunnenstr. Sd              0.003231\n",
       "am_breakfast                                        0.003216\n",
       "neighbourhood_cleansed_Frankfurter Allee Sd FK     0.002968\n",
       "neighbourhood_cleansed_Tempelhofer Vorstadt         0.002710\n",
       "zipcode_zip_10119                                   0.002596\n",
       "zipcode_zip_10245                                   0.002543\n",
       "am_essentials                                       0.002475\n",
       "am_nature_and_views                                 0.002362\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sdwest      0.002200\n",
       "neighbourhood_cleansed_Reuterstrae                 0.002128\n",
       "room_type_Shared room                               0.002116\n",
       "zipcode_zip_10405                                   0.002054\n",
       "zipcode_zip_10247                                   0.002015\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sd          0.001905\n",
       "neighbourhood_cleansed_sdliche Luisenstadt         0.001856\n",
       "zipcode_zip_10999                                   0.001827\n",
       "zipcode_zip_10439                                   0.001758\n",
       "zipcode_zip_10437                                   0.001726\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nordwest     0.001707\n",
       "property_type_House                                 0.001691\n",
       "neighbourhood_cleansed_Frankfurter Allee Nord       0.001615\n",
       "neighbourhood_cleansed_Rixdorf                      0.001610\n",
       "neighbourhood_cleansed_Schneberg-Nord              0.001566\n",
       "zipcode_zip_10117                                   0.001520\n",
       "neighbourhood_cleansed_Neukllner Mitte/Zentrum     0.001512\n",
       "zipcode_zip_10997                                   0.001478\n",
       "zipcode_zip_10435                                   0.001472\n",
       "neighbourhood_cleansed_Schillerpromenade            0.001430\n",
       "zipcode_zip_10243                                   0.001430\n",
       "zipcode_zip_10179                                   0.001409\n",
       "zipcode_zip_10249                                   0.001328\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nord         0.001321\n",
       "neighbourhood_cleansed_nrdliche Luisenstadt        0.001290\n",
       "zipcode_zip_10967                                   0.001282\n",
       "neighbourhood_cleansed_Moabit West                  0.001275\n",
       "neighbourhood_cleansed_Helmholtzplatz               0.001251\n",
       "zipcode_zip_nan                                     0.001244\n",
       "zipcode_zip_10407                                   0.001238\n",
       "zipcode_zip_12047                                   0.001230\n",
       "zipcode_zip_10178                                   0.001208\n",
       "neighbourhood_cleansed_Schneberg-Sd               0.001189\n",
       "zipcode_zip_12049                                   0.001149\n",
       "neighbourhood_cleansed_Wedding Zentrum              0.001136\n",
       "neighbourhood_cleansed_Moabit Ost                   0.001133\n",
       "zipcode_zip_10965                                   0.001128\n",
       "neighbourhood_cleansed_Sdliche Friedrichstadt      0.001111\n",
       "zipcode_zip_12051                                   0.001110\n",
       "zipcode_zip_12045                                   0.001086\n",
       "zipcode_zip_10961                                   0.001076\n",
       "neighbourhood_cleansed_Regierungsviertel            0.001068\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Sd          0.001022\n",
       "neighbourhood_cleansed_Osloer Strae                0.000965\n",
       "cancellation_policy_super_strict                    0.000956\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Nord         0.000943\n",
       "neighbourhood_cleansed_Tiergarten Sd               0.000930\n",
       "zipcode_zip_13353                                   0.000923\n",
       "room_type_Hotel room                                0.000914\n",
       "zipcode_zip_10777                                   0.000893\n",
       "zipcode_zip_13359                                   0.000887\n",
       "zipcode_zip_12053                                   0.000870\n",
       "zipcode_zip_12059                                   0.000853\n",
       "neighbourhood_cleansed_Dsseldorfer Strae          0.000844\n",
       "zipcode_zip_10785                                   0.000843\n",
       "zipcode_zip_12043                                   0.000819\n",
       "zipcode_zip_10963                                   0.000807\n",
       "neighbourhood_cleansed_Prenzlauer Berg Ost          0.000798\n",
       "neighbourhood_cleansed_Parkviertel                  0.000767\n",
       "zipcode_zip_12055                                   0.000745\n",
       "neighbourhood_cleansed_Otto-Suhr-Allee              0.000730\n",
       "neighbourhood_cleansed_Friedenau                    0.000724\n",
       "zipcode_zip_10969                                   0.000710\n",
       "neighbourhood_cleansed_Brunnenstr. Nord             0.000703\n",
       "neighbourhood_cleansed_Tempelhof                    0.000697\n",
       "neighbourhood_cleansed_Kurfrstendamm               0.000691\n",
       "neighbourhood_cleansed_Volkspark Wilmersdorf        0.000682\n",
       "zipcode_zip_12435                                   0.000642\n",
       "zipcode_zip_13357                                   0.000626\n",
       "zipcode_zip_10559                                   0.000603\n",
       "neighbourhood_cleansed_Weiensee                    0.000600\n",
       "zipcode_zip_10317                                   0.000592\n",
       "zipcode_zip_13347                                   0.000590\n",
       "property_type_Secondary unit                        0.000588\n",
       "neighbourhood_cleansed_Neu Lichtenberg              0.000570\n",
       "zipcode_zip_10829                                   0.000570\n",
       "zipcode_zip_10551                                   0.000560\n",
       "neighbourhood_cleansed_Alt  Treptow                 0.000539\n",
       "neighbourhood_cleansed_Kantstrae                   0.000520\n",
       "neighbourhood_cleansed_Pankow Sd                   0.000519\n",
       "neighbourhood_cleansed_Alt-Lichtenberg              0.000509\n",
       "zipcode_zip_10719                                   0.000501\n",
       "zipcode_zip_10827                                   0.000498\n",
       "zipcode_zip_13187                                   0.000473\n",
       "zipcode_zip_10555                                   0.000469\n",
       "zipcode_zip_10409                                   0.000453\n",
       "neighbourhood_cleansed_Pankow Zentrum               0.000445\n",
       "neighbourhood_cleansed_Neue Kantstrae              0.000444\n",
       "zipcode_zip_13189                                   0.000441\n",
       "zipcode_zip_10557                                   0.000415\n",
       "zipcode_zip_10585                                   0.000414\n",
       "zipcode_zip_10781                                   0.000410\n",
       "zipcode_zip_13086                                   0.000408\n",
       "neighbourhood_cleansed_Schlo Charlottenburg        0.000401\n",
       "neighbourhood_cleansed_Westend                      0.000396\n",
       "zipcode_zip_10365                                   0.000395\n",
       "neighbourhood_cleansed_Britz                        0.000377\n",
       "zipcode_zip_10553                                   0.000372\n",
       "zipcode_zip_13355                                   0.000368\n",
       "zipcode_zip_14057                                   0.000356\n",
       "zipcode_zip_13088                                   0.000349\n",
       "neighbourhood_cleansed_Mierendorffplatz             0.000348\n",
       "zipcode_zip_14059                                   0.000337\n",
       "zipcode_zip_10707                                   0.000332\n",
       "zipcode_zip_10787                                   0.000332\n",
       "zipcode_zip_10715                                   0.000326\n",
       "zipcode_zip_12157                                   0.000318\n",
       "zipcode_zip_10711                                   0.000314\n",
       "zipcode_zip_10717                                   0.000314\n",
       "zipcode_zip_10589                                   0.000312\n",
       "zipcode_zip_10783                                   0.000307\n",
       "zipcode_zip_10623                                   0.000304\n",
       "neighbourhood_cleansed_Halensee                     0.000304\n",
       "zipcode_zip_10629                                   0.000303\n",
       "neighbourhood_cleansed_Grunewald                    0.000299\n",
       "neighbourhood_cleansed_Zehlendorf  Nord             0.000287\n",
       "zipcode_zip_12161                                   0.000287\n",
       "zipcode_zip_12437                                   0.000281\n",
       "zipcode_zip_13351                                   0.000270\n",
       "zipcode_zip_10625                                   0.000268\n",
       "neighbourhood_cleansed_Drakestr.                    0.000267\n",
       "zipcode_zip_12099                                   0.000262\n",
       "neighbourhood_cleansed_Ost 2                        0.000260\n",
       "zipcode_zip_12163                                   0.000257\n",
       "zipcode_zip_10627                                   0.000252\n",
       "zipcode_zip_12347                                   0.000249\n",
       "zipcode_zip_13407                                   0.000244\n",
       "zipcode_zip_12101                                   0.000233\n",
       "zipcode_zip_10587                                   0.000209\n",
       "neighbourhood_cleansed_Plnterwald                  0.000208\n",
       "zipcode_zip_10315                                   0.000206\n",
       "neighbourhood_cleansed_Baumschulenweg               0.000204\n",
       "zipcode_zip_13156                                   0.000202\n",
       "zipcode_zip_10318                                   0.000202\n",
       "neighbourhood_cleansed_Karlshorst                   0.000199\n",
       "zipcode_zip_10367                                   0.000199\n",
       "zipcode_zip_13409                                   0.000197\n",
       "zipcode_zip_10823                                   0.000195\n",
       "zipcode_zip_12103                                   0.000194\n",
       "property_type_Bed and breakfast                     0.000193\n",
       "neighbourhood_cleansed_Blankenfelde/Niederschn...  0.000175\n",
       "zipcode_zip_14197                                   0.000174\n",
       "zipcode_zip_13349                                   0.000169\n",
       "property_type_Unique space                          0.000107\n",
       "neighbourhood_cleansed_Barstrae                    0.000106\n",
       "zipcode_zip_10713                                   0.000099"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and print feature importances\n",
    "grid_rf_clf_fi = feat_importances(grid_rf_clf, cv_model=True, named_steps='rf_clf', column_names=column_names)\n",
    "grid_rf_clf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_rf_clf = best_model_rf_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: \n",
      "[[ 307    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1057    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1276    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  926    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  817    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  665    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  449    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  457    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  786    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  397]]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_rf_clf, model=\"clf\")\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_pred_rf_clf)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "print(\"F1 Score: {:.2f}\".format(f1_score(y_train, y_pred_rf_clf, average='weighted')))\n",
    "#print(\"ROC/AUC: {:.2f}\".format(roc_auc_score(y_train, y_pred_lr_clf, multi_class='ovr')))\n",
    "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_train, y_pred_rf_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_rf_clf = best_model_rf_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_rf_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_xgb_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_clf',\n",
    "                              XGBClassifier(n_estimators=110,\n",
    "                                            random_state=random_state,\n",
    "                                            max_depth=5,\n",
    "                                            max_features=20,\n",
    "                                            scoring=scoring,\n",
    "                                            n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample', 'verbosity'])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_xgb_clf = XGBClassifier()\n",
    "test_xgb_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_clf = {\n",
    "    'xgb_clf__n_estimators': randint(low=10, high=200),\n",
    "    'xgb_clf__max_depth': randint(low=1, high=10),\n",
    "    'xgb_clf__learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 20.4min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 25.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_clf = RandomizedSearchCV(pipeline_xgb_clf,\n",
    "                                 param_distribs_xgb_clf,\n",
    "                                 cv=5,\n",
    "                                 n_iter=20,\n",
    "                                 scoring=scoring,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_clf = rnd_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.30\n",
      "Best parameters:\n",
      "{'xgb_clf__learning_rate': 0.2, 'xgb_clf__max_depth': 8, 'xgb_clf__n_estimators': 126}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_xgb_clf = {\n",
    "    'xgb_clf__n_estimators': [120, 130],\n",
    "    'xgb_clf__max_depth': [8, 10],\n",
    "    'xgb_clf__learning_rate': [0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['accommodates',\n",
       "                                                                          'accommodates_per_bed',\n",
       "                                                                          'am_balcony',\n",
       "                                                                          'am_breakfast',\n",
       "                                                                          'am_child_friendly',\n",
       "                                                                          'am_elevator',\n",
       "                                                                          'am_essentials',\n",
       "                                                                          'am_nature_and_views',\n",
       "                                                                          'am_pets_allo...\n",
       "                                                                          'neighbourhood_cleansed',\n",
       "                                                                          'property_type',\n",
       "                                                                          'room_type',\n",
       "                                                                          'zipcode'])])),\n",
       "                                       ('xgb_clf',\n",
       "                                        XGBClassifier(max_depth=5,\n",
       "                                                      max_features=20,\n",
       "                                                      n_estimators=110,\n",
       "                                                      n_jobs=-1,\n",
       "                                                      random_state=42,\n",
       "                                                      scoring='f1_weighted'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgb_clf__learning_rate': [0.2, 0.3],\n",
       "                         'xgb_clf__max_depth': [8, 10],\n",
       "                         'xgb_clf__n_estimators': [120, 130]},\n",
       "             return_train_score=True, scoring='f1_weighted', verbose=4)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_xgb_clf = GridSearchCV(pipeline_xgb_clf,\n",
    "                            param_grid_xgb_clf,\n",
    "                            cv=3,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_xgb_clf = grid_xgb_clf.best_estimator_['xgb_clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.29\n",
      "Best parameters:\n",
      "{'xgb_clf__learning_rate': 0.2, 'xgb_clf__max_depth': 10, 'xgb_clf__n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.054966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.018998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.017493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.013383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Ost 2</th>\n",
       "      <td>0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt-Lichtenberg</th>\n",
       "      <td>0.012494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.011030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.010751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.010312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.009451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Friedenau</th>\n",
       "      <td>0.008156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.007994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nb_other</th>\n",
       "      <td>0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Zehlendorf  Nord</th>\n",
       "      <td>0.007563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.007483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Wedding Zentrum</th>\n",
       "      <td>0.007422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.007294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.007289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.007269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.007115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_sdliche Luisenstadt</th>\n",
       "      <td>0.006945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.006924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.006911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.006894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.006793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.006660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhof</th>\n",
       "      <td>0.006578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.006563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.006499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.006387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.006326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Nord</th>\n",
       "      <td>0.006293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alexanderplatz</th>\n",
       "      <td>0.006273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.006212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.006151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.006052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neu Lichtenberg</th>\n",
       "      <td>0.006048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.005891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sdwest</th>\n",
       "      <td>0.005885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit Ost</th>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Otto-Suhr-Allee</th>\n",
       "      <td>0.005796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.005793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.005791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Osloer Strae</th>\n",
       "      <td>0.005789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Parkviertel</th>\n",
       "      <td>0.005724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Helmholtzplatz</th>\n",
       "      <td>0.005640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.005610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.005561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Rixdorf</th>\n",
       "      <td>0.005527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.005518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.005502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_nrdliche Luisenstadt</th>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.005457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Sd</th>\n",
       "      <td>0.005409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.005394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.005228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.005203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nordwest</th>\n",
       "      <td>0.005187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schillerpromenade</th>\n",
       "      <td>0.005116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.005064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Sd FK</th>\n",
       "      <td>0.005019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_location</th>\n",
       "      <td>0.004995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.004989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.004960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.004957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.004941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Dsseldorfer Strae</th>\n",
       "      <td>0.004876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Nord</th>\n",
       "      <td>0.004858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.004794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Sd</th>\n",
       "      <td>0.004779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kurfrstendamm</th>\n",
       "      <td>0.004750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.004747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_nature_and_views</th>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.004670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.004667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Westend</th>\n",
       "      <td>0.004666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.004639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Mierendorffplatz</th>\n",
       "      <td>0.004625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_unknown</th>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.004593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_people</th>\n",
       "      <td>0.004534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.004458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.004456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Sd</th>\n",
       "      <td>0.004432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.004413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tempelhofer Vorstadt</th>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Moabit West</th>\n",
       "      <td>0.004383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.004377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Kantstrae</th>\n",
       "      <td>0.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Sd</th>\n",
       "      <td>0.004275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.004265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.004263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neukllner Mitte/Zentrum</th>\n",
       "      <td>0.004224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Sdliche Friedrichstadt</th>\n",
       "      <td>0.004195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Weiensee</th>\n",
       "      <td>0.004143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a few hours</th>\n",
       "      <td>0.004107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.004058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.004043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_white_goods</th>\n",
       "      <td>0.004037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.003997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>0.003969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.003965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karl-Marx-Allee-Nord</th>\n",
       "      <td>0.003935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.003920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Brunnenstr. Nord</th>\n",
       "      <td>0.003901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.003895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.003894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.003889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listing_no</th>\n",
       "      <td>0.003883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_scores_rating_sqrt</th>\n",
       "      <td>0.003872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Plnterwald</th>\n",
       "      <td>0.003850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Regierungsviertel</th>\n",
       "      <td>0.003842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Reuterstrae</th>\n",
       "      <td>0.003815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.003788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Britz</th>\n",
       "      <td>0.003767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.003764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_extra_fees_sqrt</th>\n",
       "      <td>0.003748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Prenzlauer Berg Ost</th>\n",
       "      <td>0.003730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Volkspark Wilmersdorf</th>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Alt  Treptow</th>\n",
       "      <td>0.003683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_review_days_sqrt</th>\n",
       "      <td>0.003681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.003669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.003664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.003663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.003635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within a day</th>\n",
       "      <td>0.003629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.003623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review_days_sqrt</th>\n",
       "      <td>0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.003606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time_within an hour</th>\n",
       "      <td>0.003597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_len_sqrt</th>\n",
       "      <td>0.003577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.003555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.003531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.003530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>0.003523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schneberg-Sd</th>\n",
       "      <td>0.003509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews_ltm_log</th>\n",
       "      <td>0.003498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Drakestr.</th>\n",
       "      <td>0.003492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.003480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Grunewald</th>\n",
       "      <td>0.003445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.003388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.003382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.003353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.003310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Tiergarten Sd</th>\n",
       "      <td>0.003217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.003181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Halensee</th>\n",
       "      <td>0.003176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.003075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.003046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Frankfurter Allee Nord</th>\n",
       "      <td>0.002911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Baumschulenweg</th>\n",
       "      <td>0.002856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.002832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Schlo Charlottenburg</th>\n",
       "      <td>0.002734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.002596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Neue Kantstrae</th>\n",
       "      <td>0.002455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.002427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.002406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Pankow Zentrum</th>\n",
       "      <td>0.002389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.001947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.001878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.001812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.001785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.001756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Blankenfelde/Niederschnhausen</th>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Barstrae</th>\n",
       "      <td>0.001523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_cleansed_Karlshorst</th>\n",
       "      <td>0.001491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.001258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      weight\n",
       "room_type_Private room                              0.054966\n",
       "room_type_Shared room                               0.018998\n",
       "property_type_Boutique hotel                        0.017493\n",
       "zipcode_zip_13407                                   0.013383\n",
       "bedrooms                                            0.013143\n",
       "neighbourhood_cleansed_Ost 2                        0.012749\n",
       "neighbourhood_cleansed_Alt-Lichtenberg              0.012494\n",
       "room_type_Hotel room                                0.011030\n",
       "zipcode_zip_13187                                   0.010751\n",
       "zipcode_zip_14057                                   0.010312\n",
       "accommodates                                        0.009451\n",
       "neighbourhood_cleansed_Friedenau                    0.008156\n",
       "zipcode_zip_13359                                   0.007994\n",
       "neighbourhood_cleansed_nb_other                     0.007631\n",
       "neighbourhood_cleansed_Zehlendorf  Nord             0.007563\n",
       "zipcode_zip_10553                                   0.007483\n",
       "neighbourhood_cleansed_Wedding Zentrum              0.007422\n",
       "zipcode_zip_10243                                   0.007294\n",
       "property_type_Secondary unit                        0.007289\n",
       "zipcode_zip_10707                                   0.007269\n",
       "cancellation_policy_super_strict                    0.007202\n",
       "bathrooms_log                                       0.007115\n",
       "neighbourhood_cleansed_sdliche Luisenstadt         0.006945\n",
       "zipcode_zip_10717                                   0.006924\n",
       "zipcode_zip_10119                                   0.006911\n",
       "zipcode_zip_10783                                   0.006894\n",
       "zipcode_zip_12103                                   0.006793\n",
       "zipcode_zip_10587                                   0.006700\n",
       "zipcode_zip_13353                                   0.006660\n",
       "neighbourhood_cleansed_Tempelhof                    0.006578\n",
       "zipcode_zip_13088                                   0.006563\n",
       "zipcode_zip_10623                                   0.006499\n",
       "zipcode_zip_10555                                   0.006387\n",
       "zipcode_zip_10589                                   0.006326\n",
       "neighbourhood_cleansed_Schneberg-Nord              0.006293\n",
       "neighbourhood_cleansed_Alexanderplatz               0.006273\n",
       "zipcode_zip_10178                                   0.006212\n",
       "zipcode_zip_10435                                   0.006151\n",
       "zipcode_zip_10965                                   0.006052\n",
       "neighbourhood_cleansed_Neu Lichtenberg              0.006048\n",
       "zipcode_zip_10629                                   0.005938\n",
       "calc_host_lst_count_sqrt_log                        0.005938\n",
       "zipcode_zip_14059                                   0.005891\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sdwest      0.005885\n",
       "neighbourhood_cleansed_Moabit Ost                   0.005859\n",
       "neighbourhood_cleansed_Otto-Suhr-Allee              0.005796\n",
       "am_essentials                                       0.005793\n",
       "zipcode_zip_10551                                   0.005791\n",
       "neighbourhood_cleansed_Osloer Strae                0.005789\n",
       "neighbourhood_cleansed_Parkviertel                  0.005724\n",
       "neighbourhood_cleansed_Helmholtzplatz               0.005640\n",
       "zipcode_zip_10405                                   0.005610\n",
       "zipcode_zip_10247                                   0.005561\n",
       "neighbourhood_cleansed_Rixdorf                      0.005527\n",
       "zipcode_zip_10409                                   0.005518\n",
       "zipcode_zip_12049                                   0.005502\n",
       "neighbourhood_cleansed_nrdliche Luisenstadt        0.005500\n",
       "am_elevator                                         0.005457\n",
       "zipcode_zip_10249                                   0.005435\n",
       "neighbourhood_cleansed_Brunnenstr. Sd              0.005409\n",
       "zipcode_zip_12045                                   0.005394\n",
       "zipcode_zip_10245                                   0.005228\n",
       "zipcode_zip_12053                                   0.005208\n",
       "zipcode_zip_10439                                   0.005203\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nordwest     0.005187\n",
       "zipcode_zip_10407                                   0.005177\n",
       "neighbourhood_cleansed_Schillerpromenade            0.005116\n",
       "zipcode_zip_13189                                   0.005064\n",
       "neighbourhood_cleansed_Frankfurter Allee Sd FK     0.005019\n",
       "review_scores_location                              0.004995\n",
       "zipcode_zip_other                                   0.004989\n",
       "zipcode_zip_13086                                   0.004960\n",
       "zipcode_zip_12157                                   0.004957\n",
       "zipcode_zip_13351                                   0.004941\n",
       "neighbourhood_cleansed_Dsseldorfer Strae          0.004876\n",
       "neighbourhood_cleansed_Prenzlauer Berg Nord         0.004858\n",
       "zipcode_zip_12043                                   0.004839\n",
       "zipcode_zip_10179                                   0.004794\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Sd          0.004779\n",
       "am_breakfast                                        0.004775\n",
       "neighbourhood_cleansed_Kurfrstendamm               0.004750\n",
       "wk_mth_discount                                     0.004747\n",
       "am_nature_and_views                                 0.004687\n",
       "minimum_nights_log                                  0.004670\n",
       "zipcode_zip_12051                                   0.004667\n",
       "neighbourhood_cleansed_Westend                      0.004666\n",
       "zipcode_zip_10785                                   0.004639\n",
       "neighbourhood_cleansed_Mierendorffplatz             0.004625\n",
       "host_response_time_unknown                          0.004614\n",
       "zipcode_zip_12059                                   0.004593\n",
       "price_extra_people                                  0.004534\n",
       "zipcode_zip_12055                                   0.004458\n",
       "zipcode_zip_10117                                   0.004456\n",
       "neighbourhood_cleansed_Pankow Sd                   0.004432\n",
       "property_type_House                                 0.004413\n",
       "neighbourhood_cleansed_Tempelhofer Vorstadt         0.004400\n",
       "neighbourhood_cleansed_Moabit West                  0.004383\n",
       "zipcode_zip_10777                                   0.004377\n",
       "neighbourhood_cleansed_Kantstrae                   0.004302\n",
       "neighbourhood_cleansed_Prenzlauer Berg Sd          0.004275\n",
       "zipcode_zip_10557                                   0.004265\n",
       "zipcode_zip_10437                                   0.004263\n",
       "neighbourhood_cleansed_Neukllner Mitte/Zentrum     0.004224\n",
       "neighbourhood_cleansed_Sdliche Friedrichstadt      0.004195\n",
       "zipcode_zip_nan                                     0.004192\n",
       "neighbourhood_cleansed_Weiensee                    0.004143\n",
       "host_response_time_within a few hours               0.004107\n",
       "zipcode_zip_12163                                   0.004087\n",
       "am_private_entrance                                 0.004058\n",
       "accommodates_per_bed                                0.004043\n",
       "am_white_goods                                      0.004037\n",
       "host_response_rate                                  0.004012\n",
       "zipcode_zip_13347                                   0.004004\n",
       "zipcode_zip_10787                                   0.003997\n",
       "am_tv                                               0.003970\n",
       "latitude                                            0.003969\n",
       "zipcode_zip_12435                                   0.003965\n",
       "zipcode_zip_10585                                   0.003965\n",
       "neighbourhood_cleansed_Karl-Marx-Allee-Nord         0.003935\n",
       "zipcode_zip_12047                                   0.003920\n",
       "longitude                                           0.003906\n",
       "neighbourhood_cleansed_Brunnenstr. Nord             0.003901\n",
       "zipcode_zip_10967                                   0.003895\n",
       "zipcode_zip_10999                                   0.003894\n",
       "zipcode_zip_10719                                   0.003889\n",
       "listing_no                                          0.003883\n",
       "review_scores_rating_sqrt                           0.003872\n",
       "availability_90                                     0.003867\n",
       "neighbourhood_cleansed_Plnterwald                  0.003850\n",
       "neighbourhood_cleansed_Regierungsviertel            0.003842\n",
       "neighbourhood_cleansed_Reuterstrae                 0.003815\n",
       "zipcode_zip_10559                                   0.003788\n",
       "neighbourhood_cleansed_Britz                        0.003767\n",
       "zipcode_zip_12161                                   0.003764\n",
       "price_extra_fees_sqrt                               0.003748\n",
       "neighbourhood_cleansed_Prenzlauer Berg Ost          0.003730\n",
       "neighbourhood_cleansed_Volkspark Wilmersdorf        0.003716\n",
       "neighbourhood_cleansed_Alt  Treptow                 0.003683\n",
       "first_review_days_sqrt                              0.003681\n",
       "zipcode_zip_10715                                   0.003669\n",
       "zipcode_zip_12347                                   0.003664\n",
       "zipcode_zip_10997                                   0.003663\n",
       "am_balcony                                          0.003648\n",
       "cancellation_policy_moderate                        0.003643\n",
       "cancellation_policy_strict                          0.003635\n",
       "host_response_time_within a day                     0.003629\n",
       "zipcode_zip_10627                                   0.003623\n",
       "last_review_days_sqrt                               0.003619\n",
       "am_pets_allowed                                     0.003606\n",
       "host_response_time_within an hour                   0.003597\n",
       "text_len_sqrt                                       0.003577\n",
       "am_child_friendly                                   0.003555\n",
       "host_is_superhost                                   0.003531\n",
       "maximum_nights                                      0.003530\n",
       "host_acceptance_rate                                0.003523\n",
       "neighbourhood_cleansed_Schneberg-Sd               0.003509\n",
       "number_of_reviews_ltm_log                           0.003498\n",
       "neighbourhood_cleansed_Drakestr.                    0.003492\n",
       "zipcode_zip_10781                                   0.003480\n",
       "neighbourhood_cleansed_Grunewald                    0.003445\n",
       "zipcode_zip_10969                                   0.003388\n",
       "zipcode_zip_10365                                   0.003382\n",
       "zipcode_zip_10317                                   0.003353\n",
       "am_smoking_allowed                                  0.003310\n",
       "neighbourhood_cleansed_Tiergarten Sd               0.003217\n",
       "zipcode_zip_14197                                   0.003181\n",
       "neighbourhood_cleansed_Halensee                     0.003176\n",
       "instant_bookable                                    0.003075\n",
       "zipcode_zip_13357                                   0.003074\n",
       "zipcode_zip_10963                                   0.003046\n",
       "zipcode_zip_13355                                   0.002945\n",
       "neighbourhood_cleansed_Frankfurter Allee Nord       0.002911\n",
       "neighbourhood_cleansed_Baumschulenweg               0.002856\n",
       "zipcode_zip_10961                                   0.002832\n",
       "zipcode_zip_12099                                   0.002758\n",
       "neighbourhood_cleansed_Schlo Charlottenburg        0.002734\n",
       "zipcode_zip_10625                                   0.002596\n",
       "zipcode_zip_12101                                   0.002596\n",
       "neighbourhood_cleansed_Neue Kantstrae              0.002455\n",
       "zipcode_zip_10367                                   0.002427\n",
       "zipcode_zip_10829                                   0.002406\n",
       "neighbourhood_cleansed_Pankow Zentrum               0.002389\n",
       "zipcode_zip_10823                                   0.001947\n",
       "zipcode_zip_10711                                   0.001921\n",
       "zipcode_zip_10827                                   0.001878\n",
       "property_type_Bed and breakfast                     0.001812\n",
       "zipcode_zip_10318                                   0.001785\n",
       "zipcode_zip_10315                                   0.001756\n",
       "neighbourhood_cleansed_Blankenfelde/Niederschn...  0.001691\n",
       "neighbourhood_cleansed_Barstrae                    0.001523\n",
       "neighbourhood_cleansed_Karlshorst                   0.001491\n",
       "zipcode_zip_13349                                   0.001258\n",
       "zipcode_zip_12437                                   0.000839\n",
       "zipcode_zip_13156                                   0.000000\n",
       "zipcode_zip_13409                                   0.000000\n",
       "zipcode_zip_10713                                   0.000000\n",
       "property_type_Unique space                          0.000000"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and print feature importances\n",
    "grid_xgb_clf_fi = feat_importances(grid_xgb_clf, cv_model=True, named_steps='xgb_clf', column_names=column_names)\n",
    "grid_xgb_clf_fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_xgb_clf = best_model_xgb_clf.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n",
      "Recall: 1.00\n",
      "Precision: 1.00\n",
      "F1 Score: 1.00\n",
      "Confusion Matrix: \n",
      "[[ 307    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0 1057    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0 1353    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0 1276    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0  926    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0  817    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0  665    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0  449    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0  457    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0  786    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0  397]]\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with \"best model\"\n",
    "model_eval(y_train, y_train_pred_xgb_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_xgb_clf = best_model_xgb_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16\n",
      "RMSE: 0.40\n",
      "MAE: 0.31\n",
      "R2: 0.50\n",
      "MAPE: 7.97\n",
      "MAPE median: 6.10\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_xgb_clf, model=\"clf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## !!! NN Model 1: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: Regression (\"price_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mPRICE_LOG\u001b[0m as the target and \u001b[1mneg_median_absolute_error\u001b[0m for scoring to predict prices for \u001b[1mberlin\u001b[0m on \u001b[1m2020-03-17\u001b[0m\n",
      "\n",
      "The target variable y is set to \u001b[1mPRICE_LOG\u001b[0m\n",
      "\n",
      "You are currently using these features for its prediction:\n",
      "\u001b[1m['accommodates', 'accommodates_per_bed', 'am_balcony', 'am_breakfast', 'am_child_friendly', 'am_elevator', 'am_essentials', 'am_pets_allowed', 'am_private_entrance', 'am_smoking_allowed', 'am_tv', 'availability_90', 'bathrooms_log', 'bedrooms', 'calc_host_lst_count_sqrt_log', 'cancellation_policy', 'host_is_superhost', 'instant_bookable', 'maximum_nights', 'minimum_nights_log', 'property_type', 'room_type', 'wk_mth_discount', 'zipcode']\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "print_target_setting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "models = {\n",
    "    'Baseline':\n",
    "    DummyRegressor(strategy='mean'),\n",
    "    'LinReg':\n",
    "    LinearRegression(),\n",
    "    'Passive Aggressive':\n",
    "    PassiveAggressiveRegressor(),\n",
    "    #        'RANSAC' : RANSACRegressor(),\n",
    "    'ElasticNet':\n",
    "    ElasticNet(),\n",
    "    'Stochastic Gradient Descent':\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeRegressor(criterion=\"mse\",\n",
    "                          max_depth=3,\n",
    "                          random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestRegressor(random_state=random_state,\n",
    "                          max_features='sqrt',\n",
    "                          n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingRegressor(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBRegressor(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostRegressor(random_state=random_state),\n",
    "    'SVR':\n",
    "    SVR(),\n",
    "    'CatBoost':\n",
    "    CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.1s remaining:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   12.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.9s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.5s remaining:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.1s remaining:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   10.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   11.3s remaining:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MAPE median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.766269</td>\n",
       "      <td>9.480414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.671335</td>\n",
       "      <td>6.054153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>10.144652</td>\n",
       "      <td>8.144422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.766269</td>\n",
       "      <td>9.480414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.52</td>\n",
       "      <td>13.034482</td>\n",
       "      <td>10.043096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8.776042</td>\n",
       "      <td>6.868136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.410750</td>\n",
       "      <td>5.773472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.535995</td>\n",
       "      <td>5.968549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.545994</td>\n",
       "      <td>5.967451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>8.725021</td>\n",
       "      <td>6.942201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.424019</td>\n",
       "      <td>5.725685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.160986</td>\n",
       "      <td>5.542889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model   MSE  RMSE     R2   MAE       MAPE  \\\n",
       "0                      Baseline  0.33  0.57  -0.00  0.46  11.766269   \n",
       "1                        LinReg  0.15  0.39   0.53  0.30   7.671335   \n",
       "2            Passive Aggressive  0.27  0.52   0.19  0.40  10.144652   \n",
       "3                    ElasticNet  0.33  0.57  -0.00  0.46  11.766269   \n",
       "4   Stochastic Gradient Descent  0.49  0.70  -0.48  0.52  13.034482   \n",
       "5                 Decision Tree  0.20  0.45   0.39  0.34   8.776042   \n",
       "6                 Random Forest  0.14  0.38   0.56  0.29   7.410750   \n",
       "7                Gradient Boost  0.15  0.38   0.55  0.30   7.535995   \n",
       "8                       XGBoost  0.15  0.38   0.55  0.30   7.545994   \n",
       "9                      AdaBoost  0.19  0.44   0.41  0.34   8.725021   \n",
       "10                          SVR  0.15  0.38   0.55  0.29   7.424019   \n",
       "11                     CatBoost  0.14  0.37   0.59  0.28   7.160986   \n",
       "\n",
       "    MAPE median  \n",
       "0      9.480414  \n",
       "1      6.054153  \n",
       "2      8.144422  \n",
       "3      9.480414  \n",
       "4     10.043096  \n",
       "5      6.868136  \n",
       "6      5.773472  \n",
       "7      5.968549  \n",
       "8      5.967451  \n",
       "9      6.942201  \n",
       "10     5.725685  \n",
       "11     5.542889  "
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'R2', 'MAE', 'MAPE', 'MAPE median'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model':\n",
    "            m[0],\n",
    "            'MSE':\n",
    "            \"{:.2f}\".format(mean_squared_error(y_train, y_train_pred)),\n",
    "            'RMSE':\n",
    "            \"{:.2f}\".format(\n",
    "                mean_squared_error(y_train, y_train_pred, squared=False)),\n",
    "            'R2':\n",
    "            \"{:.2f}\".format(r2_score(y_train, y_train_pred)),\n",
    "            'MAE':\n",
    "            \"{:.2f}\".format(mean_absolute_error(y_train, y_train_pred)),\n",
    "            'MAPE': mean_absolute_percentage_error(y_train, y_train_pred),\n",
    "            'MAPE median': median_absolute_percentage_error(y_train, y_train_pred)\n",
    "        },\n",
    "        index=[i])\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 1: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_xgb_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_reg',\n",
    "                              XGBRegressor(n_estimators=160,\n",
    "                                           learning_rate=0.2,\n",
    "                                           random_state=random_state,\n",
    "                                           max_depth=4,\n",
    "                                           gamma=0.2,\n",
    "                                           bootstrap=True,\n",
    "                                           max_features=40,\n",
    "                                           scoring=scoring,\n",
    "                                           n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'importance_type', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample', 'verbosity'])"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_xgb_reg = XGBRegressor()\n",
    "test_xgb_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for XGBRegressor** (as base for hyperparameter search):\n",
    "\n",
    "max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_reg = {\n",
    "    'xgb_reg__n_estimators': randint(low=10, high=200),\n",
    "    'xgb_reg__bootstrap': [True, False],\n",
    "    'xgb_reg__gamma': [0, 0.1, 0.2, 0.5, 0.8, 0.9, 1],\n",
    "    'xgb_reg__max_depth': randint(low=1, high=5),\n",
    "    'xgb_reg__max_features': randint(low=1, high=60),\n",
    "    'xgb_reg__learning_rate': [0.01, 0.02, 0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:17] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_reg = RandomizedSearchCV(pipeline_xgb_reg,\n",
    "                                 param_distribs_xgb_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=10,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_reg = rnd_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.24\n",
      "Best parameters:\n",
      "{'xgb_reg__bootstrap': True, 'xgb_reg__gamma': 0.5, 'xgb_reg__learning_rate': 0.2, 'xgb_reg__max_depth': 3, 'xgb_reg__max_features': 43, 'xgb_reg__n_estimators': 81}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_xgb_reg = {\n",
    "#    'xgb_reg__bootstrap': [True, False],\n",
    "#    'xgb_reg__n_estimators': [190, 230, 290],\n",
    "#    'xgb_reg__max_features': [40, 45],\n",
    "    'xgb_reg__max_depth': [2, 3, 4],\n",
    "    'xgb_reg__learning_rate': [0.15, 0.2, 0.25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   36.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:55] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer_num',\n",
       "                                                                                          SimpleImputer(strategy='median')),\n",
       "                                                                                         ('std_scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['accommodates',\n",
       "                                                                          'accommodates_per_bed',\n",
       "                                                                          'am_balcony',\n",
       "                                                                          'am_breakfast',\n",
       "                                                                          'am_child_friendly',\n",
       "                                                                          'am_elevator',\n",
       "                                                                          'am_essentials',\n",
       "                                                                          'am_pets_allowed',\n",
       "                                                                          'am_private_entra...\n",
       "                                                                          'zipcode'])])),\n",
       "                                       ('xgb_reg',\n",
       "                                        XGBRegressor(bootstrap=True, gamma=0.2,\n",
       "                                                     learning_rate=0.2,\n",
       "                                                     max_depth=4,\n",
       "                                                     max_features=40,\n",
       "                                                     n_estimators=160,\n",
       "                                                     n_jobs=-1, random_state=42,\n",
       "                                                     scoring='neg_median_absolute_error'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'xgb_reg__learning_rate': [0.15, 0.2, 0.25],\n",
       "                         'xgb_reg__max_depth': [2, 3, 4]},\n",
       "             return_train_score=True, scoring='neg_median_absolute_error',\n",
       "             verbose=4)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_xgb_reg = GridSearchCV(pipeline_xgb_reg,\n",
    "                            param_grid_xgb_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_xgb_reg = grid_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_xgb_reg = grid_xgb_reg.best_estimator_['xgb_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.23\n",
      "Best parameters:\n",
      "{'xgb_reg__learning_rate': 0.25, 'xgb_reg__max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.469485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.038159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.033850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.020446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.019737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.019255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.018535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.018028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.018010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.016984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.014075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.011597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.010124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.009756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.009108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.007669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.007486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.006666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.006010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.005926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.005850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.005579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.005412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.005269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.005060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.004973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.004945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.004777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.004767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.004595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.004507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.004439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.004272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.004060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.004023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.003931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.003870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.003639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.003270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.003151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.003141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.003092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.003090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.002994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.002969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.002872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.002844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.002806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.002773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.002658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.002637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.002631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.002546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.002492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.002453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.002448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.002441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.002284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.002196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.002195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.002189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.002181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.002163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.002161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.002150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.002123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.002018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.001883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.001869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.001859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.001806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.001686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.001672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.001612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.001519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.001518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.001504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.001464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.001320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.001306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.001152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.001126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.001070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.001065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.000933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    weight\n",
       "room_type_Private room            0.469485\n",
       "bedrooms                          0.038159\n",
       "room_type_Shared room             0.033850\n",
       "zipcode_zip_10119                 0.020446\n",
       "property_type_Boutique hotel      0.019737\n",
       "am_elevator                       0.019255\n",
       "room_type_Hotel room              0.018535\n",
       "accommodates                      0.018028\n",
       "zipcode_zip_13359                 0.018010\n",
       "zipcode_zip_10117                 0.016984\n",
       "bathrooms_log                     0.014075\n",
       "zipcode_zip_other                 0.011597\n",
       "am_tv                             0.010124\n",
       "zipcode_zip_10245                 0.009756\n",
       "calc_host_lst_count_sqrt_log      0.009108\n",
       "zipcode_zip_10435                 0.007669\n",
       "zipcode_zip_10997                 0.007486\n",
       "zipcode_zip_10553                 0.006666\n",
       "availability_90                   0.006010\n",
       "zipcode_zip_10179                 0.005926\n",
       "zipcode_zip_10405                 0.005850\n",
       "minimum_nights_log                0.005579\n",
       "zipcode_zip_10707                 0.005415\n",
       "am_breakfast                      0.005412\n",
       "wk_mth_discount                   0.005269\n",
       "zipcode_zip_10178                 0.005181\n",
       "am_smoking_allowed                0.005060\n",
       "am_balcony                        0.004998\n",
       "zipcode_zip_10247                 0.004973\n",
       "zipcode_zip_10719                 0.004945\n",
       "accommodates_per_bed              0.004777\n",
       "property_type_House               0.004767\n",
       "am_essentials                     0.004595\n",
       "zipcode_zip_12347                 0.004507\n",
       "zipcode_zip_13407                 0.004439\n",
       "zipcode_zip_13353                 0.004272\n",
       "host_is_superhost                 0.004060\n",
       "zipcode_zip_12099                 0.004023\n",
       "zipcode_zip_10243                 0.003970\n",
       "zipcode_zip_10315                 0.003931\n",
       "zipcode_zip_12047                 0.003870\n",
       "am_private_entrance               0.003639\n",
       "zipcode_zip_10965                 0.003469\n",
       "zipcode_zip_13357                 0.003306\n",
       "zipcode_zip_10589                 0.003270\n",
       "zipcode_zip_10999                 0.003151\n",
       "zipcode_zip_12055                 0.003141\n",
       "zipcode_zip_13189                 0.003127\n",
       "zipcode_zip_10555                 0.003092\n",
       "zipcode_zip_13347                 0.003090\n",
       "instant_bookable                  0.003032\n",
       "zipcode_zip_10969                 0.002994\n",
       "zipcode_zip_13409                 0.002969\n",
       "zipcode_zip_10437                 0.002872\n",
       "zipcode_zip_13086                 0.002844\n",
       "zipcode_zip_12157                 0.002806\n",
       "maximum_nights                    0.002773\n",
       "zipcode_zip_10967                 0.002721\n",
       "zipcode_zip_10365                 0.002658\n",
       "zipcode_zip_12053                 0.002637\n",
       "zipcode_zip_14057                 0.002631\n",
       "zipcode_zip_12049                 0.002546\n",
       "zipcode_zip_10785                 0.002492\n",
       "am_pets_allowed                   0.002453\n",
       "zipcode_zip_13187                 0.002448\n",
       "zipcode_zip_10963                 0.002441\n",
       "zipcode_zip_10587                 0.002284\n",
       "zipcode_zip_10717                 0.002196\n",
       "zipcode_zip_10551                 0.002195\n",
       "zipcode_zip_10317                 0.002189\n",
       "zipcode_zip_12103                 0.002181\n",
       "zipcode_zip_12163                 0.002163\n",
       "property_type_Secondary unit      0.002161\n",
       "zipcode_zip_10409                 0.002150\n",
       "zipcode_zip_10829                 0.002123\n",
       "cancellation_policy_strict        0.002057\n",
       "zipcode_zip_10715                 0.002018\n",
       "zipcode_zip_10249                 0.001998\n",
       "zipcode_zip_12437                 0.001997\n",
       "zipcode_zip_13351                 0.001976\n",
       "zipcode_zip_10557                 0.001883\n",
       "cancellation_policy_moderate      0.001869\n",
       "zipcode_zip_10318                 0.001859\n",
       "cancellation_policy_super_strict  0.001806\n",
       "property_type_Unique space        0.001753\n",
       "am_child_friendly                 0.001686\n",
       "zipcode_zip_13349                 0.001672\n",
       "zipcode_zip_13355                 0.001612\n",
       "zipcode_zip_13088                 0.001519\n",
       "zipcode_zip_10367                 0.001518\n",
       "zipcode_zip_12051                 0.001504\n",
       "zipcode_zip_10439                 0.001464\n",
       "zipcode_zip_12059                 0.001408\n",
       "zipcode_zip_10961                 0.001362\n",
       "property_type_Bed and breakfast   0.001320\n",
       "zipcode_zip_12435                 0.001306\n",
       "zipcode_zip_10713                 0.001202\n",
       "zipcode_zip_10629                 0.001198\n",
       "zipcode_zip_10627                 0.001152\n",
       "zipcode_zip_13156                 0.001146\n",
       "zipcode_zip_10781                 0.001126\n",
       "zipcode_zip_14059                 0.001070\n",
       "zipcode_zip_10827                 0.001065\n",
       "zipcode_zip_nan                   0.001017\n",
       "zipcode_zip_12101                 0.000933\n",
       "zipcode_zip_12161                 0.000735\n",
       "zipcode_zip_12043                 0.000728\n",
       "zipcode_zip_14197                 0.000000\n",
       "zipcode_zip_10823                 0.000000\n",
       "zipcode_zip_10787                 0.000000\n",
       "zipcode_zip_10783                 0.000000\n",
       "zipcode_zip_10559                 0.000000\n",
       "zipcode_zip_12045                 0.000000\n",
       "zipcode_zip_10777                 0.000000\n",
       "zipcode_zip_10711                 0.000000\n",
       "zipcode_zip_10407                 0.000000\n",
       "zipcode_zip_10623                 0.000000\n",
       "zipcode_zip_10585                 0.000000\n",
       "zipcode_zip_10625                 0.000000"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_xgb_reg = get_feat_importances(best_model_xgb_reg)\n",
    "fi_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_xgb_reg = best_model_xgb_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.11\n",
      "RMSE: 0.33\n",
      "MAE: 0.25\n",
      "R2: 0.66\n",
      "MAPE: 6.49\n",
      "MAPE median: 5.09\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_xgb_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_xgb_reg = best_model_xgb_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.14\n",
      "RMSE: 0.37\n",
      "MAE: 0.28\n",
      "R2: 0.57\n",
      "MAPE: 7.33\n",
      "MAPE median: 5.57\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_xgb_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35936446, 0.38944656])"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_xgb_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_xgb_reg = (median_absolute_percentage_error(y_test, y_test_pred_xgb_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51.84, 82.57),\n",
       " (63.22, 103.08),\n",
       " (49.79, 78.93),\n",
       " (34.49, 52.37),\n",
       " (41.59, 64.56),\n",
       " (27.68, 40.95),\n",
       " (42.6, 66.3),\n",
       " (31.29, 46.96),\n",
       " (51.57, 82.1),\n",
       " (45.26, 70.95),\n",
       " (23.92, 34.78),\n",
       " (34.68, 52.68),\n",
       " (61.49, 99.94),\n",
       " (24.87, 36.33),\n",
       " (35.96, 54.87),\n",
       " (72.42, 120.0),\n",
       " (69.95, 115.44),\n",
       " (57.58, 92.87),\n",
       " (48.03, 75.82),\n",
       " (47.87, 75.53),\n",
       " (92.02, 156.84),\n",
       " (52.02, 82.9),\n",
       " (37.74, 57.91),\n",
       " (90.41, 153.78),\n",
       " (22.66, 32.74),\n",
       " (59.71, 96.71),\n",
       " (78.0, 130.39),\n",
       " (31.42, 47.19),\n",
       " (25.97, 38.13),\n",
       " (43.56, 67.98),\n",
       " (25.88, 37.98),\n",
       " (65.05, 106.43),\n",
       " (47.89, 75.57),\n",
       " (28.68, 42.6),\n",
       " (41.49, 64.39),\n",
       " (48.84, 77.25),\n",
       " (38.33, 58.93),\n",
       " (51.93, 82.73),\n",
       " (31.11, 46.66),\n",
       " (33.19, 50.15),\n",
       " (30.83, 46.19),\n",
       " (22.95, 33.21),\n",
       " (43.61, 68.06),\n",
       " (31.5, 47.32),\n",
       " (29.35, 43.71),\n",
       " (42.92, 66.86),\n",
       " (42.45, 66.05),\n",
       " (72.35, 119.87),\n",
       " (67.56, 111.03),\n",
       " (99.9, 171.94),\n",
       " (32.79, 49.48),\n",
       " (68.68, 113.09),\n",
       " (52.97, 84.59),\n",
       " (48.27, 76.25),\n",
       " (38.5, 59.22),\n",
       " (45.26, 70.95),\n",
       " (59.75, 96.79),\n",
       " (35.55, 54.16),\n",
       " (57.48, 92.69),\n",
       " (33.5, 50.69),\n",
       " (57.71, 93.09),\n",
       " (57.23, 92.23),\n",
       " (62.04, 100.94),\n",
       " (48.68, 76.98),\n",
       " (52.13, 83.1),\n",
       " (45.95, 72.17),\n",
       " (24.41, 35.58),\n",
       " (29.48, 43.93),\n",
       " (48.3, 76.31),\n",
       " (41.91, 65.1),\n",
       " (49.75, 78.86),\n",
       " (66.78, 109.6),\n",
       " (38.45, 59.13),\n",
       " (57.84, 93.34),\n",
       " (171.8, 315.2),\n",
       " (42.9, 66.84),\n",
       " (17.25, 24.13),\n",
       " (52.12, 83.08),\n",
       " (35.09, 53.38),\n",
       " (27.71, 40.99),\n",
       " (22.39, 32.31),\n",
       " (23.58, 34.24),\n",
       " (35.88, 54.73),\n",
       " (24.96, 36.47),\n",
       " (64.77, 105.93),\n",
       " (59.04, 95.49),\n",
       " (41.55, 64.48),\n",
       " (72.91, 120.92),\n",
       " (39.56, 61.04),\n",
       " (55.04, 88.31),\n",
       " (60.51, 98.16),\n",
       " (47.43, 74.76),\n",
       " (39.01, 60.1),\n",
       " (118.26, 207.63),\n",
       " (52.82, 84.33),\n",
       " (35.17, 53.51),\n",
       " (101.33, 174.68),\n",
       " (60.19, 97.59),\n",
       " (28.03, 41.52),\n",
       " (23.16, 33.55),\n",
       " (30.68, 45.95),\n",
       " (49.44, 78.33),\n",
       " (30.01, 44.83),\n",
       " (41.99, 65.25),\n",
       " (28.95, 43.05),\n",
       " (54.11, 86.64),\n",
       " (26.7, 39.33),\n",
       " (34.02, 51.57),\n",
       " (37.59, 57.65),\n",
       " (52.95, 84.55),\n",
       " (37.11, 56.83),\n",
       " (21.86, 31.46),\n",
       " (84.64, 142.84),\n",
       " (26.84, 39.56),\n",
       " (71.18, 117.7),\n",
       " (60.85, 98.78),\n",
       " (40.93, 63.41),\n",
       " (78.46, 131.25),\n",
       " (46.88, 73.79),\n",
       " (31.12, 46.67),\n",
       " (26.54, 39.07),\n",
       " (51.33, 81.67),\n",
       " (32.53, 49.05),\n",
       " (44.27, 69.22),\n",
       " (31.48, 47.28),\n",
       " (66.98, 109.98),\n",
       " (36.46, 55.72),\n",
       " (52.26, 83.33),\n",
       " (33.79, 51.18),\n",
       " (25.78, 37.81),\n",
       " (77.45, 129.36),\n",
       " (20.11, 28.65),\n",
       " (30.7, 45.97),\n",
       " (23.19, 33.6),\n",
       " (38.92, 59.94),\n",
       " (31.13, 46.69),\n",
       " (30.29, 45.29),\n",
       " (46.46, 73.05),\n",
       " (110.59, 192.63),\n",
       " (89.71, 152.45),\n",
       " (31.79, 47.8),\n",
       " (44.81, 70.16),\n",
       " (46.17, 72.55),\n",
       " (28.78, 42.78),\n",
       " (45.09, 70.66),\n",
       " (75.64, 125.98),\n",
       " (46.02, 72.28),\n",
       " (34.96, 53.16),\n",
       " (57.7, 93.08),\n",
       " (74.25, 123.4),\n",
       " (70.32, 116.11),\n",
       " (55.66, 89.42),\n",
       " (62.57, 101.91),\n",
       " (23.93, 34.79),\n",
       " (82.08, 138.04),\n",
       " (99.9, 171.94),\n",
       " (22.89, 33.11),\n",
       " (51.48, 81.94),\n",
       " (31.42, 47.19),\n",
       " (88.23, 149.64),\n",
       " (25.98, 38.14),\n",
       " (32.47, 48.95),\n",
       " (50.08, 79.46),\n",
       " (44.57, 69.75),\n",
       " (37.02, 56.67),\n",
       " (88.07, 149.33),\n",
       " (39.95, 61.72),\n",
       " (29.65, 44.23),\n",
       " (26.09, 38.33),\n",
       " (27.84, 41.21),\n",
       " (51.12, 81.3),\n",
       " (126.44, 223.74),\n",
       " (43.45, 67.79),\n",
       " (42.32, 65.83),\n",
       " (31.25, 46.9),\n",
       " (72.54, 120.22),\n",
       " (27.06, 39.93),\n",
       " (51.6, 82.15),\n",
       " (29.57, 44.08),\n",
       " (36.3, 55.45),\n",
       " (47.61, 75.08),\n",
       " (59.03, 95.48),\n",
       " (55.79, 89.64),\n",
       " (46.46, 73.06),\n",
       " (29.63, 44.18),\n",
       " (58.14, 93.87),\n",
       " (44.65, 69.88),\n",
       " (81.09, 136.17),\n",
       " (52.89, 84.45),\n",
       " (50.77, 80.68),\n",
       " (65.6, 107.45),\n",
       " (28.93, 43.03),\n",
       " (77.51, 129.46),\n",
       " (74.57, 123.99),\n",
       " (58.11, 93.82),\n",
       " (67.11, 110.22),\n",
       " (77.72, 129.86),\n",
       " (31.79, 47.81),\n",
       " (58.25, 94.07),\n",
       " (25.13, 36.75),\n",
       " (62.49, 101.76),\n",
       " (34.84, 52.95),\n",
       " (99.42, 171.01),\n",
       " (43.1, 67.17),\n",
       " (48.39, 76.46),\n",
       " (42.19, 65.59),\n",
       " (76.51, 127.61),\n",
       " (111.47, 194.35),\n",
       " (51.88, 82.64),\n",
       " (32.82, 49.54),\n",
       " (141.69, 254.12),\n",
       " (29.63, 44.18),\n",
       " (31.26, 46.91),\n",
       " (77.89, 130.17),\n",
       " (27.3, 40.32),\n",
       " (50.22, 79.69),\n",
       " (28.93, 43.02),\n",
       " (46.73, 73.54),\n",
       " (39.07, 60.2),\n",
       " (61.06, 99.16),\n",
       " (88.17, 149.53),\n",
       " (18.44, 26.0),\n",
       " (55.13, 88.47),\n",
       " (28.29, 41.96),\n",
       " (76.1, 126.84),\n",
       " (32.66, 49.26),\n",
       " (17.98, 25.28),\n",
       " (26.54, 39.06),\n",
       " (65.3, 106.89),\n",
       " (68.28, 112.37),\n",
       " (56.39, 90.73),\n",
       " (72.5, 120.14),\n",
       " (44.52, 69.65),\n",
       " (36.78, 56.26),\n",
       " (43.76, 68.33),\n",
       " (44.73, 70.03),\n",
       " (52.0, 82.86),\n",
       " (73.05, 121.16),\n",
       " (44.31, 69.29),\n",
       " (40.45, 62.58),\n",
       " (59.54, 96.41),\n",
       " (61.55, 100.06),\n",
       " (55.7, 89.48),\n",
       " (103.16, 178.21),\n",
       " (35.47, 54.04),\n",
       " (29.55, 44.05),\n",
       " (31.49, 47.3),\n",
       " (52.56, 83.86),\n",
       " (50.17, 79.6),\n",
       " (42.04, 65.33),\n",
       " (36.76, 56.24),\n",
       " (52.83, 84.34),\n",
       " (62.93, 102.56),\n",
       " (74.04, 123.0),\n",
       " (53.54, 85.61),\n",
       " (46.8, 73.66),\n",
       " (54.04, 86.5),\n",
       " (43.67, 68.17),\n",
       " (33.32, 50.38),\n",
       " (33.67, 50.97),\n",
       " (29.1, 43.3),\n",
       " (32.65, 49.25),\n",
       " (51.74, 82.39),\n",
       " (33.58, 50.81),\n",
       " (32.05, 48.25),\n",
       " (26.51, 39.01),\n",
       " (57.04, 91.9),\n",
       " (35.36, 53.84),\n",
       " (80.69, 135.42),\n",
       " (35.17, 53.52),\n",
       " (24.02, 34.95),\n",
       " (39.77, 61.41),\n",
       " (49.15, 77.81),\n",
       " (71.54, 118.37),\n",
       " (96.97, 166.31),\n",
       " (80.65, 135.34),\n",
       " (88.93, 150.96),\n",
       " (40.24, 62.21),\n",
       " (59.4, 96.15),\n",
       " (48.87, 77.3),\n",
       " (21.78, 31.32),\n",
       " (56.81, 91.47),\n",
       " (40.6, 62.83),\n",
       " (110.7, 192.85),\n",
       " (56.07, 90.15),\n",
       " (43.49, 67.86),\n",
       " (31.23, 46.86),\n",
       " (26.29, 38.65),\n",
       " (53.97, 86.39),\n",
       " (57.48, 92.68),\n",
       " (30.38, 45.44),\n",
       " (61.09, 99.22),\n",
       " (91.99, 156.78),\n",
       " (41.19, 63.86),\n",
       " (90.14, 153.26),\n",
       " (27.0, 39.83),\n",
       " (34.18, 51.83),\n",
       " (51.2, 81.45),\n",
       " (26.94, 39.73),\n",
       " (57.79, 93.24),\n",
       " (28.28, 41.95),\n",
       " (50.09, 79.47),\n",
       " (33.06, 49.95),\n",
       " (47.39, 74.7),\n",
       " (52.38, 83.54),\n",
       " (34.74, 52.78),\n",
       " (56.88, 91.61),\n",
       " (56.86, 91.56),\n",
       " (54.94, 88.12),\n",
       " (59.46, 96.26),\n",
       " (82.77, 139.32),\n",
       " (48.06, 75.88),\n",
       " (82.54, 138.9),\n",
       " (70.18, 115.86),\n",
       " (91.56, 155.97),\n",
       " (32.14, 48.38),\n",
       " (28.76, 42.74),\n",
       " (27.88, 41.28),\n",
       " (47.29, 74.52),\n",
       " (63.63, 103.85),\n",
       " (41.89, 65.08),\n",
       " (65.09, 106.5),\n",
       " (58.99, 95.4),\n",
       " (29.44, 43.87),\n",
       " (105.45, 182.66),\n",
       " (36.84, 56.36),\n",
       " (48.1, 75.95),\n",
       " (51.6, 82.15),\n",
       " (24.9, 36.38),\n",
       " (50.15, 79.57),\n",
       " (74.41, 123.69),\n",
       " (46.35, 72.87),\n",
       " (24.69, 36.03),\n",
       " (65.12, 106.56),\n",
       " (60.61, 98.35),\n",
       " (28.79, 42.79),\n",
       " (27.55, 40.73),\n",
       " (44.93, 70.38),\n",
       " (30.41, 45.49),\n",
       " (53.87, 86.21),\n",
       " (42.97, 66.95),\n",
       " (124.03, 218.99),\n",
       " (27.86, 41.25),\n",
       " (25.87, 37.96),\n",
       " (47.1, 74.19),\n",
       " (30.13, 45.03),\n",
       " (25.72, 37.72),\n",
       " (51.31, 81.64),\n",
       " (51.69, 82.31),\n",
       " (73.73, 122.43),\n",
       " (69.34, 114.32),\n",
       " (50.57, 80.31),\n",
       " (23.07, 33.4),\n",
       " (93.02, 158.76),\n",
       " (22.42, 32.35),\n",
       " (24.69, 36.04),\n",
       " (44.26, 69.2),\n",
       " (54.68, 87.65),\n",
       " (74.14, 123.19),\n",
       " (30.06, 44.91),\n",
       " (31.97, 48.11),\n",
       " (35.73, 54.47),\n",
       " (28.8, 42.81),\n",
       " (32.41, 48.84),\n",
       " (49.12, 77.74),\n",
       " (43.26, 67.46),\n",
       " (52.87, 84.41),\n",
       " (33.23, 50.22),\n",
       " (55.29, 88.75),\n",
       " (63.83, 104.2),\n",
       " (34.17, 51.82),\n",
       " (25.42, 37.22),\n",
       " (46.71, 73.5),\n",
       " (76.3, 127.22),\n",
       " (23.23, 33.67),\n",
       " (44.13, 68.97),\n",
       " (65.19, 106.69),\n",
       " (29.78, 44.44),\n",
       " (40.95, 63.44),\n",
       " (29.27, 43.58),\n",
       " (56.81, 91.48),\n",
       " (65.43, 107.14),\n",
       " (111.43, 194.27),\n",
       " (35.63, 54.3),\n",
       " (29.5, 43.97),\n",
       " (44.93, 70.38),\n",
       " (65.04, 106.42),\n",
       " (29.57, 44.08),\n",
       " (28.41, 42.16),\n",
       " (54.85, 87.96),\n",
       " (93.1, 158.91),\n",
       " (55.66, 89.42),\n",
       " (29.21, 43.48),\n",
       " (31.02, 46.51),\n",
       " (32.59, 49.15),\n",
       " (104.64, 181.07),\n",
       " (47.81, 75.43),\n",
       " (59.71, 96.71),\n",
       " (56.01, 90.04),\n",
       " (24.26, 35.34),\n",
       " (29.42, 43.84),\n",
       " (95.1, 162.73),\n",
       " (20.7, 29.58),\n",
       " (53.86, 86.19),\n",
       " (44.02, 68.78),\n",
       " (30.4, 45.47),\n",
       " (48.0, 75.77),\n",
       " (36.11, 55.12),\n",
       " (27.7, 40.98),\n",
       " (35.63, 54.3),\n",
       " (31.18, 46.78),\n",
       " (61.19, 99.39),\n",
       " (77.27, 129.01),\n",
       " (76.42, 127.43),\n",
       " (26.18, 38.48),\n",
       " (53.95, 86.34),\n",
       " (20.8, 29.75),\n",
       " (53.46, 85.47),\n",
       " (48.2, 76.13),\n",
       " (94.76, 162.07),\n",
       " (31.38, 47.11),\n",
       " (19.76, 28.09),\n",
       " (28.48, 42.27),\n",
       " (65.04, 106.41),\n",
       " (37.61, 57.68),\n",
       " (42.43, 66.0),\n",
       " (45.45, 71.29),\n",
       " (67.47, 110.87),\n",
       " (29.61, 44.16),\n",
       " (41.27, 63.99),\n",
       " (46.18, 72.56),\n",
       " (54.25, 86.88),\n",
       " (47.93, 75.64),\n",
       " (41.49, 64.37),\n",
       " (53.16, 84.94),\n",
       " (27.28, 40.29),\n",
       " (24.49, 35.71),\n",
       " (37.71, 57.85),\n",
       " (26.45, 38.92),\n",
       " (80.96, 135.93),\n",
       " (54.98, 88.19),\n",
       " (48.72, 77.04),\n",
       " (28.87, 42.92),\n",
       " (65.59, 107.42),\n",
       " (44.64, 69.87),\n",
       " (19.93, 28.36),\n",
       " (82.5, 138.82),\n",
       " (24.2, 35.23),\n",
       " (25.24, 36.94),\n",
       " (43.65, 68.14),\n",
       " (56.63, 91.16),\n",
       " (46.59, 73.29),\n",
       " (47.25, 74.45),\n",
       " (36.24, 55.34),\n",
       " (31.12, 46.67),\n",
       " (92.56, 157.88),\n",
       " (76.39, 127.37),\n",
       " (62.14, 101.12),\n",
       " (46.33, 72.83),\n",
       " (48.59, 76.81),\n",
       " (29.82, 44.5),\n",
       " (31.6, 47.48),\n",
       " (49.04, 77.61),\n",
       " (84.91, 143.36),\n",
       " (54.67, 87.64),\n",
       " (20.08, 28.61),\n",
       " (34.24, 51.94),\n",
       " (80.7, 135.44),\n",
       " (25.33, 37.07),\n",
       " (21.06, 30.17),\n",
       " (30.53, 45.68),\n",
       " (58.73, 94.94),\n",
       " (65.4, 107.08),\n",
       " (63.5, 103.6),\n",
       " (43.53, 67.93),\n",
       " (28.63, 42.52),\n",
       " (98.28, 168.81),\n",
       " (23.68, 34.39),\n",
       " (39.97, 61.76),\n",
       " (20.55, 29.35),\n",
       " (39.03, 60.13),\n",
       " (52.17, 83.17),\n",
       " (73.96, 122.86),\n",
       " (37.37, 57.27),\n",
       " (29.09, 43.29),\n",
       " (48.12, 75.98),\n",
       " (24.78, 36.18),\n",
       " (31.97, 48.11),\n",
       " (118.84, 208.77),\n",
       " (51.39, 81.79),\n",
       " (33.82, 51.23),\n",
       " (29.26, 43.57),\n",
       " (28.15, 41.72),\n",
       " (135.45, 241.64),\n",
       " (33.71, 51.04),\n",
       " (28.21, 41.82),\n",
       " (44.0, 68.75),\n",
       " (38.06, 58.45),\n",
       " (58.19, 93.96),\n",
       " (68.25, 112.3),\n",
       " (46.78, 73.62),\n",
       " (92.17, 157.14),\n",
       " (43.13, 67.23),\n",
       " (27.02, 39.86),\n",
       " (21.26, 30.49),\n",
       " (26.94, 39.73),\n",
       " (69.32, 114.28),\n",
       " (49.79, 78.94),\n",
       " (40.03, 61.85),\n",
       " (79.88, 133.9),\n",
       " (27.95, 41.4),\n",
       " (54.07, 86.56),\n",
       " (36.67, 56.08),\n",
       " (59.41, 96.17),\n",
       " (30.5, 45.64),\n",
       " (39.74, 61.35),\n",
       " (67.09, 110.17),\n",
       " (23.92, 34.78),\n",
       " (28.92, 43.01),\n",
       " (32.03, 48.21),\n",
       " (66.8, 109.63),\n",
       " (28.56, 42.41),\n",
       " (54.3, 86.98),\n",
       " (56.33, 90.62),\n",
       " (29.09, 43.29),\n",
       " (61.75, 100.42),\n",
       " (22.65, 32.72),\n",
       " (58.28, 94.12),\n",
       " (67.03, 110.06),\n",
       " (69.3, 114.24),\n",
       " (22.64, 32.71),\n",
       " (48.8, 77.18),\n",
       " (31.43, 47.2),\n",
       " (101.26, 174.56),\n",
       " (25.4, 37.2),\n",
       " (29.67, 44.25),\n",
       " (51.99, 82.85),\n",
       " (41.41, 64.23),\n",
       " (27.49, 40.64),\n",
       " (37.5, 57.5),\n",
       " (78.05, 130.47),\n",
       " (48.74, 77.08),\n",
       " (99.9, 171.94),\n",
       " (67.08, 110.16),\n",
       " (22.96, 33.22),\n",
       " (39.21, 60.43),\n",
       " (50.5, 80.19),\n",
       " (43.94, 68.64),\n",
       " (44.1, 68.92),\n",
       " (44.54, 69.69),\n",
       " (27.8, 41.14),\n",
       " (28.9, 42.97),\n",
       " (40.38, 62.45),\n",
       " (39.72, 61.31),\n",
       " (30.61, 45.83),\n",
       " (147.19, 265.17),\n",
       " (43.98, 68.72),\n",
       " (53.16, 84.93),\n",
       " (46.7, 73.48),\n",
       " (25.55, 37.45),\n",
       " (45.28, 70.98),\n",
       " (33.01, 49.86),\n",
       " (21.04, 30.13),\n",
       " (75.19, 125.15),\n",
       " (68.9, 113.5),\n",
       " (38.15, 58.62),\n",
       " (46.35, 72.87),\n",
       " (54.03, 86.49),\n",
       " (48.73, 77.06),\n",
       " (35.76, 54.53),\n",
       " (59.22, 95.82),\n",
       " (48.83, 77.24),\n",
       " (37.48, 57.47),\n",
       " (40.53, 62.72),\n",
       " (54.31, 86.99),\n",
       " (60.42, 98.01),\n",
       " (28.29, 41.96),\n",
       " (20.56, 29.37),\n",
       " (37.39, 57.32),\n",
       " (34.51, 52.4),\n",
       " (70.12, 115.76),\n",
       " (49.89, 79.11),\n",
       " (56.64, 91.17),\n",
       " (45.63, 71.61),\n",
       " (61.14, 99.31),\n",
       " (45.91, 72.09),\n",
       " (86.92, 147.17),\n",
       " (64.97, 106.28),\n",
       " (49.1, 77.71),\n",
       " (53.21, 85.03),\n",
       " (33.67, 50.97),\n",
       " (50.84, 80.79),\n",
       " (38.6, 59.39),\n",
       " (27.99, 41.46),\n",
       " (51.31, 81.64),\n",
       " (64.99, 106.33),\n",
       " (28.1, 41.64),\n",
       " (40.09, 61.95),\n",
       " (28.29, 41.96),\n",
       " (29.35, 43.72),\n",
       " (52.26, 83.32),\n",
       " (40.37, 62.43),\n",
       " (31.52, 47.35),\n",
       " (50.55, 80.29),\n",
       " (34.03, 51.57),\n",
       " (58.3, 94.17),\n",
       " (45.68, 71.69),\n",
       " (26.12, 38.38),\n",
       " (46.12, 72.46),\n",
       " (58.2, 93.98),\n",
       " (38.38, 59.02),\n",
       " (52.0, 82.87),\n",
       " (56.45, 90.83),\n",
       " (56.73, 91.34),\n",
       " (46.66, 73.41),\n",
       " (30.56, 45.74),\n",
       " (21.2, 30.39),\n",
       " (55.57, 89.25),\n",
       " (57.51, 92.74),\n",
       " (17.84, 25.06),\n",
       " (58.86, 95.18),\n",
       " (37.58, 57.63),\n",
       " (59.34, 96.05),\n",
       " (26.65, 39.25),\n",
       " (36.63, 56.01),\n",
       " (39.44, 60.83),\n",
       " (39.92, 61.66),\n",
       " (29.41, 43.81),\n",
       " (23.5, 34.11),\n",
       " (30.68, 45.95),\n",
       " (59.07, 95.56),\n",
       " (36.73, 56.17),\n",
       " (36.35, 55.52),\n",
       " (26.56, 39.11),\n",
       " (41.05, 63.61),\n",
       " (78.15, 130.66),\n",
       " (107.46, 186.54),\n",
       " (53.53, 85.6),\n",
       " (38.03, 58.41),\n",
       " (31.82, 47.85),\n",
       " (33.75, 51.1),\n",
       " (48.7, 77.01),\n",
       " (48.77, 77.14),\n",
       " (36.57, 55.91),\n",
       " (29.25, 43.55),\n",
       " (50.74, 80.63),\n",
       " (41.64, 64.64),\n",
       " (62.4, 101.6),\n",
       " (38.38, 59.01),\n",
       " (32.26, 48.59),\n",
       " (26.3, 38.67),\n",
       " (50.18, 79.63),\n",
       " (35.28, 53.71),\n",
       " (48.14, 76.01),\n",
       " (67.5, 110.92),\n",
       " (75.03, 124.85),\n",
       " (24.46, 35.66),\n",
       " (23.1, 33.45),\n",
       " (32.93, 49.73),\n",
       " (44.53, 69.68),\n",
       " (23.19, 33.6),\n",
       " (52.17, 83.17),\n",
       " (26.13, 38.4),\n",
       " (44.45, 69.54),\n",
       " (34.44, 52.28),\n",
       " (66.13, 108.42),\n",
       " (30.96, 46.41),\n",
       " (52.05, 82.95),\n",
       " (28.51, 42.32),\n",
       " (29.41, 43.83),\n",
       " (49.77, 78.9),\n",
       " (55.37, 88.89),\n",
       " (84.5, 142.59),\n",
       " (127.15, 225.15),\n",
       " (37.62, 57.7),\n",
       " (47.0, 74.0),\n",
       " (34.99, 53.21),\n",
       " (32.7, 49.34),\n",
       " (94.46, 161.51),\n",
       " (24.59, 35.88),\n",
       " (54.52, 87.37),\n",
       " (56.13, 90.26),\n",
       " (32.2, 48.5),\n",
       " (28.68, 42.61),\n",
       " (31.06, 46.59),\n",
       " (33.49, 50.67),\n",
       " (22.52, 32.52),\n",
       " (55.43, 88.99),\n",
       " (38.35, 58.96),\n",
       " (38.68, 59.53),\n",
       " (39.9, 61.62),\n",
       " (28.19, 41.79),\n",
       " (42.46, 66.07),\n",
       " (36.9, 56.47),\n",
       " (28.2, 41.81),\n",
       " (50.27, 79.78),\n",
       " (33.8, 51.19),\n",
       " (48.74, 77.07),\n",
       " (37.33, 57.2),\n",
       " (21.66, 31.13),\n",
       " (33.61, 50.88),\n",
       " (53.77, 86.03),\n",
       " (43.86, 68.5),\n",
       " (56.54, 91.0),\n",
       " (55.97, 89.97),\n",
       " (29.64, 44.2),\n",
       " (27.8, 41.14),\n",
       " (55.0, 88.22),\n",
       " (47.65, 75.15),\n",
       " (33.57, 50.8),\n",
       " (33.31, 50.36),\n",
       " (54.03, 86.5),\n",
       " (86.02, 145.46),\n",
       " (63.77, 104.09),\n",
       " (31.12, 46.67),\n",
       " (48.88, 77.33),\n",
       " (22.41, 32.34),\n",
       " (24.76, 36.15),\n",
       " (34.35, 52.13),\n",
       " (24.73, 36.09),\n",
       " (53.7, 85.9),\n",
       " (64.67, 105.73),\n",
       " (91.17, 155.22),\n",
       " (53.67, 85.85),\n",
       " (46.62, 73.33),\n",
       " (51.34, 81.68),\n",
       " (56.08, 90.16),\n",
       " (48.04, 75.84),\n",
       " (29.2, 43.47),\n",
       " (33.2, 50.18),\n",
       " (106.79, 185.25),\n",
       " (39.83, 61.51),\n",
       " (30.39, 45.46),\n",
       " (58.05, 93.71),\n",
       " (16.16, 22.44),\n",
       " (34.2, 51.88),\n",
       " (73.82, 122.6),\n",
       " (64.81, 105.99),\n",
       " (57.08, 91.97),\n",
       " (27.07, 39.95),\n",
       " (33.3, 50.35),\n",
       " (20.4, 29.11),\n",
       " (31.11, 46.65),\n",
       " (74.37, 123.63),\n",
       " (88.8, 150.72),\n",
       " (23.25, 33.69),\n",
       " (30.9, 46.31),\n",
       " (32.47, 48.94),\n",
       " (43.93, 68.62),\n",
       " (39.32, 60.63),\n",
       " (72.12, 119.45),\n",
       " (44.23, 69.16),\n",
       " (32.04, 48.22),\n",
       " (33.15, 50.1),\n",
       " (121.98, 214.94),\n",
       " (109.39, 190.29),\n",
       " (65.27, 106.84),\n",
       " (69.9, 115.34),\n",
       " (22.94, 33.19),\n",
       " (34.97, 53.18),\n",
       " (40.66, 62.93),\n",
       " (32.67, 49.28),\n",
       " (50.06, 79.41),\n",
       " (32.47, 48.95),\n",
       " (70.72, 116.85),\n",
       " (47.13, 74.23),\n",
       " (50.74, 80.63),\n",
       " (46.13, 72.47),\n",
       " (49.63, 78.64),\n",
       " (26.14, 38.41),\n",
       " (57.36, 92.47),\n",
       " (36.06, 55.03),\n",
       " (39.34, 60.65),\n",
       " (34.96, 53.17),\n",
       " (28.43, 42.19),\n",
       " (30.5, 45.64),\n",
       " (71.79, 118.84),\n",
       " (20.18, 28.75),\n",
       " (31.97, 48.1),\n",
       " (29.8, 44.47),\n",
       " (51.08, 81.22),\n",
       " (31.29, 46.97),\n",
       " (19.76, 28.08),\n",
       " (83.38, 140.48),\n",
       " (46.03, 72.3),\n",
       " (74.85, 124.51),\n",
       " (45.67, 71.67),\n",
       " (32.33, 48.72),\n",
       " (47.89, 75.57),\n",
       " (59.03, 95.48),\n",
       " (25.83, 37.9),\n",
       " (61.27, 99.55),\n",
       " (53.48, 85.51),\n",
       " (63.58, 103.74),\n",
       " (27.28, 40.29),\n",
       " (46.91, 73.85),\n",
       " (32.53, 49.06),\n",
       " (35.5, 54.07),\n",
       " (30.17, 45.09),\n",
       " (73.92, 122.79),\n",
       " (49.62, 78.64),\n",
       " (30.93, 46.35),\n",
       " (26.57, 39.11),\n",
       " (39.77, 61.4),\n",
       " (28.72, 42.67),\n",
       " (43.2, 67.34),\n",
       " (24.2, 35.24),\n",
       " (50.91, 80.92),\n",
       " (49.27, 78.01),\n",
       " (31.11, 46.66),\n",
       " (47.58, 75.02),\n",
       " (75.29, 125.32),\n",
       " (47.81, 75.43),\n",
       " (27.36, 40.42),\n",
       " (42.45, 66.04),\n",
       " (36.12, 55.14),\n",
       " (39.97, 61.74),\n",
       " (54.31, 87.0),\n",
       " (31.73, 47.7),\n",
       " (45.42, 71.23),\n",
       " (75.03, 124.84),\n",
       " (21.53, 30.93),\n",
       " (25.33, 37.08),\n",
       " (69.33, 114.29),\n",
       " (73.87, 122.7),\n",
       " (73.16, 121.37),\n",
       " (52.09, 83.02),\n",
       " (52.74, 84.19),\n",
       " (53.05, 84.74),\n",
       " (61.81, 100.53),\n",
       " (41.68, 64.71),\n",
       " (46.6, 73.3),\n",
       " (45.11, 70.69),\n",
       " (38.56, 59.32),\n",
       " (29.62, 44.17),\n",
       " (55.85, 89.74),\n",
       " (86.54, 146.44),\n",
       " (36.63, 56.01),\n",
       " (29.18, 43.44),\n",
       " (65.33, 106.95),\n",
       " (37.01, 56.66),\n",
       " (26.59, 39.15),\n",
       " (33.92, 51.39),\n",
       " (50.47, 80.15),\n",
       " (29.38, 43.76),\n",
       " (43.22, 67.38),\n",
       " (21.34, 30.62),\n",
       " (58.89, 95.23),\n",
       " (50.15, 79.58),\n",
       " (55.04, 88.3),\n",
       " (65.1, 106.52),\n",
       " (47.06, 74.12),\n",
       " (46.33, 72.82),\n",
       " (29.62, 44.17),\n",
       " (29.86, 44.57),\n",
       " (33.54, 50.76),\n",
       " (72.52, 120.18),\n",
       " (34.2, 51.87),\n",
       " (70.92, 117.23),\n",
       " (32.78, 49.47),\n",
       " (61.76, 100.43),\n",
       " (46.78, 73.61),\n",
       " (53.08, 84.78),\n",
       " (20.29, 28.94),\n",
       " (56.05, 90.11),\n",
       " (56.23, 90.43),\n",
       " (28.37, 42.09),\n",
       " (23.02, 33.33),\n",
       " (28.24, 41.88),\n",
       " (43.83, 68.45),\n",
       " (70.63, 116.69),\n",
       " (58.43, 94.41),\n",
       " (55.85, 89.74),\n",
       " (65.91, 108.01),\n",
       " (28.18, 41.78),\n",
       " (26.35, 38.76),\n",
       " (49.08, 77.67),\n",
       " (31.96, 48.08),\n",
       " (30.49, 45.63),\n",
       " (17.39, 24.35),\n",
       " (63.49, 103.59),\n",
       " (29.64, 44.2),\n",
       " (62.77, 102.27),\n",
       " (48.9, 77.37),\n",
       " (117.34, 205.82),\n",
       " (38.8, 59.72),\n",
       " (55.5, 89.12),\n",
       " (54.06, 86.55),\n",
       " (29.65, 44.22),\n",
       " (41.91, 65.11),\n",
       " (57.34, 92.43),\n",
       " (74.27, 123.43),\n",
       " (27.53, 40.7),\n",
       " (43.88, 68.55),\n",
       " (36.95, 56.55),\n",
       " (25.2, 36.87),\n",
       " (46.13, 72.47),\n",
       " (57.43, 92.59),\n",
       " (28.94, 43.04),\n",
       " (47.21, 74.39),\n",
       " (84.29, 142.19),\n",
       " (31.26, 46.91),\n",
       " (24.61, 35.91),\n",
       " (27.5, 40.64),\n",
       " (63.91, 104.35),\n",
       " (71.47, 118.24),\n",
       " (32.4, 48.83),\n",
       " (85.67, 144.79),\n",
       " (67.93, 111.72),\n",
       " (22.25, 32.08),\n",
       " (27.56, 40.75),\n",
       " (37.13, 56.86),\n",
       " (67.64, 111.17),\n",
       " (113.11, 197.54),\n",
       " (48.15, 76.03),\n",
       " (59.22, 95.83),\n",
       " (29.07, 43.26),\n",
       " (34.99, 53.21),\n",
       " (67.34, 110.63),\n",
       " (23.29, 33.76),\n",
       " (30.8, 46.13),\n",
       " (25.99, 38.16),\n",
       " (32.12, 48.35),\n",
       " (24.59, 35.87),\n",
       " (64.48, 105.39),\n",
       " (69.48, 114.57),\n",
       " (77.29, 129.05),\n",
       " (51.71, 82.35),\n",
       " (52.22, 83.25),\n",
       " (76.01, 126.66),\n",
       " (42.5, 66.13),\n",
       " (25.42, 37.22),\n",
       " (138.0, 246.74),\n",
       " (26.53, 39.05),\n",
       " (39.05, 60.16),\n",
       " (28.79, 42.79),\n",
       " (77.7, 129.81),\n",
       " (38.25, 58.78),\n",
       " (63.68, 103.92),\n",
       " (26.22, 38.54),\n",
       " (64.04, 104.59),\n",
       " (128.93, 228.68),\n",
       " (44.89, 70.3),\n",
       " (47.51, 74.9),\n",
       " (27.24, 40.21),\n",
       " (42.28, 65.76),\n",
       " (73.65, 122.28),\n",
       " (28.51, 42.32),\n",
       " (57.83, 93.32),\n",
       " (67.91, 111.68),\n",
       " (26.87, 39.61),\n",
       " (22.05, 31.75),\n",
       " (23.85, 34.67),\n",
       " (29.77, 44.42),\n",
       " (29.35, 43.71),\n",
       " (75.39, 125.52),\n",
       " (40.96, 63.46),\n",
       " (32.9, 49.67),\n",
       " (55.03, 88.27),\n",
       " (39.66, 61.22),\n",
       " (47.96, 75.7),\n",
       " (26.01, 38.19),\n",
       " (27.33, 40.37),\n",
       " (68.42, 112.62),\n",
       " (33.45, 50.61),\n",
       " (34.1, 51.7),\n",
       " (32.03, 48.21),\n",
       " (57.98, 93.59),\n",
       " (17.88, 25.12),\n",
       " (67.32, 110.6),\n",
       " (30.78, 46.1),\n",
       " (46.25, 72.69),\n",
       " (23.59, 34.24),\n",
       " (63.72, 104.01),\n",
       " (27.72, 41.02),\n",
       " (63.92, 104.36),\n",
       " (26.91, 39.68),\n",
       " (20.49, 29.25),\n",
       " (38.59, 59.37),\n",
       " (29.31, 43.65),\n",
       " (28.29, 41.96),\n",
       " (62.1, 101.04),\n",
       " (54.94, 88.12),\n",
       " (41.36, 64.16),\n",
       " (38.53, 59.27),\n",
       " (42.79, 66.63),\n",
       " (42.47, 66.08),\n",
       " (28.59, 42.46),\n",
       " (42.98, 66.97),\n",
       " (51.99, 82.85),\n",
       " (78.19, 130.73),\n",
       " (28.69, 42.63),\n",
       " (38.39, 59.03),\n",
       " (53.12, 84.86),\n",
       " (130.74, 232.27),\n",
       " (52.16, 83.14),\n",
       " (99.48, 171.14),\n",
       " (39.06, 60.18),\n",
       " (49.95, 79.22),\n",
       " (33.52, 50.72),\n",
       " ...)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_xgb_reg = tuple([(round(math.exp(el-el*MAPE_median_xgb_reg),2),round(math.exp(el+el*MAPE_median_xgb_reg),2)) for el in y_test_pred_xgb_reg])\n",
    "y_pred_interval_xgb_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_xgb_reg, title=\"best_model_xgb_reg_01\", save=\"joblib\")\n",
    "save_model(grid_xgb_reg, title=\"best_cv_xgb_reg_01\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 2: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_svm_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('svm_reg',\n",
    "                              SVR(kernel='rbf', C=10, degree=3, gamma=0.001))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for Support Vector Machine\n",
    "test_svr_reg = SVR()\n",
    "test_svr_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Support Vector Machine** (as base for hyperparameter search):\n",
    "\n",
    "kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_svm_reg = {\n",
    "    'svm_reg__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm_reg__C': [0.1, 0.5, 1, 2, 5, 10, 50, 100, 500, 1000],\n",
    "    'svm_reg__gamma': [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    'svm_reg__degree': randint(low=1, high=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  7.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  7.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_svm_reg = RandomizedSearchCV(pipeline_svm_reg,\n",
    "                                 param_distribs_svm_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=5,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_svm_reg = rnd_svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.24\n",
      "Best parameters:\n",
      "{'svm_reg__C': 10, 'svm_reg__degree': 1, 'svm_reg__gamma': 0.001, 'svm_reg__kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_svm_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_svm_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_svm_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_svm_reg = {\n",
    "#    'svm_reg__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm_reg__gamma': [0.0015, 0.002, 0.003, 0.005],\n",
    "    'svm_reg__C': [10, 12, 14, 16],\n",
    "#    'svm_reg__degree': [1, 3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   51.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_svm_reg = GridSearchCV(pipeline_svm_reg,\n",
    "                            param_grid_svm_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_svm_reg = grid_svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_svm_reg = grid_svm_reg.best_estimator_[\"svm_reg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.23\n",
      "Best parameters:\n",
      "{'svm_reg__C': 10, 'svm_reg__gamma': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_svm_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_svm_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_svm_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display feature importances\n",
    "#fi_svm_reg = get_feat_importances(best_model_svm_reg)\n",
    "#fi_svm_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_svm_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_svm_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_svm_reg = best_model_svm_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.12\n",
      "RMSE: 0.35\n",
      "MAE: 0.26\n",
      "R2: 0.64\n",
      "MAPE: 6.57\n",
      "MAPE median: 4.71\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_svm_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_svm_reg = best_model_svm_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.14\n",
      "RMSE: 0.38\n",
      "MAE: 0.28\n",
      "R2: 0.56\n",
      "MAPE: 7.35\n",
      "MAPE median: 5.47\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_svm_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36155178, 0.39367148])"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_svm_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_svm_reg = (median_absolute_percentage_error(y_test, y_test_pred_svm_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((53.12, 84.14),\n",
       " (51.18, 80.72),\n",
       " (55.53, 88.41),\n",
       " (33.31, 50.0),\n",
       " (38.42, 58.62),\n",
       " (26.45, 38.64),\n",
       " (40.57, 62.29),\n",
       " (33.56, 50.4),\n",
       " (46.12, 71.88),\n",
       " (40.16, 61.58),\n",
       " (23.38, 33.68),\n",
       " (32.57, 48.75),\n",
       " (53.56, 84.93),\n",
       " (26.83, 39.27),\n",
       " (36.89, 56.02),\n",
       " (71.04, 116.39),\n",
       " (72.96, 119.9),\n",
       " (66.26, 107.68),\n",
       " (50.53, 79.57),\n",
       " (49.11, 77.09),\n",
       " (107.08, 183.96),\n",
       " (50.51, 79.55),\n",
       " (37.65, 57.3),\n",
       " (71.65, 117.49),\n",
       " (27.14, 39.78),\n",
       " (58.15, 93.08),\n",
       " (83.24, 138.9),\n",
       " (36.45, 55.27),\n",
       " (25.58, 37.24),\n",
       " (46.86, 73.16),\n",
       " (24.72, 35.84),\n",
       " (68.19, 111.18),\n",
       " (51.71, 81.65),\n",
       " (27.01, 39.56),\n",
       " (41.13, 63.25),\n",
       " (52.75, 83.48),\n",
       " (36.01, 54.53),\n",
       " (55.4, 88.18),\n",
       " (30.14, 44.7),\n",
       " (27.82, 40.9),\n",
       " (29.37, 43.44),\n",
       " (25.01, 36.3),\n",
       " (44.76, 69.51),\n",
       " (31.98, 47.77),\n",
       " (30.1, 44.64),\n",
       " (42.12, 64.94),\n",
       " (46.45, 72.44),\n",
       " (82.71, 137.9),\n",
       " (64.54, 104.56),\n",
       " (101.83, 173.92),\n",
       " (33.48, 50.27),\n",
       " (81.78, 136.18),\n",
       " (44.58, 69.2),\n",
       " (44.79, 69.56),\n",
       " (37.16, 56.48),\n",
       " (44.88, 69.71),\n",
       " (54.8, 87.13),\n",
       " (34.37, 51.76),\n",
       " (65.97, 107.15),\n",
       " (34.5, 51.99),\n",
       " (56.64, 90.39),\n",
       " (55.47, 88.3),\n",
       " (60.55, 97.38),\n",
       " (47.13, 73.62),\n",
       " (46.42, 72.4),\n",
       " (52.66, 83.33),\n",
       " (22.65, 32.51),\n",
       " (29.37, 43.44),\n",
       " (44.51, 69.07),\n",
       " (45.06, 70.03),\n",
       " (40.98, 63.0),\n",
       " (65.65, 106.58),\n",
       " (34.65, 52.24),\n",
       " (59.45, 95.41),\n",
       " (141.05, 250.16),\n",
       " (38.45, 58.68),\n",
       " (16.67, 23.09),\n",
       " (52.91, 83.77),\n",
       " (35.43, 53.55),\n",
       " (30.62, 45.51),\n",
       " (30.13, 44.69),\n",
       " (20.23, 28.66),\n",
       " (34.92, 52.7),\n",
       " (22.85, 32.82),\n",
       " (88.9, 149.48),\n",
       " (62.12, 100.19),\n",
       " (44.49, 69.04),\n",
       " (69.29, 113.18),\n",
       " (41.87, 64.52),\n",
       " (54.63, 86.82),\n",
       " (64.62, 104.71),\n",
       " (41.62, 64.09),\n",
       " (36.47, 55.31),\n",
       " (129.67, 227.75),\n",
       " (60.33, 96.97),\n",
       " (27.41, 40.21),\n",
       " (126.36, 221.28),\n",
       " (55.41, 88.19),\n",
       " (32.83, 49.18),\n",
       " (23.67, 34.15),\n",
       " (32.4, 48.47),\n",
       " (33.63, 50.52),\n",
       " (27.45, 40.28),\n",
       " (51.64, 81.54),\n",
       " (29.75, 44.07),\n",
       " (49.73, 78.18),\n",
       " (25.44, 37.0),\n",
       " (35.68, 53.97),\n",
       " (36.58, 55.49),\n",
       " (53.51, 84.83),\n",
       " (39.6, 60.62),\n",
       " (24.35, 35.24),\n",
       " (94.05, 159.16),\n",
       " (29.65, 43.91),\n",
       " (81.66, 135.95),\n",
       " (61.29, 98.71),\n",
       " (40.58, 62.3),\n",
       " (93.58, 158.27),\n",
       " (48.47, 75.96),\n",
       " (30.99, 46.13),\n",
       " (27.37, 40.15),\n",
       " (48.99, 76.87),\n",
       " (30.86, 45.91),\n",
       " (40.85, 62.77),\n",
       " (31.87, 47.59),\n",
       " (62.26, 100.45),\n",
       " (34.44, 51.88),\n",
       " (48.85, 76.64),\n",
       " (33.25, 49.89),\n",
       " (24.94, 36.2),\n",
       " (82.86, 138.19),\n",
       " (22.38, 32.07),\n",
       " (34.28, 51.62),\n",
       " (24.1, 34.83),\n",
       " (35.89, 54.33),\n",
       " (32.8, 49.14),\n",
       " (30.99, 46.12),\n",
       " (40.92, 62.89),\n",
       " (131.77, 231.87),\n",
       " (119.63, 208.17),\n",
       " (34.35, 51.72),\n",
       " (44.55, 69.14),\n",
       " (46.36, 72.28),\n",
       " (28.09, 41.33),\n",
       " (47.41, 74.12),\n",
       " (83.87, 140.07),\n",
       " (44.51, 69.07),\n",
       " (31.23, 46.52),\n",
       " (58.62, 93.93),\n",
       " (75.96, 125.41),\n",
       " (108.54, 186.75),\n",
       " (48.03, 75.19),\n",
       " (65.68, 106.64),\n",
       " (25.67, 37.38),\n",
       " (79.69, 132.31),\n",
       " (101.83, 173.92),\n",
       " (19.07, 26.83),\n",
       " (47.76, 74.72),\n",
       " (32.74, 49.03),\n",
       " (76.18, 125.81),\n",
       " (30.94, 46.04),\n",
       " (31.78, 47.43),\n",
       " (64.16, 103.87),\n",
       " (52.13, 82.4),\n",
       " (38.6, 58.93),\n",
       " (95.83, 162.52),\n",
       " (43.51, 67.35),\n",
       " (28.3, 41.67),\n",
       " (27.52, 40.4),\n",
       " (29.58, 43.78),\n",
       " (57.81, 92.47),\n",
       " (147.93, 263.83),\n",
       " (36.27, 54.97),\n",
       " (37.85, 57.65),\n",
       " (27.26, 39.97),\n",
       " (65.21, 105.77),\n",
       " (28.85, 42.58),\n",
       " (50.47, 79.48),\n",
       " (28.65, 42.25),\n",
       " (35.49, 53.66),\n",
       " (46.28, 72.15),\n",
       " (71.92, 117.99),\n",
       " (58.25, 93.26),\n",
       " (42.44, 65.51),\n",
       " (27.43, 40.25),\n",
       " (58.99, 94.59),\n",
       " (42.86, 66.23),\n",
       " (57.85, 92.55),\n",
       " (53.97, 85.64),\n",
       " (42.42, 65.46),\n",
       " (65.55, 106.39),\n",
       " (27.55, 40.44),\n",
       " (88.45, 148.63),\n",
       " (70.86, 116.05),\n",
       " (48.63, 76.25),\n",
       " (96.12, 163.08),\n",
       " (89.17, 149.97),\n",
       " (28.36, 41.77),\n",
       " (63.28, 102.29),\n",
       " (23.96, 34.61),\n",
       " (53.58, 84.96),\n",
       " (39.74, 60.87),\n",
       " (96.64, 164.07),\n",
       " (45.71, 71.15),\n",
       " (43.99, 68.17),\n",
       " (47.42, 74.14),\n",
       " (81.89, 136.37),\n",
       " (110.18, 189.92),\n",
       " (48.42, 75.88),\n",
       " (32.09, 47.96),\n",
       " (159.73, 287.42),\n",
       " (29.09, 42.98),\n",
       " (33.74, 50.71),\n",
       " (103.69, 177.48),\n",
       " (26.56, 38.83),\n",
       " (44.67, 69.34),\n",
       " (29.59, 43.8),\n",
       " (44.89, 69.73),\n",
       " (52.87, 83.69),\n",
       " (69.55, 113.66),\n",
       " (100.74, 171.85),\n",
       " (27.32, 40.06),\n",
       " (54.17, 86.0),\n",
       " (25.64, 37.32),\n",
       " (78.5, 130.09),\n",
       " (30.88, 45.93),\n",
       " (17.3, 24.06),\n",
       " (24.8, 35.96),\n",
       " (59.57, 95.61),\n",
       " (78.59, 130.26),\n",
       " (52.83, 83.64),\n",
       " (71.44, 117.11),\n",
       " (47.21, 73.77),\n",
       " (37.21, 56.57),\n",
       " (39.76, 60.9),\n",
       " (42.14, 64.99),\n",
       " (48.6, 76.19),\n",
       " (73.27, 120.47),\n",
       " (41.8, 64.39),\n",
       " (44.37, 68.83),\n",
       " (61.52, 99.11),\n",
       " (65.77, 106.8),\n",
       " (55.06, 87.58),\n",
       " (95.5, 161.9),\n",
       " (36.34, 55.09),\n",
       " (29.27, 43.28),\n",
       " (27.76, 40.79),\n",
       " (39.21, 59.96),\n",
       " (47.4, 74.09),\n",
       " (51.24, 80.83),\n",
       " (40.22, 61.69),\n",
       " (57.7, 92.28),\n",
       " (68.98, 112.62),\n",
       " (85.43, 142.97),\n",
       " (55.02, 87.51),\n",
       " (62.93, 101.66),\n",
       " (62.81, 101.45),\n",
       " (41.6, 64.06),\n",
       " (34.71, 52.34),\n",
       " (34.49, 51.97),\n",
       " (30.31, 44.99),\n",
       " (35.17, 53.11),\n",
       " (47.14, 73.64),\n",
       " (31.88, 47.61),\n",
       " (36.4, 55.2),\n",
       " (28.24, 41.58),\n",
       " (52.3, 82.69),\n",
       " (36.31, 55.04),\n",
       " (67.32, 109.61),\n",
       " (36.21, 54.86),\n",
       " (22.7, 32.59),\n",
       " (45.49, 70.78),\n",
       " (53.02, 83.97),\n",
       " (52.64, 83.3),\n",
       " (98.32, 167.25),\n",
       " (78.6, 130.28),\n",
       " (95.89, 162.65),\n",
       " (38.56, 58.85),\n",
       " (62.32, 100.55),\n",
       " (52.07, 82.29),\n",
       " (26.64, 38.95),\n",
       " (59.08, 94.74),\n",
       " (46.74, 72.95),\n",
       " (163.83, 295.66),\n",
       " (63.61, 102.89),\n",
       " (44.19, 68.52),\n",
       " (32.23, 48.18),\n",
       " (24.86, 36.07),\n",
       " (63.73, 103.1),\n",
       " (51.57, 81.41),\n",
       " (31.55, 47.06),\n",
       " (74.77, 123.23),\n",
       " (88.7, 149.1),\n",
       " (42.66, 65.88),\n",
       " (56.09, 89.41),\n",
       " (26.64, 38.96),\n",
       " (31.19, 46.45),\n",
       " (52.09, 82.32),\n",
       " (25.41, 36.96),\n",
       " (46.84, 73.13),\n",
       " (29.16, 43.09),\n",
       " (52.44, 82.95),\n",
       " (32.55, 48.71),\n",
       " (41.36, 63.65),\n",
       " (50.58, 79.66),\n",
       " (34.21, 51.5),\n",
       " (65.38, 106.09),\n",
       " (58.1, 92.99),\n",
       " (42.33, 65.3),\n",
       " (62.57, 101.0),\n",
       " (94.95, 160.87),\n",
       " (47.36, 74.03),\n",
       " (98.72, 168.0),\n",
       " (57.83, 92.51),\n",
       " (119.63, 208.18),\n",
       " (29.34, 43.39),\n",
       " (26.7, 39.05),\n",
       " (27.9, 41.01),\n",
       " (45.62, 71.01),\n",
       " (62.78, 101.38),\n",
       " (41.01, 63.04),\n",
       " (69.91, 114.32),\n",
       " (70.79, 115.92),\n",
       " (30.03, 44.53),\n",
       " (101.95, 174.14),\n",
       " (41.48, 63.85),\n",
       " (50.48, 79.5),\n",
       " (53.5, 84.82),\n",
       " (24.94, 36.19),\n",
       " (51.83, 81.87),\n",
       " (72.1, 118.33),\n",
       " (37.25, 56.63),\n",
       " (28.55, 42.08),\n",
       " (57.67, 92.23),\n",
       " (65.65, 106.57),\n",
       " (33.71, 50.66),\n",
       " (25.2, 36.61),\n",
       " (46.31, 72.21),\n",
       " (29.7, 43.99),\n",
       " (37.42, 56.91),\n",
       " (46.25, 72.09),\n",
       " (124.43, 217.52),\n",
       " (25.36, 36.88),\n",
       " (24.13, 34.88),\n",
       " (47.13, 73.64),\n",
       " (30.12, 44.67),\n",
       " (25.69, 37.41),\n",
       " (47.34, 73.99),\n",
       " (53.54, 84.89),\n",
       " (75.73, 124.98),\n",
       " (68.42, 111.6),\n",
       " (55.48, 88.33),\n",
       " (25.8, 37.58),\n",
       " (88.07, 147.92),\n",
       " (23.62, 34.06),\n",
       " (27.12, 39.74),\n",
       " (45.41, 70.64),\n",
       " (53.23, 84.34),\n",
       " (67.12, 109.23),\n",
       " (29.54, 43.72),\n",
       " (35.95, 54.44),\n",
       " (32.64, 48.87),\n",
       " (31.43, 46.85),\n",
       " (31.78, 47.43),\n",
       " (52.86, 83.69),\n",
       " (37.83, 57.61),\n",
       " (56.67, 90.43),\n",
       " (35.98, 54.48),\n",
       " (56.86, 90.77),\n",
       " (57.5, 91.92),\n",
       " (32.9, 49.31),\n",
       " (22.93, 32.96),\n",
       " (52.52, 83.08),\n",
       " (74.01, 121.82),\n",
       " (24.99, 36.27),\n",
       " (39.34, 60.18),\n",
       " (56.24, 89.67),\n",
       " (26.69, 39.05),\n",
       " (45.29, 70.43),\n",
       " (27.8, 40.86),\n",
       " (60.12, 96.6),\n",
       " (62.78, 101.4),\n",
       " (125.42, 219.44),\n",
       " (34.35, 51.73),\n",
       " (31.88, 47.6),\n",
       " (39.09, 59.75),\n",
       " (59.22, 95.0),\n",
       " (28.69, 42.32),\n",
       " (28.99, 42.82),\n",
       " (62.06, 100.09),\n",
       " (91.76, 154.84),\n",
       " (51.36, 81.04),\n",
       " (28.51, 42.02),\n",
       " (35.28, 53.29),\n",
       " (30.35, 45.06),\n",
       " (98.25, 167.11),\n",
       " (43.98, 68.16),\n",
       " (61.24, 98.62),\n",
       " (56.52, 90.18),\n",
       " (25.8, 37.59),\n",
       " (31.66, 47.24),\n",
       " (117.65, 204.34),\n",
       " (19.03, 26.77),\n",
       " (49.52, 77.81),\n",
       " (39.42, 60.33),\n",
       " (28.43, 41.89),\n",
       " (53.56, 84.92),\n",
       " (37.83, 57.61),\n",
       " (24.93, 36.18),\n",
       " (35.3, 53.33),\n",
       " (28.61, 42.19),\n",
       " (70.07, 114.61),\n",
       " (79.04, 131.1),\n",
       " (83.16, 138.75),\n",
       " (25.34, 36.84),\n",
       " (48.12, 75.35),\n",
       " (18.64, 26.16),\n",
       " (53.33, 84.51),\n",
       " (52.2, 82.51),\n",
       " (95.42, 161.76),\n",
       " (30.47, 45.25),\n",
       " (19.29, 27.17),\n",
       " (25.55, 37.19),\n",
       " (56.04, 89.31),\n",
       " (35.53, 53.71),\n",
       " (42.68, 65.92),\n",
       " (40.18, 61.61),\n",
       " (61.2, 98.55),\n",
       " (29.04, 42.9),\n",
       " (37.86, 57.67),\n",
       " (48.19, 75.47),\n",
       " (56.63, 90.36),\n",
       " (43.87, 67.97),\n",
       " (30.67, 45.59),\n",
       " (59.62, 95.7),\n",
       " (26.07, 38.03),\n",
       " (24.03, 34.72),\n",
       " (39.92, 61.18),\n",
       " (30.04, 44.54),\n",
       " (71.17, 116.61),\n",
       " (53.56, 84.92),\n",
       " (54.18, 86.02),\n",
       " (27.62, 40.56),\n",
       " (65.88, 106.98),\n",
       " (44.05, 68.28),\n",
       " (16.6, 22.98),\n",
       " (92.98, 157.14),\n",
       " (23.36, 33.64),\n",
       " (24.41, 35.33),\n",
       " (43.99, 68.17),\n",
       " (63.21, 102.17),\n",
       " (42.79, 66.1),\n",
       " (44.47, 69.01),\n",
       " (35.39, 53.48),\n",
       " (35.98, 54.48),\n",
       " (98.77, 168.1),\n",
       " (71.06, 116.42),\n",
       " (53.74, 85.25),\n",
       " (42.61, 65.8),\n",
       " (47.31, 73.94),\n",
       " (26.92, 39.41),\n",
       " (33.57, 50.42),\n",
       " (49.18, 77.22),\n",
       " (76.67, 126.72),\n",
       " (57.65, 92.18),\n",
       " (20.09, 28.44),\n",
       " (37.45, 56.97),\n",
       " (82.14, 136.84),\n",
       " (26.44, 38.63),\n",
       " (19.16, 26.97),\n",
       " (35.37, 53.46),\n",
       " (42.97, 66.41),\n",
       " (52.77, 83.53),\n",
       " (69.32, 113.24),\n",
       " (43.3, 66.98),\n",
       " (24.5, 35.48),\n",
       " (99.41, 169.32),\n",
       " (29.64, 43.88),\n",
       " (49.21, 77.26),\n",
       " (16.7, 23.14),\n",
       " (43.78, 67.81),\n",
       " (51.81, 81.83),\n",
       " (71.4, 117.04),\n",
       " (37.29, 56.69),\n",
       " (30.84, 45.88),\n",
       " (48.51, 76.04),\n",
       " (24.79, 35.96),\n",
       " (39.91, 61.16),\n",
       " (141.34, 250.75),\n",
       " (47.55, 74.36),\n",
       " (31.59, 47.12),\n",
       " (33.48, 50.27),\n",
       " (25.33, 36.82),\n",
       " (83.98, 140.28),\n",
       " (37.77, 57.51),\n",
       " (30.64, 45.54),\n",
       " (41.97, 64.69),\n",
       " (37.56, 57.15),\n",
       " (54.11, 85.9),\n",
       " (71.53, 117.28),\n",
       " (46.7, 72.88),\n",
       " (94.0, 159.07),\n",
       " (44.59, 69.21),\n",
       " (26.21, 38.25),\n",
       " (23.64, 34.1),\n",
       " (26.66, 38.98),\n",
       " (64.98, 105.36),\n",
       " (53.47, 84.76),\n",
       " (42.03, 64.8),\n",
       " (77.41, 128.08),\n",
       " (29.18, 43.12),\n",
       " (63.82, 103.26),\n",
       " (28.2, 41.51),\n",
       " (60.5, 97.28),\n",
       " (31.7, 47.3),\n",
       " (40.24, 61.72),\n",
       " (86.65, 145.26),\n",
       " (20.77, 29.51),\n",
       " (24.65, 35.72),\n",
       " (31.34, 46.69),\n",
       " (77.72, 128.66),\n",
       " (32.27, 48.25),\n",
       " (51.93, 82.04),\n",
       " (67.45, 109.83),\n",
       " (27.58, 40.49),\n",
       " (56.17, 89.55),\n",
       " (24.59, 35.62),\n",
       " (57.99, 92.79),\n",
       " (73.03, 120.03),\n",
       " (63.62, 102.91),\n",
       " (21.25, 30.28),\n",
       " (47.6, 74.45),\n",
       " (31.64, 47.2),\n",
       " (116.18, 201.49),\n",
       " (22.6, 32.43),\n",
       " (28.96, 42.76),\n",
       " (54.5, 86.58),\n",
       " (37.86, 57.66),\n",
       " (33.23, 49.85),\n",
       " (31.59, 47.12),\n",
       " (93.22, 157.6),\n",
       " (41.88, 64.54),\n",
       " (101.83, 173.92),\n",
       " (74.28, 122.33),\n",
       " (22.0, 31.47),\n",
       " (39.0, 59.61),\n",
       " (47.62, 74.48),\n",
       " (44.69, 69.39),\n",
       " (38.66, 59.03),\n",
       " (44.35, 68.79),\n",
       " (26.02, 37.94),\n",
       " (31.45, 46.89),\n",
       " (36.0, 54.51),\n",
       " (37.38, 56.85),\n",
       " (27.96, 41.12),\n",
       " (127.17, 222.86),\n",
       " (42.11, 64.93),\n",
       " (57.54, 91.98),\n",
       " (52.77, 83.52),\n",
       " (25.53, 37.15),\n",
       " (53.87, 85.46),\n",
       " (33.97, 51.09),\n",
       " (21.48, 30.63),\n",
       " (77.06, 127.44),\n",
       " (70.93, 116.17),\n",
       " (39.41, 60.31),\n",
       " (42.02, 64.79),\n",
       " (52.02, 82.19),\n",
       " (49.12, 77.1),\n",
       " (41.05, 63.11),\n",
       " (46.44, 72.43),\n",
       " (47.88, 74.94),\n",
       " (34.98, 52.79),\n",
       " (43.2, 66.81),\n",
       " (55.17, 87.77),\n",
       " (66.04, 107.28),\n",
       " (28.94, 42.73),\n",
       " (20.27, 28.72),\n",
       " (31.66, 47.24),\n",
       " (31.11, 46.31),\n",
       " (71.19, 116.66),\n",
       " (38.7, 59.1),\n",
       " (55.87, 89.01),\n",
       " (37.57, 57.18),\n",
       " (62.67, 101.19),\n",
       " (45.15, 70.18),\n",
       " (94.77, 160.53),\n",
       " (46.77, 73.0),\n",
       " (55.19, 87.81),\n",
       " (52.41, 82.89),\n",
       " (33.55, 50.39),\n",
       " (54.33, 86.29),\n",
       " (34.14, 51.38),\n",
       " (24.89, 36.11),\n",
       " (54.72, 86.97),\n",
       " (65.68, 106.62),\n",
       " (27.38, 40.17),\n",
       " (43.92, 68.06),\n",
       " (28.05, 41.27),\n",
       " (26.55, 38.8),\n",
       " (50.75, 79.96),\n",
       " (35.29, 53.31),\n",
       " (36.81, 55.88),\n",
       " (47.41, 74.11),\n",
       " (29.01, 42.84),\n",
       " (56.9, 90.86),\n",
       " (37.71, 57.42),\n",
       " (24.43, 35.38),\n",
       " (43.72, 67.7),\n",
       " (65.1, 105.58),\n",
       " (40.2, 61.66),\n",
       " (51.54, 81.35),\n",
       " (60.57, 97.41),\n",
       " (59.24, 95.02),\n",
       " (45.22, 70.31),\n",
       " (28.64, 42.23),\n",
       " (20.57, 29.19),\n",
       " (58.83, 94.3),\n",
       " (54.31, 86.25),\n",
       " (20.63, 29.28),\n",
       " (72.12, 118.36),\n",
       " (35.91, 54.36),\n",
       " (52.12, 82.39),\n",
       " (34.01, 51.15),\n",
       " (39.87, 61.08),\n",
       " (44.04, 68.26),\n",
       " (39.39, 60.27),\n",
       " (25.76, 37.52),\n",
       " (25.64, 37.33),\n",
       " (32.32, 48.33),\n",
       " (61.27, 98.68),\n",
       " (34.49, 51.97),\n",
       " (38.06, 58.01),\n",
       " (29.49, 43.64),\n",
       " (41.19, 63.35),\n",
       " (85.57, 143.23),\n",
       " (86.48, 144.93),\n",
       " (52.31, 82.71),\n",
       " (36.75, 55.78),\n",
       " (29.82, 44.19),\n",
       " (36.09, 54.66),\n",
       " (48.52, 76.06),\n",
       " (49.61, 77.97),\n",
       " (35.0, 52.83),\n",
       " (33.35, 50.06),\n",
       " (48.7, 76.37),\n",
       " (43.54, 67.41),\n",
       " (70.84, 116.01),\n",
       " (37.58, 57.18),\n",
       " (32.71, 48.99),\n",
       " (28.83, 42.55),\n",
       " (54.3, 86.23),\n",
       " (37.02, 56.23),\n",
       " (47.48, 74.24),\n",
       " (61.9, 99.8),\n",
       " (86.23, 144.47),\n",
       " (26.77, 39.18),\n",
       " (21.3, 30.35),\n",
       " (36.83, 55.92),\n",
       " (52.98, 83.9),\n",
       " (23.62, 34.06),\n",
       " (52.41, 82.89),\n",
       " (27.19, 39.86),\n",
       " (47.27, 73.88),\n",
       " (37.31, 56.74),\n",
       " (54.63, 86.82),\n",
       " (29.55, 43.74),\n",
       " (50.78, 80.02),\n",
       " (25.54, 37.17),\n",
       " (28.75, 42.42),\n",
       " (48.73, 76.42),\n",
       " (57.9, 92.64),\n",
       " (82.69, 137.86),\n",
       " (164.45, 296.9),\n",
       " (35.08, 52.96),\n",
       " (49.42, 77.62),\n",
       " (32.68, 48.94),\n",
       " (30.58, 45.43),\n",
       " (83.89, 140.1),\n",
       " (25.9, 37.75),\n",
       " (56.6, 90.31),\n",
       " (62.72, 101.28),\n",
       " (36.44, 55.26),\n",
       " (29.37, 43.44),\n",
       " (35.45, 53.58),\n",
       " (30.73, 45.68),\n",
       " (20.94, 29.77),\n",
       " (64.57, 104.62),\n",
       " (37.55, 57.13),\n",
       " (40.79, 62.67),\n",
       " (32.05, 47.88),\n",
       " (23.91, 34.53),\n",
       " (46.92, 73.27),\n",
       " (30.67, 45.59),\n",
       " (27.77, 40.8),\n",
       " (54.61, 86.78),\n",
       " (32.63, 48.85),\n",
       " (63.9, 103.41),\n",
       " (37.08, 56.34),\n",
       " (27.06, 39.65),\n",
       " (36.76, 55.79),\n",
       " (52.46, 82.98),\n",
       " (40.05, 61.4),\n",
       " (60.61, 97.48),\n",
       " (52.92, 83.79),\n",
       " (31.24, 46.54),\n",
       " (29.56, 43.74),\n",
       " (50.11, 78.84),\n",
       " (47.57, 74.39),\n",
       " (31.57, 47.09),\n",
       " (39.46, 60.39),\n",
       " (49.21, 77.26),\n",
       " (88.57, 148.85),\n",
       " (66.0, 107.2),\n",
       " (33.07, 49.58),\n",
       " (58.01, 92.83),\n",
       " (27.6, 40.52),\n",
       " (27.41, 40.22),\n",
       " (34.07, 51.27),\n",
       " (31.32, 46.66),\n",
       " (56.74, 90.56),\n",
       " (46.1, 71.84),\n",
       " (94.58, 160.16),\n",
       " (57.16, 91.32),\n",
       " (47.37, 74.04),\n",
       " (51.21, 80.77),\n",
       " (61.37, 98.85),\n",
       " (50.32, 79.2),\n",
       " (30.12, 44.68),\n",
       " (33.96, 51.08),\n",
       " (93.26, 157.67),\n",
       " (41.81, 64.41),\n",
       " (33.59, 50.45),\n",
       " (59.5, 95.49),\n",
       " (16.05, 22.13),\n",
       " (28.21, 41.53),\n",
       " (68.02, 110.87),\n",
       " (62.61, 101.09),\n",
       " (56.05, 89.33),\n",
       " (32.31, 48.32),\n",
       " (47.9, 74.97),\n",
       " (22.89, 32.89),\n",
       " (31.41, 46.82),\n",
       " (77.25, 127.79),\n",
       " (118.59, 206.15),\n",
       " (19.31, 27.21),\n",
       " (30.42, 45.18),\n",
       " (34.27, 51.59),\n",
       " (34.05, 51.23),\n",
       " (41.15, 63.29),\n",
       " (81.71, 136.04),\n",
       " (42.18, 65.05),\n",
       " (30.95, 46.06),\n",
       " (31.33, 46.68),\n",
       " (112.91, 195.16),\n",
       " (102.18, 174.59),\n",
       " (73.03, 120.02),\n",
       " (62.27, 100.46),\n",
       " (23.14, 33.29),\n",
       " (39.4, 60.28),\n",
       " (39.49, 60.44),\n",
       " (37.6, 57.21),\n",
       " (49.21, 77.25),\n",
       " (30.63, 45.51),\n",
       " (68.56, 111.85),\n",
       " (52.77, 83.53),\n",
       " (53.11, 84.12),\n",
       " (48.05, 75.23),\n",
       " (52.15, 82.43),\n",
       " (30.23, 44.86),\n",
       " (71.43, 117.09),\n",
       " (34.76, 52.42),\n",
       " (39.97, 61.26),\n",
       " (37.28, 56.68),\n",
       " (28.34, 41.73),\n",
       " (32.62, 48.83),\n",
       " (70.86, 116.06),\n",
       " (20.53, 29.13),\n",
       " (34.34, 51.72),\n",
       " (30.03, 44.52),\n",
       " (45.11, 70.12),\n",
       " (29.19, 43.13),\n",
       " (27.33, 40.08),\n",
       " (78.28, 129.7),\n",
       " (47.51, 74.29),\n",
       " (73.99, 121.78),\n",
       " (43.51, 67.34),\n",
       " (31.87, 47.59),\n",
       " (43.81, 67.87),\n",
       " (52.15, 82.43),\n",
       " (23.93, 34.57),\n",
       " (58.99, 94.58),\n",
       " (53.82, 85.38),\n",
       " (63.24, 102.22),\n",
       " (27.84, 40.92),\n",
       " (44.0, 68.19),\n",
       " (26.42, 38.6),\n",
       " (30.26, 44.91),\n",
       " (31.51, 46.99),\n",
       " (69.6, 113.76),\n",
       " (52.65, 83.31),\n",
       " (29.73, 44.02),\n",
       " (27.83, 40.9),\n",
       " (37.91, 57.75),\n",
       " (28.8, 42.5),\n",
       " (48.42, 75.88),\n",
       " (22.01, 31.48),\n",
       " (52.35, 82.78),\n",
       " (46.41, 72.37),\n",
       " (27.89, 41.0),\n",
       " (48.45, 75.94),\n",
       " (63.15, 102.06),\n",
       " (48.41, 75.86),\n",
       " (27.3, 40.03),\n",
       " (39.43, 60.34),\n",
       " (34.4, 51.81),\n",
       " (44.07, 68.32),\n",
       " (58.1, 92.99),\n",
       " (31.35, 46.72),\n",
       " (44.28, 68.68),\n",
       " (71.92, 117.98),\n",
       " (20.87, 29.67),\n",
       " (26.32, 38.44),\n",
       " (67.0, 109.02),\n",
       " (84.44, 141.12),\n",
       " (64.17, 103.9),\n",
       " (54.42, 86.44),\n",
       " (59.33, 95.18),\n",
       " (52.82, 83.62),\n",
       " (58.66, 93.99),\n",
       " (37.04, 56.27),\n",
       " (48.5, 76.03),\n",
       " (43.23, 66.86),\n",
       " (37.13, 56.42),\n",
       " (28.74, 42.4),\n",
       " (56.46, 90.07),\n",
       " (103.17, 176.48),\n",
       " (38.94, 59.5),\n",
       " (30.95, 46.05),\n",
       " (62.62, 101.1),\n",
       " (34.35, 51.73),\n",
       " (27.39, 40.18),\n",
       " (33.77, 50.76),\n",
       " (56.87, 90.8),\n",
       " (30.02, 44.51),\n",
       " (43.77, 67.79),\n",
       " (19.67, 27.77),\n",
       " (60.07, 96.51),\n",
       " (45.47, 70.74),\n",
       " (59.3, 95.14),\n",
       " (62.68, 101.21),\n",
       " (52.8, 83.58),\n",
       " (52.86, 83.69),\n",
       " (28.58, 42.14),\n",
       " (27.28, 40.01),\n",
       " (30.66, 45.58),\n",
       " (84.85, 141.89),\n",
       " (32.21, 48.15),\n",
       " (71.22, 116.71),\n",
       " (32.36, 48.4),\n",
       " (50.74, 79.94),\n",
       " (48.65, 76.27),\n",
       " (48.84, 76.62),\n",
       " (18.76, 26.35),\n",
       " (60.3, 96.94),\n",
       " (57.88, 92.6),\n",
       " (27.12, 39.74),\n",
       " (20.45, 29.0),\n",
       " (24.95, 36.21),\n",
       " (42.37, 65.37),\n",
       " (58.17, 93.12),\n",
       " (48.48, 75.99),\n",
       " (51.35, 81.02),\n",
       " (67.56, 110.05),\n",
       " (28.43, 41.89),\n",
       " (25.9, 37.75),\n",
       " (74.75, 123.18),\n",
       " (29.76, 44.08),\n",
       " (31.21, 46.48),\n",
       " (18.59, 26.07),\n",
       " (66.4, 107.93),\n",
       " (31.44, 46.87),\n",
       " (61.15, 98.46),\n",
       " (46.3, 72.18),\n",
       " (121.03, 210.89),\n",
       " (42.37, 65.37),\n",
       " (51.35, 81.02),\n",
       " (44.88, 69.72),\n",
       " (27.56, 40.46),\n",
       " (25.24, 36.67),\n",
       " (61.36, 98.83),\n",
       " (73.47, 120.84),\n",
       " (27.38, 40.17),\n",
       " (42.86, 66.22),\n",
       " (35.74, 54.07),\n",
       " (27.56, 40.46),\n",
       " (44.73, 69.46),\n",
       " (57.15, 91.29),\n",
       " (33.19, 49.79),\n",
       " (46.76, 72.99),\n",
       " (91.89, 155.08),\n",
       " (26.51, 38.74),\n",
       " (24.1, 34.84),\n",
       " (25.76, 37.52),\n",
       " (65.43, 106.18),\n",
       " (59.34, 95.21),\n",
       " (29.92, 44.34),\n",
       " (78.31, 129.75),\n",
       " (72.93, 119.84),\n",
       " (26.37, 38.52),\n",
       " (29.22, 43.19),\n",
       " (36.12, 54.71),\n",
       " (69.98, 114.45),\n",
       " (141.74, 251.53),\n",
       " (50.71, 79.89),\n",
       " (55.71, 88.73),\n",
       " (26.15, 38.16),\n",
       " (35.77, 54.12),\n",
       " (58.63, 93.93),\n",
       " (22.96, 33.01),\n",
       " (31.13, 46.35),\n",
       " (24.67, 35.75),\n",
       " (31.91, 47.66),\n",
       " (23.75, 34.28),\n",
       " (65.57, 106.42),\n",
       " (75.73, 124.98),\n",
       " (81.14, 134.98),\n",
       " (52.23, 82.57),\n",
       " (60.1, 96.57),\n",
       " (76.45, 126.31),\n",
       " (46.46, 72.46),\n",
       " (24.42, 35.35),\n",
       " (134.86, 237.96),\n",
       " (24.13, 34.89),\n",
       " (37.75, 57.48),\n",
       " (27.19, 39.85),\n",
       " (86.47, 144.92),\n",
       " (32.78, 49.1),\n",
       " (62.37, 100.65),\n",
       " (25.75, 37.51),\n",
       " (60.09, 96.55),\n",
       " (137.05, 242.28),\n",
       " (43.18, 66.78),\n",
       " (49.33, 77.48),\n",
       " (26.5, 38.72),\n",
       " (47.91, 74.99),\n",
       " (72.51, 119.07),\n",
       " (27.51, 40.38),\n",
       " (59.76, 95.97),\n",
       " (69.08, 112.8),\n",
       " (29.55, 43.74),\n",
       " (19.58, 27.62),\n",
       " (25.87, 37.7),\n",
       " (31.11, 46.33),\n",
       " (27.25, 39.95),\n",
       " (99.06, 168.65),\n",
       " (29.45, 43.58),\n",
       " (33.0, 49.47),\n",
       " (54.56, 86.69),\n",
       " (41.32, 63.57),\n",
       " (50.66, 79.81),\n",
       " (22.52, 32.29),\n",
       " (26.59, 38.88),\n",
       " (71.93, 118.01),\n",
       " (34.7, 52.33),\n",
       " (38.68, 59.05),\n",
       " (31.8, 47.47),\n",
       " (62.76, 101.35),\n",
       " (17.36, 24.15),\n",
       " (51.55, 81.37),\n",
       " (39.12, 59.82),\n",
       " (47.84, 74.86),\n",
       " (21.39, 30.49),\n",
       " (56.84, 90.74),\n",
       " (24.04, 34.73),\n",
       " (69.46, 113.5),\n",
       " (24.74, 35.88),\n",
       " (19.38, 27.32),\n",
       " (36.24, 54.93),\n",
       " (29.88, 44.27),\n",
       " (26.95, 39.46),\n",
       " (66.37, 107.87),\n",
       " (55.86, 89.0),\n",
       " (39.44, 60.36),\n",
       " (38.8, 59.27),\n",
       " (40.68, 62.47),\n",
       " (39.81, 60.98),\n",
       " (27.48, 40.33),\n",
       " (49.0, 76.9),\n",
       " (49.46, 77.71),\n",
       " (68.19, 111.18),\n",
       " (30.63, 45.52),\n",
       " (39.17, 59.9),\n",
       " (58.11, 93.01),\n",
       " (126.17, 220.91),\n",
       " (58.17, 93.12),\n",
       " (122.04, 212.86),\n",
       " (38.49, 58.73),\n",
       " (49.68, 78.09),\n",
       " (35.03, 52.87),\n",
       " ...)"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_svm_reg = tuple([(round(math.exp(el-el*MAPE_median_svm_reg),2),round(math.exp(el+el*MAPE_median_svm_reg),2)) for el in y_test_pred_svm_reg])\n",
    "y_pred_interval_svm_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_svm_reg, title=\"best_model_svm_reg_01\", save=\"joblib\")\n",
    "save_model(grid_svm_reg, title=\"best_cv_svm_reg_01\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_rf_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_reg',\n",
    "                             RandomForestRegressor(n_estimators=1500,\n",
    "                                                   max_features='sqrt',\n",
    "                                                   random_state=random_state,\n",
    "                                                   max_depth=4,\n",
    "                                                   min_samples_split=10,\n",
    "                                                   min_samples_leaf=1,\n",
    "                                                   bootstrap=False,\n",
    "                                                   n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_rf_reg = RandomForestRegressor()\n",
    "test_rf_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Random Forest Regressor** (as base for hyperparameter search):\n",
    "\n",
    "n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_rf_reg = {\n",
    "    'rf_reg__n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "    'rf_reg__max_features': ['auto', 'sqrt'],\n",
    "    'rf_reg__max_depth': [None, 1, 2, 3, 4, 5, 7, 10, 15, 20, 30, 40, 50, 75, 100],\n",
    "    'rf_reg__min_samples_split': [2, 5, 10],\n",
    "    'rf_reg__min_samples_leaf': [1, 2, 4],\n",
    "    'rf_reg__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 45.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_rf_reg = RandomizedSearchCV(pipeline_rf_reg,\n",
    "                                 param_distribs_rf_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=10,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_rf_reg = rnd_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.23\n",
      "Best parameters:\n",
      "{'rf_reg__n_estimators': 1000, 'rf_reg__min_samples_split': 10, 'rf_reg__min_samples_leaf': 1, 'rf_reg__max_features': 'sqrt', 'rf_reg__max_depth': 100, 'rf_reg__bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_reg = {\n",
    "#    'rf_reg__n_estimators': [1200, 2000],\n",
    "#    'rf_reg__max_features': ['auto', 'sqrt'],\n",
    "    'rf_reg__max_depth': [10, 15],\n",
    "    'rf_reg__min_samples_split': [6, 10],\n",
    "#    'rf_reg__min_samples_leaf': [1, 2],\n",
    "#    'rf_reg__bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_reg = GridSearchCV(pipeline_rf_reg,\n",
    "                            param_grid_rf_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_rf_reg = grid_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_rf_reg = grid_rf_reg.best_estimator_['rf_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.24\n",
      "Best parameters:\n",
      "{'rf_reg__max_depth': 15, 'rf_reg__min_samples_split': 6}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>0.227147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>0.138154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>0.113998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>0.045111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>0.042288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>0.037592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>0.033099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>0.032034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>0.027565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>0.023683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>0.023266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>0.020177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.017680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>0.017303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>0.016305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>0.011836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.009851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.009247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.008488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.008482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>0.008462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.008287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.006347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.005633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.005314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.004192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.003971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.003280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.002769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.002229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.001955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.001928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.001875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.001837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.001799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.001592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.001322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.001236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.001177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.001153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.001140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.001138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.000886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.000680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.000645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.000620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.000617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.000603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.000590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.000537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.000517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.000501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.000471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.000457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.000407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.000388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.000368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.000275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.000243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.000229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.000218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.000133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.000073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    weight\n",
       "room_type_Private room            0.227147\n",
       "accommodates                      0.138154\n",
       "bedrooms                          0.113998\n",
       "calc_host_lst_count_sqrt_log      0.045111\n",
       "am_tv                             0.042288\n",
       "bathrooms_log                     0.037592\n",
       "availability_90                   0.033099\n",
       "accommodates_per_bed              0.032034\n",
       "am_elevator                       0.027565\n",
       "minimum_nights_log                0.023683\n",
       "maximum_nights                    0.023266\n",
       "am_private_entrance               0.020177\n",
       "am_child_friendly                 0.017680\n",
       "property_type_Boutique hotel      0.017303\n",
       "room_type_Shared room             0.016305\n",
       "zipcode_zip_other                 0.011836\n",
       "room_type_Hotel room              0.009851\n",
       "zipcode_zip_10117                 0.009247\n",
       "am_smoking_allowed                0.008488\n",
       "am_balcony                        0.008482\n",
       "wk_mth_discount                   0.008462\n",
       "cancellation_policy_super_strict  0.008288\n",
       "zipcode_zip_10119                 0.008287\n",
       "host_is_superhost                 0.006347\n",
       "cancellation_policy_strict        0.005638\n",
       "zipcode_zip_13359                 0.005633\n",
       "instant_bookable                  0.005314\n",
       "am_pets_allowed                   0.004192\n",
       "zipcode_zip_10179                 0.003971\n",
       "cancellation_policy_moderate      0.003840\n",
       "am_breakfast                      0.003534\n",
       "am_essentials                     0.003280\n",
       "property_type_House               0.002769\n",
       "zipcode_zip_10245                 0.002275\n",
       "zipcode_zip_10435                 0.002229\n",
       "zipcode_zip_10405                 0.002156\n",
       "zipcode_zip_10719                 0.002057\n",
       "zipcode_zip_10247                 0.001955\n",
       "zipcode_zip_10559                 0.001928\n",
       "zipcode_zip_10243                 0.001922\n",
       "zipcode_zip_10999                 0.001875\n",
       "zipcode_zip_10178                 0.001856\n",
       "zipcode_zip_10439                 0.001837\n",
       "zipcode_zip_10997                 0.001799\n",
       "zipcode_zip_10969                 0.001592\n",
       "zipcode_zip_10785                 0.001322\n",
       "zipcode_zip_13407                 0.001236\n",
       "zipcode_zip_13353                 0.001232\n",
       "zipcode_zip_10437                 0.001177\n",
       "zipcode_zip_12047                 0.001153\n",
       "zipcode_zip_10963                 0.001140\n",
       "zipcode_zip_13357                 0.001138\n",
       "zipcode_zip_10965                 0.001124\n",
       "zipcode_zip_12049                 0.001007\n",
       "zipcode_zip_13347                 0.000954\n",
       "zipcode_zip_nan                   0.000943\n",
       "zipcode_zip_10553                 0.000939\n",
       "zipcode_zip_12347                 0.000888\n",
       "zipcode_zip_12053                 0.000886\n",
       "zipcode_zip_12051                 0.000848\n",
       "zipcode_zip_12437                 0.000818\n",
       "zipcode_zip_13349                 0.000812\n",
       "zipcode_zip_10407                 0.000761\n",
       "zipcode_zip_12059                 0.000754\n",
       "property_type_Secondary unit      0.000736\n",
       "zipcode_zip_13086                 0.000736\n",
       "zipcode_zip_12043                 0.000731\n",
       "zipcode_zip_10777                 0.000691\n",
       "zipcode_zip_12045                 0.000688\n",
       "zipcode_zip_10557                 0.000680\n",
       "zipcode_zip_10967                 0.000667\n",
       "zipcode_zip_10249                 0.000666\n",
       "zipcode_zip_10589                 0.000646\n",
       "zipcode_zip_12055                 0.000645\n",
       "zipcode_zip_12099                 0.000626\n",
       "zipcode_zip_10317                 0.000620\n",
       "zipcode_zip_10787                 0.000617\n",
       "zipcode_zip_10555                 0.000603\n",
       "zipcode_zip_10707                 0.000590\n",
       "zipcode_zip_12103                 0.000575\n",
       "zipcode_zip_10551                 0.000574\n",
       "zipcode_zip_12435                 0.000572\n",
       "zipcode_zip_10315                 0.000562\n",
       "zipcode_zip_13187                 0.000560\n",
       "zipcode_zip_14057                 0.000537\n",
       "zipcode_zip_12157                 0.000517\n",
       "zipcode_zip_13189                 0.000501\n",
       "zipcode_zip_10783                 0.000495\n",
       "zipcode_zip_14197                 0.000491\n",
       "zipcode_zip_10711                 0.000475\n",
       "zipcode_zip_10715                 0.000471\n",
       "property_type_Bed and breakfast   0.000457\n",
       "zipcode_zip_10623                 0.000451\n",
       "zipcode_zip_10409                 0.000438\n",
       "zipcode_zip_10365                 0.000430\n",
       "zipcode_zip_10629                 0.000407\n",
       "zipcode_zip_10829                 0.000388\n",
       "zipcode_zip_10585                 0.000384\n",
       "zipcode_zip_10961                 0.000384\n",
       "zipcode_zip_10781                 0.000368\n",
       "zipcode_zip_10827                 0.000357\n",
       "zipcode_zip_13088                 0.000344\n",
       "zipcode_zip_13355                 0.000343\n",
       "zipcode_zip_13409                 0.000340\n",
       "property_type_Unique space        0.000334\n",
       "zipcode_zip_10367                 0.000279\n",
       "zipcode_zip_10587                 0.000279\n",
       "zipcode_zip_14059                 0.000275\n",
       "zipcode_zip_12161                 0.000272\n",
       "zipcode_zip_10625                 0.000243\n",
       "zipcode_zip_13351                 0.000229\n",
       "zipcode_zip_10717                 0.000227\n",
       "zipcode_zip_12163                 0.000218\n",
       "zipcode_zip_10318                 0.000203\n",
       "zipcode_zip_10823                 0.000177\n",
       "zipcode_zip_13156                 0.000133\n",
       "zipcode_zip_10627                 0.000114\n",
       "zipcode_zip_12101                 0.000108\n",
       "zipcode_zip_10713                 0.000073"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_rf_reg = get_feat_importances(best_model_rf_reg)\n",
    "fi_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_rf_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_rf_reg_01\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_rf_reg = best_model_rf_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10\n",
      "RMSE: 0.31\n",
      "MAE: 0.25\n",
      "R2: 0.70\n",
      "MAPE: 6.31\n",
      "MAPE median: 5.07\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_rf_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_rf_reg = best_model_rf_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.15\n",
      "RMSE: 0.38\n",
      "MAE: 0.29\n",
      "R2: 0.54\n",
      "MAPE: 7.61\n",
      "MAPE median: 5.83\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_rf_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36322871, 0.39248337])"
      ]
     },
     "execution_count": 1003,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_rf_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_rf_reg = (median_absolute_percentage_error(y_test, y_test_pred_rf_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52.49, 84.34),\n",
       " (63.69, 104.73),\n",
       " (48.79, 77.71),\n",
       " (31.74, 48.02),\n",
       " (37.33, 57.58),\n",
       " (31.18, 47.07),\n",
       " (40.96, 63.88),\n",
       " (39.19, 60.8),\n",
       " (50.29, 80.39),\n",
       " (43.01, 67.48),\n",
       " (25.4, 37.42),\n",
       " (40.63, 63.31),\n",
       " (60.1, 98.14),\n",
       " (26.03, 38.45),\n",
       " (34.87, 53.35),\n",
       " (65.81, 108.65),\n",
       " (68.9, 114.37),\n",
       " (52.99, 85.24),\n",
       " (57.08, 92.64),\n",
       " (47.3, 75.06),\n",
       " (85.92, 146.45),\n",
       " (50.15, 80.13),\n",
       " (42.29, 66.21),\n",
       " (76.92, 129.38),\n",
       " (25.16, 37.02),\n",
       " (50.02, 79.91),\n",
       " (76.51, 128.6),\n",
       " (33.78, 51.48),\n",
       " (28.21, 42.09),\n",
       " (45.88, 72.54),\n",
       " (26.96, 40.0),\n",
       " (56.11, 90.88),\n",
       " (55.91, 90.52),\n",
       " (29.42, 44.11),\n",
       " (44.83, 70.68),\n",
       " (58.97, 96.07),\n",
       " (36.57, 56.26),\n",
       " (51.65, 82.83),\n",
       " (33.59, 51.16),\n",
       " (32.83, 49.87),\n",
       " (31.65, 47.86),\n",
       " (25.48, 37.55),\n",
       " (38.19, 59.07),\n",
       " (35.32, 54.12),\n",
       " (30.45, 45.84),\n",
       " (46.57, 73.76),\n",
       " (47.55, 75.5),\n",
       " (72.92, 121.87),\n",
       " (59.19, 96.49),\n",
       " (90.86, 155.9),\n",
       " (34.06, 51.96),\n",
       " (66.47, 109.87),\n",
       " (52.47, 84.3),\n",
       " (48.38, 76.98),\n",
       " (35.34, 54.15),\n",
       " (46.65, 73.9),\n",
       " (57.55, 93.5),\n",
       " (33.75, 51.44),\n",
       " (53.35, 85.89),\n",
       " (34.6, 52.89),\n",
       " (54.31, 87.61),\n",
       " (55.14, 89.13),\n",
       " (59.51, 97.07),\n",
       " (46.6, 73.82),\n",
       " (53.62, 86.38),\n",
       " (45.53, 71.91),\n",
       " (27.74, 41.3),\n",
       " (30.72, 46.29),\n",
       " (45.95, 72.67),\n",
       " (42.77, 67.05),\n",
       " (49.66, 79.26),\n",
       " (87.26, 149.01),\n",
       " (38.47, 59.55),\n",
       " (55.25, 89.31),\n",
       " (121.63, 216.12),\n",
       " (42.85, 67.21),\n",
       " (17.95, 25.37),\n",
       " (62.71, 102.94),\n",
       " (41.25, 64.39),\n",
       " (28.8, 43.07),\n",
       " (27.48, 40.85),\n",
       " (23.99, 35.1),\n",
       " (37.71, 58.24),\n",
       " (26.3, 38.9),\n",
       " (58.84, 95.84),\n",
       " (54.84, 88.57),\n",
       " (44.0, 69.22),\n",
       " (67.78, 112.29),\n",
       " (39.91, 62.05),\n",
       " (54.44, 87.86),\n",
       " (66.76, 110.4),\n",
       " (47.89, 76.11),\n",
       " (41.24, 64.38),\n",
       " (112.29, 197.63),\n",
       " (53.12, 85.47),\n",
       " (30.66, 46.19),\n",
       " (93.65, 161.27),\n",
       " (54.66, 88.26),\n",
       " (29.75, 44.65),\n",
       " (23.08, 33.61),\n",
       " (31.18, 47.07),\n",
       " (38.07, 58.86),\n",
       " (31.47, 47.56),\n",
       " (42.53, 66.64),\n",
       " (28.53, 42.61),\n",
       " (58.21, 94.7),\n",
       " (28.95, 43.31),\n",
       " (39.94, 62.11),\n",
       " (37.78, 58.35),\n",
       " (49.03, 78.13),\n",
       " (32.86, 49.92),\n",
       " (23.76, 34.72),\n",
       " (76.03, 127.7),\n",
       " (27.51, 40.91),\n",
       " (65.8, 108.63),\n",
       " (66.77, 110.42),\n",
       " (39.11, 60.67),\n",
       " (80.84, 136.78),\n",
       " (45.15, 71.24),\n",
       " (34.31, 52.39),\n",
       " (30.76, 46.36),\n",
       " (50.02, 79.92),\n",
       " (33.47, 50.96),\n",
       " (42.84, 67.18),\n",
       " (31.64, 47.84),\n",
       " (61.75, 101.17),\n",
       " (34.81, 53.25),\n",
       " (49.21, 78.46),\n",
       " (34.1, 52.03),\n",
       " (29.19, 43.72),\n",
       " (81.92, 138.82),\n",
       " (23.88, 34.92),\n",
       " (31.96, 48.38),\n",
       " (26.51, 39.26),\n",
       " (35.77, 54.9),\n",
       " (32.85, 49.89),\n",
       " (31.63, 47.83),\n",
       " (48.22, 76.7),\n",
       " (98.87, 171.37),\n",
       " (90.77, 155.73),\n",
       " (32.49, 49.29),\n",
       " (41.82, 65.4),\n",
       " (47.77, 75.9),\n",
       " (29.12, 43.6),\n",
       " (46.52, 73.67),\n",
       " (78.43, 132.23),\n",
       " (44.43, 69.98),\n",
       " (36.16, 55.56),\n",
       " (53.67, 86.47),\n",
       " (63.78, 104.89),\n",
       " (68.88, 114.33),\n",
       " (54.77, 88.44),\n",
       " (56.04, 90.74),\n",
       " (31.73, 48.01),\n",
       " (70.59, 117.52),\n",
       " (90.86, 155.9),\n",
       " (25.83, 38.13),\n",
       " (49.19, 78.43),\n",
       " (32.11, 48.65),\n",
       " (85.8, 146.22),\n",
       " (34.55, 52.81),\n",
       " (32.0, 48.45),\n",
       " (59.38, 96.83),\n",
       " (44.69, 70.44),\n",
       " (44.25, 69.67),\n",
       " (81.24, 137.55),\n",
       " (46.12, 72.96),\n",
       " (30.02, 45.12),\n",
       " (27.17, 40.35),\n",
       " (31.23, 47.15),\n",
       " (50.48, 80.73),\n",
       " (130.48, 233.8),\n",
       " (37.67, 58.17),\n",
       " (45.77, 72.34),\n",
       " (31.96, 48.39),\n",
       " (70.45, 117.26),\n",
       " (28.98, 43.37),\n",
       " (56.65, 91.87),\n",
       " (30.37, 45.7),\n",
       " (39.5, 61.34),\n",
       " (49.77, 79.46),\n",
       " (65.53, 108.13),\n",
       " (53.46, 86.09),\n",
       " (51.13, 81.9),\n",
       " (29.23, 43.78),\n",
       " (52.46, 84.28),\n",
       " (42.53, 66.64),\n",
       " (63.03, 103.52),\n",
       " (50.64, 81.01),\n",
       " (45.32, 71.55),\n",
       " (55.74, 90.21),\n",
       " (28.94, 43.3),\n",
       " (62.06, 101.74),\n",
       " (64.78, 106.73),\n",
       " (55.53, 89.82),\n",
       " (57.0, 92.5),\n",
       " (63.56, 104.48),\n",
       " (31.26, 47.21),\n",
       " (54.01, 87.07),\n",
       " (29.38, 44.04),\n",
       " (59.81, 97.62),\n",
       " (33.14, 50.4),\n",
       " (100.23, 174.02),\n",
       " (45.51, 71.89),\n",
       " (52.69, 84.71),\n",
       " (43.08, 67.61),\n",
       " (56.44, 91.47),\n",
       " (78.76, 132.86),\n",
       " (48.18, 76.62),\n",
       " (31.66, 47.88),\n",
       " (114.42, 201.82),\n",
       " (28.9, 43.23),\n",
       " (36.71, 56.51),\n",
       " (67.74, 112.22),\n",
       " (29.97, 45.03),\n",
       " (51.16, 81.95),\n",
       " (29.8, 44.74),\n",
       " (46.32, 73.33),\n",
       " (40.79, 63.59),\n",
       " (57.18, 92.83),\n",
       " (91.48, 157.09),\n",
       " (24.06, 35.21),\n",
       " (57.99, 94.29),\n",
       " (30.98, 46.74),\n",
       " (72.06, 120.26),\n",
       " (32.24, 48.86),\n",
       " (19.75, 28.22),\n",
       " (29.23, 43.79),\n",
       " (57.08, 92.64),\n",
       " (67.35, 111.49),\n",
       " (60.38, 98.66),\n",
       " (62.73, 102.97),\n",
       " (46.97, 74.48),\n",
       " (36.62, 56.36),\n",
       " (43.12, 67.66),\n",
       " (48.29, 76.82),\n",
       " (52.56, 84.47),\n",
       " (62.52, 102.58),\n",
       " (45.95, 72.66),\n",
       " (43.43, 68.22),\n",
       " (58.79, 95.75),\n",
       " (62.12, 101.85),\n",
       " (53.78, 86.67),\n",
       " (93.86, 161.68),\n",
       " (33.71, 51.37),\n",
       " (33.07, 50.27),\n",
       " (30.68, 46.23),\n",
       " (44.14, 69.46),\n",
       " (47.64, 75.66),\n",
       " (45.73, 72.27),\n",
       " (33.83, 51.58),\n",
       " (56.66, 91.88),\n",
       " (52.52, 84.4),\n",
       " (71.55, 119.31),\n",
       " (55.83, 90.38),\n",
       " (48.44, 77.09),\n",
       " (57.72, 93.8),\n",
       " (44.65, 70.36),\n",
       " (31.51, 47.64),\n",
       " (32.75, 49.73),\n",
       " (29.58, 44.37),\n",
       " (33.37, 50.79),\n",
       " (48.78, 77.7),\n",
       " (30.56, 46.03),\n",
       " (41.87, 65.48),\n",
       " (33.4, 50.84),\n",
       " (53.92, 86.91),\n",
       " (33.7, 51.35),\n",
       " (65.52, 108.11),\n",
       " (44.2, 69.57),\n",
       " (26.27, 38.85),\n",
       " (50.12, 80.08),\n",
       " (50.22, 80.26),\n",
       " (59.45, 96.95),\n",
       " (94.49, 162.9),\n",
       " (72.74, 121.53),\n",
       " (79.48, 134.22),\n",
       " (36.68, 56.47),\n",
       " (57.93, 94.18),\n",
       " (50.13, 80.1),\n",
       " (25.4, 37.41),\n",
       " (60.69, 99.23),\n",
       " (39.13, 60.7),\n",
       " (96.93, 167.62),\n",
       " (52.78, 84.87),\n",
       " (47.18, 74.85),\n",
       " (32.0, 48.46),\n",
       " (25.7, 37.91),\n",
       " (63.95, 105.21),\n",
       " (51.36, 82.3),\n",
       " (30.51, 45.93),\n",
       " (53.13, 85.48),\n",
       " (83.98, 142.74),\n",
       " (43.6, 68.52),\n",
       " (68.87, 114.32),\n",
       " (29.93, 44.95),\n",
       " (33.54, 51.08),\n",
       " (49.01, 78.11),\n",
       " (30.88, 46.56),\n",
       " (56.52, 91.62),\n",
       " (29.05, 43.49),\n",
       " (49.98, 79.84),\n",
       " (32.22, 48.83),\n",
       " (49.81, 79.52),\n",
       " (54.53, 88.01),\n",
       " (35.92, 55.16),\n",
       " (55.77, 90.26),\n",
       " (54.04, 87.13),\n",
       " (56.11, 90.87),\n",
       " (58.68, 95.56),\n",
       " (73.15, 122.3),\n",
       " (50.25, 80.32),\n",
       " (73.74, 123.41),\n",
       " (70.39, 117.14),\n",
       " (87.76, 149.95),\n",
       " (31.55, 47.7),\n",
       " (25.28, 37.21),\n",
       " (27.53, 40.95),\n",
       " (47.04, 74.59),\n",
       " (64.63, 106.47),\n",
       " (46.01, 72.76),\n",
       " (70.9, 118.1),\n",
       " (59.61, 97.25),\n",
       " (29.68, 44.54),\n",
       " (94.4, 162.71),\n",
       " (48.48, 77.15),\n",
       " (45.5, 71.87),\n",
       " (52.89, 85.06),\n",
       " (24.1, 35.27),\n",
       " (50.83, 81.37),\n",
       " (65.9, 108.81),\n",
       " (46.2, 73.1),\n",
       " (27.4, 40.73),\n",
       " (57.4, 93.22),\n",
       " (58.98, 96.1),\n",
       " (33.09, 50.3),\n",
       " (29.24, 43.81),\n",
       " (43.24, 67.89),\n",
       " (30.49, 45.91),\n",
       " (44.85, 70.71),\n",
       " (41.83, 65.41),\n",
       " (108.48, 190.14),\n",
       " (29.7, 44.58),\n",
       " (26.28, 38.87),\n",
       " (51.92, 83.31),\n",
       " (29.96, 45.02),\n",
       " (32.69, 49.63),\n",
       " (48.12, 76.52),\n",
       " (52.76, 84.82),\n",
       " (86.83, 148.17),\n",
       " (59.82, 97.63),\n",
       " (49.78, 79.48),\n",
       " (27.7, 41.22),\n",
       " (70.19, 116.77),\n",
       " (25.44, 37.48),\n",
       " (27.53, 40.95),\n",
       " (51.89, 83.26),\n",
       " (53.63, 86.4),\n",
       " (80.82, 136.75),\n",
       " (30.13, 45.31),\n",
       " (33.22, 50.53),\n",
       " (40.74, 63.51),\n",
       " (31.98, 48.42),\n",
       " (31.07, 46.89),\n",
       " (52.76, 84.83),\n",
       " (36.18, 55.6),\n",
       " (55.49, 89.75),\n",
       " (30.63, 46.15),\n",
       " (53.68, 86.48),\n",
       " (66.79, 110.45),\n",
       " (31.39, 47.42),\n",
       " (26.11, 38.59),\n",
       " (45.55, 71.96),\n",
       " (56.64, 91.85),\n",
       " (26.39, 39.04),\n",
       " (41.88, 65.5),\n",
       " (61.0, 99.8),\n",
       " (30.52, 45.96),\n",
       " (39.18, 60.79),\n",
       " (28.51, 42.58),\n",
       " (54.03, 87.11),\n",
       " (62.49, 102.52),\n",
       " (94.06, 162.06),\n",
       " (33.61, 51.19),\n",
       " (34.12, 52.07),\n",
       " (48.32, 76.87),\n",
       " (58.53, 95.29),\n",
       " (30.95, 46.68),\n",
       " (27.43, 40.78),\n",
       " (53.3, 85.8),\n",
       " (84.71, 144.14),\n",
       " (54.03, 87.11),\n",
       " (30.0, 45.07),\n",
       " (36.11, 55.48),\n",
       " (30.37, 45.7),\n",
       " (99.9, 173.36),\n",
       " (46.49, 73.62),\n",
       " (58.94, 96.02),\n",
       " (60.03, 98.01),\n",
       " (28.26, 42.16),\n",
       " (30.38, 45.73),\n",
       " (77.84, 131.12),\n",
       " (29.18, 43.7),\n",
       " (47.71, 75.78),\n",
       " (51.41, 82.39),\n",
       " (31.46, 47.54),\n",
       " (46.16, 73.04),\n",
       " (35.29, 54.07),\n",
       " (32.96, 50.08),\n",
       " (31.49, 47.59),\n",
       " (32.02, 48.49),\n",
       " (66.55, 110.02),\n",
       " (73.24, 122.46),\n",
       " (64.16, 105.61),\n",
       " (28.57, 42.69),\n",
       " (52.73, 84.78),\n",
       " (22.25, 32.26),\n",
       " (50.13, 80.1),\n",
       " (48.4, 77.02),\n",
       " (78.8, 132.92),\n",
       " (38.62, 59.82),\n",
       " (24.79, 36.41),\n",
       " (36.16, 55.57),\n",
       " (60.17, 98.27),\n",
       " (39.52, 61.37),\n",
       " (42.43, 66.45),\n",
       " (46.82, 74.2),\n",
       " (65.69, 108.42),\n",
       " (32.88, 49.96),\n",
       " (47.44, 75.31),\n",
       " (47.88, 76.09),\n",
       " (57.57, 93.53),\n",
       " (44.67, 70.39),\n",
       " (33.09, 50.31),\n",
       " (50.4, 80.59),\n",
       " (31.05, 46.85),\n",
       " (29.05, 43.49),\n",
       " (41.83, 65.41),\n",
       " (27.75, 41.31),\n",
       " (72.35, 120.79),\n",
       " (49.92, 79.73),\n",
       " (45.13, 71.22),\n",
       " (30.12, 45.29),\n",
       " (67.33, 111.46),\n",
       " (44.5, 70.1),\n",
       " (23.55, 34.38),\n",
       " (73.12, 122.24),\n",
       " (26.27, 38.85),\n",
       " (27.56, 40.99),\n",
       " (40.98, 63.93),\n",
       " (57.93, 94.19),\n",
       " (45.93, 72.63),\n",
       " (47.31, 75.07),\n",
       " (32.26, 48.91),\n",
       " (32.0, 48.45),\n",
       " (86.1, 146.79),\n",
       " (62.51, 102.56),\n",
       " (62.56, 102.65),\n",
       " (46.33, 73.34),\n",
       " (48.79, 77.72),\n",
       " (28.99, 43.39),\n",
       " (32.42, 49.18),\n",
       " (46.68, 73.95),\n",
       " (62.86, 103.21),\n",
       " (53.63, 86.39),\n",
       " (25.01, 36.77),\n",
       " (32.76, 49.74),\n",
       " (66.96, 110.76),\n",
       " (27.9, 41.56),\n",
       " (22.83, 33.2),\n",
       " (32.1, 48.63),\n",
       " (56.54, 91.66),\n",
       " (59.2, 96.51),\n",
       " (59.18, 96.47),\n",
       " (43.73, 68.74),\n",
       " (32.87, 49.93),\n",
       " (100.62, 174.77),\n",
       " (29.5, 44.25),\n",
       " (33.99, 51.85),\n",
       " (29.19, 43.72),\n",
       " (38.21, 59.1),\n",
       " (52.21, 83.83),\n",
       " (68.7, 113.99),\n",
       " (37.22, 57.39),\n",
       " (27.6, 41.07),\n",
       " (51.34, 82.28),\n",
       " (26.34, 38.97),\n",
       " (35.28, 54.05),\n",
       " (107.64, 188.48),\n",
       " (48.45, 77.1),\n",
       " (33.23, 50.54),\n",
       " (30.37, 45.7),\n",
       " (28.58, 42.7),\n",
       " (83.18, 141.22),\n",
       " (33.5, 51.01),\n",
       " (31.16, 47.04),\n",
       " (44.04, 69.3),\n",
       " (37.02, 57.05),\n",
       " (54.32, 87.64),\n",
       " (65.65, 108.34),\n",
       " (49.35, 78.7),\n",
       " (80.94, 136.98),\n",
       " (43.19, 67.79),\n",
       " (30.96, 46.69),\n",
       " (25.49, 37.56),\n",
       " (31.58, 47.75),\n",
       " (68.32, 113.3),\n",
       " (47.82, 75.98),\n",
       " (47.14, 74.77),\n",
       " (77.14, 129.79),\n",
       " (35.27, 54.03),\n",
       " (51.47, 82.5),\n",
       " (37.23, 57.42),\n",
       " (56.78, 92.1),\n",
       " (30.77, 46.39),\n",
       " (37.7, 58.23),\n",
       " (77.75, 130.95),\n",
       " (26.45, 39.15),\n",
       " (30.25, 45.49),\n",
       " (30.59, 46.07),\n",
       " (68.64, 113.88),\n",
       " (30.6, 46.09),\n",
       " (53.8, 86.7),\n",
       " (55.78, 90.29),\n",
       " (30.97, 46.71),\n",
       " (54.71, 88.35),\n",
       " (28.24, 42.13),\n",
       " (66.22, 109.41),\n",
       " (63.68, 104.72),\n",
       " (74.8, 125.4),\n",
       " (26.46, 39.17),\n",
       " (45.73, 72.28),\n",
       " (31.66, 47.88),\n",
       " (100.83, 175.18),\n",
       " (25.73, 37.96),\n",
       " (30.52, 45.95),\n",
       " (50.11, 80.06),\n",
       " (35.17, 53.87),\n",
       " (31.07, 46.89),\n",
       " (34.87, 53.36),\n",
       " (82.03, 139.05),\n",
       " (47.46, 75.34),\n",
       " (90.86, 155.9),\n",
       " (59.27, 96.64),\n",
       " (24.64, 36.16),\n",
       " (37.21, 57.37),\n",
       " (47.08, 74.66),\n",
       " (44.03, 69.28),\n",
       " (42.91, 67.3),\n",
       " (45.37, 71.63),\n",
       " (30.92, 46.62),\n",
       " (33.01, 50.17),\n",
       " (44.91, 70.82),\n",
       " (39.39, 61.15),\n",
       " (30.1, 45.25),\n",
       " (129.4, 231.65),\n",
       " (43.78, 68.84),\n",
       " (53.54, 86.24),\n",
       " (46.6, 73.82),\n",
       " (26.37, 39.02),\n",
       " (44.43, 69.97),\n",
       " (35.61, 54.62),\n",
       " (26.68, 39.53),\n",
       " (74.6, 125.02),\n",
       " (69.1, 114.74),\n",
       " (34.95, 53.49),\n",
       " (43.94, 69.11),\n",
       " (53.37, 85.92),\n",
       " (45.91, 72.59),\n",
       " (36.26, 55.75),\n",
       " (51.95, 83.37),\n",
       " (50.39, 80.57),\n",
       " (37.62, 58.09),\n",
       " (39.37, 61.12),\n",
       " (53.58, 86.3),\n",
       " (53.91, 86.89),\n",
       " (29.09, 43.56),\n",
       " (18.94, 26.93),\n",
       " (42.85, 67.2),\n",
       " (37.93, 58.63),\n",
       " (56.69, 91.94),\n",
       " (49.7, 79.33),\n",
       " (51.29, 82.18),\n",
       " (44.33, 69.81),\n",
       " (52.37, 84.13),\n",
       " (44.71, 70.47),\n",
       " (80.25, 135.67),\n",
       " (54.17, 87.36),\n",
       " (45.65, 72.14),\n",
       " (56.8, 92.13),\n",
       " (38.65, 59.87),\n",
       " (41.1, 64.14),\n",
       " (38.77, 60.07),\n",
       " (30.69, 46.24),\n",
       " (54.62, 88.19),\n",
       " (63.17, 103.78),\n",
       " (33.92, 51.73),\n",
       " (48.76, 77.66),\n",
       " (27.52, 40.93),\n",
       " (30.67, 46.21),\n",
       " (52.37, 84.12),\n",
       " (41.25, 64.4),\n",
       " (32.82, 49.84),\n",
       " (48.73, 77.6),\n",
       " (33.34, 50.74),\n",
       " (56.28, 91.18),\n",
       " (48.05, 76.4),\n",
       " (29.18, 43.7),\n",
       " (41.58, 64.97),\n",
       " (56.55, 91.69),\n",
       " (36.07, 55.41),\n",
       " (53.98, 87.02),\n",
       " (50.53, 80.82),\n",
       " (48.58, 77.34),\n",
       " (46.67, 73.94),\n",
       " (29.8, 44.74),\n",
       " (23.59, 34.45),\n",
       " (52.14, 83.71),\n",
       " (52.49, 84.34),\n",
       " (20.74, 29.82),\n",
       " (56.48, 91.55),\n",
       " (32.72, 49.68),\n",
       " (54.79, 88.49),\n",
       " (32.3, 48.96),\n",
       " (35.39, 54.24),\n",
       " (39.89, 62.02),\n",
       " (40.85, 63.69),\n",
       " (29.83, 44.79),\n",
       " (24.71, 36.28),\n",
       " (31.4, 47.44),\n",
       " (57.61, 93.6),\n",
       " (35.25, 54.01),\n",
       " (33.9, 51.68),\n",
       " (32.81, 49.84),\n",
       " (45.25, 71.43),\n",
       " (62.86, 103.21),\n",
       " (89.69, 153.66),\n",
       " (61.11, 100.0),\n",
       " (32.76, 49.74),\n",
       " (31.63, 47.83),\n",
       " (33.07, 50.27),\n",
       " (47.76, 75.88),\n",
       " (45.8, 72.4),\n",
       " (33.77, 51.47),\n",
       " (29.21, 43.76),\n",
       " (50.06, 79.99),\n",
       " (41.79, 65.34),\n",
       " (54.55, 88.05),\n",
       " (38.98, 60.44),\n",
       " (36.37, 55.93),\n",
       " (32.62, 49.51),\n",
       " (53.03, 85.32),\n",
       " (34.3, 52.37),\n",
       " (46.94, 74.42),\n",
       " (62.53, 102.6),\n",
       " (67.83, 112.39),\n",
       " (26.32, 38.94),\n",
       " (24.21, 35.46),\n",
       " (34.25, 52.29),\n",
       " (50.15, 80.14),\n",
       " (25.57, 37.69),\n",
       " (50.27, 80.36),\n",
       " (29.24, 43.81),\n",
       " (43.59, 68.49),\n",
       " (37.54, 57.94),\n",
       " (62.24, 102.07),\n",
       " (33.96, 51.79),\n",
       " (49.03, 78.13),\n",
       " (29.67, 44.52),\n",
       " (30.52, 45.96),\n",
       " (50.83, 81.35),\n",
       " (54.34, 87.67),\n",
       " (72.22, 120.57),\n",
       " (117.85, 208.62),\n",
       " (31.82, 48.15),\n",
       " (45.69, 72.21),\n",
       " (36.84, 56.73),\n",
       " (31.64, 47.86),\n",
       " (84.15, 143.06),\n",
       " (31.28, 47.24),\n",
       " (59.76, 97.52),\n",
       " (55.17, 89.18),\n",
       " (32.56, 49.4),\n",
       " (25.76, 38.01),\n",
       " (30.74, 46.32),\n",
       " (36.89, 56.82),\n",
       " (28.37, 42.35),\n",
       " (56.6, 91.76),\n",
       " (36.5, 56.14),\n",
       " (36.3, 55.81),\n",
       " (42.32, 66.27),\n",
       " (38.56, 59.7),\n",
       " (39.84, 61.94),\n",
       " (35.39, 54.25),\n",
       " (29.31, 43.92),\n",
       " (51.47, 82.51),\n",
       " (32.73, 49.7),\n",
       " (41.69, 65.16),\n",
       " (39.48, 61.31),\n",
       " (28.44, 42.47),\n",
       " (32.56, 49.41),\n",
       " (52.0, 83.45),\n",
       " (42.16, 65.99),\n",
       " (60.98, 99.76),\n",
       " (53.56, 86.26),\n",
       " (30.27, 45.53),\n",
       " (31.55, 47.7),\n",
       " (53.07, 85.39),\n",
       " (45.09, 71.15),\n",
       " (33.28, 50.64),\n",
       " (37.41, 57.72),\n",
       " (54.63, 88.2),\n",
       " (75.67, 127.03),\n",
       " (65.61, 108.27),\n",
       " (32.26, 48.9),\n",
       " (47.33, 75.11),\n",
       " (27.66, 41.17),\n",
       " (28.08, 41.86),\n",
       " (32.79, 49.79),\n",
       " (32.25, 48.88),\n",
       " (50.44, 80.66),\n",
       " (58.69, 95.56),\n",
       " (90.04, 154.33),\n",
       " (51.73, 82.97),\n",
       " (47.24, 74.95),\n",
       " (47.83, 76.01),\n",
       " (52.51, 84.37),\n",
       " (47.23, 74.94),\n",
       " (29.91, 44.93),\n",
       " (43.23, 67.87),\n",
       " (97.85, 169.39),\n",
       " (43.71, 68.71),\n",
       " (32.22, 48.83),\n",
       " (58.61, 95.42),\n",
       " (18.76, 26.65),\n",
       " (32.86, 49.93),\n",
       " (67.99, 112.67),\n",
       " (48.94, 77.98),\n",
       " (55.61, 89.98),\n",
       " (29.44, 44.14),\n",
       " (36.32, 55.85),\n",
       " (24.81, 36.44),\n",
       " (30.66, 46.2),\n",
       " (59.91, 97.79),\n",
       " (88.28, 150.95),\n",
       " (25.83, 38.13),\n",
       " (28.71, 42.92),\n",
       " (33.91, 51.7),\n",
       " (44.11, 69.41),\n",
       " (38.29, 59.24),\n",
       " (63.4, 104.2),\n",
       " (47.4, 75.23),\n",
       " (31.1, 46.93),\n",
       " (32.07, 48.57),\n",
       " (95.72, 165.27),\n",
       " (98.1, 169.88),\n",
       " (70.52, 117.39),\n",
       " (57.97, 94.25),\n",
       " (26.11, 38.59),\n",
       " (34.08, 52.0),\n",
       " (40.57, 63.21),\n",
       " (36.69, 56.48),\n",
       " (49.12, 78.31),\n",
       " (33.19, 50.49),\n",
       " (57.82, 93.98),\n",
       " (48.84, 77.79),\n",
       " (50.47, 80.72),\n",
       " (44.44, 70.0),\n",
       " (50.39, 80.58),\n",
       " (27.03, 40.11),\n",
       " (64.92, 107.0),\n",
       " (33.29, 50.65),\n",
       " (41.73, 65.23),\n",
       " (35.6, 54.6),\n",
       " (29.44, 44.14),\n",
       " (35.08, 53.71),\n",
       " (65.8, 108.63),\n",
       " (23.96, 35.04),\n",
       " (32.53, 49.36),\n",
       " (31.22, 47.14),\n",
       " (48.06, 76.41),\n",
       " (29.01, 43.41),\n",
       " (24.82, 36.45),\n",
       " (76.54, 128.66),\n",
       " (44.75, 70.54),\n",
       " (61.17, 100.1),\n",
       " (47.73, 75.83),\n",
       " (30.79, 46.42),\n",
       " (42.88, 67.26),\n",
       " (52.14, 83.7),\n",
       " (29.18, 43.71),\n",
       " (62.52, 102.58),\n",
       " (54.62, 88.19),\n",
       " (53.78, 86.67),\n",
       " (29.86, 44.85),\n",
       " (46.98, 74.5),\n",
       " (37.25, 57.45),\n",
       " (31.62, 47.82),\n",
       " (29.66, 44.51),\n",
       " (69.51, 115.5),\n",
       " (53.45, 86.07),\n",
       " (33.38, 50.8),\n",
       " (29.5, 44.24),\n",
       " (41.92, 65.56),\n",
       " (31.49, 47.59),\n",
       " (39.15, 60.73),\n",
       " (27.35, 40.65),\n",
       " (52.7, 84.72),\n",
       " (47.03, 74.57),\n",
       " (29.74, 44.64),\n",
       " (41.24, 64.38),\n",
       " (82.69, 140.3),\n",
       " (49.36, 78.72),\n",
       " (28.85, 43.16),\n",
       " (42.51, 66.6),\n",
       " (34.34, 52.45),\n",
       " (40.11, 62.41),\n",
       " (47.74, 75.84),\n",
       " (31.8, 48.11),\n",
       " (45.32, 71.54),\n",
       " (66.86, 110.58),\n",
       " (24.49, 35.92),\n",
       " (28.54, 42.62),\n",
       " (56.39, 91.38),\n",
       " (81.4, 137.84),\n",
       " (61.49, 100.69),\n",
       " (48.43, 77.06),\n",
       " (52.07, 83.58),\n",
       " (47.94, 76.2),\n",
       " (63.11, 103.67),\n",
       " (37.89, 58.56),\n",
       " (48.9, 77.92),\n",
       " (48.86, 77.84),\n",
       " (41.53, 64.88),\n",
       " (27.54, 40.95),\n",
       " (50.19, 80.22),\n",
       " (90.8, 155.8),\n",
       " (37.09, 57.16),\n",
       " (32.8, 49.81),\n",
       " (55.67, 90.08),\n",
       " (39.65, 61.6),\n",
       " (26.45, 39.16),\n",
       " (34.65, 52.98),\n",
       " (49.9, 79.69),\n",
       " (29.13, 43.61),\n",
       " (46.76, 74.1),\n",
       " (24.08, 35.25),\n",
       " (56.25, 91.13),\n",
       " (51.17, 81.97),\n",
       " (52.48, 84.33),\n",
       " (54.29, 87.59),\n",
       " (47.97, 76.25),\n",
       " (49.36, 78.72),\n",
       " (31.77, 48.07),\n",
       " (30.39, 45.74),\n",
       " (34.21, 52.22),\n",
       " (79.76, 134.74),\n",
       " (31.83, 48.18),\n",
       " (70.05, 116.52),\n",
       " (33.69, 51.34),\n",
       " (56.07, 90.8),\n",
       " (46.16, 73.04),\n",
       " (48.48, 77.15),\n",
       " (24.85, 36.5),\n",
       " (52.1, 83.65),\n",
       " (58.33, 94.92),\n",
       " (30.52, 45.95),\n",
       " (27.5, 40.89),\n",
       " (29.44, 44.13),\n",
       " (44.33, 69.81),\n",
       " (62.11, 101.83),\n",
       " (61.37, 100.46),\n",
       " (66.56, 110.04),\n",
       " (61.44, 100.6),\n",
       " (30.28, 45.56),\n",
       " (26.93, 39.95),\n",
       " (56.91, 92.33),\n",
       " (31.81, 48.14),\n",
       " (36.1, 55.47),\n",
       " (22.73, 33.04),\n",
       " (54.81, 88.53),\n",
       " (30.71, 46.28),\n",
       " (53.84, 86.78),\n",
       " (46.93, 74.4),\n",
       " (99.33, 172.27),\n",
       " (35.01, 53.59),\n",
       " (51.71, 82.94),\n",
       " (57.49, 93.38),\n",
       " (30.51, 45.93),\n",
       " (47.0, 74.53),\n",
       " (54.88, 88.64),\n",
       " (64.2, 105.68),\n",
       " (30.19, 45.39),\n",
       " (44.61, 70.3),\n",
       " (34.2, 52.21),\n",
       " (31.57, 47.73),\n",
       " (51.21, 82.05),\n",
       " (49.91, 79.7),\n",
       " (35.74, 54.84),\n",
       " (42.31, 66.25),\n",
       " (74.3, 124.46),\n",
       " (30.62, 46.12),\n",
       " (26.1, 38.56),\n",
       " (30.49, 45.9),\n",
       " (57.78, 93.91),\n",
       " (70.97, 118.23),\n",
       " (42.17, 66.0),\n",
       " (73.24, 122.46),\n",
       " (64.71, 106.61),\n",
       " (27.51, 40.91),\n",
       " (32.0, 48.46),\n",
       " (38.21, 59.11),\n",
       " (57.79, 93.93),\n",
       " (88.52, 151.41),\n",
       " (47.27, 75.01),\n",
       " (53.45, 86.07),\n",
       " (30.62, 46.12),\n",
       " (34.96, 53.5),\n",
       " (62.05, 101.72),\n",
       " (27.05, 40.15),\n",
       " (29.06, 43.51),\n",
       " (27.61, 41.08),\n",
       " (34.51, 52.74),\n",
       " (30.28, 45.55),\n",
       " (60.61, 99.07),\n",
       " (64.27, 105.8),\n",
       " (73.7, 123.33),\n",
       " (50.77, 81.25),\n",
       " (47.26, 74.99),\n",
       " (68.65, 113.91),\n",
       " (41.55, 64.91),\n",
       " (26.19, 38.72),\n",
       " (102.07, 177.6),\n",
       " (29.69, 44.55),\n",
       " (35.25, 54.01),\n",
       " (29.85, 44.82),\n",
       " (68.56, 113.74),\n",
       " (35.58, 54.56),\n",
       " (62.96, 103.4),\n",
       " (29.07, 43.51),\n",
       " (62.79, 103.08),\n",
       " (107.73, 188.67),\n",
       " (42.79, 67.08),\n",
       " (46.26, 73.22),\n",
       " (29.32, 43.94),\n",
       " (42.17, 66.0),\n",
       " (58.84, 95.84),\n",
       " (30.29, 45.57),\n",
       " (55.49, 89.76),\n",
       " (69.77, 115.98),\n",
       " (25.91, 38.26),\n",
       " (26.48, 39.2),\n",
       " (25.5, 37.57),\n",
       " (33.18, 50.47),\n",
       " (30.21, 45.43),\n",
       " (58.36, 94.97),\n",
       " (42.99, 67.44),\n",
       " (31.62, 47.81),\n",
       " (56.25, 91.13),\n",
       " (40.78, 63.57),\n",
       " (51.85, 83.18),\n",
       " (25.12, 36.96),\n",
       " (30.38, 45.72),\n",
       " (63.32, 104.04),\n",
       " (30.7, 46.26),\n",
       " (33.92, 51.73),\n",
       " (31.15, 47.02),\n",
       " (54.98, 88.82),\n",
       " (17.36, 24.44),\n",
       " (61.67, 101.01),\n",
       " (42.89, 67.27),\n",
       " (44.52, 70.14),\n",
       " (26.1, 38.58),\n",
       " (56.58, 91.73),\n",
       " (31.77, 48.06),\n",
       " (62.7, 102.91),\n",
       " (29.56, 44.34),\n",
       " (23.95, 35.03),\n",
       " (33.53, 51.06),\n",
       " (30.89, 46.58),\n",
       " (31.8, 48.13),\n",
       " (58.65, 95.49),\n",
       " (45.97, 72.69),\n",
       " (43.58, 68.48),\n",
       " (45.13, 71.22),\n",
       " (48.54, 77.27),\n",
       " (36.8, 56.66),\n",
       " (30.76, 46.36),\n",
       " (42.6, 66.76),\n",
       " (46.12, 72.97),\n",
       " (71.6, 119.41),\n",
       " (30.19, 45.4),\n",
       " (34.67, 53.01),\n",
       " (53.37, 85.93),\n",
       " (98.77, 171.18),\n",
       " (50.99, 81.65),\n",
       " (89.19, 152.7),\n",
       " (34.84, 53.3),\n",
       " (49.07, 78.21),\n",
       " (35.2, 53.91),\n",
       " ...)"
      ]
     },
     "execution_count": 1005,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_rf_reg = tuple([(round(math.exp(el-el*MAPE_median_rf_reg),2),round(math.exp(el+el*MAPE_median_rf_reg),2)) for el in y_test_pred_rf_reg])\n",
    "y_pred_interval_rf_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_rf_reg, title=\"best_model_rf_reg_01\", save=\"joblib\")\n",
    "save_model(grid_rf_reg, title=\"best_cv_rf_reg_01\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 4: CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_cat_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('cat_reg',\n",
    "                              CatBoostRegressor(n_estimators=173,\n",
    "                                                learning_rate=0.25,\n",
    "                                                l2_leaf_reg=7,\n",
    "                                                random_state=random_state,\n",
    "                                                depth=6))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss_function'])"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_cat_reg = CatBoostRegressor()\n",
    "test_cat_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for CatBoostRegressor** (as base for hyperparameter search):\n",
    "\n",
    "iterations=None, learning_rate=None, depth=None, l2_leaf_reg=None, model_size_reg=None, rsm=None, loss_function='RMSE', border_count=None, feature_border_type=None, per_float_feature_quantization=None, input_borders=None, output_borders=None, fold_permutation_block=None, od_pval=None, od_wait=None, od_type=None, nan_mode=None, counter_calc_method=None, leaf_estimation_iterations=None, leaf_estimation_method=None, thread_count=None, random_seed=None, use_best_model=None, best_model_min_trees=None, verbose=None, silent=None, logging_level=None, metric_period=None, ctr_leaf_count_limit=None, store_all_simple_ctr=None, max_ctr_complexity=None, has_time=None, allow_const_label=None, target_border=None, one_hot_max_size=None, random_strength=None, name=None, ignored_features=None, train_dir=None, custom_metric=None, eval_metric=None, bagging_temperature=None, save_snapshot=None, snapshot_file=None, snapshot_interval=None, fold_len_multiplier=None, used_ram_limit=None, gpu_ram_part=None, pinned_memory_size=None, allow_writing_files=None, final_ctr_computation_mode=None, approx_on_full_history=None, boosting_type=None, simple_ctr=None, combinations_ctr=None, per_feature_ctr=None, ctr_description=None, ctr_target_border_count=None, task_type=None, device_config=None, devices=None, bootstrap_type=None, subsample=None, mvs_reg=None, sampling_frequency=None, sampling_unit=None, dev_score_calc_obj_block_size=None, dev_efb_max_buckets=None, sparse_features_conflict_fraction=None, max_depth=None, n_estimators=None, num_boost_round=None, num_trees=None, colsample_bylevel=None, random_state=None, reg_lambda=None, objective=None, eta=None, max_bin=None, gpu_cat_features_storage=None, data_partition=None, metadata=None, early_stopping_rounds=None, cat_features=None, grow_policy=None, min_data_in_leaf=None, min_child_samples=None, max_leaves=None, num_leaves=None, score_function=None, leaf_estimation_backtracking=None, ctr_history_unit=None, monotone_constraints=None, feature_weights=None, penalties_coefficient=None, first_feature_use_penalties=None, per_object_feature_penalties=None, model_shrink_rate=None, model_shrink_mode=None, langevin=None, diffusion_temperature=None, boost_from_average=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_cat_reg = {\n",
    "    'cat_reg__n_estimators': randint(low=130, high=180),    # initial: randint(low=10, high=200)\n",
    "    'cat_reg__l2_leaf_reg': randint(low=2, high=11),       # initial: randint(low=1, high=15)\n",
    "    'cat_reg__depth': randint(low=7, high=8),             # initial: randint(low=1, high=15)\n",
    "    'cat_reg__learning_rate': [0.15, 0.18, 0.2, 0.22, 0.25, 0.27, 0.3] # initial: [0.01, 0.02, 0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   44.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5175471\ttotal: 6.93ms\tremaining: 1.14s\n",
      "1:\tlearn: 0.4805338\ttotal: 10.9ms\tremaining: 890ms\n",
      "2:\tlearn: 0.4551306\ttotal: 15ms\tremaining: 810ms\n",
      "3:\tlearn: 0.4379611\ttotal: 18.9ms\tremaining: 761ms\n",
      "4:\tlearn: 0.4268119\ttotal: 24.5ms\tremaining: 783ms\n",
      "5:\tlearn: 0.4171543\ttotal: 27.9ms\tremaining: 739ms\n",
      "6:\tlearn: 0.4097105\ttotal: 31.9ms\tremaining: 721ms\n",
      "7:\tlearn: 0.4043049\ttotal: 38.4ms\tremaining: 753ms\n",
      "8:\tlearn: 0.4006181\ttotal: 42ms\tremaining: 727ms\n",
      "9:\tlearn: 0.3973614\ttotal: 46ms\tremaining: 713ms\n",
      "10:\tlearn: 0.3938652\ttotal: 49.8ms\tremaining: 698ms\n",
      "11:\tlearn: 0.3910972\ttotal: 55.6ms\tremaining: 709ms\n",
      "12:\tlearn: 0.3884338\ttotal: 59.7ms\tremaining: 698ms\n",
      "13:\tlearn: 0.3865130\ttotal: 63.3ms\tremaining: 682ms\n",
      "14:\tlearn: 0.3843151\ttotal: 68.8ms\tremaining: 688ms\n",
      "15:\tlearn: 0.3828185\ttotal: 73.6ms\tremaining: 686ms\n",
      "16:\tlearn: 0.3813783\ttotal: 77.4ms\tremaining: 674ms\n",
      "17:\tlearn: 0.3797530\ttotal: 80.8ms\tremaining: 660ms\n",
      "18:\tlearn: 0.3787822\ttotal: 86.6ms\tremaining: 665ms\n",
      "19:\tlearn: 0.3773355\ttotal: 90.3ms\tremaining: 655ms\n",
      "20:\tlearn: 0.3767968\ttotal: 93.7ms\tremaining: 642ms\n",
      "21:\tlearn: 0.3754939\ttotal: 97.4ms\tremaining: 633ms\n",
      "22:\tlearn: 0.3747891\ttotal: 101ms\tremaining: 624ms\n",
      "23:\tlearn: 0.3738909\ttotal: 104ms\tremaining: 613ms\n",
      "24:\tlearn: 0.3727924\ttotal: 109ms\tremaining: 612ms\n",
      "25:\tlearn: 0.3720835\ttotal: 113ms\tremaining: 606ms\n",
      "26:\tlearn: 0.3714708\ttotal: 117ms\tremaining: 598ms\n",
      "27:\tlearn: 0.3706688\ttotal: 123ms\tremaining: 603ms\n",
      "28:\tlearn: 0.3701125\ttotal: 129ms\tremaining: 606ms\n",
      "29:\tlearn: 0.3695015\ttotal: 135ms\tremaining: 608ms\n",
      "30:\tlearn: 0.3689129\ttotal: 141ms\tremaining: 608ms\n",
      "31:\tlearn: 0.3684726\ttotal: 147ms\tremaining: 610ms\n",
      "32:\tlearn: 0.3671436\ttotal: 155ms\tremaining: 620ms\n",
      "33:\tlearn: 0.3666417\ttotal: 161ms\tremaining: 619ms\n",
      "34:\tlearn: 0.3661355\ttotal: 167ms\tremaining: 619ms\n",
      "35:\tlearn: 0.3654376\ttotal: 171ms\tremaining: 614ms\n",
      "36:\tlearn: 0.3647081\ttotal: 175ms\tremaining: 605ms\n",
      "37:\tlearn: 0.3638989\ttotal: 179ms\tremaining: 597ms\n",
      "38:\tlearn: 0.3628206\ttotal: 184ms\tremaining: 594ms\n",
      "39:\tlearn: 0.3623447\ttotal: 187ms\tremaining: 585ms\n",
      "40:\tlearn: 0.3618323\ttotal: 191ms\tremaining: 577ms\n",
      "41:\tlearn: 0.3610089\ttotal: 194ms\tremaining: 569ms\n",
      "42:\tlearn: 0.3601365\ttotal: 198ms\tremaining: 561ms\n",
      "43:\tlearn: 0.3596786\ttotal: 202ms\tremaining: 556ms\n",
      "44:\tlearn: 0.3592250\ttotal: 208ms\tremaining: 555ms\n",
      "45:\tlearn: 0.3583881\ttotal: 214ms\tremaining: 554ms\n",
      "46:\tlearn: 0.3575518\ttotal: 220ms\tremaining: 552ms\n",
      "47:\tlearn: 0.3571346\ttotal: 226ms\tremaining: 550ms\n",
      "48:\tlearn: 0.3564489\ttotal: 231ms\tremaining: 547ms\n",
      "49:\tlearn: 0.3560769\ttotal: 237ms\tremaining: 545ms\n",
      "50:\tlearn: 0.3557852\ttotal: 244ms\tremaining: 546ms\n",
      "51:\tlearn: 0.3552782\ttotal: 249ms\tremaining: 542ms\n",
      "52:\tlearn: 0.3546120\ttotal: 253ms\tremaining: 535ms\n",
      "53:\tlearn: 0.3542558\ttotal: 257ms\tremaining: 528ms\n",
      "54:\tlearn: 0.3539133\ttotal: 262ms\tremaining: 525ms\n",
      "55:\tlearn: 0.3533273\ttotal: 266ms\tremaining: 518ms\n",
      "56:\tlearn: 0.3526135\ttotal: 270ms\tremaining: 511ms\n",
      "57:\tlearn: 0.3522752\ttotal: 273ms\tremaining: 504ms\n",
      "58:\tlearn: 0.3519694\ttotal: 277ms\tremaining: 498ms\n",
      "59:\tlearn: 0.3509512\ttotal: 281ms\tremaining: 492ms\n",
      "60:\tlearn: 0.3504655\ttotal: 284ms\tremaining: 485ms\n",
      "61:\tlearn: 0.3497479\ttotal: 288ms\tremaining: 479ms\n",
      "62:\tlearn: 0.3492642\ttotal: 292ms\tremaining: 472ms\n",
      "63:\tlearn: 0.3487814\ttotal: 296ms\tremaining: 467ms\n",
      "64:\tlearn: 0.3480057\ttotal: 300ms\tremaining: 461ms\n",
      "65:\tlearn: 0.3475242\ttotal: 304ms\tremaining: 456ms\n",
      "66:\tlearn: 0.3471557\ttotal: 307ms\tremaining: 449ms\n",
      "67:\tlearn: 0.3465675\ttotal: 311ms\tremaining: 444ms\n",
      "68:\tlearn: 0.3461573\ttotal: 315ms\tremaining: 438ms\n",
      "69:\tlearn: 0.3455579\ttotal: 319ms\tremaining: 433ms\n",
      "70:\tlearn: 0.3451722\ttotal: 322ms\tremaining: 427ms\n",
      "71:\tlearn: 0.3445198\ttotal: 326ms\tremaining: 422ms\n",
      "72:\tlearn: 0.3442546\ttotal: 330ms\tremaining: 416ms\n",
      "73:\tlearn: 0.3437947\ttotal: 334ms\tremaining: 411ms\n",
      "74:\tlearn: 0.3431751\ttotal: 340ms\tremaining: 408ms\n",
      "75:\tlearn: 0.3429345\ttotal: 348ms\tremaining: 408ms\n",
      "76:\tlearn: 0.3427921\ttotal: 357ms\tremaining: 408ms\n",
      "77:\tlearn: 0.3423866\ttotal: 362ms\tremaining: 403ms\n",
      "78:\tlearn: 0.3421374\ttotal: 366ms\tremaining: 398ms\n",
      "79:\tlearn: 0.3419622\ttotal: 371ms\tremaining: 394ms\n",
      "80:\tlearn: 0.3416345\ttotal: 374ms\tremaining: 388ms\n",
      "81:\tlearn: 0.3412937\ttotal: 378ms\tremaining: 383ms\n",
      "82:\tlearn: 0.3411917\ttotal: 381ms\tremaining: 377ms\n",
      "83:\tlearn: 0.3404368\ttotal: 385ms\tremaining: 371ms\n",
      "84:\tlearn: 0.3398156\ttotal: 389ms\tremaining: 366ms\n",
      "85:\tlearn: 0.3394409\ttotal: 392ms\tremaining: 360ms\n",
      "86:\tlearn: 0.3389688\ttotal: 400ms\tremaining: 359ms\n",
      "87:\tlearn: 0.3385779\ttotal: 410ms\tremaining: 359ms\n",
      "88:\tlearn: 0.3381744\ttotal: 420ms\tremaining: 359ms\n",
      "89:\tlearn: 0.3377967\ttotal: 428ms\tremaining: 357ms\n",
      "90:\tlearn: 0.3376100\ttotal: 438ms\tremaining: 356ms\n",
      "91:\tlearn: 0.3372367\ttotal: 446ms\tremaining: 354ms\n",
      "92:\tlearn: 0.3367300\ttotal: 454ms\tremaining: 351ms\n",
      "93:\tlearn: 0.3364677\ttotal: 457ms\tremaining: 346ms\n",
      "94:\tlearn: 0.3360234\ttotal: 461ms\tremaining: 340ms\n",
      "95:\tlearn: 0.3357587\ttotal: 467ms\tremaining: 335ms\n",
      "96:\tlearn: 0.3354242\ttotal: 472ms\tremaining: 331ms\n",
      "97:\tlearn: 0.3351825\ttotal: 475ms\tremaining: 325ms\n",
      "98:\tlearn: 0.3347904\ttotal: 480ms\tremaining: 320ms\n",
      "99:\tlearn: 0.3343889\ttotal: 486ms\tremaining: 316ms\n",
      "100:\tlearn: 0.3342429\ttotal: 489ms\tremaining: 310ms\n",
      "101:\tlearn: 0.3336947\ttotal: 494ms\tremaining: 305ms\n",
      "102:\tlearn: 0.3334420\ttotal: 499ms\tremaining: 300ms\n",
      "103:\tlearn: 0.3332054\ttotal: 504ms\tremaining: 296ms\n",
      "104:\tlearn: 0.3329560\ttotal: 509ms\tremaining: 291ms\n",
      "105:\tlearn: 0.3323994\ttotal: 513ms\tremaining: 286ms\n",
      "106:\tlearn: 0.3320921\ttotal: 517ms\tremaining: 280ms\n",
      "107:\tlearn: 0.3317952\ttotal: 520ms\tremaining: 275ms\n",
      "108:\tlearn: 0.3316155\ttotal: 524ms\tremaining: 269ms\n",
      "109:\tlearn: 0.3314151\ttotal: 528ms\tremaining: 264ms\n",
      "110:\tlearn: 0.3311720\ttotal: 531ms\tremaining: 258ms\n",
      "111:\tlearn: 0.3308261\ttotal: 535ms\tremaining: 253ms\n",
      "112:\tlearn: 0.3303707\ttotal: 538ms\tremaining: 248ms\n",
      "113:\tlearn: 0.3300794\ttotal: 542ms\tremaining: 242ms\n",
      "114:\tlearn: 0.3298945\ttotal: 545ms\tremaining: 237ms\n",
      "115:\tlearn: 0.3296305\ttotal: 549ms\tremaining: 232ms\n",
      "116:\tlearn: 0.3295291\ttotal: 553ms\tremaining: 227ms\n",
      "117:\tlearn: 0.3287120\ttotal: 556ms\tremaining: 222ms\n",
      "118:\tlearn: 0.3284143\ttotal: 560ms\tremaining: 216ms\n",
      "119:\tlearn: 0.3279441\ttotal: 563ms\tremaining: 211ms\n",
      "120:\tlearn: 0.3278116\ttotal: 567ms\tremaining: 206ms\n",
      "121:\tlearn: 0.3276829\ttotal: 570ms\tremaining: 201ms\n",
      "122:\tlearn: 0.3274177\ttotal: 574ms\tremaining: 196ms\n",
      "123:\tlearn: 0.3269558\ttotal: 577ms\tremaining: 191ms\n",
      "124:\tlearn: 0.3267066\ttotal: 581ms\tremaining: 186ms\n",
      "125:\tlearn: 0.3262549\ttotal: 584ms\tremaining: 181ms\n",
      "126:\tlearn: 0.3259009\ttotal: 588ms\tremaining: 176ms\n",
      "127:\tlearn: 0.3256723\ttotal: 593ms\tremaining: 171ms\n",
      "128:\tlearn: 0.3250732\ttotal: 599ms\tremaining: 167ms\n",
      "129:\tlearn: 0.3247849\ttotal: 609ms\tremaining: 164ms\n",
      "130:\tlearn: 0.3245709\ttotal: 614ms\tremaining: 159ms\n",
      "131:\tlearn: 0.3243527\ttotal: 620ms\tremaining: 155ms\n",
      "132:\tlearn: 0.3239445\ttotal: 627ms\tremaining: 151ms\n",
      "133:\tlearn: 0.3237158\ttotal: 638ms\tremaining: 148ms\n",
      "134:\tlearn: 0.3233971\ttotal: 644ms\tremaining: 143ms\n",
      "135:\tlearn: 0.3228535\ttotal: 653ms\tremaining: 139ms\n",
      "136:\tlearn: 0.3226673\ttotal: 658ms\tremaining: 135ms\n",
      "137:\tlearn: 0.3223396\ttotal: 664ms\tremaining: 130ms\n",
      "138:\tlearn: 0.3222123\ttotal: 672ms\tremaining: 126ms\n",
      "139:\tlearn: 0.3219498\ttotal: 676ms\tremaining: 121ms\n",
      "140:\tlearn: 0.3215959\ttotal: 680ms\tremaining: 116ms\n",
      "141:\tlearn: 0.3213061\ttotal: 685ms\tremaining: 111ms\n",
      "142:\tlearn: 0.3211759\ttotal: 689ms\tremaining: 106ms\n",
      "143:\tlearn: 0.3208322\ttotal: 692ms\tremaining: 101ms\n",
      "144:\tlearn: 0.3205722\ttotal: 696ms\tremaining: 96ms\n",
      "145:\tlearn: 0.3204161\ttotal: 700ms\tremaining: 91.1ms\n",
      "146:\tlearn: 0.3202717\ttotal: 703ms\tremaining: 86.1ms\n",
      "147:\tlearn: 0.3197558\ttotal: 707ms\tremaining: 81.2ms\n",
      "148:\tlearn: 0.3194442\ttotal: 711ms\tremaining: 76.3ms\n",
      "149:\tlearn: 0.3191613\ttotal: 714ms\tremaining: 71.4ms\n",
      "150:\tlearn: 0.3189545\ttotal: 718ms\tremaining: 66.5ms\n",
      "151:\tlearn: 0.3187236\ttotal: 721ms\tremaining: 61.7ms\n",
      "152:\tlearn: 0.3185113\ttotal: 725ms\tremaining: 56.8ms\n",
      "153:\tlearn: 0.3179970\ttotal: 729ms\tremaining: 52ms\n",
      "154:\tlearn: 0.3178723\ttotal: 732ms\tremaining: 47.2ms\n",
      "155:\tlearn: 0.3177547\ttotal: 736ms\tremaining: 42.4ms\n",
      "156:\tlearn: 0.3175664\ttotal: 740ms\tremaining: 37.7ms\n",
      "157:\tlearn: 0.3173351\ttotal: 744ms\tremaining: 33ms\n",
      "158:\tlearn: 0.3170920\ttotal: 749ms\tremaining: 28.3ms\n",
      "159:\tlearn: 0.3167059\ttotal: 752ms\tremaining: 23.5ms\n",
      "160:\tlearn: 0.3162522\ttotal: 756ms\tremaining: 18.8ms\n",
      "161:\tlearn: 0.3160518\ttotal: 760ms\tremaining: 14.1ms\n",
      "162:\tlearn: 0.3158359\ttotal: 764ms\tremaining: 9.37ms\n",
      "163:\tlearn: 0.3155734\ttotal: 767ms\tremaining: 4.68ms\n",
      "164:\tlearn: 0.3154032\ttotal: 771ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_cat_reg = RandomizedSearchCV(pipeline_cat_reg,\n",
    "                                 param_distribs_cat_reg,\n",
    "                                 cv=5,\n",
    "                                 scoring=scoring,\n",
    "                                 n_iter=15,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_cat_reg = rnd_cat_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.22\n",
      "Best parameters:\n",
      "{'cat_reg__depth': 6, 'cat_reg__l2_leaf_reg': 7, 'cat_reg__learning_rate': 0.25, 'cat_reg__n_estimators': 173}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_cat_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_cat_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(rnd_cat_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_cat_reg = {\n",
    "#    'cat_reg__n_estimators': [150, 155],\n",
    "#    'cat_reg__l2_leaf_reg': [3, 4],\n",
    "    'cat_reg__depth': [6, 7],\n",
    "#    'cat_reg__learning_rate': [0.15, 0.2, 0.25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of  10 | elapsed:    7.0s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5181187\ttotal: 3.05ms\tremaining: 525ms\n",
      "1:\tlearn: 0.4815579\ttotal: 6ms\tremaining: 513ms\n",
      "2:\tlearn: 0.4570183\ttotal: 8.69ms\tremaining: 492ms\n",
      "3:\tlearn: 0.4400758\ttotal: 11.3ms\tremaining: 476ms\n",
      "4:\tlearn: 0.4289910\ttotal: 13.9ms\tremaining: 466ms\n",
      "5:\tlearn: 0.4209999\ttotal: 16.5ms\tremaining: 459ms\n",
      "6:\tlearn: 0.4141739\ttotal: 19ms\tremaining: 451ms\n",
      "7:\tlearn: 0.4086418\ttotal: 21.7ms\tremaining: 448ms\n",
      "8:\tlearn: 0.4029687\ttotal: 24.4ms\tremaining: 445ms\n",
      "9:\tlearn: 0.4003921\ttotal: 27ms\tremaining: 440ms\n",
      "10:\tlearn: 0.3968916\ttotal: 29.6ms\tremaining: 436ms\n",
      "11:\tlearn: 0.3946512\ttotal: 32.2ms\tremaining: 432ms\n",
      "12:\tlearn: 0.3928321\ttotal: 34.7ms\tremaining: 427ms\n",
      "13:\tlearn: 0.3907135\ttotal: 37.2ms\tremaining: 422ms\n",
      "14:\tlearn: 0.3890330\ttotal: 39.7ms\tremaining: 418ms\n",
      "15:\tlearn: 0.3870456\ttotal: 42.3ms\tremaining: 415ms\n",
      "16:\tlearn: 0.3855917\ttotal: 45ms\tremaining: 413ms\n",
      "17:\tlearn: 0.3845600\ttotal: 47.5ms\tremaining: 409ms\n",
      "18:\tlearn: 0.3835890\ttotal: 50ms\tremaining: 405ms\n",
      "19:\tlearn: 0.3819666\ttotal: 52.6ms\tremaining: 402ms\n",
      "20:\tlearn: 0.3810367\ttotal: 55.1ms\tremaining: 399ms\n",
      "21:\tlearn: 0.3800945\ttotal: 57.7ms\tremaining: 396ms\n",
      "22:\tlearn: 0.3791030\ttotal: 60.3ms\tremaining: 393ms\n",
      "23:\tlearn: 0.3780925\ttotal: 62.8ms\tremaining: 390ms\n",
      "24:\tlearn: 0.3773141\ttotal: 65.4ms\tremaining: 387ms\n",
      "25:\tlearn: 0.3764395\ttotal: 68.1ms\tremaining: 385ms\n",
      "26:\tlearn: 0.3758171\ttotal: 70.6ms\tremaining: 382ms\n",
      "27:\tlearn: 0.3750296\ttotal: 73.2ms\tremaining: 379ms\n",
      "28:\tlearn: 0.3744563\ttotal: 75.8ms\tremaining: 377ms\n",
      "29:\tlearn: 0.3737381\ttotal: 78.4ms\tremaining: 374ms\n",
      "30:\tlearn: 0.3732742\ttotal: 81ms\tremaining: 371ms\n",
      "31:\tlearn: 0.3726712\ttotal: 83.6ms\tremaining: 369ms\n",
      "32:\tlearn: 0.3720367\ttotal: 86.2ms\tremaining: 366ms\n",
      "33:\tlearn: 0.3715932\ttotal: 88.8ms\tremaining: 363ms\n",
      "34:\tlearn: 0.3712869\ttotal: 91.4ms\tremaining: 360ms\n",
      "35:\tlearn: 0.3709726\ttotal: 93.9ms\tremaining: 357ms\n",
      "36:\tlearn: 0.3705730\ttotal: 96.5ms\tremaining: 355ms\n",
      "37:\tlearn: 0.3694634\ttotal: 99ms\tremaining: 352ms\n",
      "38:\tlearn: 0.3688641\ttotal: 102ms\tremaining: 349ms\n",
      "39:\tlearn: 0.3682294\ttotal: 104ms\tremaining: 347ms\n",
      "40:\tlearn: 0.3672959\ttotal: 107ms\tremaining: 344ms\n",
      "41:\tlearn: 0.3665582\ttotal: 110ms\tremaining: 342ms\n",
      "42:\tlearn: 0.3658769\ttotal: 112ms\tremaining: 339ms\n",
      "43:\tlearn: 0.3652444\ttotal: 115ms\tremaining: 336ms\n",
      "44:\tlearn: 0.3648216\ttotal: 117ms\tremaining: 334ms\n",
      "45:\tlearn: 0.3642565\ttotal: 120ms\tremaining: 331ms\n",
      "46:\tlearn: 0.3638112\ttotal: 122ms\tremaining: 328ms\n",
      "47:\tlearn: 0.3634654\ttotal: 125ms\tremaining: 326ms\n",
      "48:\tlearn: 0.3630850\ttotal: 129ms\tremaining: 328ms\n",
      "49:\tlearn: 0.3625556\ttotal: 134ms\tremaining: 330ms\n",
      "50:\tlearn: 0.3620499\ttotal: 139ms\tremaining: 332ms\n",
      "51:\tlearn: 0.3613709\ttotal: 143ms\tremaining: 333ms\n",
      "52:\tlearn: 0.3609522\ttotal: 147ms\tremaining: 334ms\n",
      "53:\tlearn: 0.3603847\ttotal: 152ms\tremaining: 334ms\n",
      "54:\tlearn: 0.3600216\ttotal: 156ms\tremaining: 334ms\n",
      "55:\tlearn: 0.3592386\ttotal: 160ms\tremaining: 335ms\n",
      "56:\tlearn: 0.3586679\ttotal: 167ms\tremaining: 340ms\n",
      "57:\tlearn: 0.3583025\ttotal: 171ms\tremaining: 339ms\n",
      "58:\tlearn: 0.3579439\ttotal: 175ms\tremaining: 338ms\n",
      "59:\tlearn: 0.3575342\ttotal: 178ms\tremaining: 335ms\n",
      "60:\tlearn: 0.3569443\ttotal: 180ms\tremaining: 331ms\n",
      "61:\tlearn: 0.3563122\ttotal: 183ms\tremaining: 328ms\n",
      "62:\tlearn: 0.3553919\ttotal: 186ms\tremaining: 324ms\n",
      "63:\tlearn: 0.3550669\ttotal: 189ms\tremaining: 321ms\n",
      "64:\tlearn: 0.3547782\ttotal: 191ms\tremaining: 318ms\n",
      "65:\tlearn: 0.3543277\ttotal: 194ms\tremaining: 315ms\n",
      "66:\tlearn: 0.3539706\ttotal: 198ms\tremaining: 313ms\n",
      "67:\tlearn: 0.3535485\ttotal: 202ms\tremaining: 312ms\n",
      "68:\tlearn: 0.3531551\ttotal: 207ms\tremaining: 312ms\n",
      "69:\tlearn: 0.3525126\ttotal: 211ms\tremaining: 311ms\n",
      "70:\tlearn: 0.3519903\ttotal: 215ms\tremaining: 309ms\n",
      "71:\tlearn: 0.3514582\ttotal: 220ms\tremaining: 308ms\n",
      "72:\tlearn: 0.3508541\ttotal: 224ms\tremaining: 307ms\n",
      "73:\tlearn: 0.3505738\ttotal: 229ms\tremaining: 306ms\n",
      "74:\tlearn: 0.3500497\ttotal: 233ms\tremaining: 305ms\n",
      "75:\tlearn: 0.3495491\ttotal: 238ms\tremaining: 303ms\n",
      "76:\tlearn: 0.3488774\ttotal: 244ms\tremaining: 305ms\n",
      "77:\tlearn: 0.3483607\ttotal: 248ms\tremaining: 302ms\n",
      "78:\tlearn: 0.3479564\ttotal: 251ms\tremaining: 299ms\n",
      "79:\tlearn: 0.3477140\ttotal: 255ms\tremaining: 296ms\n",
      "80:\tlearn: 0.3474767\ttotal: 257ms\tremaining: 292ms\n",
      "81:\tlearn: 0.3472982\ttotal: 260ms\tremaining: 288ms\n",
      "82:\tlearn: 0.3469693\ttotal: 263ms\tremaining: 285ms\n",
      "83:\tlearn: 0.3466263\ttotal: 265ms\tremaining: 281ms\n",
      "84:\tlearn: 0.3460588\ttotal: 268ms\tremaining: 278ms\n",
      "85:\tlearn: 0.3457366\ttotal: 271ms\tremaining: 274ms\n",
      "86:\tlearn: 0.3455296\ttotal: 273ms\tremaining: 270ms\n",
      "87:\tlearn: 0.3452358\ttotal: 276ms\tremaining: 267ms\n",
      "88:\tlearn: 0.3450638\ttotal: 279ms\tremaining: 263ms\n",
      "89:\tlearn: 0.3448278\ttotal: 281ms\tremaining: 259ms\n",
      "90:\tlearn: 0.3446728\ttotal: 284ms\tremaining: 256ms\n",
      "91:\tlearn: 0.3443708\ttotal: 286ms\tremaining: 252ms\n",
      "92:\tlearn: 0.3442448\ttotal: 289ms\tremaining: 249ms\n",
      "93:\tlearn: 0.3440159\ttotal: 292ms\tremaining: 245ms\n",
      "94:\tlearn: 0.3438238\ttotal: 294ms\tremaining: 242ms\n",
      "95:\tlearn: 0.3434349\ttotal: 297ms\tremaining: 238ms\n",
      "96:\tlearn: 0.3430826\ttotal: 300ms\tremaining: 235ms\n",
      "97:\tlearn: 0.3428807\ttotal: 303ms\tremaining: 232ms\n",
      "98:\tlearn: 0.3425415\ttotal: 305ms\tremaining: 228ms\n",
      "99:\tlearn: 0.3420916\ttotal: 308ms\tremaining: 225ms\n",
      "100:\tlearn: 0.3416972\ttotal: 311ms\tremaining: 221ms\n",
      "101:\tlearn: 0.3415242\ttotal: 313ms\tremaining: 218ms\n",
      "102:\tlearn: 0.3414472\ttotal: 316ms\tremaining: 215ms\n",
      "103:\tlearn: 0.3412645\ttotal: 319ms\tremaining: 211ms\n",
      "104:\tlearn: 0.3408980\ttotal: 321ms\tremaining: 208ms\n",
      "105:\tlearn: 0.3404821\ttotal: 324ms\tremaining: 205ms\n",
      "106:\tlearn: 0.3401715\ttotal: 327ms\tremaining: 201ms\n",
      "107:\tlearn: 0.3395514\ttotal: 329ms\tremaining: 198ms\n",
      "108:\tlearn: 0.3392896\ttotal: 332ms\tremaining: 195ms\n",
      "109:\tlearn: 0.3388975\ttotal: 335ms\tremaining: 192ms\n",
      "110:\tlearn: 0.3386710\ttotal: 337ms\tremaining: 188ms\n",
      "111:\tlearn: 0.3384374\ttotal: 340ms\tremaining: 185ms\n",
      "112:\tlearn: 0.3380735\ttotal: 342ms\tremaining: 182ms\n",
      "113:\tlearn: 0.3378825\ttotal: 345ms\tremaining: 178ms\n",
      "114:\tlearn: 0.3376891\ttotal: 348ms\tremaining: 175ms\n",
      "115:\tlearn: 0.3373357\ttotal: 350ms\tremaining: 172ms\n",
      "116:\tlearn: 0.3370164\ttotal: 353ms\tremaining: 169ms\n",
      "117:\tlearn: 0.3368981\ttotal: 356ms\tremaining: 166ms\n",
      "118:\tlearn: 0.3366653\ttotal: 358ms\tremaining: 163ms\n",
      "119:\tlearn: 0.3363003\ttotal: 361ms\tremaining: 159ms\n",
      "120:\tlearn: 0.3359741\ttotal: 364ms\tremaining: 156ms\n",
      "121:\tlearn: 0.3357195\ttotal: 366ms\tremaining: 153ms\n",
      "122:\tlearn: 0.3351591\ttotal: 369ms\tremaining: 150ms\n",
      "123:\tlearn: 0.3349393\ttotal: 371ms\tremaining: 147ms\n",
      "124:\tlearn: 0.3346872\ttotal: 374ms\tremaining: 144ms\n",
      "125:\tlearn: 0.3341105\ttotal: 377ms\tremaining: 141ms\n",
      "126:\tlearn: 0.3339215\ttotal: 379ms\tremaining: 137ms\n",
      "127:\tlearn: 0.3335878\ttotal: 382ms\tremaining: 134ms\n",
      "128:\tlearn: 0.3331104\ttotal: 387ms\tremaining: 132ms\n",
      "129:\tlearn: 0.3328913\ttotal: 391ms\tremaining: 129ms\n",
      "130:\tlearn: 0.3326485\ttotal: 396ms\tremaining: 127ms\n",
      "131:\tlearn: 0.3323717\ttotal: 400ms\tremaining: 124ms\n",
      "132:\tlearn: 0.3322008\ttotal: 404ms\tremaining: 122ms\n",
      "133:\tlearn: 0.3319196\ttotal: 409ms\tremaining: 119ms\n",
      "134:\tlearn: 0.3316035\ttotal: 413ms\tremaining: 116ms\n",
      "135:\tlearn: 0.3314045\ttotal: 417ms\tremaining: 114ms\n",
      "136:\tlearn: 0.3310830\ttotal: 426ms\tremaining: 112ms\n",
      "137:\tlearn: 0.3304739\ttotal: 430ms\tremaining: 109ms\n",
      "138:\tlearn: 0.3302859\ttotal: 435ms\tremaining: 106ms\n",
      "139:\tlearn: 0.3299513\ttotal: 441ms\tremaining: 104ms\n",
      "140:\tlearn: 0.3295284\ttotal: 445ms\tremaining: 101ms\n",
      "141:\tlearn: 0.3291803\ttotal: 450ms\tremaining: 98.2ms\n",
      "142:\tlearn: 0.3288957\ttotal: 454ms\tremaining: 95.3ms\n",
      "143:\tlearn: 0.3286666\ttotal: 459ms\tremaining: 92.5ms\n",
      "144:\tlearn: 0.3285082\ttotal: 463ms\tremaining: 89.5ms\n",
      "145:\tlearn: 0.3282982\ttotal: 467ms\tremaining: 86.3ms\n",
      "146:\tlearn: 0.3280616\ttotal: 470ms\tremaining: 83.1ms\n",
      "147:\tlearn: 0.3278967\ttotal: 472ms\tremaining: 79.8ms\n",
      "148:\tlearn: 0.3277059\ttotal: 475ms\tremaining: 76.5ms\n",
      "149:\tlearn: 0.3275172\ttotal: 478ms\tremaining: 73.3ms\n",
      "150:\tlearn: 0.3271607\ttotal: 481ms\tremaining: 70ms\n",
      "151:\tlearn: 0.3270975\ttotal: 483ms\tremaining: 66.8ms\n",
      "152:\tlearn: 0.3268695\ttotal: 487ms\tremaining: 63.7ms\n",
      "153:\tlearn: 0.3267177\ttotal: 490ms\tremaining: 60.5ms\n",
      "154:\tlearn: 0.3265187\ttotal: 493ms\tremaining: 57.2ms\n",
      "155:\tlearn: 0.3263198\ttotal: 495ms\tremaining: 54ms\n",
      "156:\tlearn: 0.3262068\ttotal: 498ms\tremaining: 50.8ms\n",
      "157:\tlearn: 0.3258530\ttotal: 501ms\tremaining: 47.6ms\n",
      "158:\tlearn: 0.3255932\ttotal: 504ms\tremaining: 44.3ms\n",
      "159:\tlearn: 0.3252181\ttotal: 506ms\tremaining: 41.1ms\n",
      "160:\tlearn: 0.3249940\ttotal: 509ms\tremaining: 37.9ms\n",
      "161:\tlearn: 0.3247372\ttotal: 512ms\tremaining: 34.7ms\n",
      "162:\tlearn: 0.3246059\ttotal: 514ms\tremaining: 31.5ms\n",
      "163:\tlearn: 0.3242402\ttotal: 517ms\tremaining: 28.4ms\n",
      "164:\tlearn: 0.3241096\ttotal: 520ms\tremaining: 25.2ms\n",
      "165:\tlearn: 0.3238177\ttotal: 522ms\tremaining: 22ms\n",
      "166:\tlearn: 0.3235791\ttotal: 525ms\tremaining: 18.9ms\n",
      "167:\tlearn: 0.3232734\ttotal: 527ms\tremaining: 15.7ms\n",
      "168:\tlearn: 0.3228549\ttotal: 530ms\tremaining: 12.5ms\n",
      "169:\tlearn: 0.3227143\ttotal: 533ms\tremaining: 9.4ms\n",
      "170:\tlearn: 0.3224844\ttotal: 535ms\tremaining: 6.26ms\n",
      "171:\tlearn: 0.3221869\ttotal: 538ms\tremaining: 3.13ms\n",
      "172:\tlearn: 0.3220206\ttotal: 541ms\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_cat_reg = GridSearchCV(pipeline_cat_reg,\n",
    "                            param_grid_cat_reg,\n",
    "                            cv=5,\n",
    "                            scoring=scoring,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_cat_reg = grid_cat_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save best model\n",
    "best_model_cat_reg = grid_cat_reg.best_estimator_['cat_reg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "-0.22\n",
      "Best parameters:\n",
      "{'cat_reg__depth': 6}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_cat_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_cat_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_xgb_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>room_type_Private room</th>\n",
       "      <td>28.067064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>10.536815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates</th>\n",
       "      <td>6.425896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_90</th>\n",
       "      <td>4.978674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calc_host_lst_count_sqrt_log</th>\n",
       "      <td>4.965670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_elevator</th>\n",
       "      <td>4.727967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_log</th>\n",
       "      <td>3.674083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <td>3.419661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Boutique hotel</th>\n",
       "      <td>3.371647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <td>3.067622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum_nights</th>\n",
       "      <td>2.692494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accommodates_per_bed</th>\n",
       "      <td>2.337358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_other</th>\n",
       "      <td>1.965233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_tv</th>\n",
       "      <td>1.843464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_private_entrance</th>\n",
       "      <td>1.054086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wk_mth_discount</th>\n",
       "      <td>1.035193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>0.970918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10119</th>\n",
       "      <td>0.968911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_balcony</th>\n",
       "      <td>0.927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10117</th>\n",
       "      <td>0.810333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instant_bookable</th>\n",
       "      <td>0.775005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <td>0.738694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_essentials</th>\n",
       "      <td>0.716376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_super_strict</th>\n",
       "      <td>0.675913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_strict</th>\n",
       "      <td>0.631558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_smoking_allowed</th>\n",
       "      <td>0.538730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_child_friendly</th>\n",
       "      <td>0.519459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_breakfast</th>\n",
       "      <td>0.498101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>am_pets_allowed</th>\n",
       "      <td>0.431015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10997</th>\n",
       "      <td>0.344243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_House</th>\n",
       "      <td>0.340723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13359</th>\n",
       "      <td>0.328963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10405</th>\n",
       "      <td>0.289884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10245</th>\n",
       "      <td>0.278008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancellation_policy_moderate</th>\n",
       "      <td>0.233898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10178</th>\n",
       "      <td>0.233727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10999</th>\n",
       "      <td>0.218410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10435</th>\n",
       "      <td>0.211992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12047</th>\n",
       "      <td>0.187463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13407</th>\n",
       "      <td>0.154474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13353</th>\n",
       "      <td>0.140717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13189</th>\n",
       "      <td>0.126197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10179</th>\n",
       "      <td>0.120847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12051</th>\n",
       "      <td>0.119306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10965</th>\n",
       "      <td>0.118093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13347</th>\n",
       "      <td>0.116328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10967</th>\n",
       "      <td>0.107761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10719</th>\n",
       "      <td>0.100954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12347</th>\n",
       "      <td>0.100599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10437</th>\n",
       "      <td>0.094665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10317</th>\n",
       "      <td>0.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10247</th>\n",
       "      <td>0.091167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10439</th>\n",
       "      <td>0.089923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13086</th>\n",
       "      <td>0.086492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10249</th>\n",
       "      <td>0.080119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10715</th>\n",
       "      <td>0.075084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10315</th>\n",
       "      <td>0.075073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10365</th>\n",
       "      <td>0.074603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10589</th>\n",
       "      <td>0.073532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10785</th>\n",
       "      <td>0.071981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13357</th>\n",
       "      <td>0.071616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13187</th>\n",
       "      <td>0.071107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10587</th>\n",
       "      <td>0.066921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13409</th>\n",
       "      <td>0.065310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12435</th>\n",
       "      <td>0.062919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12157</th>\n",
       "      <td>0.062446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10969</th>\n",
       "      <td>0.061377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Secondary unit</th>\n",
       "      <td>0.059519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10559</th>\n",
       "      <td>0.059023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14057</th>\n",
       "      <td>0.056978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12059</th>\n",
       "      <td>0.056296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10557</th>\n",
       "      <td>0.056030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13351</th>\n",
       "      <td>0.055871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12437</th>\n",
       "      <td>0.053633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12055</th>\n",
       "      <td>0.045672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12099</th>\n",
       "      <td>0.045028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10318</th>\n",
       "      <td>0.042064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_nan</th>\n",
       "      <td>0.040986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10777</th>\n",
       "      <td>0.040848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10555</th>\n",
       "      <td>0.040781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13349</th>\n",
       "      <td>0.038687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12045</th>\n",
       "      <td>0.037915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10707</th>\n",
       "      <td>0.037879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12053</th>\n",
       "      <td>0.037741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10717</th>\n",
       "      <td>0.035253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10553</th>\n",
       "      <td>0.032232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12103</th>\n",
       "      <td>0.031687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10551</th>\n",
       "      <td>0.031056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10963</th>\n",
       "      <td>0.030441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10409</th>\n",
       "      <td>0.029276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14197</th>\n",
       "      <td>0.027218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13156</th>\n",
       "      <td>0.027131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10243</th>\n",
       "      <td>0.027103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Bed and breakfast</th>\n",
       "      <td>0.027102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10407</th>\n",
       "      <td>0.025937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12101</th>\n",
       "      <td>0.025857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10827</th>\n",
       "      <td>0.025049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13088</th>\n",
       "      <td>0.022766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10961</th>\n",
       "      <td>0.022285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12163</th>\n",
       "      <td>0.021708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10367</th>\n",
       "      <td>0.019044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10627</th>\n",
       "      <td>0.018193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12049</th>\n",
       "      <td>0.017672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10585</th>\n",
       "      <td>0.017054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10625</th>\n",
       "      <td>0.014615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10781</th>\n",
       "      <td>0.010777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10829</th>\n",
       "      <td>0.010418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10629</th>\n",
       "      <td>0.009799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10713</th>\n",
       "      <td>0.009230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10787</th>\n",
       "      <td>0.008717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_14059</th>\n",
       "      <td>0.008382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_13355</th>\n",
       "      <td>0.005083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10623</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10711</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10783</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12161</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>property_type_Unique space</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_10823</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zipcode_zip_12043</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     weight\n",
       "room_type_Private room            28.067064\n",
       "bedrooms                          10.536815\n",
       "accommodates                       6.425896\n",
       "availability_90                    4.978674\n",
       "calc_host_lst_count_sqrt_log       4.965670\n",
       "am_elevator                        4.727967\n",
       "bathrooms_log                      3.674083\n",
       "minimum_nights_log                 3.419661\n",
       "property_type_Boutique hotel       3.371647\n",
       "room_type_Shared room              3.067622\n",
       "maximum_nights                     2.692494\n",
       "accommodates_per_bed               2.337358\n",
       "zipcode_zip_other                  1.965233\n",
       "am_tv                              1.843464\n",
       "am_private_entrance                1.054086\n",
       "wk_mth_discount                    1.035193\n",
       "host_is_superhost                  0.970918\n",
       "zipcode_zip_10119                  0.968911\n",
       "am_balcony                         0.927600\n",
       "zipcode_zip_10117                  0.810333\n",
       "instant_bookable                   0.775005\n",
       "room_type_Hotel room               0.738694\n",
       "am_essentials                      0.716376\n",
       "cancellation_policy_super_strict   0.675913\n",
       "cancellation_policy_strict         0.631558\n",
       "am_smoking_allowed                 0.538730\n",
       "am_child_friendly                  0.519459\n",
       "am_breakfast                       0.498101\n",
       "am_pets_allowed                    0.431015\n",
       "zipcode_zip_10997                  0.344243\n",
       "property_type_House                0.340723\n",
       "zipcode_zip_13359                  0.328963\n",
       "zipcode_zip_10405                  0.289884\n",
       "zipcode_zip_10245                  0.278008\n",
       "cancellation_policy_moderate       0.233898\n",
       "zipcode_zip_10178                  0.233727\n",
       "zipcode_zip_10999                  0.218410\n",
       "zipcode_zip_10435                  0.211992\n",
       "zipcode_zip_12047                  0.187463\n",
       "zipcode_zip_13407                  0.154474\n",
       "zipcode_zip_13353                  0.140717\n",
       "zipcode_zip_13189                  0.126197\n",
       "zipcode_zip_10179                  0.120847\n",
       "zipcode_zip_12051                  0.119306\n",
       "zipcode_zip_10965                  0.118093\n",
       "zipcode_zip_13347                  0.116328\n",
       "zipcode_zip_10967                  0.107761\n",
       "zipcode_zip_10719                  0.100954\n",
       "zipcode_zip_12347                  0.100599\n",
       "zipcode_zip_10437                  0.094665\n",
       "zipcode_zip_10317                  0.091500\n",
       "zipcode_zip_10247                  0.091167\n",
       "zipcode_zip_10439                  0.089923\n",
       "zipcode_zip_13086                  0.086492\n",
       "zipcode_zip_10249                  0.080119\n",
       "zipcode_zip_10715                  0.075084\n",
       "zipcode_zip_10315                  0.075073\n",
       "zipcode_zip_10365                  0.074603\n",
       "zipcode_zip_10589                  0.073532\n",
       "zipcode_zip_10785                  0.071981\n",
       "zipcode_zip_13357                  0.071616\n",
       "zipcode_zip_13187                  0.071107\n",
       "zipcode_zip_10587                  0.066921\n",
       "zipcode_zip_13409                  0.065310\n",
       "zipcode_zip_12435                  0.062919\n",
       "zipcode_zip_12157                  0.062446\n",
       "zipcode_zip_10969                  0.061377\n",
       "property_type_Secondary unit       0.059519\n",
       "zipcode_zip_10559                  0.059023\n",
       "zipcode_zip_14057                  0.056978\n",
       "zipcode_zip_12059                  0.056296\n",
       "zipcode_zip_10557                  0.056030\n",
       "zipcode_zip_13351                  0.055871\n",
       "zipcode_zip_12437                  0.053633\n",
       "zipcode_zip_12055                  0.045672\n",
       "zipcode_zip_12099                  0.045028\n",
       "zipcode_zip_10318                  0.042064\n",
       "zipcode_zip_nan                    0.040986\n",
       "zipcode_zip_10777                  0.040848\n",
       "zipcode_zip_10555                  0.040781\n",
       "zipcode_zip_13349                  0.038687\n",
       "zipcode_zip_12045                  0.037915\n",
       "zipcode_zip_10707                  0.037879\n",
       "zipcode_zip_12053                  0.037741\n",
       "zipcode_zip_10717                  0.035253\n",
       "zipcode_zip_10553                  0.032232\n",
       "zipcode_zip_12103                  0.031687\n",
       "zipcode_zip_10551                  0.031056\n",
       "zipcode_zip_10963                  0.030441\n",
       "zipcode_zip_10409                  0.029276\n",
       "zipcode_zip_14197                  0.027218\n",
       "zipcode_zip_13156                  0.027131\n",
       "zipcode_zip_10243                  0.027103\n",
       "property_type_Bed and breakfast    0.027102\n",
       "zipcode_zip_10407                  0.025937\n",
       "zipcode_zip_12101                  0.025857\n",
       "zipcode_zip_10827                  0.025049\n",
       "zipcode_zip_13088                  0.022766\n",
       "zipcode_zip_10961                  0.022285\n",
       "zipcode_zip_12163                  0.021708\n",
       "zipcode_zip_10367                  0.019044\n",
       "zipcode_zip_10627                  0.018193\n",
       "zipcode_zip_12049                  0.017672\n",
       "zipcode_zip_10585                  0.017054\n",
       "zipcode_zip_10625                  0.014615\n",
       "zipcode_zip_10781                  0.010777\n",
       "zipcode_zip_10829                  0.010418\n",
       "zipcode_zip_10629                  0.009799\n",
       "zipcode_zip_10713                  0.009230\n",
       "zipcode_zip_10787                  0.008717\n",
       "zipcode_zip_14059                  0.008382\n",
       "zipcode_zip_13355                  0.005083\n",
       "zipcode_zip_10623                  0.000000\n",
       "zipcode_zip_10711                  0.000000\n",
       "zipcode_zip_10783                  0.000000\n",
       "zipcode_zip_12161                  0.000000\n",
       "property_type_Unique space         0.000000\n",
       "zipcode_zip_10823                  0.000000\n",
       "zipcode_zip_12043                  0.000000"
      ]
     },
     "execution_count": 1176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature importances\n",
    "fi_cat_reg = get_feat_importances(best_model_cat_reg)\n",
    "fi_cat_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Load existing model\n",
    "#load_best_model = load_model(title=\"best_model_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)\n",
    "#load_best_cv = load_model(title=\"best_cv_xgb_reg\", dataset_loc=dataset_loc, dataset_date=dataset_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Curves (Overfitting)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_cat_reg = best_model_cat_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10\n",
      "RMSE: 0.32\n",
      "MAE: 0.25\n",
      "R2: 0.69\n",
      "MAPE: 6.32\n",
      "MAPE median: 4.97\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_train, y_train_pred_cat_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_test_pred_cat_reg = best_model_cat_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.14\n",
      "RMSE: 0.37\n",
      "MAE: 0.28\n",
      "R2: 0.58\n",
      "MAPE: 7.22\n",
      "MAPE median: 5.37\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "model_eval(y_test, y_test_pred_cat_reg, model=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35436153, 0.38434794])"
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_test_pred_cat_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Median Price Intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Save MAPE_median as variable\n",
    "MAPE_median_cat_reg = (median_absolute_percentage_error(y_test, y_test_pred_cat_reg))/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49.95, 77.88),\n",
       " (65.1, 104.61),\n",
       " (50.01, 77.99),\n",
       " (33.39, 49.74),\n",
       " (38.42, 58.14),\n",
       " (26.71, 38.78),\n",
       " (48.31, 75.04),\n",
       " (36.5, 54.93),\n",
       " (52.5, 82.33),\n",
       " (43.32, 66.47),\n",
       " (25.34, 36.59),\n",
       " (29.22, 42.87),\n",
       " (60.0, 95.52),\n",
       " (24.12, 34.63),\n",
       " (37.14, 56.0),\n",
       " (81.05, 133.53),\n",
       " (73.21, 119.22),\n",
       " (60.97, 97.25),\n",
       " (52.19, 81.79),\n",
       " (50.01, 77.99),\n",
       " (104.87, 177.9),\n",
       " (47.01, 72.81),\n",
       " (41.61, 63.55),\n",
       " (85.46, 141.63),\n",
       " (24.46, 35.18),\n",
       " (56.82, 89.91),\n",
       " (78.53, 128.91),\n",
       " (32.36, 48.03),\n",
       " (24.59, 35.38),\n",
       " (46.2, 71.4),\n",
       " (26.73, 38.82),\n",
       " (67.16, 108.3),\n",
       " (55.56, 87.69),\n",
       " (29.3, 43.0),\n",
       " (40.77, 62.12),\n",
       " (53.14, 83.45),\n",
       " (36.3, 54.59),\n",
       " (53.03, 83.26),\n",
       " (30.91, 45.64),\n",
       " (29.46, 43.27),\n",
       " (31.3, 46.28),\n",
       " (25.93, 37.54),\n",
       " (40.23, 61.21),\n",
       " (30.05, 44.22),\n",
       " (30.17, 44.42),\n",
       " (41.98, 64.19),\n",
       " (45.59, 70.35),\n",
       " (73.79, 120.28),\n",
       " (65.13, 104.67),\n",
       " (100.08, 168.88),\n",
       " (37.05, 55.84),\n",
       " (78.74, 129.29),\n",
       " (52.04, 81.52),\n",
       " (48.8, 75.89),\n",
       " (36.4, 54.75),\n",
       " (47.73, 74.05),\n",
       " (67.2, 108.37),\n",
       " (34.32, 51.29),\n",
       " (64.69, 103.88),\n",
       " (33.1, 49.26),\n",
       " (59.64, 94.89),\n",
       " (56.18, 88.78),\n",
       " (55.62, 87.79),\n",
       " (44.32, 68.18),\n",
       " (49.57, 77.22),\n",
       " (48.29, 75.01),\n",
       " (24.94, 35.94),\n",
       " (30.13, 44.37),\n",
       " (47.59, 73.8),\n",
       " (40.86, 62.27),\n",
       " (48.05, 74.6),\n",
       " (89.29, 148.72),\n",
       " (37.82, 57.15),\n",
       " (60.51, 96.43),\n",
       " (185.25, 335.23),\n",
       " (47.94, 74.41),\n",
       " (17.72, 24.57),\n",
       " (56.45, 89.26),\n",
       " (34.98, 52.37),\n",
       " (30.0, 44.14),\n",
       " (23.88, 34.24),\n",
       " (22.62, 32.24),\n",
       " (33.59, 50.07),\n",
       " (22.16, 31.5),\n",
       " (58.88, 93.53),\n",
       " (59.18, 94.08),\n",
       " (41.79, 63.86),\n",
       " (76.25, 124.75),\n",
       " (38.71, 58.64),\n",
       " (62.78, 100.47),\n",
       " (62.45, 99.89),\n",
       " (48.03, 74.56),\n",
       " (40.39, 61.47),\n",
       " (142.52, 250.34),\n",
       " (55.73, 87.99),\n",
       " (36.27, 54.53),\n",
       " (126.96, 220.09),\n",
       " (61.14, 97.55),\n",
       " (28.11, 41.05),\n",
       " (23.54, 33.69),\n",
       " (32.05, 47.52),\n",
       " (45.3, 69.85),\n",
       " (28.44, 41.6),\n",
       " (44.0, 67.62),\n",
       " (29.67, 43.61),\n",
       " (59.44, 94.54),\n",
       " (27.18, 39.55),\n",
       " (41.9, 64.05),\n",
       " (38.4, 58.12),\n",
       " (50.94, 79.61),\n",
       " (33.86, 50.52),\n",
       " (23.58, 33.76),\n",
       " (74.49, 121.55),\n",
       " (27.0, 39.25),\n",
       " (84.48, 139.83),\n",
       " (61.84, 98.8),\n",
       " (42.17, 64.5),\n",
       " (85.43, 141.58),\n",
       " (45.55, 70.29),\n",
       " (33.56, 50.02),\n",
       " (24.49, 35.21),\n",
       " (51.88, 81.25),\n",
       " (32.46, 48.2),\n",
       " (43.2, 66.25),\n",
       " (32.34, 48.0),\n",
       " (70.42, 114.18),\n",
       " (35.76, 53.68),\n",
       " (56.24, 88.89),\n",
       " (34.13, 50.96),\n",
       " (27.95, 40.79),\n",
       " (95.96, 161.15),\n",
       " (21.81, 30.96),\n",
       " (31.69, 46.92),\n",
       " (22.53, 32.09),\n",
       " (37.99, 57.43),\n",
       " (32.97, 49.04),\n",
       " (30.0, 44.14),\n",
       " (43.8, 67.29),\n",
       " (110.73, 189.0),\n",
       " (122.25, 211.02),\n",
       " (32.04, 47.5),\n",
       " (41.23, 62.9),\n",
       " (45.65, 70.46),\n",
       " (27.73, 40.45),\n",
       " (48.05, 74.59),\n",
       " (76.46, 125.14),\n",
       " (47.71, 74.0),\n",
       " (34.81, 52.1),\n",
       " (57.72, 91.49),\n",
       " (73.36, 119.5),\n",
       " (89.42, 148.97),\n",
       " (52.89, 83.01),\n",
       " (64.47, 103.48),\n",
       " (24.47, 35.19),\n",
       " (84.76, 140.34),\n",
       " (100.08, 168.88),\n",
       " (22.26, 31.66),\n",
       " (48.76, 75.82),\n",
       " (31.07, 45.91),\n",
       " (88.79, 147.8),\n",
       " (25.94, 37.55),\n",
       " (31.79, 47.09),\n",
       " (53.18, 83.52),\n",
       " (50.98, 79.67),\n",
       " (42.27, 64.68),\n",
       " (98.85, 166.57),\n",
       " (42.84, 65.65),\n",
       " (28.45, 41.61),\n",
       " (24.79, 35.7),\n",
       " (28.43, 41.59),\n",
       " (58.77, 93.34),\n",
       " (136.25, 238.1),\n",
       " (40.84, 62.25),\n",
       " (42.61, 65.25),\n",
       " (29.89, 43.96),\n",
       " (71.83, 116.73),\n",
       " (29.06, 42.6),\n",
       " (51.42, 80.44),\n",
       " (29.54, 43.39),\n",
       " (36.29, 54.58),\n",
       " (52.47, 82.28),\n",
       " (64.9, 104.26),\n",
       " (55.12, 86.92),\n",
       " (49.66, 77.38),\n",
       " (29.94, 44.05),\n",
       " (62.23, 99.48),\n",
       " (43.67, 67.05),\n",
       " (83.44, 137.91),\n",
       " (53.17, 83.5),\n",
       " (50.07, 78.1),\n",
       " (64.53, 103.6),\n",
       " (25.74, 37.23),\n",
       " (82.5, 136.18),\n",
       " (71.2, 115.59),\n",
       " (54.49, 85.82),\n",
       " (63.36, 101.5),\n",
       " (93.12, 155.84),\n",
       " (31.75, 47.02),\n",
       " (61.44, 98.08),\n",
       " (24.96, 35.98),\n",
       " (49.47, 77.05),\n",
       " (34.73, 51.96),\n",
       " (99.4, 167.6),\n",
       " (45.26, 69.79),\n",
       " (51.97, 81.41),\n",
       " (44.24, 68.03),\n",
       " (61.25, 97.74),\n",
       " (96.78, 162.69),\n",
       " (52.08, 81.59),\n",
       " (33.2, 49.42),\n",
       " (142.1, 249.52),\n",
       " (28.91, 42.36),\n",
       " (33.23, 49.47),\n",
       " (93.48, 156.51),\n",
       " (27.2, 39.58),\n",
       " (48.75, 75.81),\n",
       " (27.4, 39.91),\n",
       " (47.81, 74.19),\n",
       " (45.25, 69.78),\n",
       " (66.1, 106.39),\n",
       " (106.37, 180.73),\n",
       " (22.44, 31.95),\n",
       " (56.85, 89.96),\n",
       " (26.03, 37.7),\n",
       " (80.76, 132.99),\n",
       " (31.94, 47.33),\n",
       " (16.46, 22.62),\n",
       " (27.24, 39.65),\n",
       " (65.1, 104.6),\n",
       " (74.46, 121.49),\n",
       " (56.7, 89.69),\n",
       " (73.3, 119.39),\n",
       " (47.93, 74.39),\n",
       " (36.74, 55.33),\n",
       " (39.47, 59.93),\n",
       " (44.25, 68.06),\n",
       " (54.02, 84.98),\n",
       " (73.65, 120.02),\n",
       " (48.89, 76.06),\n",
       " (42.43, 64.94),\n",
       " (59.23, 94.17),\n",
       " (61.04, 97.38),\n",
       " (57.49, 91.09),\n",
       " (106.53, 181.04),\n",
       " (34.48, 51.55),\n",
       " (30.73, 45.35),\n",
       " (30.84, 45.52),\n",
       " (47.91, 74.34),\n",
       " (49.41, 76.94),\n",
       " (45.07, 69.47),\n",
       " (36.7, 55.26),\n",
       " (59.01, 93.76),\n",
       " (53.86, 84.7),\n",
       " (75.07, 122.6),\n",
       " (51.29, 80.21),\n",
       " (48.65, 75.64),\n",
       " (59.25, 94.2),\n",
       " (42.17, 64.51),\n",
       " (30.39, 44.78),\n",
       " (31.15, 46.04),\n",
       " (28.85, 42.27),\n",
       " (33.02, 49.12),\n",
       " (46.42, 71.79),\n",
       " (31.77, 47.05),\n",
       " (42.13, 64.43),\n",
       " (18.93, 26.44),\n",
       " (52.85, 82.95),\n",
       " (32.87, 48.87),\n",
       " (71.73, 116.55),\n",
       " (39.73, 60.37),\n",
       " (24.09, 34.57),\n",
       " (47.39, 73.46),\n",
       " (47.92, 74.37),\n",
       " (64.61, 103.73),\n",
       " (104.73, 177.63),\n",
       " (78.88, 129.54),\n",
       " (86.66, 143.86),\n",
       " (40.15, 61.08),\n",
       " (52.92, 83.06),\n",
       " (50.51, 78.86),\n",
       " (23.53, 33.69),\n",
       " (60.27, 96.0),\n",
       " (38.71, 58.63),\n",
       " (112.9, 193.14),\n",
       " (60.54, 96.49),\n",
       " (43.68, 67.08),\n",
       " (30.87, 45.58),\n",
       " (26.95, 39.17),\n",
       " (54.93, 86.58),\n",
       " (56.82, 89.9),\n",
       " (31.6, 46.77),\n",
       " (64.29, 103.16),\n",
       " (99.91, 168.55),\n",
       " (43.55, 66.86),\n",
       " (95.73, 160.72),\n",
       " (24.76, 35.65),\n",
       " (32.42, 48.13),\n",
       " (49.32, 76.79),\n",
       " (25.39, 36.67),\n",
       " (53.26, 83.66),\n",
       " (28.47, 41.65),\n",
       " (54.31, 85.5),\n",
       " (31.82, 47.14),\n",
       " (39.47, 59.92),\n",
       " (57.12, 90.43),\n",
       " (30.36, 44.74),\n",
       " (64.13, 102.88),\n",
       " (56.72, 89.73),\n",
       " (56.02, 88.5),\n",
       " (66.34, 106.83),\n",
       " (82.9, 136.93),\n",
       " (43.9, 67.45),\n",
       " (85.68, 142.04),\n",
       " (66.86, 107.77),\n",
       " (94.1, 157.67),\n",
       " (32.14, 47.67),\n",
       " (24.48, 35.2),\n",
       " (27.0, 39.26),\n",
       " (49.1, 76.41),\n",
       " (67.5, 108.91),\n",
       " (41.1, 62.68),\n",
       " (65.55, 105.41),\n",
       " (64.83, 104.13),\n",
       " (29.66, 43.59),\n",
       " (120.88, 208.39),\n",
       " (38.18, 57.75),\n",
       " (48.36, 75.14),\n",
       " (58.41, 92.7),\n",
       " (24.11, 34.61),\n",
       " (51.3, 80.24),\n",
       " (72.02, 117.07),\n",
       " (44.88, 69.13),\n",
       " (25.62, 37.03),\n",
       " (65.44, 105.22),\n",
       " (67.04, 108.09),\n",
       " (30.93, 45.68),\n",
       " (28.47, 41.65),\n",
       " (46.84, 72.5),\n",
       " (30.69, 45.28),\n",
       " (49.1, 76.41),\n",
       " (39.79, 60.47),\n",
       " (135.27, 236.19),\n",
       " (27.91, 40.74),\n",
       " (25.58, 36.97),\n",
       " (52.12, 81.66),\n",
       " (30.91, 45.65),\n",
       " (27.36, 39.85),\n",
       " (50.48, 78.81),\n",
       " (53.37, 83.85),\n",
       " (87.11, 144.68),\n",
       " (73.16, 119.13),\n",
       " (50.02, 78.01),\n",
       " (24.04, 34.5),\n",
       " (88.78, 147.78),\n",
       " (21.87, 31.05),\n",
       " (25.78, 37.3),\n",
       " (48.1, 74.68),\n",
       " (54.45, 85.73),\n",
       " (81.8, 134.9),\n",
       " (30.51, 44.98),\n",
       " (30.66, 45.23),\n",
       " (33.99, 50.74),\n",
       " (32.95, 49.01),\n",
       " (32.46, 48.19),\n",
       " (54.0, 84.95),\n",
       " (39.8, 60.47),\n",
       " (56.38, 89.14),\n",
       " (34.74, 51.99),\n",
       " (58.63, 93.11),\n",
       " (56.08, 88.6),\n",
       " (33.9, 50.59),\n",
       " (24.49, 35.22),\n",
       " (44.69, 68.8),\n",
       " (73.12, 119.05),\n",
       " (23.36, 33.41),\n",
       " (38.97, 59.07),\n",
       " (66.82, 107.69),\n",
       " (30.19, 44.46),\n",
       " (40.91, 62.37),\n",
       " (27.93, 40.77),\n",
       " (59.96, 95.46),\n",
       " (70.67, 114.63),\n",
       " (112.74, 192.83),\n",
       " (34.0, 50.75),\n",
       " (30.51, 44.98),\n",
       " (49.1, 76.4),\n",
       " (63.02, 100.89),\n",
       " (29.49, 43.31),\n",
       " (26.71, 38.79),\n",
       " (60.51, 96.42),\n",
       " (92.5, 154.7),\n",
       " (57.09, 90.39),\n",
       " (31.07, 45.9),\n",
       " (31.62, 46.81),\n",
       " (32.01, 47.46),\n",
       " (90.08, 150.18),\n",
       " (47.5, 73.65),\n",
       " (66.07, 106.35),\n",
       " (56.65, 89.6),\n",
       " (25.81, 37.33),\n",
       " (29.56, 43.43),\n",
       " (69.41, 112.36),\n",
       " (22.41, 31.91),\n",
       " (49.88, 77.77),\n",
       " (39.61, 60.16),\n",
       " (29.43, 43.21),\n",
       " (49.55, 77.2),\n",
       " (37.25, 56.17),\n",
       " (28.36, 41.47),\n",
       " (33.73, 50.3),\n",
       " (34.33, 51.29),\n",
       " (66.97, 107.97),\n",
       " (78.23, 128.35),\n",
       " (69.39, 112.32),\n",
       " (26.92, 39.12),\n",
       " (52.16, 81.73),\n",
       " (21.67, 30.73),\n",
       " (56.58, 89.48),\n",
       " (46.24, 71.47),\n",
       " (101.31, 171.18),\n",
       " (33.79, 50.41),\n",
       " (21.09, 29.82),\n",
       " (29.36, 43.09),\n",
       " (56.12, 88.67),\n",
       " (39.13, 59.35),\n",
       " (45.12, 69.54),\n",
       " (39.87, 60.61),\n",
       " (68.95, 111.52),\n",
       " (32.67, 48.54),\n",
       " (48.98, 76.21),\n",
       " (48.37, 75.15),\n",
       " (54.25, 85.39),\n",
       " (46.42, 71.78),\n",
       " (32.7, 48.59),\n",
       " (52.94, 83.1),\n",
       " (28.15, 41.13),\n",
       " (25.68, 37.12),\n",
       " (41.27, 62.98),\n",
       " (25.77, 37.28),\n",
       " (92.2, 154.13),\n",
       " (57.54, 91.18),\n",
       " (47.75, 74.08),\n",
       " (27.72, 40.43),\n",
       " (66.56, 107.23),\n",
       " (44.1, 67.8),\n",
       " (18.86, 26.33),\n",
       " (86.87, 144.24),\n",
       " (25.62, 37.03),\n",
       " (26.43, 38.34),\n",
       " (45.38, 69.99),\n",
       " (60.04, 95.6),\n",
       " (45.17, 69.63),\n",
       " (47.54, 73.71),\n",
       " (33.27, 49.54),\n",
       " (32.71, 48.61),\n",
       " (113.68, 194.62),\n",
       " (72.05, 117.12),\n",
       " (61.55, 98.28),\n",
       " (44.82, 69.04),\n",
       " (51.67, 80.89),\n",
       " (29.97, 44.1),\n",
       " (33.15, 49.33),\n",
       " (49.97, 77.92),\n",
       " (73.72, 120.14),\n",
       " (63.65, 102.01),\n",
       " (21.12, 29.87),\n",
       " (34.24, 51.15),\n",
       " (81.86, 135.02),\n",
       " (26.07, 37.75),\n",
       " (21.05, 29.75),\n",
       " (32.1, 47.6),\n",
       " (52.7, 82.68),\n",
       " (56.44, 89.23),\n",
       " (69.5, 112.51),\n",
       " (43.03, 65.98),\n",
       " (28.77, 42.14),\n",
       " (106.5, 180.98),\n",
       " (26.01, 37.67),\n",
       " (35.84, 53.82),\n",
       " (21.58, 30.6),\n",
       " (38.64, 58.52),\n",
       " (55.54, 87.65),\n",
       " (71.11, 115.42),\n",
       " (37.44, 56.5),\n",
       " (29.13, 42.72),\n",
       " (50.51, 78.86),\n",
       " (25.93, 37.53),\n",
       " (33.66, 50.19),\n",
       " (135.24, 236.13),\n",
       " (51.31, 80.26),\n",
       " (32.65, 48.51),\n",
       " (27.93, 40.77),\n",
       " (28.49, 41.67),\n",
       " (95.62, 160.51),\n",
       " (33.73, 50.3),\n",
       " (28.66, 41.95),\n",
       " (45.58, 70.35),\n",
       " (38.46, 58.22),\n",
       " (53.41, 83.92),\n",
       " (70.0, 113.41),\n",
       " (59.5, 94.63),\n",
       " (90.95, 151.8),\n",
       " (41.71, 63.73),\n",
       " (28.38, 41.5),\n",
       " (23.33, 33.37),\n",
       " (29.43, 43.22),\n",
       " (67.18, 108.34),\n",
       " (54.14, 85.2),\n",
       " (47.49, 73.62),\n",
       " (73.24, 119.28),\n",
       " (27.65, 40.32),\n",
       " (58.78, 93.37),\n",
       " (33.58, 50.05),\n",
       " (55.1, 86.89),\n",
       " (29.96, 44.09),\n",
       " (35.4, 53.09),\n",
       " (82.86, 136.85),\n",
       " (22.27, 31.68),\n",
       " (27.94, 40.78),\n",
       " (31.28, 46.25),\n",
       " (75.03, 122.52),\n",
       " (29.6, 43.49),\n",
       " (56.19, 88.79),\n",
       " (53.31, 83.74),\n",
       " (28.92, 42.38),\n",
       " (61.81, 98.74),\n",
       " (25.02, 36.07),\n",
       " (62.49, 99.95),\n",
       " (62.47, 99.92),\n",
       " (68.93, 111.49),\n",
       " (22.98, 32.8),\n",
       " (48.12, 74.71),\n",
       " (32.49, 48.24),\n",
       " (99.62, 168.01),\n",
       " (25.34, 36.57),\n",
       " (29.52, 43.36),\n",
       " (52.6, 82.5),\n",
       " (39.22, 59.5),\n",
       " (30.48, 44.94),\n",
       " (33.97, 50.7),\n",
       " (82.81, 136.76),\n",
       " (49.39, 76.91),\n",
       " (100.08, 168.88),\n",
       " (61.5, 98.19),\n",
       " (22.28, 31.7),\n",
       " (39.11, 59.32),\n",
       " (49.79, 77.6),\n",
       " (41.06, 62.61),\n",
       " (40.25, 61.24),\n",
       " (43.42, 66.63),\n",
       " (27.74, 40.46),\n",
       " (29.23, 42.88),\n",
       " (40.39, 61.48),\n",
       " (40.63, 61.88),\n",
       " (26.71, 38.79),\n",
       " (152.38, 269.7),\n",
       " (41.02, 62.55),\n",
       " (50.58, 78.98),\n",
       " (47.83, 74.22),\n",
       " (25.78, 37.29),\n",
       " (50.51, 78.87),\n",
       " (36.28, 54.55),\n",
       " (22.83, 32.57),\n",
       " (78.44, 128.75),\n",
       " (77.06, 126.22),\n",
       " (39.12, 59.32),\n",
       " (51.94, 81.35),\n",
       " (47.76, 74.1),\n",
       " (51.05, 79.79),\n",
       " (33.51, 49.93),\n",
       " (53.13, 83.43),\n",
       " (51.41, 80.43),\n",
       " (34.96, 52.35),\n",
       " (39.57, 60.09),\n",
       " (51.46, 80.51),\n",
       " (55.88, 88.26),\n",
       " (23.99, 34.42),\n",
       " (20.46, 28.83),\n",
       " (38.46, 58.22),\n",
       " (30.79, 45.44),\n",
       " (64.99, 104.42),\n",
       " (46.08, 71.2),\n",
       " (57.81, 91.64),\n",
       " (44.09, 67.78),\n",
       " (63.9, 102.47),\n",
       " (47.03, 72.83),\n",
       " (87.32, 145.07),\n",
       " (48.73, 75.77),\n",
       " (51.12, 79.93),\n",
       " (52.13, 81.69),\n",
       " (34.9, 52.25),\n",
       " (51.98, 81.42),\n",
       " (37.27, 56.21),\n",
       " (27.64, 40.29),\n",
       " (55.59, 87.74),\n",
       " (66.71, 107.5),\n",
       " (31.83, 47.16),\n",
       " (50.91, 79.55),\n",
       " (27.04, 39.32),\n",
       " (29.16, 42.77),\n",
       " (54.94, 86.6),\n",
       " (37.39, 56.42),\n",
       " (34.42, 51.45),\n",
       " (48.86, 76.0),\n",
       " (32.22, 47.81),\n",
       " (69.5, 112.52),\n",
       " (45.99, 71.04),\n",
       " (26.15, 37.88),\n",
       " (48.1, 74.68),\n",
       " (58.52, 92.9),\n",
       " (39.28, 59.59),\n",
       " (53.53, 84.13),\n",
       " (55.22, 87.08),\n",
       " (63.3, 101.39),\n",
       " (47.34, 73.36),\n",
       " (30.35, 44.72),\n",
       " (19.98, 28.08),\n",
       " (58.82, 93.44),\n",
       " (56.07, 88.59),\n",
       " (18.68, 26.04),\n",
       " (71.53, 116.18),\n",
       " (37.91, 57.28),\n",
       " (65.44, 105.22),\n",
       " (31.33, 46.33),\n",
       " (39.21, 59.48),\n",
       " (46.31, 71.58),\n",
       " (41.79, 63.86),\n",
       " (28.43, 41.59),\n",
       " (25.65, 37.08),\n",
       " (32.42, 48.12),\n",
       " (62.65, 100.24),\n",
       " (37.19, 56.08),\n",
       " (37.62, 56.79),\n",
       " (28.0, 40.89),\n",
       " (41.92, 64.08),\n",
       " (75.21, 122.85),\n",
       " (94.15, 157.77),\n",
       " (48.91, 76.08),\n",
       " (36.9, 55.6),\n",
       " (30.03, 44.19),\n",
       " (32.04, 47.49),\n",
       " (49.17, 76.53),\n",
       " (49.3, 76.76),\n",
       " (37.24, 56.17),\n",
       " (27.57, 40.18),\n",
       " (48.36, 75.14),\n",
       " (43.07, 66.03),\n",
       " (63.73, 102.16),\n",
       " (37.97, 57.4),\n",
       " (32.61, 48.45),\n",
       " (29.9, 43.98),\n",
       " (50.2, 78.32),\n",
       " (35.14, 52.65),\n",
       " (45.6, 70.37),\n",
       " (61.97, 99.03),\n",
       " (89.92, 149.88),\n",
       " (25.52, 36.87),\n",
       " (22.59, 32.19),\n",
       " (33.25, 49.5),\n",
       " (53.34, 83.79),\n",
       " (22.47, 31.99),\n",
       " (52.85, 82.93),\n",
       " (27.56, 40.17),\n",
       " (42.12, 64.42),\n",
       " (33.1, 49.26),\n",
       " (77.59, 127.2),\n",
       " (30.79, 45.44),\n",
       " (51.16, 79.99),\n",
       " (28.27, 41.32),\n",
       " (30.29, 44.62),\n",
       " (50.77, 79.32),\n",
       " (56.94, 90.12),\n",
       " (104.57, 177.33),\n",
       " (149.01, 263.07),\n",
       " (30.52, 44.99),\n",
       " (48.94, 76.13),\n",
       " (33.16, 49.35),\n",
       " (32.22, 47.81),\n",
       " (82.44, 136.08),\n",
       " (26.93, 39.14),\n",
       " (59.66, 94.92),\n",
       " (61.84, 98.79),\n",
       " (33.05, 49.17),\n",
       " (23.68, 33.93),\n",
       " (31.04, 45.85),\n",
       " (32.21, 47.78),\n",
       " (21.92, 31.13),\n",
       " (56.91, 90.06),\n",
       " (35.0, 52.41),\n",
       " (35.82, 53.78),\n",
       " (33.43, 49.81),\n",
       " (30.66, 45.22),\n",
       " (40.24, 61.22),\n",
       " (36.32, 54.63),\n",
       " (29.73, 43.71),\n",
       " (49.49, 77.09),\n",
       " (32.18, 47.73),\n",
       " (49.59, 77.27),\n",
       " (33.32, 49.61),\n",
       " (24.76, 35.65),\n",
       " (37.82, 57.14),\n",
       " (52.64, 82.57),\n",
       " (43.41, 66.63),\n",
       " (66.77, 107.61),\n",
       " (59.85, 95.26),\n",
       " (29.81, 43.83),\n",
       " (29.32, 43.03),\n",
       " (53.68, 84.4),\n",
       " (47.93, 74.38),\n",
       " (33.86, 50.52),\n",
       " (34.46, 51.52),\n",
       " (49.18, 76.55),\n",
       " (73.62, 119.96),\n",
       " (67.68, 109.25),\n",
       " (32.61, 48.45),\n",
       " (51.24, 80.14),\n",
       " (23.92, 34.31),\n",
       " (26.38, 38.25),\n",
       " (35.38, 53.05),\n",
       " (28.55, 41.78),\n",
       " (49.25, 76.66),\n",
       " (66.96, 107.95),\n",
       " (93.75, 157.02),\n",
       " (56.63, 89.57),\n",
       " (45.02, 69.38),\n",
       " (50.58, 78.98),\n",
       " (57.12, 90.43),\n",
       " (48.89, 76.05),\n",
       " (29.73, 43.7),\n",
       " (35.36, 53.01),\n",
       " (127.4, 220.95),\n",
       " (41.7, 63.7),\n",
       " (32.02, 47.46),\n",
       " (56.98, 90.18),\n",
       " (15.57, 21.26),\n",
       " (31.63, 46.83),\n",
       " (82.9, 136.93),\n",
       " (60.13, 95.76),\n",
       " (60.39, 96.21),\n",
       " (26.82, 38.97),\n",
       " (36.24, 54.49),\n",
       " (22.55, 32.12),\n",
       " (31.09, 45.94),\n",
       " (82.74, 136.62),\n",
       " (109.38, 186.43),\n",
       " (22.28, 31.7),\n",
       " (30.1, 44.31),\n",
       " (34.73, 51.96),\n",
       " (40.94, 62.41),\n",
       " (39.08, 59.26),\n",
       " (69.86, 113.16),\n",
       " (46.92, 72.64),\n",
       " (31.51, 46.63),\n",
       " (33.72, 50.29),\n",
       " (121.62, 209.82),\n",
       " (101.13, 170.84),\n",
       " (76.49, 125.18),\n",
       " (61.8, 98.72),\n",
       " (24.12, 34.63),\n",
       " (36.09, 54.24),\n",
       " (41.36, 63.13),\n",
       " (34.75, 52.0),\n",
       " (48.64, 75.61),\n",
       " (31.63, 46.82),\n",
       " (71.33, 115.82),\n",
       " (50.97, 79.66),\n",
       " (53.6, 84.26),\n",
       " (46.21, 71.43),\n",
       " (52.91, 83.05),\n",
       " (26.55, 38.54),\n",
       " (67.79, 109.44),\n",
       " (35.11, 52.6),\n",
       " (39.32, 59.67),\n",
       " (35.77, 53.7),\n",
       " (29.2, 42.83),\n",
       " (31.3, 46.29),\n",
       " (73.74, 120.19),\n",
       " (19.87, 27.9),\n",
       " (31.67, 46.89),\n",
       " (29.12, 42.7),\n",
       " (50.49, 78.82),\n",
       " (27.22, 39.62),\n",
       " (32.49, 48.24),\n",
       " (82.07, 135.39),\n",
       " (45.93, 70.93),\n",
       " (70.63, 114.56),\n",
       " (44.56, 68.59),\n",
       " (32.28, 47.89),\n",
       " (45.22, 69.73),\n",
       " (61.19, 97.64),\n",
       " (26.08, 37.78),\n",
       " (58.32, 92.55),\n",
       " (51.77, 81.05),\n",
       " (63.18, 101.17),\n",
       " (26.94, 39.16),\n",
       " (46.74, 72.33),\n",
       " (30.79, 45.45),\n",
       " (29.37, 43.11),\n",
       " (30.42, 44.84),\n",
       " (67.01, 108.03),\n",
       " (55.01, 86.73),\n",
       " (28.89, 42.33),\n",
       " (27.62, 40.27),\n",
       " (40.54, 61.73),\n",
       " (28.12, 41.08),\n",
       " (40.48, 61.63),\n",
       " (23.35, 33.4),\n",
       " (45.53, 70.25),\n",
       " (44.59, 68.64),\n",
       " (30.92, 45.66),\n",
       " (44.91, 69.18),\n",
       " (86.33, 143.25),\n",
       " (48.34, 75.1),\n",
       " (25.65, 37.08),\n",
       " (41.32, 63.05),\n",
       " (35.2, 52.74),\n",
       " (41.42, 63.22),\n",
       " (55.66, 87.86),\n",
       " (33.87, 50.53),\n",
       " (46.8, 72.44),\n",
       " (73.29, 119.37),\n",
       " (22.13, 31.46),\n",
       " (24.35, 34.99),\n",
       " (64.8, 104.08),\n",
       " (81.52, 134.39),\n",
       " (77.25, 126.57),\n",
       " (53.2, 83.55),\n",
       " (51.12, 79.92),\n",
       " (55.06, 86.81),\n",
       " (56.35, 89.08),\n",
       " (35.89, 53.89),\n",
       " (56.67, 89.63),\n",
       " (49.23, 76.64),\n",
       " (39.68, 60.28),\n",
       " (27.26, 39.68),\n",
       " (55.04, 86.77),\n",
       " (99.83, 168.39),\n",
       " (37.65, 56.86),\n",
       " (33.9, 50.59),\n",
       " (61.83, 98.77),\n",
       " (34.92, 52.28),\n",
       " (27.48, 40.04),\n",
       " (36.19, 54.4),\n",
       " (53.46, 84.01),\n",
       " (28.58, 41.82),\n",
       " (46.79, 72.42),\n",
       " (21.16, 29.93),\n",
       " (58.39, 92.67),\n",
       " (47.84, 74.23),\n",
       " (59.39, 94.44),\n",
       " (64.35, 103.27),\n",
       " (49.68, 77.41),\n",
       " (52.92, 83.06),\n",
       " (28.18, 41.18),\n",
       " (30.11, 44.33),\n",
       " (31.91, 47.29),\n",
       " (74.45, 121.47),\n",
       " (32.84, 48.83),\n",
       " (71.28, 115.73),\n",
       " (33.01, 49.11),\n",
       " (53.53, 84.13),\n",
       " (49.24, 76.65),\n",
       " (45.69, 70.53),\n",
       " (21.1, 29.84),\n",
       " (60.4, 96.24),\n",
       " (54.03, 85.0),\n",
       " (28.08, 41.01),\n",
       " (23.91, 34.29),\n",
       " (28.77, 42.14),\n",
       " (46.24, 71.47),\n",
       " (70.02, 113.45),\n",
       " (52.27, 81.93),\n",
       " (71.38, 115.91),\n",
       " (70.82, 114.89),\n",
       " (28.23, 41.25),\n",
       " (26.13, 37.85),\n",
       " (66.96, 107.94),\n",
       " (33.4, 49.76),\n",
       " (35.33, 52.96),\n",
       " (18.61, 25.94),\n",
       " (67.1, 108.19),\n",
       " (31.37, 46.4),\n",
       " (64.1, 102.82),\n",
       " (49.05, 76.33),\n",
       " (137.29, 240.14),\n",
       " (36.31, 54.6),\n",
       " (57.79, 91.61),\n",
       " (52.13, 81.67),\n",
       " (26.79, 38.92),\n",
       " (41.33, 63.08),\n",
       " (60.87, 97.08),\n",
       " (73.04, 118.91),\n",
       " (27.26, 39.68),\n",
       " (46.37, 71.69),\n",
       " (35.52, 53.29),\n",
       " (26.87, 39.05),\n",
       " (56.1, 88.63),\n",
       " (54.93, 86.59),\n",
       " (30.94, 45.68),\n",
       " (46.58, 72.05),\n",
       " (78.31, 128.51),\n",
       " (29.15, 42.76),\n",
       " (23.81, 34.12),\n",
       " (29.38, 43.14),\n",
       " (58.25, 92.42),\n",
       " (72.05, 117.12),\n",
       " (31.03, 45.83),\n",
       " (79.18, 130.1),\n",
       " (69.91, 113.25),\n",
       " (21.36, 30.24),\n",
       " (31.17, 46.07),\n",
       " (36.93, 55.64),\n",
       " (64.12, 102.86),\n",
       " (112.42, 192.22),\n",
       " (49.97, 77.92),\n",
       " (53.83, 84.66),\n",
       " (28.49, 41.68),\n",
       " (34.76, 52.02),\n",
       " (59.13, 93.99),\n",
       " (23.11, 33.02),\n",
       " (29.5, 43.33),\n",
       " (24.3, 34.91),\n",
       " (32.83, 48.81),\n",
       " (24.45, 35.16),\n",
       " (68.8, 111.25),\n",
       " (70.17, 113.72),\n",
       " (76.1, 124.48),\n",
       " (56.38, 89.13),\n",
       " (51.52, 80.61),\n",
       " (71.38, 115.91),\n",
       " (44.54, 68.55),\n",
       " (24.7, 35.56),\n",
       " (138.3, 242.1),\n",
       " (24.85, 35.79),\n",
       " (38.8, 58.78),\n",
       " (27.26, 39.69),\n",
       " (72.53, 117.98),\n",
       " (32.98, 49.05),\n",
       " (71.36, 115.87),\n",
       " (25.69, 37.14),\n",
       " (63.67, 102.06),\n",
       " (124.16, 214.7),\n",
       " (43.22, 66.29),\n",
       " (49.1, 76.42),\n",
       " (27.47, 40.02),\n",
       " (43.85, 67.38),\n",
       " (70.3, 113.96),\n",
       " (29.22, 42.86),\n",
       " (60.51, 96.44),\n",
       " (67.31, 108.57),\n",
       " (27.16, 39.52),\n",
       " (22.86, 32.62),\n",
       " (23.92, 34.31),\n",
       " (30.55, 45.04),\n",
       " (27.41, 39.92),\n",
       " (81.96, 135.2),\n",
       " (39.2, 59.47),\n",
       " (33.01, 49.11),\n",
       " (61.66, 98.48),\n",
       " (39.07, 59.24),\n",
       " (58.89, 93.56),\n",
       " (27.37, 39.86),\n",
       " (27.9, 40.72),\n",
       " (72.16, 117.32),\n",
       " (30.03, 44.19),\n",
       " (33.98, 50.72),\n",
       " (32.09, 47.58),\n",
       " (58.7, 93.22),\n",
       " (17.47, 24.17),\n",
       " (69.01, 111.63),\n",
       " (34.65, 51.83),\n",
       " (48.02, 74.55),\n",
       " (21.86, 31.04),\n",
       " (58.42, 92.73),\n",
       " (24.91, 35.89),\n",
       " (63.41, 101.59),\n",
       " (26.76, 38.87),\n",
       " (20.88, 29.48),\n",
       " (37.58, 56.73),\n",
       " (30.3, 44.63),\n",
       " (25.55, 36.92),\n",
       " (58.8, 93.39),\n",
       " (46.23, 71.46),\n",
       " (38.62, 58.49),\n",
       " (36.78, 55.39),\n",
       " (42.84, 65.64),\n",
       " (43.39, 66.58),\n",
       " (31.24, 46.18),\n",
       " (42.21, 64.57),\n",
       " (49.91, 77.83),\n",
       " (73.02, 118.89),\n",
       " (28.77, 42.14),\n",
       " (39.03, 59.18),\n",
       " (53.28, 83.69),\n",
       " (126.77, 219.73),\n",
       " (50.32, 78.54),\n",
       " (113.92, 195.07),\n",
       " (39.37, 59.75),\n",
       " (50.1, 78.14),\n",
       " (33.51, 49.94),\n",
       " ...)"
      ]
     },
     "execution_count": 1186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate price interval for MAPE median\n",
    "y_pred_interval_cat_reg = tuple([(round(math.exp(el-el*MAPE_median_cat_reg),2),round(math.exp(el+el*MAPE_median_cat_reg),2)) for el in y_test_pred_cat_reg])\n",
    "y_pred_interval_cat_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model and Params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Save best model and cv\n",
    "save_model(best_model_cat_reg, title=\"best_model_cat_reg_01\", save=\"joblib\")\n",
    "save_model(grid_cat_reg, title=\"best_cv_cat_reg_01\", save=\"joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN Model 1: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model_nn_seq = models.Sequential()\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(128,\n",
    "                 input_shape=(X_train_prep.shape[1], ),\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(256,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(256,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(\n",
    "    layers.Dense(512,\n",
    "                 kernel_regularizer=regularizers.l1(0.005),\n",
    "                 activation='relu'))\n",
    "model_nn_seq.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model_nn_seq.compile(loss='mean_squared_error',\n",
    "                     optimizer='adam',\n",
    "                     metrics=['mean_squared_error'])\n",
    "\n",
    "# Model summary\n",
    "print(model_nn_seq.summary())\n",
    "\n",
    "# Visualize the neural network\n",
    "#SVG(model_to_dot(model_nn_seq, show_layer_names=False, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "#model_nn_seq_start = time.time()\n",
    "\n",
    "model_nn_seq_history = model_nn_seq.fit(X_train_prep,\n",
    "                                        y_train,\n",
    "                                        epochs=20,\n",
    "                                        batch_size=256,\n",
    "                                        validation_split=0.2)\n",
    "\n",
    "#model_nn_seq_end = time.time()\n",
    "\n",
    "#print(f\"Time taken to run: {round((model_nn_seq_end - model_nn_seq_start)/60,1)} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "#model_nn_seq_model_evaluation(model_nn_seq, skip_epochs=2, X_train=X_train, X_test=X_test)\n",
    "\n",
    "#score_nn_seq = model_nn_seq.evaluate(X_train_prep, y_train,verbose=1)\n",
    "#print(score_nn_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation with Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_reg = [best_model_xgb_reg, best_model_svm_reg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_test for final evaluation\n",
    "#X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "#y_pred_rf_reg = best_model_rf_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "#print(\"MSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"RMSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg, squared=False))),\n",
    "#print(\"MAE: {:.2f}\".format(mean_absolute_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"R2: {:.2f}\".format(r2_score(y_test, y_pred_rf_reg))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate best model\n",
    "#fig, axes = plt.subplots(1, 2, figsize = (14, 6))\n",
    "#axes = axes.flatten()\n",
    "\n",
    "#y_pred = best_model.predict(X_test_prep)\n",
    "#axes[0].scatter(y_test, y_pred)\n",
    "#axes[0].set_xlabel('y_test')\n",
    "#axes[0].set_ylabel('y_pred')\n",
    "\n",
    "#coef = best_model.best_estimator_.named_steps['xgb'].coef_\n",
    "#mean_coef = np.mean(coef)\n",
    "#axes[1].plot(coef, 'o')\n",
    "#axes[1].set_xlabel('coefficient index')\n",
    "#axes[1].set_ylabel('coefficient size')\n",
    "#axes[1].axhline(y = mean_coef, color = 'red', linestyle = '--', alpha = 0.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "#confidence = 0.95\n",
    "#squared_errors = (y_pred_rf_reg - y_test) ** 2\n",
    "#np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "#                         loc=squared_errors.mean(),\n",
    "#                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
