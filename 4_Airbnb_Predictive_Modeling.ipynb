{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "# For 1 | Preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline # Same, but with the latter it is not necessary to name estimator and transformer\n",
    "#from imblearn.pipeline import Pipeline as Imb_Pipe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# For 2 | Predictive Modeling: Classification (\"occupancy_class\")\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score, cross_validate, KFold\n",
    "from sklearn.metrics import r2_score, make_scorer, fbeta_score, accuracy_score, confusion_matrix, f1_score, precision_recall_curve, recall_score, precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# For 3 | Predictive Modeling: Regression (\"price\")\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import RANSACRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data_engineered\n",
    "data = pd.read_pickle(\"saves/data_engineered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Alternative: Import from csv\n",
    "#data_types_engineered = pd.read_csv('saves/types_engineered.csv')['types']\n",
    "#data = pd.read_csv(\"saves/data_engineered.csv\", dtype=data_types_engineered.to_dict())\n",
    "#data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard\n",
    "target = 'price'\n",
    "test_size = 0.3\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.zipcode = [str(i) for i in data.zipcode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (Train/Test Split and Pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancellation_policy', 'neighbourhood', 'room_type', 'zipcode']"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\") \n",
    "cat_features = list(data.columns[data.dtypes==object])\n",
    "#cat_features.remove(\"zipcode\")\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Removing all categorical columns\n",
    "#data.drop(cat_features, axis=1, inplace=True)\n",
    "#cat_features = list(data.columns[data.dtypes==object])\n",
    "#cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP: Removing all with price >$500\n",
    "data = data[data.price <= 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates',\n",
       " 'am_balcony',\n",
       " 'am_breakfast',\n",
       " 'am_child_friendly',\n",
       " 'am_coffee_machine',\n",
       " 'am_cooking_basics',\n",
       " 'am_elevator',\n",
       " 'am_essentials',\n",
       " 'am_nature_and_views',\n",
       " 'am_parking',\n",
       " 'am_pets_allowed',\n",
       " 'am_private_entrance',\n",
       " 'am_smoking_allowed',\n",
       " 'am_tv',\n",
       " 'am_white_goods',\n",
       " 'availability_365',\n",
       " 'bathrooms',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'calculated_host_listings_count',\n",
       " 'cleaning_fee',\n",
       " 'extra_people',\n",
       " 'guests_included',\n",
       " 'host_identity_verified',\n",
       " 'host_is_superhost',\n",
       " 'host_listings_count',\n",
       " 'house_rules',\n",
       " 'instant_bookable',\n",
       " 'is_location_exact',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'maximum_nights',\n",
       " 'minimum_nights',\n",
       " 'monthly_price',\n",
       " 'occupancy_class',\n",
       " 'occupancy_rate',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'security_deposit',\n",
       " 'space',\n",
       " 'weekly_price']"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "num_features = list(data.columns[data.dtypes!=object])\n",
    "num_features.remove(target)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Pipeline using Pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer_num', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24399, 50)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>am_balcony</th>\n",
       "      <th>am_breakfast</th>\n",
       "      <th>am_child_friendly</th>\n",
       "      <th>am_coffee_machine</th>\n",
       "      <th>am_cooking_basics</th>\n",
       "      <th>am_elevator</th>\n",
       "      <th>am_essentials</th>\n",
       "      <th>am_nature_and_views</th>\n",
       "      <th>am_parking</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_checkin</th>\n",
       "      <th>review_scores_cleanliness</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>room_type</th>\n",
       "      <th>security_deposit</th>\n",
       "      <th>space</th>\n",
       "      <th>weekly_price</th>\n",
       "      <th>zipcode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>zip_10405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3309</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>zip_10777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accommodates  am_balcony  am_breakfast  am_child_friendly  \\\n",
       "id                                                                \n",
       "3176             4         0.0           0.0                1.0   \n",
       "3309             1         0.0           0.0                0.0   \n",
       "\n",
       "      am_coffee_machine  am_cooking_basics  am_elevator  am_essentials  \\\n",
       "id                                                                       \n",
       "3176                0.0                0.0          0.0            1.0   \n",
       "3309                0.0                0.0          0.0            1.0   \n",
       "\n",
       "      am_nature_and_views  am_parking  ...  review_scores_checkin  \\\n",
       "id                                     ...                          \n",
       "3176                  0.0         0.0  ...                    9.0   \n",
       "3309                  0.0         1.0  ...                    9.0   \n",
       "\n",
       "      review_scores_cleanliness  review_scores_communication  \\\n",
       "id                                                             \n",
       "3176                        9.0                          9.0   \n",
       "3309                        9.0                         10.0   \n",
       "\n",
       "      review_scores_location  review_scores_value        room_type  \\\n",
       "id                                                                   \n",
       "3176                    10.0                  9.0  Entire home/apt   \n",
       "3309                     9.0                  9.0     Private room   \n",
       "\n",
       "      security_deposit  space  weekly_price    zipcode  \n",
       "id                                                      \n",
       "3176                 1      1             1  zip_10405  \n",
       "3309                 1      1             1  zip_10777  \n",
       "\n",
       "[2 rows x 50 columns]"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train/test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size,\n",
    "                                                        random_state=random_state,\n",
    "                                                        shuffle=True)\n",
    "#                                                   stratify=y) # Use stratify=y if labels are inbalanced (e.g. most wines are 5 or 6; check with value_counts()!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving preprocessed X_train and X_test\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dummy Classifier (to establish baseline)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set dummy classifier\n",
    "#dum_clf = DummyClassifier(strategy='most_frequent').fit(X_train,y_train)\n",
    "#y_pred_dum_clf = dum_clf.predict(X_test)\n",
    "\n",
    "#Distribution of y test\n",
    "#print('y actual : \\n' +  str(y_test_full.value_counts()))\n",
    "\n",
    "#Distribution of y predicted\n",
    "#print('y predicted : \\n' + str(pd.Series(y_pred_dum_clf).value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17079, 233)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling: Classification (\"occupancy_class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling: Regression (\"price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (OLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_train_prep and y_train to required format\n",
    "X_train_prep_ols = X_train_prep.toarray()            # OneHotEncoder outputs csr_matrix, which gives an error when trying to add a constant. Hence, transformed into numpy array\n",
    "X_train_prep_ols = sm.add_constant(X_train_prep_ols)\n",
    "y_train_ols = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initiate and fit model\n",
    "reg_ols = sm.OLS(y_train_ols, X_train_prep_ols).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.517</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   79.18</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 18 Jul 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:51:19</td>     <th>  Log-Likelihood:    </th> <td> -84588.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 17079</td>      <th>  AIC:               </th> <td>1.696e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 16850</td>      <th>  BIC:               </th> <td>1.714e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   228</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   56.4788</td> <td>    6.115</td> <td>    9.237</td> <td> 0.000</td> <td>   44.493</td> <td>   68.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   14.9503</td> <td>    0.503</td> <td>   29.733</td> <td> 0.000</td> <td>   13.965</td> <td>   15.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    2.0774</td> <td>    0.322</td> <td>    6.442</td> <td> 0.000</td> <td>    1.445</td> <td>    2.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.9343</td> <td>    0.269</td> <td>    3.477</td> <td> 0.001</td> <td>    0.408</td> <td>    1.461</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.7091</td> <td>    0.292</td> <td>   -5.845</td> <td> 0.000</td> <td>   -2.282</td> <td>   -1.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    0.5571</td> <td>    0.377</td> <td>    1.477</td> <td> 0.140</td> <td>   -0.182</td> <td>    1.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    0.1690</td> <td>    0.407</td> <td>    0.415</td> <td> 0.678</td> <td>   -0.629</td> <td>    0.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    3.1003</td> <td>    0.293</td> <td>   10.583</td> <td> 0.000</td> <td>    2.526</td> <td>    3.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    0.0849</td> <td>    0.278</td> <td>    0.306</td> <td> 0.760</td> <td>   -0.460</td> <td>    0.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>    0.1391</td> <td>    0.280</td> <td>    0.497</td> <td> 0.619</td> <td>   -0.409</td> <td>    0.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    0.8915</td> <td>    0.324</td> <td>    2.748</td> <td> 0.006</td> <td>    0.256</td> <td>    1.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -0.0788</td> <td>    0.274</td> <td>   -0.288</td> <td> 0.773</td> <td>   -0.615</td> <td>    0.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    1.8162</td> <td>    0.287</td> <td>    6.323</td> <td> 0.000</td> <td>    1.253</td> <td>    2.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -1.3762</td> <td>    0.282</td> <td>   -4.881</td> <td> 0.000</td> <td>   -1.929</td> <td>   -0.824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    2.2250</td> <td>    0.299</td> <td>    7.433</td> <td> 0.000</td> <td>    1.638</td> <td>    2.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.2117</td> <td>    0.277</td> <td>   -0.764</td> <td> 0.445</td> <td>   -0.755</td> <td>    0.332</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    5.5617</td> <td>    0.317</td> <td>   17.540</td> <td> 0.000</td> <td>    4.940</td> <td>    6.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>    4.1581</td> <td>    0.287</td> <td>   14.506</td> <td> 0.000</td> <td>    3.596</td> <td>    4.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>    7.9438</td> <td>    0.372</td> <td>   21.337</td> <td> 0.000</td> <td>    7.214</td> <td>    8.674</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -1.5372</td> <td>    0.450</td> <td>   -3.416</td> <td> 0.001</td> <td>   -2.419</td> <td>   -0.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -1.8457</td> <td>    0.315</td> <td>   -5.852</td> <td> 0.000</td> <td>   -2.464</td> <td>   -1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -0.7470</td> <td>    0.384</td> <td>   -1.944</td> <td> 0.052</td> <td>   -1.500</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>    0.0119</td> <td>    0.302</td> <td>    0.039</td> <td> 0.969</td> <td>   -0.579</td> <td>    0.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    3.7840</td> <td>    0.341</td> <td>   11.111</td> <td> 0.000</td> <td>    3.116</td> <td>    4.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.1775</td> <td>    0.275</td> <td>    0.645</td> <td> 0.519</td> <td>   -0.362</td> <td>    0.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    1.8370</td> <td>    0.312</td> <td>    5.883</td> <td> 0.000</td> <td>    1.225</td> <td>    2.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>    0.1455</td> <td>    0.337</td> <td>    0.431</td> <td> 0.666</td> <td>   -0.516</td> <td>    0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.4098</td> <td>    0.288</td> <td>   -1.421</td> <td> 0.155</td> <td>   -0.975</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    0.4927</td> <td>    0.280</td> <td>    1.761</td> <td> 0.078</td> <td>   -0.056</td> <td>    1.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.1239</td> <td>    0.270</td> <td>    0.459</td> <td> 0.646</td> <td>   -0.405</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>    0.4355</td> <td>    0.776</td> <td>    0.561</td> <td> 0.575</td> <td>   -1.085</td> <td>    1.956</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -1.4980</td> <td>    0.777</td> <td>   -1.929</td> <td> 0.054</td> <td>   -3.021</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    1.0965</td> <td>    0.271</td> <td>    4.048</td> <td> 0.000</td> <td>    0.566</td> <td>    1.627</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -2.3616</td> <td>    0.273</td> <td>   -8.646</td> <td> 0.000</td> <td>   -2.897</td> <td>   -1.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    0.1560</td> <td>    0.381</td> <td>    0.410</td> <td> 0.682</td> <td>   -0.590</td> <td>    0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    0.6866</td> <td>    1.711</td> <td>    0.401</td> <td> 0.688</td> <td>   -2.667</td> <td>    4.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>   -5.2337</td> <td>    1.704</td> <td>   -3.072</td> <td> 0.002</td> <td>   -8.573</td> <td>   -1.894</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.6597</td> <td>    0.377</td> <td>    1.748</td> <td> 0.080</td> <td>   -0.080</td> <td>    1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>    0.2374</td> <td>    0.351</td> <td>    0.677</td> <td> 0.499</td> <td>   -0.450</td> <td>    0.925</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    3.1592</td> <td>    0.340</td> <td>    9.292</td> <td> 0.000</td> <td>    2.493</td> <td>    3.826</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.6379</td> <td>    0.363</td> <td>    1.759</td> <td> 0.079</td> <td>   -0.073</td> <td>    1.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    0.6132</td> <td>    0.329</td> <td>    1.865</td> <td> 0.062</td> <td>   -0.031</td> <td>    1.258</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -2.9806</td> <td>    0.378</td> <td>   -7.892</td> <td> 0.000</td> <td>   -3.721</td> <td>   -2.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>   -0.4372</td> <td>    0.372</td> <td>   -1.174</td> <td> 0.240</td> <td>   -1.167</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    0.5252</td> <td>    0.295</td> <td>    1.778</td> <td> 0.075</td> <td>   -0.054</td> <td>    1.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -2.0069</td> <td>    0.385</td> <td>   -5.218</td> <td> 0.000</td> <td>   -2.761</td> <td>   -1.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>   <td>    0.9723</td> <td>    0.690</td> <td>    1.409</td> <td> 0.159</td> <td>   -0.381</td> <td>    2.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>   <td>    1.9272</td> <td>    0.735</td> <td>    2.621</td> <td> 0.009</td> <td>    0.486</td> <td>    3.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>   <td>   -4.4520</td> <td>    6.113</td> <td>   -0.728</td> <td> 0.466</td> <td>  -16.435</td> <td>    7.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>   <td>    6.4605</td> <td>   10.875</td> <td>    0.594</td> <td> 0.552</td> <td>  -14.856</td> <td>   27.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>   <td>    1.7221</td> <td>   13.941</td> <td>    0.124</td> <td> 0.902</td> <td>  -25.603</td> <td>   29.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>   <td>   12.2630</td> <td>   18.389</td> <td>    0.667</td> <td> 0.505</td> <td>  -23.781</td> <td>   48.307</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>   <td>   -5.3766</td> <td>    4.610</td> <td>   -1.166</td> <td> 0.243</td> <td>  -14.412</td> <td>    3.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>   <td>   -5.1028</td> <td>   17.693</td> <td>   -0.288</td> <td> 0.773</td> <td>  -39.784</td> <td>   29.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>   <td>   -1.3136</td> <td>    9.917</td> <td>   -0.132</td> <td> 0.895</td> <td>  -20.751</td> <td>   18.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>   <td>    9.8195</td> <td>    7.648</td> <td>    1.284</td> <td> 0.199</td> <td>   -5.171</td> <td>   24.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>   <td>  -14.8632</td> <td>   17.383</td> <td>   -0.855</td> <td> 0.393</td> <td>  -48.936</td> <td>   19.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>   <td>  -41.1921</td> <td>   19.167</td> <td>   -2.149</td> <td> 0.032</td> <td>  -78.761</td> <td>   -3.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>   <td>   -7.7320</td> <td>    4.902</td> <td>   -1.577</td> <td> 0.115</td> <td>  -17.340</td> <td>    1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>   <td>    3.9463</td> <td>    8.758</td> <td>    0.451</td> <td> 0.652</td> <td>  -13.221</td> <td>   21.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>   <td>  -42.4329</td> <td>   20.157</td> <td>   -2.105</td> <td> 0.035</td> <td>  -81.942</td> <td>   -2.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>   <td>    7.0587</td> <td>    7.199</td> <td>    0.981</td> <td> 0.327</td> <td>   -7.051</td> <td>   21.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>   <td>   13.4268</td> <td>   10.776</td> <td>    1.246</td> <td> 0.213</td> <td>   -7.696</td> <td>   34.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>   <td>   -6.6799</td> <td>    9.525</td> <td>   -0.701</td> <td> 0.483</td> <td>  -25.350</td> <td>   11.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>   <td>    7.0303</td> <td>   10.039</td> <td>    0.700</td> <td> 0.484</td> <td>  -12.648</td> <td>   26.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>   <td>   10.1936</td> <td>   17.923</td> <td>    0.569</td> <td> 0.570</td> <td>  -24.938</td> <td>   45.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>   <td>   25.8213</td> <td>   39.630</td> <td>    0.652</td> <td> 0.515</td> <td>  -51.858</td> <td>  103.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>   <td>  -54.0892</td> <td>   31.024</td> <td>   -1.743</td> <td> 0.081</td> <td> -114.899</td> <td>    6.720</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>   <td>    8.6183</td> <td>    5.609</td> <td>    1.537</td> <td> 0.124</td> <td>   -2.376</td> <td>   19.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>   <td>    2.5566</td> <td>   12.045</td> <td>    0.212</td> <td> 0.832</td> <td>  -21.053</td> <td>   26.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>   <td>   -7.5061</td> <td>    9.875</td> <td>   -0.760</td> <td> 0.447</td> <td>  -26.861</td> <td>   11.849</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>   <td>  -41.8286</td> <td>   17.673</td> <td>   -2.367</td> <td> 0.018</td> <td>  -76.469</td> <td>   -7.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>   <td>    1.2104</td> <td>    6.913</td> <td>    0.175</td> <td> 0.861</td> <td>  -12.340</td> <td>   14.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>   <td>  -54.7050</td> <td>   34.463</td> <td>   -1.587</td> <td> 0.112</td> <td> -122.256</td> <td>   12.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>   <td>    7.4891</td> <td>    7.339</td> <td>    1.020</td> <td> 0.308</td> <td>   -6.896</td> <td>   21.874</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>   <td>    7.4824</td> <td>   10.986</td> <td>    0.681</td> <td> 0.496</td> <td>  -14.051</td> <td>   29.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>   <td>   28.5802</td> <td>    5.964</td> <td>    4.792</td> <td> 0.000</td> <td>   16.890</td> <td>   40.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>   <td>   13.2008</td> <td>   17.493</td> <td>    0.755</td> <td> 0.450</td> <td>  -21.088</td> <td>   47.490</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>   <td>   15.1112</td> <td>    6.715</td> <td>    2.250</td> <td> 0.024</td> <td>    1.950</td> <td>   28.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>   <td>    2.8244</td> <td>    5.146</td> <td>    0.549</td> <td> 0.583</td> <td>   -7.262</td> <td>   12.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>   <td>   -2.4569</td> <td>   20.107</td> <td>   -0.122</td> <td> 0.903</td> <td>  -41.868</td> <td>   36.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>   <td>    4.3370</td> <td>    4.111</td> <td>    1.055</td> <td> 0.291</td> <td>   -3.721</td> <td>   12.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>   <td>   18.9500</td> <td>    8.567</td> <td>    2.212</td> <td> 0.027</td> <td>    2.159</td> <td>   35.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>   <td>    5.6448</td> <td>   14.983</td> <td>    0.377</td> <td> 0.706</td> <td>  -23.724</td> <td>   35.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>   <td>   35.6488</td> <td>    7.593</td> <td>    4.695</td> <td> 0.000</td> <td>   20.767</td> <td>   50.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>   <td>   22.2488</td> <td>    6.106</td> <td>    3.644</td> <td> 0.000</td> <td>   10.281</td> <td>   34.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>   <td>   72.8342</td> <td>   20.752</td> <td>    3.510</td> <td> 0.000</td> <td>   32.157</td> <td>  113.511</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>   <td>    8.6518</td> <td>   10.020</td> <td>    0.863</td> <td> 0.388</td> <td>  -10.988</td> <td>   28.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>   <td>  -17.9091</td> <td>    8.383</td> <td>   -2.136</td> <td> 0.033</td> <td>  -34.340</td> <td>   -1.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>   <td>  -64.6908</td> <td>   20.325</td> <td>   -3.183</td> <td> 0.001</td> <td> -104.530</td> <td>  -24.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>   <td>   13.7037</td> <td>   12.804</td> <td>    1.070</td> <td> 0.285</td> <td>  -11.393</td> <td>   38.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>   <td>    0.2374</td> <td>    5.825</td> <td>    0.041</td> <td> 0.967</td> <td>  -11.179</td> <td>   11.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>   <td>    1.1682</td> <td>   11.628</td> <td>    0.100</td> <td> 0.920</td> <td>  -21.624</td> <td>   23.960</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>   <td>    0.7509</td> <td>    6.906</td> <td>    0.109</td> <td> 0.913</td> <td>  -12.786</td> <td>   14.288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>   <td>   -9.4963</td> <td>   12.015</td> <td>   -0.790</td> <td> 0.429</td> <td>  -33.047</td> <td>   14.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>   <td>   10.0247</td> <td>    9.140</td> <td>    1.097</td> <td> 0.273</td> <td>   -7.890</td> <td>   27.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>   <td>    3.9402</td> <td>    7.507</td> <td>    0.525</td> <td> 0.600</td> <td>  -10.775</td> <td>   18.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>   <td>   17.0521</td> <td>   17.775</td> <td>    0.959</td> <td> 0.337</td> <td>  -17.789</td> <td>   51.893</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>   <td>   23.4339</td> <td>    9.651</td> <td>    2.428</td> <td> 0.015</td> <td>    4.517</td> <td>   42.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>   <td>   16.6741</td> <td>   20.671</td> <td>    0.807</td> <td> 0.420</td> <td>  -23.844</td> <td>   57.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th>  <td>  -21.6472</td> <td>    9.840</td> <td>   -2.200</td> <td> 0.028</td> <td>  -40.936</td> <td>   -2.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th>  <td>   18.5873</td> <td>    8.727</td> <td>    2.130</td> <td> 0.033</td> <td>    1.481</td> <td>   35.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th>  <td>   -4.2230</td> <td>    6.986</td> <td>   -0.605</td> <td> 0.546</td> <td>  -17.916</td> <td>    9.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th>  <td>   -8.9613</td> <td>    8.594</td> <td>   -1.043</td> <td> 0.297</td> <td>  -25.806</td> <td>    7.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th>  <td>    3.2884</td> <td>    7.560</td> <td>    0.435</td> <td> 0.664</td> <td>  -11.531</td> <td>   18.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th>  <td>    0.0970</td> <td>    5.227</td> <td>    0.019</td> <td> 0.985</td> <td>  -10.148</td> <td>   10.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th>  <td>   55.9775</td> <td>    3.294</td> <td>   16.996</td> <td> 0.000</td> <td>   49.522</td> <td>   62.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th>  <td>  -20.6079</td> <td>    0.647</td> <td>  -31.834</td> <td> 0.000</td> <td>  -21.877</td> <td>  -19.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th>  <td>  -24.9481</td> <td>    2.577</td> <td>   -9.680</td> <td> 0.000</td> <td>  -30.000</td> <td>  -19.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th>  <td>   13.5160</td> <td>    2.778</td> <td>    4.865</td> <td> 0.000</td> <td>    8.071</td> <td>   18.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th>  <td>    9.3355</td> <td>    2.379</td> <td>    3.924</td> <td> 0.000</td> <td>    4.672</td> <td>   13.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th>  <td>    2.7878</td> <td>    2.967</td> <td>    0.940</td> <td> 0.347</td> <td>   -3.027</td> <td>    8.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th>  <td>    6.3368</td> <td>    2.783</td> <td>    2.277</td> <td> 0.023</td> <td>    0.882</td> <td>   11.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th>  <td>   11.2644</td> <td>    6.723</td> <td>    1.676</td> <td> 0.094</td> <td>   -1.912</td> <td>   24.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th>  <td>   10.5323</td> <td>    6.620</td> <td>    1.591</td> <td> 0.112</td> <td>   -2.444</td> <td>   23.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th>  <td>    8.8333</td> <td>    6.545</td> <td>    1.350</td> <td> 0.177</td> <td>   -3.996</td> <td>   21.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th>  <td>    7.4550</td> <td>    6.553</td> <td>    1.138</td> <td> 0.255</td> <td>   -5.390</td> <td>   20.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th>  <td>   54.8370</td> <td>   20.512</td> <td>    2.673</td> <td> 0.008</td> <td>   14.631</td> <td>   95.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th>  <td>   74.9536</td> <td>   21.424</td> <td>    3.499</td> <td> 0.000</td> <td>   32.961</td> <td>  116.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th>  <td>   57.2792</td> <td>   31.739</td> <td>    1.805</td> <td> 0.071</td> <td>   -4.933</td> <td>  119.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x120</th>  <td>   41.5399</td> <td>   22.314</td> <td>    1.862</td> <td> 0.063</td> <td>   -2.197</td> <td>   85.277</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x121</th>  <td>   51.2665</td> <td>   18.867</td> <td>    2.717</td> <td> 0.007</td> <td>   14.285</td> <td>   88.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x122</th>  <td>   45.2940</td> <td>   19.044</td> <td>    2.378</td> <td> 0.017</td> <td>    7.965</td> <td>   82.623</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x123</th>  <td>   41.5959</td> <td>   21.311</td> <td>    1.952</td> <td> 0.051</td> <td>   -0.176</td> <td>   83.368</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x124</th>  <td>    3.2793</td> <td>    3.769</td> <td>    0.870</td> <td> 0.384</td> <td>   -4.109</td> <td>   10.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x125</th>  <td>   -1.9716</td> <td>    3.974</td> <td>   -0.496</td> <td> 0.620</td> <td>   -9.761</td> <td>    5.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x126</th>  <td>  -10.3016</td> <td>    4.726</td> <td>   -2.180</td> <td> 0.029</td> <td>  -19.565</td> <td>   -1.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x127</th>  <td>    7.1211</td> <td>    3.442</td> <td>    2.069</td> <td> 0.039</td> <td>    0.375</td> <td>   13.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x128</th>  <td>   -2.6573</td> <td>    3.705</td> <td>   -0.717</td> <td> 0.473</td> <td>   -9.920</td> <td>    4.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x129</th>  <td>   -8.6313</td> <td>    3.798</td> <td>   -2.272</td> <td> 0.023</td> <td>  -16.077</td> <td>   -1.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x130</th>  <td>   -6.9754</td> <td>   19.223</td> <td>   -0.363</td> <td> 0.717</td> <td>  -44.655</td> <td>   30.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x131</th>  <td>  -13.0104</td> <td>   19.348</td> <td>   -0.672</td> <td> 0.501</td> <td>  -50.935</td> <td>   24.915</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x132</th>  <td>   -6.1424</td> <td>   19.229</td> <td>   -0.319</td> <td> 0.749</td> <td>  -43.833</td> <td>   31.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x133</th>  <td>    1.2175</td> <td>   19.079</td> <td>    0.064</td> <td> 0.949</td> <td>  -36.180</td> <td>   38.615</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x134</th>  <td>   -0.2634</td> <td>   19.213</td> <td>   -0.014</td> <td> 0.989</td> <td>  -37.922</td> <td>   37.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x135</th>  <td>    1.6411</td> <td>   10.989</td> <td>    0.149</td> <td> 0.881</td> <td>  -19.898</td> <td>   23.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x136</th>  <td>   -7.5685</td> <td>   11.127</td> <td>   -0.680</td> <td> 0.496</td> <td>  -29.378</td> <td>   14.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x137</th>  <td>   -5.9692</td> <td>   11.139</td> <td>   -0.536</td> <td> 0.592</td> <td>  -27.803</td> <td>   15.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x138</th>  <td>    5.6969</td> <td>   11.326</td> <td>    0.503</td> <td> 0.615</td> <td>  -16.504</td> <td>   27.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x139</th>  <td>    0.7252</td> <td>   11.348</td> <td>    0.064</td> <td> 0.949</td> <td>  -21.517</td> <td>   22.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x140</th>  <td>    1.5144</td> <td>   11.028</td> <td>    0.137</td> <td> 0.891</td> <td>  -20.102</td> <td>   23.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x141</th>  <td>   13.0570</td> <td>   11.133</td> <td>    1.173</td> <td> 0.241</td> <td>   -8.764</td> <td>   34.878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x142</th>  <td>   26.1108</td> <td>   10.499</td> <td>    2.487</td> <td> 0.013</td> <td>    5.532</td> <td>   46.689</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x143</th>  <td>   31.0045</td> <td>   11.233</td> <td>    2.760</td> <td> 0.006</td> <td>    8.986</td> <td>   53.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x144</th>  <td>    3.3944</td> <td>   11.959</td> <td>    0.284</td> <td> 0.777</td> <td>  -20.047</td> <td>   26.836</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x145</th>  <td>   10.3889</td> <td>   11.186</td> <td>    0.929</td> <td> 0.353</td> <td>  -11.537</td> <td>   32.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x146</th>  <td>   14.3898</td> <td>   10.384</td> <td>    1.386</td> <td> 0.166</td> <td>   -5.964</td> <td>   34.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x147</th>  <td>    8.3256</td> <td>   10.478</td> <td>    0.795</td> <td> 0.427</td> <td>  -12.213</td> <td>   28.864</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x148</th>  <td>   32.4809</td> <td>   10.358</td> <td>    3.136</td> <td> 0.002</td> <td>   12.178</td> <td>   52.784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x149</th>  <td>   12.1932</td> <td>    8.959</td> <td>    1.361</td> <td> 0.174</td> <td>   -5.368</td> <td>   29.754</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x150</th>  <td>   24.0716</td> <td>    9.876</td> <td>    2.437</td> <td> 0.015</td> <td>    4.714</td> <td>   43.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x151</th>  <td>   15.3705</td> <td>    9.178</td> <td>    1.675</td> <td> 0.094</td> <td>   -2.620</td> <td>   33.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x152</th>  <td>   10.9144</td> <td>    9.266</td> <td>    1.178</td> <td> 0.239</td> <td>   -7.248</td> <td>   29.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x153</th>  <td>   22.4920</td> <td>    9.448</td> <td>    2.381</td> <td> 0.017</td> <td>    3.973</td> <td>   41.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x154</th>  <td>   16.7145</td> <td>    9.375</td> <td>    1.783</td> <td> 0.075</td> <td>   -1.661</td> <td>   35.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x155</th>  <td>   31.4273</td> <td>   10.841</td> <td>    2.899</td> <td> 0.004</td> <td>   10.178</td> <td>   52.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x156</th>  <td>   14.0101</td> <td>    9.382</td> <td>    1.493</td> <td> 0.135</td> <td>   -4.379</td> <td>   32.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x157</th>  <td>   18.0063</td> <td>   10.202</td> <td>    1.765</td> <td> 0.078</td> <td>   -1.991</td> <td>   38.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x158</th>  <td>   10.6739</td> <td>    8.930</td> <td>    1.195</td> <td> 0.232</td> <td>   -6.831</td> <td>   28.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x159</th>  <td>   12.4416</td> <td>    8.866</td> <td>    1.403</td> <td> 0.161</td> <td>   -4.936</td> <td>   29.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x160</th>  <td>    8.6028</td> <td>    7.385</td> <td>    1.165</td> <td> 0.244</td> <td>   -5.872</td> <td>   23.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x161</th>  <td>   12.7348</td> <td>    7.267</td> <td>    1.752</td> <td> 0.080</td> <td>   -1.509</td> <td>   26.979</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x162</th>  <td>    9.2889</td> <td>    7.359</td> <td>    1.262</td> <td> 0.207</td> <td>   -5.135</td> <td>   23.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x163</th>  <td>   12.9532</td> <td>    7.305</td> <td>    1.773</td> <td> 0.076</td> <td>   -1.365</td> <td>   27.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x164</th>  <td>   17.9680</td> <td>    7.547</td> <td>    2.381</td> <td> 0.017</td> <td>    3.176</td> <td>   32.760</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x165</th>  <td>   16.4301</td> <td>    7.320</td> <td>    2.244</td> <td> 0.025</td> <td>    2.081</td> <td>   30.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x166</th>  <td>   12.7575</td> <td>    7.311</td> <td>    1.745</td> <td> 0.081</td> <td>   -1.574</td> <td>   27.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x167</th>  <td>    0.2933</td> <td>    8.480</td> <td>    0.035</td> <td> 0.972</td> <td>  -16.329</td> <td>   16.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x168</th>  <td>    1.3590</td> <td>    8.441</td> <td>    0.161</td> <td> 0.872</td> <td>  -15.187</td> <td>   17.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x169</th>  <td>    3.4750</td> <td>    8.359</td> <td>    0.416</td> <td> 0.678</td> <td>  -12.910</td> <td>   19.860</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x170</th>  <td>    0.4690</td> <td>    8.438</td> <td>    0.056</td> <td> 0.956</td> <td>  -16.070</td> <td>   17.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x171</th>  <td>   -3.0922</td> <td>    8.437</td> <td>   -0.367</td> <td> 0.714</td> <td>  -19.629</td> <td>   13.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x172</th>  <td>    0.6553</td> <td>    8.482</td> <td>    0.077</td> <td> 0.938</td> <td>  -15.971</td> <td>   17.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x173</th>  <td>   -4.9730</td> <td>    8.555</td> <td>   -0.581</td> <td> 0.561</td> <td>  -21.742</td> <td>   11.796</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x174</th>  <td>   -5.7974</td> <td>    9.785</td> <td>   -0.592</td> <td> 0.554</td> <td>  -24.977</td> <td>   13.382</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x175</th>  <td>   -1.0434</td> <td>    8.536</td> <td>   -0.122</td> <td> 0.903</td> <td>  -17.774</td> <td>   15.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x176</th>  <td>    5.8564</td> <td>   11.486</td> <td>    0.510</td> <td> 0.610</td> <td>  -16.658</td> <td>   28.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x177</th>  <td>    3.7902</td> <td>   11.619</td> <td>    0.326</td> <td> 0.744</td> <td>  -18.984</td> <td>   26.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x178</th>  <td>    2.6856</td> <td>   11.489</td> <td>    0.234</td> <td> 0.815</td> <td>  -19.835</td> <td>   25.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x179</th>  <td>   -8.3421</td> <td>   11.105</td> <td>   -0.751</td> <td> 0.453</td> <td>  -30.110</td> <td>   13.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x180</th>  <td>   -0.4037</td> <td>    9.621</td> <td>   -0.042</td> <td> 0.967</td> <td>  -19.262</td> <td>   18.454</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x181</th>  <td>   -1.7002</td> <td>   10.819</td> <td>   -0.157</td> <td> 0.875</td> <td>  -22.907</td> <td>   19.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x182</th>  <td>    7.7559</td> <td>   11.402</td> <td>    0.680</td> <td> 0.496</td> <td>  -14.592</td> <td>   30.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x183</th>  <td>   10.6148</td> <td>   10.749</td> <td>    0.988</td> <td> 0.323</td> <td>  -10.454</td> <td>   31.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x184</th>  <td>   -3.0602</td> <td>   11.447</td> <td>   -0.267</td> <td> 0.789</td> <td>  -25.497</td> <td>   19.376</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x185</th>  <td>    5.9986</td> <td>   12.923</td> <td>    0.464</td> <td> 0.643</td> <td>  -19.332</td> <td>   31.329</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x186</th>  <td>    8.2756</td> <td>   11.296</td> <td>    0.733</td> <td> 0.464</td> <td>  -13.865</td> <td>   30.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x187</th>  <td>    7.4395</td> <td>   20.010</td> <td>    0.372</td> <td> 0.710</td> <td>  -31.782</td> <td>   46.661</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x188</th>  <td>   19.6690</td> <td>   20.784</td> <td>    0.946</td> <td> 0.344</td> <td>  -21.071</td> <td>   60.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x189</th>  <td>   10.7464</td> <td>   15.659</td> <td>    0.686</td> <td> 0.493</td> <td>  -19.948</td> <td>   41.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x190</th>  <td>   -1.7939</td> <td>   19.367</td> <td>   -0.093</td> <td> 0.926</td> <td>  -39.756</td> <td>   36.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x191</th>  <td>    2.8244</td> <td>    5.146</td> <td>    0.549</td> <td> 0.583</td> <td>   -7.262</td> <td>   12.911</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x192</th>  <td>    4.3370</td> <td>    4.111</td> <td>    1.055</td> <td> 0.291</td> <td>   -3.721</td> <td>   12.395</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x193</th>  <td>  -22.7131</td> <td>   39.870</td> <td>   -0.570</td> <td> 0.569</td> <td> -100.863</td> <td>   55.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x194</th>  <td>    6.5963</td> <td>    9.526</td> <td>    0.692</td> <td> 0.489</td> <td>  -12.075</td> <td>   25.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x195</th>  <td>    1.5927</td> <td>   12.591</td> <td>    0.126</td> <td> 0.899</td> <td>  -23.088</td> <td>   26.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x196</th>  <td>   -2.0963</td> <td>   15.295</td> <td>   -0.137</td> <td> 0.891</td> <td>  -32.077</td> <td>   27.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x197</th>  <td>    5.7046</td> <td>   16.036</td> <td>    0.356</td> <td> 0.722</td> <td>  -25.728</td> <td>   37.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x198</th>  <td>  -85.3858</td> <td>   23.247</td> <td>   -3.673</td> <td> 0.000</td> <td> -130.953</td> <td>  -39.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x199</th>  <td>   56.6428</td> <td>   36.428</td> <td>    1.555</td> <td> 0.120</td> <td>  -14.760</td> <td>  128.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x200</th>  <td>   -3.9950</td> <td>   14.967</td> <td>   -0.267</td> <td> 0.790</td> <td>  -33.332</td> <td>   25.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x201</th>  <td>   -5.3766</td> <td>    4.610</td> <td>   -1.166</td> <td> 0.243</td> <td>  -14.412</td> <td>    3.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x202</th>  <td>   -6.9666</td> <td>   14.695</td> <td>   -0.474</td> <td> 0.635</td> <td>  -35.770</td> <td>   21.837</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x203</th>  <td>  -11.8602</td> <td>   20.295</td> <td>   -0.584</td> <td> 0.559</td> <td>  -51.640</td> <td>   27.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x204</th>  <td>   -9.6184</td> <td>   20.499</td> <td>   -0.469</td> <td> 0.639</td> <td>  -49.798</td> <td>   30.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x205</th>  <td>  -20.6780</td> <td>   12.141</td> <td>   -1.703</td> <td> 0.089</td> <td>  -44.477</td> <td>    3.121</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x206</th>  <td>   -7.7320</td> <td>    4.902</td> <td>   -1.577</td> <td> 0.115</td> <td>  -17.340</td> <td>    1.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x207</th>  <td>    6.8832</td> <td>   21.409</td> <td>    0.322</td> <td> 0.748</td> <td>  -35.081</td> <td>   48.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x208</th>  <td>  -12.9449</td> <td>    7.946</td> <td>   -1.629</td> <td> 0.103</td> <td>  -28.520</td> <td>    2.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x209</th>  <td>  -11.9160</td> <td>    7.509</td> <td>   -1.587</td> <td> 0.113</td> <td>  -26.635</td> <td>    2.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x210</th>  <td>  -13.6700</td> <td>    9.917</td> <td>   -1.378</td> <td> 0.168</td> <td>  -33.108</td> <td>    5.768</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x211</th>  <td>  -24.0346</td> <td>   10.798</td> <td>   -2.226</td> <td> 0.026</td> <td>  -45.199</td> <td>   -2.870</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x212</th>  <td>  -24.4323</td> <td>   10.412</td> <td>   -2.346</td> <td> 0.019</td> <td>  -44.841</td> <td>   -4.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x213</th>  <td>  -17.1092</td> <td>    9.891</td> <td>   -1.730</td> <td> 0.084</td> <td>  -36.497</td> <td>    2.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x214</th>  <td>  -10.7179</td> <td>   10.499</td> <td>   -1.021</td> <td> 0.307</td> <td>  -31.297</td> <td>    9.862</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x215</th>  <td>  -15.1768</td> <td>    9.868</td> <td>   -1.538</td> <td> 0.124</td> <td>  -34.519</td> <td>    4.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x216</th>  <td>  -20.2526</td> <td>    9.917</td> <td>   -2.042</td> <td> 0.041</td> <td>  -39.691</td> <td>   -0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x217</th>  <td>  -11.8524</td> <td>   12.522</td> <td>   -0.946</td> <td> 0.344</td> <td>  -36.397</td> <td>   12.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x218</th>  <td>  -15.4994</td> <td>   11.444</td> <td>   -1.354</td> <td> 0.176</td> <td>  -37.930</td> <td>    6.931</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x219</th>  <td>   -9.1141</td> <td>   11.340</td> <td>   -0.804</td> <td> 0.422</td> <td>  -31.341</td> <td>   13.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x220</th>  <td>    5.5545</td> <td>   15.580</td> <td>    0.357</td> <td> 0.721</td> <td>  -24.985</td> <td>   36.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x221</th>  <td>  -32.9220</td> <td>   14.667</td> <td>   -2.245</td> <td> 0.025</td> <td>  -61.671</td> <td>   -4.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x222</th>  <td>   23.0164</td> <td>   13.353</td> <td>    1.724</td> <td> 0.085</td> <td>   -3.157</td> <td>   49.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x223</th>  <td>   41.3509</td> <td>   13.829</td> <td>    2.990</td> <td> 0.003</td> <td>   14.245</td> <td>   68.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x224</th>  <td>   39.3434</td> <td>   13.512</td> <td>    2.912</td> <td> 0.004</td> <td>   12.858</td> <td>   65.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x225</th>  <td>    6.7516</td> <td>   11.048</td> <td>    0.611</td> <td> 0.541</td> <td>  -14.904</td> <td>   28.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x226</th>  <td>    5.0800</td> <td>   10.794</td> <td>    0.471</td> <td> 0.638</td> <td>  -16.077</td> <td>   26.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x227</th>  <td>  -30.8753</td> <td>   19.680</td> <td>   -1.569</td> <td> 0.117</td> <td>  -69.451</td> <td>    7.700</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x228</th>  <td>   -2.9696</td> <td>   12.764</td> <td>   -0.233</td> <td> 0.816</td> <td>  -27.988</td> <td>   22.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x229</th>  <td>   -1.9154</td> <td>   13.593</td> <td>   -0.141</td> <td> 0.888</td> <td>  -28.559</td> <td>   24.728</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x230</th>  <td>   35.5592</td> <td>   17.414</td> <td>    2.042</td> <td> 0.041</td> <td>    1.426</td> <td>   69.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x231</th>  <td>   14.8261</td> <td>   10.583</td> <td>    1.401</td> <td> 0.161</td> <td>   -5.918</td> <td>   35.570</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x232</th>  <td>   -9.1722</td> <td>   16.378</td> <td>   -0.560</td> <td> 0.575</td> <td>  -41.275</td> <td>   22.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x233</th>  <td>   -0.3771</td> <td>    8.791</td> <td>   -0.043</td> <td> 0.966</td> <td>  -17.609</td> <td>   16.854</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>12679.900</td> <th>  Durbin-Watson:     </th>  <td>   2.010</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>515719.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.150</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>29.173</td>   <th>  Cond. No.          </th>  <td>4.91e+16</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 3.73e-29. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.517\n",
       "Model:                            OLS   Adj. R-squared:                  0.511\n",
       "Method:                 Least Squares   F-statistic:                     79.18\n",
       "Date:                Sat, 18 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        12:51:19   Log-Likelihood:                -84588.\n",
       "No. Observations:               17079   AIC:                         1.696e+05\n",
       "Df Residuals:                   16850   BIC:                         1.714e+05\n",
       "Df Model:                         228                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         56.4788      6.115      9.237      0.000      44.493      68.464\n",
       "x1            14.9503      0.503     29.733      0.000      13.965      15.936\n",
       "x2             2.0774      0.322      6.442      0.000       1.445       2.710\n",
       "x3             0.9343      0.269      3.477      0.001       0.408       1.461\n",
       "x4            -1.7091      0.292     -5.845      0.000      -2.282      -1.136\n",
       "x5             0.5571      0.377      1.477      0.140      -0.182       1.296\n",
       "x6             0.1690      0.407      0.415      0.678      -0.629       0.967\n",
       "x7             3.1003      0.293     10.583      0.000       2.526       3.674\n",
       "x8             0.0849      0.278      0.306      0.760      -0.460       0.629\n",
       "x9             0.1391      0.280      0.497      0.619      -0.409       0.687\n",
       "x10            0.8915      0.324      2.748      0.006       0.256       1.527\n",
       "x11           -0.0788      0.274     -0.288      0.773      -0.615       0.457\n",
       "x12            1.8162      0.287      6.323      0.000       1.253       2.379\n",
       "x13           -1.3762      0.282     -4.881      0.000      -1.929      -0.824\n",
       "x14            2.2250      0.299      7.433      0.000       1.638       2.812\n",
       "x15           -0.2117      0.277     -0.764      0.445      -0.755       0.332\n",
       "x16            5.5617      0.317     17.540      0.000       4.940       6.183\n",
       "x17            4.1581      0.287     14.506      0.000       3.596       4.720\n",
       "x18            7.9438      0.372     21.337      0.000       7.214       8.674\n",
       "x19           -1.5372      0.450     -3.416      0.001      -2.419      -0.655\n",
       "x20           -1.8457      0.315     -5.852      0.000      -2.464      -1.227\n",
       "x21           -0.7470      0.384     -1.944      0.052      -1.500       0.006\n",
       "x22            0.0119      0.302      0.039      0.969      -0.579       0.603\n",
       "x23            3.7840      0.341     11.111      0.000       3.116       4.452\n",
       "x24            0.1775      0.275      0.645      0.519      -0.362       0.717\n",
       "x25            1.8370      0.312      5.883      0.000       1.225       2.449\n",
       "x26            0.1455      0.337      0.431      0.666      -0.516       0.807\n",
       "x27           -0.4098      0.288     -1.421      0.155      -0.975       0.156\n",
       "x28            0.4927      0.280      1.761      0.078      -0.056       1.041\n",
       "x29            0.1239      0.270      0.459      0.646      -0.405       0.653\n",
       "x30            0.4355      0.776      0.561      0.575      -1.085       1.956\n",
       "x31           -1.4980      0.777     -1.929      0.054      -3.021       0.024\n",
       "x32            1.0965      0.271      4.048      0.000       0.566       1.627\n",
       "x33           -2.3616      0.273     -8.646      0.000      -2.897      -1.826\n",
       "x34            0.1560      0.381      0.410      0.682      -0.590       0.902\n",
       "x35            0.6866      1.711      0.401      0.688      -2.667       4.040\n",
       "x36           -5.2337      1.704     -3.072      0.002      -8.573      -1.894\n",
       "x37            0.6597      0.377      1.748      0.080      -0.080       1.399\n",
       "x38            0.2374      0.351      0.677      0.499      -0.450       0.925\n",
       "x39            3.1592      0.340      9.292      0.000       2.493       3.826\n",
       "x40            0.6379      0.363      1.759      0.079      -0.073       1.349\n",
       "x41            0.6132      0.329      1.865      0.062      -0.031       1.258\n",
       "x42           -2.9806      0.378     -7.892      0.000      -3.721      -2.240\n",
       "x43           -0.4372      0.372     -1.174      0.240      -1.167       0.293\n",
       "x44            0.5252      0.295      1.778      0.075      -0.054       1.104\n",
       "x45           -2.0069      0.385     -5.218      0.000      -2.761      -1.253\n",
       "x46            0.9723      0.690      1.409      0.159      -0.381       2.325\n",
       "x47            1.9272      0.735      2.621      0.009       0.486       3.368\n",
       "x48           -4.4520      6.113     -0.728      0.466     -16.435       7.531\n",
       "x49            6.4605     10.875      0.594      0.552     -14.856      27.777\n",
       "x50            1.7221     13.941      0.124      0.902     -25.603      29.048\n",
       "x51           12.2630     18.389      0.667      0.505     -23.781      48.307\n",
       "x52           -5.3766      4.610     -1.166      0.243     -14.412       3.659\n",
       "x53           -5.1028     17.693     -0.288      0.773     -39.784      29.578\n",
       "x54           -1.3136      9.917     -0.132      0.895     -20.751      18.124\n",
       "x55            9.8195      7.648      1.284      0.199      -5.171      24.810\n",
       "x56          -14.8632     17.383     -0.855      0.393     -48.936      19.209\n",
       "x57          -41.1921     19.167     -2.149      0.032     -78.761      -3.623\n",
       "x58           -7.7320      4.902     -1.577      0.115     -17.340       1.876\n",
       "x59            3.9463      8.758      0.451      0.652     -13.221      21.114\n",
       "x60          -42.4329     20.157     -2.105      0.035     -81.942      -2.924\n",
       "x61            7.0587      7.199      0.981      0.327      -7.051      21.169\n",
       "x62           13.4268     10.776      1.246      0.213      -7.696      34.550\n",
       "x63           -6.6799      9.525     -0.701      0.483     -25.350      11.990\n",
       "x64            7.0303     10.039      0.700      0.484     -12.648      26.708\n",
       "x65           10.1936     17.923      0.569      0.570     -24.938      45.325\n",
       "x66           25.8213     39.630      0.652      0.515     -51.858     103.501\n",
       "x67          -54.0892     31.024     -1.743      0.081    -114.899       6.720\n",
       "x68            8.6183      5.609      1.537      0.124      -2.376      19.612\n",
       "x69            2.5566     12.045      0.212      0.832     -21.053      26.166\n",
       "x70           -7.5061      9.875     -0.760      0.447     -26.861      11.849\n",
       "x71          -41.8286     17.673     -2.367      0.018     -76.469      -7.188\n",
       "x72            1.2104      6.913      0.175      0.861     -12.340      14.761\n",
       "x73          -54.7050     34.463     -1.587      0.112    -122.256      12.846\n",
       "x74            7.4891      7.339      1.020      0.308      -6.896      21.874\n",
       "x75            7.4824     10.986      0.681      0.496     -14.051      29.016\n",
       "x76           28.5802      5.964      4.792      0.000      16.890      40.271\n",
       "x77           13.2008     17.493      0.755      0.450     -21.088      47.490\n",
       "x78           15.1112      6.715      2.250      0.024       1.950      28.273\n",
       "x79            2.8244      5.146      0.549      0.583      -7.262      12.911\n",
       "x80           -2.4569     20.107     -0.122      0.903     -41.868      36.955\n",
       "x81            4.3370      4.111      1.055      0.291      -3.721      12.395\n",
       "x82           18.9500      8.567      2.212      0.027       2.159      35.741\n",
       "x83            5.6448     14.983      0.377      0.706     -23.724      35.013\n",
       "x84           35.6488      7.593      4.695      0.000      20.767      50.531\n",
       "x85           22.2488      6.106      3.644      0.000      10.281      34.217\n",
       "x86           72.8342     20.752      3.510      0.000      32.157     113.511\n",
       "x87            8.6518     10.020      0.863      0.388     -10.988      28.292\n",
       "x88          -17.9091      8.383     -2.136      0.033     -34.340      -1.478\n",
       "x89          -64.6908     20.325     -3.183      0.001    -104.530     -24.851\n",
       "x90           13.7037     12.804      1.070      0.285     -11.393      38.801\n",
       "x91            0.2374      5.825      0.041      0.967     -11.179      11.654\n",
       "x92            1.1682     11.628      0.100      0.920     -21.624      23.960\n",
       "x93            0.7509      6.906      0.109      0.913     -12.786      14.288\n",
       "x94           -9.4963     12.015     -0.790      0.429     -33.047      14.055\n",
       "x95           10.0247      9.140      1.097      0.273      -7.890      27.940\n",
       "x96            3.9402      7.507      0.525      0.600     -10.775      18.656\n",
       "x97           17.0521     17.775      0.959      0.337     -17.789      51.893\n",
       "x98           23.4339      9.651      2.428      0.015       4.517      42.351\n",
       "x99           16.6741     20.671      0.807      0.420     -23.844      57.192\n",
       "x100         -21.6472      9.840     -2.200      0.028     -40.936      -2.359\n",
       "x101          18.5873      8.727      2.130      0.033       1.481      35.693\n",
       "x102          -4.2230      6.986     -0.605      0.546     -17.916       9.470\n",
       "x103          -8.9613      8.594     -1.043      0.297     -25.806       7.883\n",
       "x104           3.2884      7.560      0.435      0.664     -11.531      18.108\n",
       "x105           0.0970      5.227      0.019      0.985     -10.148      10.342\n",
       "x106          55.9775      3.294     16.996      0.000      49.522      62.433\n",
       "x107         -20.6079      0.647    -31.834      0.000     -21.877     -19.339\n",
       "x108         -24.9481      2.577     -9.680      0.000     -30.000     -19.896\n",
       "x109          13.5160      2.778      4.865      0.000       8.071      18.961\n",
       "x110           9.3355      2.379      3.924      0.000       4.672      13.999\n",
       "x111           2.7878      2.967      0.940      0.347      -3.027       8.603\n",
       "x112           6.3368      2.783      2.277      0.023       0.882      11.792\n",
       "x113          11.2644      6.723      1.676      0.094      -1.912      24.441\n",
       "x114          10.5323      6.620      1.591      0.112      -2.444      23.508\n",
       "x115           8.8333      6.545      1.350      0.177      -3.996      21.663\n",
       "x116           7.4550      6.553      1.138      0.255      -5.390      20.300\n",
       "x117          54.8370     20.512      2.673      0.008      14.631      95.043\n",
       "x118          74.9536     21.424      3.499      0.000      32.961     116.946\n",
       "x119          57.2792     31.739      1.805      0.071      -4.933     119.491\n",
       "x120          41.5399     22.314      1.862      0.063      -2.197      85.277\n",
       "x121          51.2665     18.867      2.717      0.007      14.285      88.248\n",
       "x122          45.2940     19.044      2.378      0.017       7.965      82.623\n",
       "x123          41.5959     21.311      1.952      0.051      -0.176      83.368\n",
       "x124           3.2793      3.769      0.870      0.384      -4.109      10.668\n",
       "x125          -1.9716      3.974     -0.496      0.620      -9.761       5.818\n",
       "x126         -10.3016      4.726     -2.180      0.029     -19.565      -1.038\n",
       "x127           7.1211      3.442      2.069      0.039       0.375      13.867\n",
       "x128          -2.6573      3.705     -0.717      0.473      -9.920       4.606\n",
       "x129          -8.6313      3.798     -2.272      0.023     -16.077      -1.186\n",
       "x130          -6.9754     19.223     -0.363      0.717     -44.655      30.705\n",
       "x131         -13.0104     19.348     -0.672      0.501     -50.935      24.915\n",
       "x132          -6.1424     19.229     -0.319      0.749     -43.833      31.548\n",
       "x133           1.2175     19.079      0.064      0.949     -36.180      38.615\n",
       "x134          -0.2634     19.213     -0.014      0.989     -37.922      37.395\n",
       "x135           1.6411     10.989      0.149      0.881     -19.898      23.180\n",
       "x136          -7.5685     11.127     -0.680      0.496     -29.378      14.241\n",
       "x137          -5.9692     11.139     -0.536      0.592     -27.803      15.864\n",
       "x138           5.6969     11.326      0.503      0.615     -16.504      27.898\n",
       "x139           0.7252     11.348      0.064      0.949     -21.517      22.968\n",
       "x140           1.5144     11.028      0.137      0.891     -20.102      23.131\n",
       "x141          13.0570     11.133      1.173      0.241      -8.764      34.878\n",
       "x142          26.1108     10.499      2.487      0.013       5.532      46.689\n",
       "x143          31.0045     11.233      2.760      0.006       8.986      53.023\n",
       "x144           3.3944     11.959      0.284      0.777     -20.047      26.836\n",
       "x145          10.3889     11.186      0.929      0.353     -11.537      32.314\n",
       "x146          14.3898     10.384      1.386      0.166      -5.964      34.743\n",
       "x147           8.3256     10.478      0.795      0.427     -12.213      28.864\n",
       "x148          32.4809     10.358      3.136      0.002      12.178      52.784\n",
       "x149          12.1932      8.959      1.361      0.174      -5.368      29.754\n",
       "x150          24.0716      9.876      2.437      0.015       4.714      43.429\n",
       "x151          15.3705      9.178      1.675      0.094      -2.620      33.361\n",
       "x152          10.9144      9.266      1.178      0.239      -7.248      29.077\n",
       "x153          22.4920      9.448      2.381      0.017       3.973      41.010\n",
       "x154          16.7145      9.375      1.783      0.075      -1.661      35.090\n",
       "x155          31.4273     10.841      2.899      0.004      10.178      52.677\n",
       "x156          14.0101      9.382      1.493      0.135      -4.379      32.399\n",
       "x157          18.0063     10.202      1.765      0.078      -1.991      38.004\n",
       "x158          10.6739      8.930      1.195      0.232      -6.831      28.179\n",
       "x159          12.4416      8.866      1.403      0.161      -4.936      29.819\n",
       "x160           8.6028      7.385      1.165      0.244      -5.872      23.078\n",
       "x161          12.7348      7.267      1.752      0.080      -1.509      26.979\n",
       "x162           9.2889      7.359      1.262      0.207      -5.135      23.712\n",
       "x163          12.9532      7.305      1.773      0.076      -1.365      27.272\n",
       "x164          17.9680      7.547      2.381      0.017       3.176      32.760\n",
       "x165          16.4301      7.320      2.244      0.025       2.081      30.779\n",
       "x166          12.7575      7.311      1.745      0.081      -1.574      27.088\n",
       "x167           0.2933      8.480      0.035      0.972     -16.329      16.916\n",
       "x168           1.3590      8.441      0.161      0.872     -15.187      17.905\n",
       "x169           3.4750      8.359      0.416      0.678     -12.910      19.860\n",
       "x170           0.4690      8.438      0.056      0.956     -16.070      17.008\n",
       "x171          -3.0922      8.437     -0.367      0.714     -19.629      13.445\n",
       "x172           0.6553      8.482      0.077      0.938     -15.971      17.282\n",
       "x173          -4.9730      8.555     -0.581      0.561     -21.742      11.796\n",
       "x174          -5.7974      9.785     -0.592      0.554     -24.977      13.382\n",
       "x175          -1.0434      8.536     -0.122      0.903     -17.774      15.687\n",
       "x176           5.8564     11.486      0.510      0.610     -16.658      28.370\n",
       "x177           3.7902     11.619      0.326      0.744     -18.984      26.565\n",
       "x178           2.6856     11.489      0.234      0.815     -19.835      25.206\n",
       "x179          -8.3421     11.105     -0.751      0.453     -30.110      13.426\n",
       "x180          -0.4037      9.621     -0.042      0.967     -19.262      18.454\n",
       "x181          -1.7002     10.819     -0.157      0.875     -22.907      19.507\n",
       "x182           7.7559     11.402      0.680      0.496     -14.592      30.104\n",
       "x183          10.6148     10.749      0.988      0.323     -10.454      31.684\n",
       "x184          -3.0602     11.447     -0.267      0.789     -25.497      19.376\n",
       "x185           5.9986     12.923      0.464      0.643     -19.332      31.329\n",
       "x186           8.2756     11.296      0.733      0.464     -13.865      30.416\n",
       "x187           7.4395     20.010      0.372      0.710     -31.782      46.661\n",
       "x188          19.6690     20.784      0.946      0.344     -21.071      60.409\n",
       "x189          10.7464     15.659      0.686      0.493     -19.948      41.440\n",
       "x190          -1.7939     19.367     -0.093      0.926     -39.756      36.168\n",
       "x191           2.8244      5.146      0.549      0.583      -7.262      12.911\n",
       "x192           4.3370      4.111      1.055      0.291      -3.721      12.395\n",
       "x193         -22.7131     39.870     -0.570      0.569    -100.863      55.437\n",
       "x194           6.5963      9.526      0.692      0.489     -12.075      25.268\n",
       "x195           1.5927     12.591      0.126      0.899     -23.088      26.273\n",
       "x196          -2.0963     15.295     -0.137      0.891     -32.077      27.884\n",
       "x197           5.7046     16.036      0.356      0.722     -25.728      37.137\n",
       "x198         -85.3858     23.247     -3.673      0.000    -130.953     -39.819\n",
       "x199          56.6428     36.428      1.555      0.120     -14.760     128.046\n",
       "x200          -3.9950     14.967     -0.267      0.790     -33.332      25.342\n",
       "x201          -5.3766      4.610     -1.166      0.243     -14.412       3.659\n",
       "x202          -6.9666     14.695     -0.474      0.635     -35.770      21.837\n",
       "x203         -11.8602     20.295     -0.584      0.559     -51.640      27.920\n",
       "x204          -9.6184     20.499     -0.469      0.639     -49.798      30.561\n",
       "x205         -20.6780     12.141     -1.703      0.089     -44.477       3.121\n",
       "x206          -7.7320      4.902     -1.577      0.115     -17.340       1.876\n",
       "x207           6.8832     21.409      0.322      0.748     -35.081      48.847\n",
       "x208         -12.9449      7.946     -1.629      0.103     -28.520       2.630\n",
       "x209         -11.9160      7.509     -1.587      0.113     -26.635       2.803\n",
       "x210         -13.6700      9.917     -1.378      0.168     -33.108       5.768\n",
       "x211         -24.0346     10.798     -2.226      0.026     -45.199      -2.870\n",
       "x212         -24.4323     10.412     -2.346      0.019     -44.841      -4.023\n",
       "x213         -17.1092      9.891     -1.730      0.084     -36.497       2.278\n",
       "x214         -10.7179     10.499     -1.021      0.307     -31.297       9.862\n",
       "x215         -15.1768      9.868     -1.538      0.124     -34.519       4.166\n",
       "x216         -20.2526      9.917     -2.042      0.041     -39.691      -0.814\n",
       "x217         -11.8524     12.522     -0.946      0.344     -36.397      12.693\n",
       "x218         -15.4994     11.444     -1.354      0.176     -37.930       6.931\n",
       "x219          -9.1141     11.340     -0.804      0.422     -31.341      13.113\n",
       "x220           5.5545     15.580      0.357      0.721     -24.985      36.094\n",
       "x221         -32.9220     14.667     -2.245      0.025     -61.671      -4.173\n",
       "x222          23.0164     13.353      1.724      0.085      -3.157      49.190\n",
       "x223          41.3509     13.829      2.990      0.003      14.245      68.457\n",
       "x224          39.3434     13.512      2.912      0.004      12.858      65.829\n",
       "x225           6.7516     11.048      0.611      0.541     -14.904      28.407\n",
       "x226           5.0800     10.794      0.471      0.638     -16.077      26.237\n",
       "x227         -30.8753     19.680     -1.569      0.117     -69.451       7.700\n",
       "x228          -2.9696     12.764     -0.233      0.816     -27.988      22.049\n",
       "x229          -1.9154     13.593     -0.141      0.888     -28.559      24.728\n",
       "x230          35.5592     17.414      2.042      0.041       1.426      69.692\n",
       "x231          14.8261     10.583      1.401      0.161      -5.918      35.570\n",
       "x232          -9.1722     16.378     -0.560      0.575     -41.275      22.930\n",
       "x233          -0.3771      8.791     -0.043      0.966     -17.609      16.854\n",
       "==============================================================================\n",
       "Omnibus:                    12679.900   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           515719.967\n",
       "Skew:                           3.150   Prob(JB):                         0.00\n",
       "Kurtosis:                      29.173   Cond. No.                     4.91e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 3.73e-29. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model summary\n",
    "reg_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict target (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression w/o preprocessing (to roughly see feature importance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train_prep and y_train to required format\n",
    "X_ols_wo = X.drop(['cancellation_policy', 'neighbourhood', 'room_type', 'zipcode'], axis=1)#.toarray()            # OneHotEncoder outputs csr_matrix, which gives an error when trying to add a constant. Hence, transformed into numpy array\n",
    "X_ols_wo = sm.add_constant(X_ols_wo)\n",
    "X_ols_wo = np.asarray(X_ols_wo)\n",
    "y_ols_wo = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_ols_wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate and fit model\n",
    "reg_ols_wo = sm.OLS(y_ols_wo, X_ols_wo).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.427</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.426</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   402.6</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 18 Jul 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:03:05</td>     <th>  Log-Likelihood:    </th> <td>-1.2314e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 24399</td>      <th>  AIC:               </th>  <td>2.464e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 24353</td>      <th>  BIC:               </th>  <td>2.467e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    45</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-1104.1907</td> <td>  414.192</td> <td>   -2.666</td> <td> 0.008</td> <td>-1916.033</td> <td> -292.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   11.7510</td> <td>    0.280</td> <td>   42.002</td> <td> 0.000</td> <td>   11.203</td> <td>   12.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    4.9728</td> <td>    0.767</td> <td>    6.480</td> <td> 0.000</td> <td>    3.469</td> <td>    6.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    4.2830</td> <td>    1.085</td> <td>    3.947</td> <td> 0.000</td> <td>    2.156</td> <td>    6.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.1309</td> <td>    0.578</td> <td>   -1.955</td> <td> 0.051</td> <td>   -2.265</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>    1.6398</td> <td>    0.752</td> <td>    2.179</td> <td> 0.029</td> <td>    0.165</td> <td>    3.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>    2.0986</td> <td>    0.767</td> <td>    2.735</td> <td> 0.006</td> <td>    0.595</td> <td>    3.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>   13.7116</td> <td>    0.601</td> <td>   22.820</td> <td> 0.000</td> <td>   12.534</td> <td>   14.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>   -0.1306</td> <td>    0.912</td> <td>   -0.143</td> <td> 0.886</td> <td>   -1.918</td> <td>    1.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -1.8945</td> <td>    1.566</td> <td>   -1.210</td> <td> 0.226</td> <td>   -4.964</td> <td>    1.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>   -2.0042</td> <td>    0.580</td> <td>   -3.454</td> <td> 0.001</td> <td>   -3.142</td> <td>   -0.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>   -1.6845</td> <td>    0.666</td> <td>   -2.528</td> <td> 0.011</td> <td>   -2.991</td> <td>   -0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    9.0185</td> <td>    0.689</td> <td>   13.082</td> <td> 0.000</td> <td>    7.667</td> <td>   10.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>   -7.3406</td> <td>    0.657</td> <td>  -11.179</td> <td> 0.000</td> <td>   -8.628</td> <td>   -6.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>   <td>    7.9658</td> <td>    0.526</td> <td>   15.138</td> <td> 0.000</td> <td>    6.934</td> <td>    8.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>   <td>   -0.9354</td> <td>    0.691</td> <td>   -1.355</td> <td> 0.176</td> <td>   -2.289</td> <td>    0.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>   <td>    0.0563</td> <td>    0.003</td> <td>   21.697</td> <td> 0.000</td> <td>    0.051</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>   <td>   10.0492</td> <td>    0.737</td> <td>   13.643</td> <td> 0.000</td> <td>    8.605</td> <td>   11.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>   <td>   11.0021</td> <td>    0.504</td> <td>   21.833</td> <td> 0.000</td> <td>   10.014</td> <td>   11.990</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>   <td>   -2.2217</td> <td>    0.339</td> <td>   -6.559</td> <td> 0.000</td> <td>   -2.886</td> <td>   -1.558</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>   <td>   -0.2773</td> <td>    0.056</td> <td>   -4.974</td> <td> 0.000</td> <td>   -0.387</td> <td>   -0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>   <td>   -1.5730</td> <td>    0.765</td> <td>   -2.055</td> <td> 0.040</td> <td>   -3.073</td> <td>   -0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>   <td>   -0.0449</td> <td>    0.023</td> <td>   -1.924</td> <td> 0.054</td> <td>   -0.091</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>   <td>    6.3346</td> <td>    0.343</td> <td>   18.448</td> <td> 0.000</td> <td>    5.662</td> <td>    7.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>   <td>    0.3323</td> <td>    0.521</td> <td>    0.638</td> <td> 0.524</td> <td>   -0.689</td> <td>    1.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>   <td>    5.5860</td> <td>    0.760</td> <td>    7.347</td> <td> 0.000</td> <td>    4.096</td> <td>    7.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>   <td>   -0.0110</td> <td>    0.007</td> <td>   -1.646</td> <td> 0.100</td> <td>   -0.024</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>   <td>   -0.2097</td> <td>    0.522</td> <td>   -0.402</td> <td> 0.688</td> <td>   -1.233</td> <td>    0.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>   <td>    1.4682</td> <td>    0.530</td> <td>    2.771</td> <td> 0.006</td> <td>    0.430</td> <td>    2.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>   <td>    0.4585</td> <td>    0.574</td> <td>    0.799</td> <td> 0.424</td> <td>   -0.666</td> <td>    1.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>   <td>   21.5861</td> <td>    7.708</td> <td>    2.800</td> <td> 0.005</td> <td>    6.477</td> <td>   36.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>   <td>   -5.6280</td> <td>    4.106</td> <td>   -1.371</td> <td> 0.170</td> <td>  -13.675</td> <td>    2.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>   <td>    0.0025</td> <td>    0.000</td> <td>    5.605</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>   <td>   -0.0648</td> <td>    0.009</td> <td>   -6.960</td> <td> 0.000</td> <td>   -0.083</td> <td>   -0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>   <td>    1.0825</td> <td>    1.221</td> <td>    0.887</td> <td> 0.375</td> <td>   -1.310</td> <td>    3.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>   <td>    1.2472</td> <td>    0.841</td> <td>    1.483</td> <td> 0.138</td> <td>   -0.401</td> <td>    2.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>   <td>  -22.5141</td> <td>    4.994</td> <td>   -4.508</td> <td> 0.000</td> <td>  -32.303</td> <td>  -12.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>   <td>    0.5817</td> <td>    0.510</td> <td>    1.140</td> <td> 0.254</td> <td>   -0.419</td> <td>    1.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>   <td>   -0.5441</td> <td>    0.517</td> <td>   -1.052</td> <td> 0.293</td> <td>   -1.557</td> <td>    0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>   <td>    3.9669</td> <td>    0.330</td> <td>   12.008</td> <td> 0.000</td> <td>    3.319</td> <td>    4.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>   <td>    0.1249</td> <td>    0.540</td> <td>    0.231</td> <td> 0.817</td> <td>   -0.933</td> <td>    1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>   <td>    6.1977</td> <td>    0.425</td> <td>   14.570</td> <td> 0.000</td> <td>    5.364</td> <td>    7.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>   <td>   -6.0631</td> <td>    0.446</td> <td>  -13.589</td> <td> 0.000</td> <td>   -6.938</td> <td>   -5.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>   <td>    0.7814</td> <td>    0.696</td> <td>    1.122</td> <td> 0.262</td> <td>   -0.584</td> <td>    2.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>   <td>    1.7329</td> <td>    0.557</td> <td>    3.109</td> <td> 0.002</td> <td>    0.641</td> <td>    2.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>   <td>   -4.3225</td> <td>    1.062</td> <td>   -4.069</td> <td> 0.000</td> <td>   -6.405</td> <td>   -2.240</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>18533.315</td> <th>  Durbin-Watson:     </th>  <td>   1.834</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>734616.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 3.280</td>   <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>29.069</td>   <th>  Cond. No.          </th>  <td>1.40e+06</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.427\n",
       "Model:                            OLS   Adj. R-squared:                  0.426\n",
       "Method:                 Least Squares   F-statistic:                     402.6\n",
       "Date:                Sat, 18 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        13:03:05   Log-Likelihood:            -1.2314e+05\n",
       "No. Observations:               24399   AIC:                         2.464e+05\n",
       "Df Residuals:                   24353   BIC:                         2.467e+05\n",
       "Df Model:                          45                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -1104.1907    414.192     -2.666      0.008   -1916.033    -292.349\n",
       "x1            11.7510      0.280     42.002      0.000      11.203      12.299\n",
       "x2             4.9728      0.767      6.480      0.000       3.469       6.477\n",
       "x3             4.2830      1.085      3.947      0.000       2.156       6.410\n",
       "x4            -1.1309      0.578     -1.955      0.051      -2.265       0.003\n",
       "x5             1.6398      0.752      2.179      0.029       0.165       3.115\n",
       "x6             2.0986      0.767      2.735      0.006       0.595       3.602\n",
       "x7            13.7116      0.601     22.820      0.000      12.534      14.889\n",
       "x8            -0.1306      0.912     -0.143      0.886      -1.918       1.656\n",
       "x9            -1.8945      1.566     -1.210      0.226      -4.964       1.175\n",
       "x10           -2.0042      0.580     -3.454      0.001      -3.142      -0.867\n",
       "x11           -1.6845      0.666     -2.528      0.011      -2.991      -0.378\n",
       "x12            9.0185      0.689     13.082      0.000       7.667      10.370\n",
       "x13           -7.3406      0.657    -11.179      0.000      -8.628      -6.054\n",
       "x14            7.9658      0.526     15.138      0.000       6.934       8.997\n",
       "x15           -0.9354      0.691     -1.355      0.176      -2.289       0.418\n",
       "x16            0.0563      0.003     21.697      0.000       0.051       0.061\n",
       "x17           10.0492      0.737     13.643      0.000       8.605      11.493\n",
       "x18           11.0021      0.504     21.833      0.000      10.014      11.990\n",
       "x19           -2.2217      0.339     -6.559      0.000      -2.886      -1.558\n",
       "x20           -0.2773      0.056     -4.974      0.000      -0.387      -0.168\n",
       "x21           -1.5730      0.765     -2.055      0.040      -3.073      -0.073\n",
       "x22           -0.0449      0.023     -1.924      0.054      -0.091       0.001\n",
       "x23            6.3346      0.343     18.448      0.000       5.662       7.008\n",
       "x24            0.3323      0.521      0.638      0.524      -0.689       1.354\n",
       "x25            5.5860      0.760      7.347      0.000       4.096       7.076\n",
       "x26           -0.0110      0.007     -1.646      0.100      -0.024       0.002\n",
       "x27           -0.2097      0.522     -0.402      0.688      -1.233       0.814\n",
       "x28            1.4682      0.530      2.771      0.006       0.430       2.507\n",
       "x29            0.4585      0.574      0.799      0.424      -0.666       1.583\n",
       "x30           21.5861      7.708      2.800      0.005       6.477      36.695\n",
       "x31           -5.6280      4.106     -1.371      0.170     -13.675       2.419\n",
       "x32            0.0025      0.000      5.605      0.000       0.002       0.003\n",
       "x33           -0.0648      0.009     -6.960      0.000      -0.083      -0.047\n",
       "x34            1.0825      1.221      0.887      0.375      -1.310       3.475\n",
       "x35            1.2472      0.841      1.483      0.138      -0.401       2.896\n",
       "x36          -22.5141      4.994     -4.508      0.000     -32.303     -12.725\n",
       "x37            0.5817      0.510      1.140      0.254      -0.419       1.582\n",
       "x38           -0.5441      0.517     -1.052      0.293      -1.557       0.469\n",
       "x39            3.9669      0.330     12.008      0.000       3.319       4.614\n",
       "x40            0.1249      0.540      0.231      0.817      -0.933       1.183\n",
       "x41            6.1977      0.425     14.570      0.000       5.364       7.031\n",
       "x42           -6.0631      0.446    -13.589      0.000      -6.938      -5.189\n",
       "x43            0.7814      0.696      1.122      0.262      -0.584       2.147\n",
       "x44            1.7329      0.557      3.109      0.002       0.641       2.825\n",
       "x45           -4.3225      1.062     -4.069      0.000      -6.405      -2.240\n",
       "==============================================================================\n",
       "Omnibus:                    18533.315   Durbin-Watson:                   1.834\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           734616.359\n",
       "Skew:                           3.280   Prob(JB):                         0.00\n",
       "Kurtosis:                      29.069   Cond. No.                     1.40e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model summary\n",
    "reg_ols_wo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression (Scikit Learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate and fit model\n",
    "reg_lr = LinearRegression()\n",
    "reg_lr.fit(X_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target\n",
    "y_pred_lr = reg_lr.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 21.372572057152503\n",
      "MSE: 1304.4970239349193\n",
      "RMSE: 36.117821417340764\n",
      "R2: 0.4903321409855689\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot errors\n",
    "plt.scatter(y_test, y_pred_lr)\n",
    "plt.xlabel('Y Test')\n",
    "plt.ylabel('Predicted Y')\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred_lr))\n",
    "print('MSE:', metrics.mean_squared_error(y_test, y_pred_lr))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, y_pred_lr)))\n",
    "print('R2:', r2_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
