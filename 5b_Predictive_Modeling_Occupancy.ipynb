{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "# General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline  # Same, but with the latter it is not necessary to name estimator and transformer\n",
    "#from imblearn.pipeline import Pipeline as Imb_Pipe\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, GenericUnivariateSelect, mutual_info_classif\n",
    "import eli5\n",
    "\n",
    "# Predictive Modeling (Models)\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_predict, cross_val_score, cross_validate, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, PassiveAggressiveRegressor, ElasticNet, SGDRegressor, RANSACRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingRegressor, VotingClassifier, RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, IsolationForest\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer, fbeta_score, accuracy_score, confusion_matrix, f1_score, precision_recall_curve, recall_score, precision_score\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Neural Networks\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import data_engineered\n",
    "data = pd.read_pickle(\"saves/data_engineered.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Alternative: Import from csv\n",
    "#data_types_engineered = pd.read_csv('saves/types_engineered.csv')['types']\n",
    "#data = pd.read_csv(\"saves/data_engineered.csv\", dtype=data_types_engineered.to_dict())\n",
    "#data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Dashboard\n",
    "target = 'occupancy_class'  # for regression: 'occupancy_rate', 'price_log' | for classification: 'occupancy_class'\n",
    "drop_cols = [\n",
    "    'occupancy_rate'\n",
    "]  # additional columns to drop: 'occupancy_class', 'occupancy_rate'\n",
    "scoring = 'f1'  # for regression: 'neg_mean_squared_error', 'r2', 'neg_mean_poisson_deviance', 'neg_median_absolute_error' | for classification: \"f1\", \"recall\", \"precision\", \"accuracy\", \"roc_auc\"\n",
    "test_size = 0.2\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (Train/Test Split and Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "data = data.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows\n",
    "data = data[data.room_type != \"shared_room\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancellation_policy',\n",
       " 'neighbourhood',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'zipcode']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for categorical predictors/features (used in \"Scaling with Preprocessing Pipeline\")\n",
    "cat_features = list(data.columns[data.dtypes == object])\n",
    "#cat_features.remove(\"neighbourhood\")\n",
    "#cat_features.remove(\"zipcode\")\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates',\n",
       " 'accommodates_per_bed',\n",
       " 'am_balcony',\n",
       " 'am_breakfast',\n",
       " 'am_child_friendly',\n",
       " 'am_elevator',\n",
       " 'am_essentials',\n",
       " 'am_nature_and_views',\n",
       " 'am_pets_allowed',\n",
       " 'am_private_entrance',\n",
       " 'am_smoking_allowed',\n",
       " 'am_tv',\n",
       " 'am_white_goods',\n",
       " 'availability_90',\n",
       " 'bathrooms_log',\n",
       " 'bedrooms',\n",
       " 'calculated_host_listings_count',\n",
       " 'first_review_days',\n",
       " 'host_is_superhost',\n",
       " 'instant_bookable',\n",
       " 'last_review_days',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'maximum_nights',\n",
       " 'minimum_nights_log',\n",
       " 'price_extra_fees_sqrt',\n",
       " 'price_extra_people',\n",
       " 'price_log',\n",
       " 'review_scores_rating_sqrt',\n",
       " 'text_len_sqrt',\n",
       " 'wk_mth_discount']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create list for numerical predictors/features (removing target column, used in \"Scaling with Preprocessing Pipeline\")\n",
    "num_features = list(data.columns[data.dtypes != object])\n",
    "num_features.remove(target)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Build preprocessor pipeline\n",
    "# Pipeline for numerical features\n",
    "num_pipeline = Pipeline([('imputer_num', SimpleImputer(strategy='median')),\n",
    "                         ('std_scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline for categorical features\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(drop='first', handle_unknown='error'))\n",
    "])\n",
    "\n",
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([('num', num_pipeline, num_features),\n",
    "                                  ('cat', cat_pipeline, cat_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Function for getting column names after preprocessing\n",
    "def get_column_names_from_ColumnTransformer(column_transformer):\n",
    "    col_name = []\n",
    "    for transformer_in_columns in column_transformer.transformers_[:\n",
    "                                                                   -1]:  #the last transformer is ColumnTransformer's 'remainder'\n",
    "        raw_col_name = transformer_in_columns[2]\n",
    "        if isinstance(transformer_in_columns[1], Pipeline):\n",
    "            transformer = transformer_in_columns[1].steps[-1][1]\n",
    "        else:\n",
    "            transformer = transformer_in_columns[1]\n",
    "        try:\n",
    "            names = transformer.get_feature_names()\n",
    "        except AttributeError:  # if no 'get_feature_names' function, use raw column name\n",
    "            names = raw_col_name\n",
    "        if isinstance(names, np.ndarray):  # eg.\n",
    "            col_name += names.tolist()\n",
    "        elif isinstance(names, list):\n",
    "            col_name += names\n",
    "        elif isinstance(names, str):\n",
    "            col_name.append(names)\n",
    "    return col_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define predictors and target variable\n",
    "X = data.drop([target], axis=1)\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=test_size,\n",
    "                                                    random_state=random_state,\n",
    "                                                    shuffle=True)\n",
    "#                                                   stratify=y) # Use stratify=y if labels are inbalanced (e.g. most wines are 5 or 6; check with value_counts()!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Saving preprocessed X_train and X_test\n",
    "X_train_prep_preprocessor = preprocessor.fit(X_train)\n",
    "X_train_prep_cols = get_column_names_from_ColumnTransformer(\n",
    "    X_train_prep_preprocessor)\n",
    "\n",
    "X_train_prep = X_train_prep_preprocessor.transform(X_train)\n",
    "X_train_num_prep = num_pipeline.fit_transform(X_train[num_features])\n",
    "X_test_prep = X_train_prep_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "#train_outl = num_pipeline.fit_transform(X_train[num_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit DBSCAN model\n",
    "#outl_model = DBSCAN(eps=3.0, min_samples=10).fit(train_outl)\n",
    "#outl_labels = outl_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display results (# of outliers)\n",
    "#pd.Series(outl_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Illustrate results\n",
    "#plt.figure(figsize=(10,10))\n",
    "#\n",
    "#unique_labels = set(outl_labels)\n",
    "#colors = ['blue', 'red']\n",
    "#\n",
    "#for color,label in zip(colors, unique_labels):\n",
    "#    sample_mask = [True if l == label else False for l in outl_labels]\n",
    "#    plt.plot(train_outl[:,0][sample_mask], train_outl[:, 1][sample_mask], 'o', color=color);\n",
    "#plt.xlabel('accommodates_per_bed');\n",
    "#plt.ylabel('accommodates_per_room');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the results:\n",
    "\n",
    "- https://www.kaggle.com/kevinarvai/outlier-detection-practice-uni-multivariate\n",
    "- https://datascience.stackexchange.com/questions/46092/how-do-we-interpret-the-outputs-of-dbscan-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Feature Selection (add most useful to modeling pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Set X_fs to desired variable\n",
    "X_fs = X_train[\n",
    "    num_features]  # X_train_prep, X_train_num_prep, X_train[num_features]\n",
    "#X_fs = pd.DataFrame(X_fs, columns = X_train_prep_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GenericUnivariateSelect** (Classification and Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply GenericUnivariateSelect\n",
    "trans_GUS = GenericUnivariateSelect(score_func=lambda X, y: X.mean(axis=0),\n",
    "                                    mode='k_best',\n",
    "                                    param=15)  #mode='percentile', 'k_best'\n",
    "X_train_GUS = trans_GUS.fit_transform(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mutual_info_classif** (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit mutual_info_classif\n",
    "X_train_mic = mutual_info_classif(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1872x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot feature importance\n",
    "plt.subplots(1, figsize=(26, 1))\n",
    "sns.heatmap(X_train_mic[:, np.newaxis].T,\n",
    "            cmap='Blues',\n",
    "            cbar=False,\n",
    "            linewidths=1,\n",
    "            annot=True)\n",
    "plt.yticks([], [])\n",
    "plt.gca().set_xticklabels(X_fs.columns, rotation=45, ha='right', fontsize=12)\n",
    "plt.suptitle(\"Feature Importance (mutual_info_classif)\", fontsize=18, y=1.2)\n",
    "plt.gcf().subplots_adjust(wspace=0.2)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Apply GenericUnivariateSelect to reduce features (optional)\n",
    "trans_mic = GenericUnivariateSelect(score_func=mutual_info_classif,\n",
    "                                    mode='k_best',\n",
    "                                    param=15)  #mode='percentile', 'k_best',\n",
    "X_train_mic_GUS = trans_mic.fit_transform(X_fs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We started with 30 features but retained only 15 of them!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accommodates</th>\n",
       "      <th>am_white_goods</th>\n",
       "      <th>availability_90</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>first_review_days</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>last_review_days</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>minimum_nights_log</th>\n",
       "      <th>price_extra_fees_sqrt</th>\n",
       "      <th>review_scores_rating_sqrt</th>\n",
       "      <th>text_len_sqrt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>52.49772</td>\n",
       "      <td>13.47841</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.530058</td>\n",
       "      <td>0.067641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>52.51983</td>\n",
       "      <td>13.30225</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.748119</td>\n",
       "      <td>0.427670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>52.50498</td>\n",
       "      <td>13.31578</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>0.305561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52.52299</td>\n",
       "      <td>13.41016</td>\n",
       "      <td>1125.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.627647</td>\n",
       "      <td>0.518208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>52.53618</td>\n",
       "      <td>13.18963</td>\n",
       "      <td>183.0</td>\n",
       "      <td>5.477226</td>\n",
       "      <td>15.811388</td>\n",
       "      <td>8.944272</td>\n",
       "      <td>0.558772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accommodates  am_white_goods  availability_90  \\\n",
       "0           2.0             1.0              0.0   \n",
       "1           2.0             1.0              0.0   \n",
       "2           2.0             1.0             69.0   \n",
       "3           2.0             1.0             11.0   \n",
       "4           3.0             1.0              0.0   \n",
       "\n",
       "   calculated_host_listings_count  first_review_days  host_is_superhost  \\\n",
       "0                             1.0              209.0                1.0   \n",
       "1                             1.0              105.0                0.0   \n",
       "2                             1.0               75.0                0.0   \n",
       "3                             1.0               80.0                0.0   \n",
       "4                            19.0             1118.0                0.0   \n",
       "\n",
       "   instant_bookable  last_review_days  latitude  longitude  maximum_nights  \\\n",
       "0               1.0              49.0  52.49772   13.47841             7.0   \n",
       "1               1.0              79.0  52.51983   13.30225            29.0   \n",
       "2               0.0              16.0  52.50498   13.31578          1125.0   \n",
       "3               1.0              20.0  52.52299   13.41016          1125.0   \n",
       "4               0.0             273.0  52.53618   13.18963           183.0   \n",
       "\n",
       "   minimum_nights_log  price_extra_fees_sqrt  review_scores_rating_sqrt  \\\n",
       "0            1.000000               3.000000                   7.530058   \n",
       "1            1.732051               0.000000                   3.748119   \n",
       "2            1.414214               0.000000                   8.944272   \n",
       "3            1.000000               0.000000                   5.627647   \n",
       "4            5.477226              15.811388                   8.944272   \n",
       "\n",
       "   text_len_sqrt  \n",
       "0       0.067641  \n",
       "1       0.427670  \n",
       "2       0.305561  \n",
       "3       0.518208  \n",
       "4       0.558772  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print kept features\n",
    "print(\"We started with {0} features but retained only {1} of them!\".format(\n",
    "    X_fs.shape[1] - 1, X_train_mic_GUS.shape[1]))\n",
    "\n",
    "columns_retained_Select = X_fs.columns[trans_mic.get_support()].values\n",
    "pd.DataFrame(X_train_mic_GUS, columns=columns_retained_Select).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**chi2** (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mutual_info_regression** (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling: Classification (\"occupancy_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mOCCUPANCY_CLASS\u001b[0m as the target\n",
      "The target variable y is currently set to \u001b[1mOCCUPANCY_CLASS\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "y_upper = y_train.name.upper()\n",
    "print(\"You are currently using \" + f\"\\033[1m{target_upper}\\033[0m\" +\n",
    "      \" as the target\")\n",
    "print(\"The target variable y is currently set to \" +\n",
    "      f\"\\033[1m{y_upper}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select dataset to use\n",
    "#X_train = X_train_mic_GUS_red       # X_train, X_train_GUS, X_train_mic, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "models = {\n",
    "    'Baseline':\n",
    "    DummyClassifier(strategy='most_frequent'),\n",
    "    'LogReg':\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    'KNN':\n",
    "    KNeighborsClassifier(),\n",
    "    'SVC':\n",
    "    SVC(kernel='rbf', C=1E6),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeClassifier(criterion=\"gini\",\n",
    "                           max_depth=3,\n",
    "                           random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestClassifier(random_state=random_state,\n",
    "                           max_features='sqrt',\n",
    "                           n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingClassifier(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBClassifier(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostClassifier(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Baseline: \n",
      "[[6000    0]\n",
      " [2554    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix LogReg: \n",
      "[[5243  757]\n",
      " [ 925 1629]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.2s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix KNN: \n",
      "[[5071  929]\n",
      " [1292 1262]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    9.9s remaining:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix SVC: \n",
      "[[5088  912]\n",
      " [ 986 1568]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Decision Tree: \n",
      "[[4924 1076]\n",
      " [ 647 1907]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    7.4s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Random Forest: \n",
      "[[5588  412]\n",
      " [1171 1383]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.6s remaining:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix Gradient Boost: \n",
      "[[5321  679]\n",
      " [ 763 1791]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.1s remaining:    4.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix XGBoost: \n",
      "[[5307  693]\n",
      " [ 735 1819]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.4s remaining:    2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix AdaBoost: \n",
      "[[5264  736]\n",
      " [ 770 1784]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.298574</td>\n",
       "      <td>0.546419</td>\n",
       "      <td>-0.425667</td>\n",
       "      <td>0.298574</td>\n",
       "      <td>0.701426</td>\n",
       "      <td>0.701426</td>\n",
       "      <td>0.491999</td>\n",
       "      <td>0.578337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.196633</td>\n",
       "      <td>0.443433</td>\n",
       "      <td>0.061092</td>\n",
       "      <td>0.196633</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.803367</td>\n",
       "      <td>0.800081</td>\n",
       "      <td>0.801381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.259645</td>\n",
       "      <td>0.509553</td>\n",
       "      <td>-0.239783</td>\n",
       "      <td>0.259645</td>\n",
       "      <td>0.740355</td>\n",
       "      <td>0.740355</td>\n",
       "      <td>0.730979</td>\n",
       "      <td>0.734236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.221884</td>\n",
       "      <td>0.471046</td>\n",
       "      <td>-0.059481</td>\n",
       "      <td>0.221884</td>\n",
       "      <td>0.778116</td>\n",
       "      <td>0.778116</td>\n",
       "      <td>0.776339</td>\n",
       "      <td>0.777165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.201426</td>\n",
       "      <td>0.448805</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>0.201426</td>\n",
       "      <td>0.798574</td>\n",
       "      <td>0.798574</td>\n",
       "      <td>0.810840</td>\n",
       "      <td>0.802643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.185060</td>\n",
       "      <td>0.430186</td>\n",
       "      <td>0.116355</td>\n",
       "      <td>0.185060</td>\n",
       "      <td>0.814940</td>\n",
       "      <td>0.814940</td>\n",
       "      <td>0.809947</td>\n",
       "      <td>0.804296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.168576</td>\n",
       "      <td>0.410580</td>\n",
       "      <td>0.195062</td>\n",
       "      <td>0.168576</td>\n",
       "      <td>0.831424</td>\n",
       "      <td>0.831424</td>\n",
       "      <td>0.829956</td>\n",
       "      <td>0.830601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>0.408582</td>\n",
       "      <td>0.202877</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>0.833061</td>\n",
       "      <td>0.833061</td>\n",
       "      <td>0.832303</td>\n",
       "      <td>0.832660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.176058</td>\n",
       "      <td>0.419593</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>0.176058</td>\n",
       "      <td>0.823942</td>\n",
       "      <td>0.823942</td>\n",
       "      <td>0.823288</td>\n",
       "      <td>0.823601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model       MSE      RMSE        R2       MAE  Accuracy    Recall  \\\n",
       "0        Baseline  0.298574  0.546419 -0.425667  0.298574  0.701426  0.701426   \n",
       "1          LogReg  0.196633  0.443433  0.061092  0.196633  0.803367  0.803367   \n",
       "2             KNN  0.259645  0.509553 -0.239783  0.259645  0.740355  0.740355   \n",
       "3             SVC  0.221884  0.471046 -0.059481  0.221884  0.778116  0.778116   \n",
       "4   Decision Tree  0.201426  0.448805  0.038205  0.201426  0.798574  0.798574   \n",
       "5   Random Forest  0.185060  0.430186  0.116355  0.185060  0.814940  0.814940   \n",
       "6  Gradient Boost  0.168576  0.410580  0.195062  0.168576  0.831424  0.831424   \n",
       "7         XGBoost  0.166939  0.408582  0.202877  0.166939  0.833061  0.833061   \n",
       "8        AdaBoost  0.176058  0.419593  0.159337  0.176058  0.823942  0.823942   \n",
       "\n",
       "   Precision  F1 Score  \n",
       "0   0.491999  0.578337  \n",
       "1   0.800081  0.801381  \n",
       "2   0.730979  0.734236  \n",
       "3   0.776339  0.777165  \n",
       "4   0.810840  0.802643  \n",
       "5   0.809947  0.804296  \n",
       "6   0.829956  0.830601  \n",
       "7   0.832303  0.832660  \n",
       "8   0.823288  0.823601  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'R2'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model': m[0],\n",
    "            'MSE': mean_squared_error(y_train, y_train_pred),\n",
    "            'RMSE': mean_squared_error(y_train, y_train_pred, squared=False),\n",
    "            'MAE': mean_absolute_error(y_train, y_train_pred),\n",
    "            'R2': r2_score(y_train, y_train_pred),\n",
    "            'Accuracy': accuracy_score(y_train, y_train_pred),\n",
    "            'Recall': recall_score(y_train, y_train_pred, average=\"weighted\"),\n",
    "            'Precision': precision_score(\n",
    "                y_train, y_train_pred, average=\"weighted\"),\n",
    "            'F1 Score': f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "        },\n",
    "        index=[i])\n",
    "    print(f\"Confusion Matrix {m[0]}: \\n\" +\n",
    "          str(confusion_matrix(y_train, y_train_pred)))\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 1: LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomSearchCV and GridSearchCV\n",
    "pipeline_lr_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('lr_clf',\n",
    "                             LogisticRegression(penalty='l2',\n",
    "                                                max_iter=100,\n",
    "                                                C=0.9,\n",
    "                                                random_state=random_state,\n",
    "                                                l1_ratio=0.5,\n",
    "                                                n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for LogisticRegression\n",
    "test_lr_clf = LogisticRegression()\n",
    "test_lr_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_lr_clf = {\n",
    "    'lr_clf__penalty': ['l1', 'l2'],\n",
    "    'lr_clf__max_iter': [10, 50, 100],\n",
    "    'lr_clf__C': [0, 0.05, 0.1, 0.2],\n",
    "    'lr_clf__l1_ratio': [None, 0.1, 0.5, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed:   24.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_lr_clf = GridSearchCV(pipeline_lr_clf,\n",
    "                           param_grid_lr_clf,\n",
    "                           cv=5,\n",
    "                           return_train_score=True,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_lr_clf.fit(X_train, y_train)\n",
    "best_model_lr_clf = grid_lr_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.81\n",
      "Best parameters:\n",
      "{'lr_clf__C': 0.1, 'lr_clf__l1_ratio': None, 'lr_clf__max_iter': 50, 'lr_clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_lr_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_lr_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomSearchCV and GridSearchCV\n",
    "pipeline_rf_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_clf',\n",
    "                             RandomForestClassifier(n_estimators=110,\n",
    "                                                    random_state=random_state,\n",
    "                                                    max_depth=5,\n",
    "                                                    max_features=20,\n",
    "                                                    n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for RandomForestClassifier\n",
    "test_rf_clf = RandomForestClassifier()\n",
    "test_rf_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for LogisticRegression** (as base for hyperparameter search):\n",
    "\n",
    "n_estimators=100, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_clf = {\n",
    "    'rf_clf__n_estimators': [190, 230, 290],\n",
    "    'rf_clf__max_depth': [1, 3, 5, 10],\n",
    "    'rf_clf__max_features': [30, 60, 100],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  7.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_clf = GridSearchCV(pipeline_rf_clf,\n",
    "                           param_grid_rf_clf,\n",
    "                           cv=5,\n",
    "                           return_train_score=True,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_rf_clf.fit(X_train, y_train)\n",
    "best_model_rf_clf = grid_rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.83\n",
      "Best parameters:\n",
      "{'rf_clf__max_depth': 10, 'rf_clf__max_features': 60, 'rf_clf__n_estimators': 190}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_xgb_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_clf',\n",
    "                              XGBClassifier(n_estimators=110,\n",
    "                                            random_state=random_state,\n",
    "                                            max_depth=5,\n",
    "                                            max_features=20,\n",
    "                                            scoring=scoring,\n",
    "                                            n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_clf = {\n",
    "    'xgb_clf__n_estimators': randint(low=10, high=200),\n",
    "    'xgb_clf__max_depth': randint(low=1, high=10),\n",
    "    'xgb_clf__learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_clf = RandomizedSearchCV(pipeline_xgb_clf,\n",
    "                                 param_distribs_xgb_clf,\n",
    "                                 cv=5,\n",
    "                                 n_iter=20,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_clf = rnd_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.84\n",
      "Best parameters:\n",
      "{'xgb_clf__learning_rate': 0.2, 'xgb_clf__max_depth': 2, 'xgb_clf__n_estimators': 141}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_clf.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Fit XGB pipeline\n",
    "pipeline_xgb_clf_fi = pipeline_xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get feature names from pipeline\n",
    "onehot_columns = list(\n",
    "    pipeline_xgb_clf_fi.named_steps['preprocessor'].named_transformers_['cat'].\n",
    "    named_steps['1hot'].get_feature_names(input_features=cat_features))\n",
    "features_prep_list = list(num_features)\n",
    "features_prep_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1482\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                last_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0466\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                instant_bookable\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0329\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                minimum_nights_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0311\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                availability_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0310\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                review_scores_rating_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.94%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0269\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                host_is_superhost\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0251\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                first_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0236\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Prenzlauer Berg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0221\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_smoking_allowed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.08%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0200\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_breakfast\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.12%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0198\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_other\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0171\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12045\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0165\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Hotel room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0155\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10437\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0136\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_essentials\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0134\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10963\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.30%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0133\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.37%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0130\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Kreuzberg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                accommodates\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0123\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                text_len_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0123\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Tiergarten\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.53%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10589\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10827\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0114\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_child_friendly\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0113\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_13347\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0110\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cancellation_policy_moderate\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0109\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10178\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0109\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                maximum_nights\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0108\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_white_goods\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0108\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10435\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10551\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0103\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0103\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10439\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Private room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                calculated_host_listings_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_pets_allowed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                property_type_Boutique hotel\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.01%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10243\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.02%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                accommodates_per_bed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0096\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wk_mth_discount\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.14%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_people\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10557\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.15%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bedrooms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12047\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_fees_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.23%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_13088\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0087\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                property_type_House\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10247\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_balcony\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.32%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 111 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"XGBClassifier(max_depth=5, max_features=20, n_estimators=110, n_jobs=-1,\\n              random_state=42, scoring='f1')\", description='\\nXGBoost feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='last_review_days', weight=0.14816476, std=None, value=None), FeatureWeight(feature='instant_bookable', weight=0.04664588, std=None, value=None), FeatureWeight(feature='minimum_nights_log', weight=0.0328894, std=None, value=None), FeatureWeight(feature='availability_90', weight=0.031106316, std=None, value=None), FeatureWeight(feature='review_scores_rating_sqrt', weight=0.03102368, std=None, value=None), FeatureWeight(feature='host_is_superhost', weight=0.02689868, std=None, value=None), FeatureWeight(feature='first_review_days', weight=0.025064098, std=None, value=None), FeatureWeight(feature='neighbourhood_Prenzlauer Berg', weight=0.023598809, std=None, value=None), FeatureWeight(feature='am_smoking_allowed', weight=0.022107992, std=None, value=None), FeatureWeight(feature='am_breakfast', weight=0.019968525, std=None, value=None), FeatureWeight(feature='zipcode_zip_other', weight=0.019762298, std=None, value=None), FeatureWeight(feature='zipcode_zip_12045', weight=0.017139224, std=None, value=None), FeatureWeight(feature='room_type_Hotel room', weight=0.016482005, std=None, value=None), FeatureWeight(feature='zipcode_zip_10437', weight=0.015535438, std=None, value=None), FeatureWeight(feature='am_essentials', weight=0.013579426, std=None, value=None), FeatureWeight(feature='zipcode_zip_10963', weight=0.013414957, std=None, value=None), FeatureWeight(feature='latitude', weight=0.01332073, std=None, value=None), FeatureWeight(feature='neighbourhood_Kreuzberg', weight=0.012960235, std=None, value=None), FeatureWeight(feature='accommodates', weight=0.0127300285, std=None, value=None), FeatureWeight(feature='text_len_sqrt', weight=0.012268547, std=None, value=None), FeatureWeight(feature='neighbourhood_Tiergarten', weight=0.0122655025, std=None, value=None), FeatureWeight(feature='zipcode_zip_10589', weight=0.0121422075, std=None, value=None), FeatureWeight(feature='zipcode_zip_10827', weight=0.012105269, std=None, value=None), FeatureWeight(feature='am_child_friendly', weight=0.011438491, std=None, value=None), FeatureWeight(feature='zipcode_zip_13347', weight=0.011305135, std=None, value=None), FeatureWeight(feature='cancellation_policy_moderate', weight=0.010955179, std=None, value=None), FeatureWeight(feature='zipcode_zip_10178', weight=0.010883003, std=None, value=None), FeatureWeight(feature='maximum_nights', weight=0.010880247, std=None, value=None), FeatureWeight(feature='am_white_goods', weight=0.010848387, std=None, value=None), FeatureWeight(feature='zipcode_zip_10435', weight=0.010839632, std=None, value=None), FeatureWeight(feature='zipcode_zip_10551', weight=0.01061028, std=None, value=None), FeatureWeight(feature='price_log', weight=0.010260007, std=None, value=None), FeatureWeight(feature='zipcode_zip_10439', weight=0.01025529, std=None, value=None), FeatureWeight(feature='room_type_Private room', weight=0.010231376, std=None, value=None), FeatureWeight(feature='calculated_host_listings_count', weight=0.01022802, std=None, value=None), FeatureWeight(feature='am_pets_allowed', weight=0.010208776, std=None, value=None), FeatureWeight(feature='property_type_Boutique hotel', weight=0.010046708, std=None, value=None), FeatureWeight(feature='longitude', weight=0.010039362, std=None, value=None), FeatureWeight(feature='zipcode_zip_10243', weight=0.009808379, std=None, value=None), FeatureWeight(feature='accommodates_per_bed', weight=0.009782527, std=None, value=None), FeatureWeight(feature='wk_mth_discount', weight=0.009559014, std=None, value=None), FeatureWeight(feature='price_extra_people', weight=0.009218025, std=None, value=None), FeatureWeight(feature='zipcode_zip_10557', weight=0.009170913, std=None, value=None), FeatureWeight(feature='bedrooms', weight=0.009168325, std=None, value=None), FeatureWeight(feature='zipcode_zip_12047', weight=0.008982221, std=None, value=None), FeatureWeight(feature='price_extra_fees_sqrt', weight=0.008976682, std=None, value=None), FeatureWeight(feature='zipcode_zip_13088', weight=0.00880743, std=None, value=None), FeatureWeight(feature='property_type_House', weight=0.008735234, std=None, value=None), FeatureWeight(feature='zipcode_zip_10247', weight=0.008422613, std=None, value=None), FeatureWeight(feature='am_balcony', weight=0.008396273, std=None, value=None)], remaining=111), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine and print feature importance\n",
    "eli5.explain_weights(pipeline_xgb_clf_fi.named_steps['xgb_clf'],\n",
    "                     top=50,\n",
    "                     feature_names=features_prep_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clf Model 4: Supply Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomizedSearchCV and GridSearchCV\n",
    "pipeline_svm_clf = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('svm_clf',\n",
    "                              SVC(kernel='rbf',\n",
    "                                  C=1,\n",
    "                                  degree=3,\n",
    "                                  random_state=random_state))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for Supply Vector Machine\n",
    "test_rf_clf = SVC()\n",
    "test_rf_clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for Supply Vector Machine** (as base for hyperparameter search):\n",
    "\n",
    "C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_svm_clf = {\n",
    "    'svm_clf__kernel': ['linear', 'poly', 'rbf'],\n",
    "    'svm_clf__C': [0.1, 0.5, 1, 2, 5, 10, 50, 100, 500, 1000],\n",
    "    'svm_clf__degree': randint(low=1, high=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  9.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  9.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_svm_clf = RandomizedSearchCV(pipeline_svm_clf,\n",
    "                                 param_distribs_svm_clf,\n",
    "                                 cv=5,\n",
    "                                 n_iter=5,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_svm_clf = rnd_svm_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.80\n",
      "Best parameters:\n",
      "{'svm_clf__C': 100, 'svm_clf__degree': 1, 'svm_clf__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_svm_clf.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_svm_clf.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_clf.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation with Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_test for final evaluation\n",
    "#X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "#y_pred_rf_clf = best_model_rf_clf.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred_rf_clf)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_test, y_pred_rf_clf)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_test, y_pred_rf_clf)))\n",
    "#print(\"F1 Score: {:.2f}\".format(f1_score(y_test, y_pred_rf_clf)))\n",
    "#print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred_rf_clf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling: Regression (\"occupancy_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mOCCUPANCY_RATE\u001b[0m as the target\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "print(\"You are currently using \" + f\"\\033[1m{target_upper}\\033[0m\" +\n",
    "      \" as the target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_train_prep and y_train to required format\n",
    "#X_train_prep_ols = X_train_prep.toarray()            # OneHotEncoder outputs csr_matrix, which gives an error when trying to add a constant. Hence, transformed into numpy array\n",
    "#X_train_prep_ols = sm.add_constant(X_train_prep_ols)\n",
    "#y_train_ols = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "reg_ols = sm.OLS(y_train, X_train_prep).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>occupancy_rate</td>  <th>  R-squared (uncentered):</th>      <td>   0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.552</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   71.21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 27 Jul 2020</td> <th>  Prob (F-statistic):</th>           <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:55:04</td>     <th>  Log-Likelihood:    </th>          <td> -606.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6783</td>      <th>  AIC:               </th>          <td>   1451.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6664</td>      <th>  BIC:               </th>          <td>   2263.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   119</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>   <td>    0.0026</td> <td>    0.004</td> <td>    0.700</td> <td> 0.484</td> <td>   -0.005</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>   <td>    0.0194</td> <td>    0.004</td> <td>    4.548</td> <td> 0.000</td> <td>    0.011</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>   <td>   -0.0054</td> <td>    0.004</td> <td>   -1.549</td> <td> 0.121</td> <td>   -0.012</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>   <td>   -0.0133</td> <td>    0.003</td> <td>   -3.994</td> <td> 0.000</td> <td>   -0.020</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>   <td>   -0.0020</td> <td>    0.004</td> <td>   -0.509</td> <td> 0.611</td> <td>   -0.010</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>   <td>    0.0005</td> <td>    0.004</td> <td>    0.141</td> <td> 0.888</td> <td>   -0.007</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>   <td>    0.0126</td> <td>    0.003</td> <td>    3.608</td> <td> 0.000</td> <td>    0.006</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>   <td>   -0.0011</td> <td>    0.003</td> <td>   -0.327</td> <td> 0.744</td> <td>   -0.008</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>   <td>   -0.0049</td> <td>    0.003</td> <td>   -1.436</td> <td> 0.151</td> <td>   -0.011</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>  <td>    0.0045</td> <td>    0.004</td> <td>    1.272</td> <td> 0.204</td> <td>   -0.002</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>  <td>   -0.0083</td> <td>    0.003</td> <td>   -2.431</td> <td> 0.015</td> <td>   -0.015</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>  <td>    0.0096</td> <td>    0.004</td> <td>    2.544</td> <td> 0.011</td> <td>    0.002</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>  <td>   -0.0117</td> <td>    0.003</td> <td>   -3.349</td> <td> 0.001</td> <td>   -0.019</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>  <td>    0.0530</td> <td>    0.004</td> <td>   14.487</td> <td> 0.000</td> <td>    0.046</td> <td>    0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>  <td>   -0.0033</td> <td>    0.004</td> <td>   -0.900</td> <td> 0.368</td> <td>   -0.011</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>  <td>    0.0340</td> <td>    0.005</td> <td>    7.373</td> <td> 0.000</td> <td>    0.025</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>  <td>   -0.0085</td> <td>    0.004</td> <td>   -2.428</td> <td> 0.015</td> <td>   -0.015</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>  <td>    0.0235</td> <td>    0.005</td> <td>    4.286</td> <td> 0.000</td> <td>    0.013</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>  <td>    0.0123</td> <td>    0.004</td> <td>    2.733</td> <td> 0.006</td> <td>    0.003</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>  <td>    0.0650</td> <td>    0.004</td> <td>   16.801</td> <td> 0.000</td> <td>    0.057</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>  <td>    0.0443</td> <td>    0.003</td> <td>   12.673</td> <td> 0.000</td> <td>    0.037</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>  <td>   -0.0748</td> <td>    0.004</td> <td>  -20.763</td> <td> 0.000</td> <td>   -0.082</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>  <td>    0.0030</td> <td>    0.005</td> <td>    0.564</td> <td> 0.573</td> <td>   -0.007</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>  <td>   -0.0114</td> <td>    0.005</td> <td>   -2.442</td> <td> 0.015</td> <td>   -0.020</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>  <td>    0.0076</td> <td>    0.003</td> <td>    2.252</td> <td> 0.024</td> <td>    0.001</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>  <td>    0.0008</td> <td>    0.003</td> <td>    0.234</td> <td> 0.815</td> <td>   -0.006</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>  <td>    0.0092</td> <td>    0.004</td> <td>    2.394</td> <td> 0.017</td> <td>    0.002</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>  <td>    0.0007</td> <td>    0.004</td> <td>    0.175</td> <td> 0.861</td> <td>   -0.007</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>  <td>    0.0036</td> <td>    0.004</td> <td>    0.969</td> <td> 0.332</td> <td>   -0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>  <td>   -0.0093</td> <td>    0.004</td> <td>   -2.387</td> <td> 0.017</td> <td>   -0.017</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>  <td>   -0.0266</td> <td>    0.004</td> <td>   -7.283</td> <td> 0.000</td> <td>   -0.034</td> <td>   -0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>  <td>   -0.0750</td> <td>    0.005</td> <td>  -14.392</td> <td> 0.000</td> <td>   -0.085</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>  <td>   -0.0145</td> <td>    0.004</td> <td>   -3.927</td> <td> 0.000</td> <td>   -0.022</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>  <td>    0.0394</td> <td>    0.009</td> <td>    4.150</td> <td> 0.000</td> <td>    0.021</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>  <td>   -0.0069</td> <td>    0.010</td> <td>   -0.717</td> <td> 0.473</td> <td>   -0.026</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>  <td>   -0.0114</td> <td>    0.004</td> <td>   -2.989</td> <td> 0.003</td> <td>   -0.019</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>  <td>    0.0172</td> <td>    0.009</td> <td>    1.892</td> <td> 0.059</td> <td>   -0.001</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>  <td>    0.0168</td> <td>    0.009</td> <td>    1.849</td> <td> 0.065</td> <td>   -0.001</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>  <td>   -0.0973</td> <td>    0.043</td> <td>   -2.260</td> <td> 0.024</td> <td>   -0.182</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>  <td>    0.1804</td> <td>    0.048</td> <td>    3.753</td> <td> 0.000</td> <td>    0.086</td> <td>    0.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>  <td>    0.3211</td> <td>    0.061</td> <td>    5.246</td> <td> 0.000</td> <td>    0.201</td> <td>    0.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>  <td>    0.1993</td> <td>    0.059</td> <td>    3.376</td> <td> 0.001</td> <td>    0.084</td> <td>    0.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>  <td>    0.1437</td> <td>    0.071</td> <td>    2.033</td> <td> 0.042</td> <td>    0.005</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>  <td>    0.0984</td> <td>    0.063</td> <td>    1.555</td> <td> 0.120</td> <td>   -0.026</td> <td>    0.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>  <td>    0.3340</td> <td>    0.019</td> <td>   17.699</td> <td> 0.000</td> <td>    0.297</td> <td>    0.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>  <td>    0.1857</td> <td>    0.085</td> <td>    2.185</td> <td> 0.029</td> <td>    0.019</td> <td>    0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>  <td>    0.2101</td> <td>    0.054</td> <td>    3.897</td> <td> 0.000</td> <td>    0.104</td> <td>    0.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>  <td>    0.4895</td> <td>    0.108</td> <td>    4.519</td> <td> 0.000</td> <td>    0.277</td> <td>    0.702</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>  <td>    0.3741</td> <td>    0.037</td> <td>   10.234</td> <td> 0.000</td> <td>    0.302</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>  <td>    0.0443</td> <td>    0.060</td> <td>    0.734</td> <td> 0.463</td> <td>   -0.074</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>  <td>   -0.0463</td> <td>    0.162</td> <td>   -0.286</td> <td> 0.775</td> <td>   -0.363</td> <td>    0.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>  <td>    0.1771</td> <td>    0.049</td> <td>    3.631</td> <td> 0.000</td> <td>    0.081</td> <td>    0.273</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>  <td>    0.1022</td> <td>    0.058</td> <td>    1.767</td> <td> 0.077</td> <td>   -0.011</td> <td>    0.216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>  <td>    0.1110</td> <td>    0.054</td> <td>    2.062</td> <td> 0.039</td> <td>    0.005</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>  <td>    0.2039</td> <td>    0.079</td> <td>    2.566</td> <td> 0.010</td> <td>    0.048</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>  <td>    0.1872</td> <td>    0.052</td> <td>    3.580</td> <td> 0.000</td> <td>    0.085</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>  <td>    0.1862</td> <td>    0.062</td> <td>    2.987</td> <td> 0.003</td> <td>    0.064</td> <td>    0.308</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>  <td>    0.0404</td> <td>    0.059</td> <td>    0.685</td> <td> 0.493</td> <td>   -0.075</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>  <td>    0.1056</td> <td>    0.050</td> <td>    2.104</td> <td> 0.035</td> <td>    0.007</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>  <td>    0.0821</td> <td>    0.045</td> <td>    1.841</td> <td> 0.066</td> <td>   -0.005</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>  <td>   -0.0985</td> <td>    0.073</td> <td>   -1.349</td> <td> 0.177</td> <td>   -0.242</td> <td>    0.045</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>  <td>   -0.0565</td> <td>    0.025</td> <td>   -2.258</td> <td> 0.024</td> <td>   -0.105</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>  <td>   -0.0212</td> <td>    0.020</td> <td>   -1.086</td> <td> 0.278</td> <td>   -0.059</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>  <td>   -0.0059</td> <td>    0.034</td> <td>   -0.174</td> <td> 0.862</td> <td>   -0.072</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>  <td>   -0.0576</td> <td>    0.071</td> <td>   -0.812</td> <td> 0.417</td> <td>   -0.197</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>  <td>   -0.1001</td> <td>    0.036</td> <td>   -2.817</td> <td> 0.005</td> <td>   -0.170</td> <td>   -0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>  <td>   -0.0732</td> <td>    0.010</td> <td>   -7.701</td> <td> 0.000</td> <td>   -0.092</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>  <td>   -0.1787</td> <td>    0.039</td> <td>   -4.629</td> <td> 0.000</td> <td>   -0.254</td> <td>   -0.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>  <td>  1.35e-05</td> <td>    0.029</td> <td>    0.000</td> <td> 1.000</td> <td>   -0.056</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>  <td>   -0.0136</td> <td>    0.026</td> <td>   -0.526</td> <td> 0.599</td> <td>   -0.064</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>  <td>    0.0409</td> <td>    0.032</td> <td>    1.275</td> <td> 0.202</td> <td>   -0.022</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>  <td>   -0.0280</td> <td>    0.030</td> <td>   -0.931</td> <td> 0.352</td> <td>   -0.087</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>  <td>    0.0079</td> <td>    0.065</td> <td>    0.121</td> <td> 0.903</td> <td>   -0.119</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>  <td>   -0.0471</td> <td>    0.063</td> <td>   -0.745</td> <td> 0.456</td> <td>   -0.171</td> <td>    0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>  <td>   -0.0381</td> <td>    0.063</td> <td>   -0.610</td> <td> 0.542</td> <td>   -0.161</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>  <td>   -0.0658</td> <td>    0.063</td> <td>   -1.040</td> <td> 0.299</td> <td>   -0.190</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>  <td>    0.3759</td> <td>    0.165</td> <td>    2.281</td> <td> 0.023</td> <td>    0.053</td> <td>    0.699</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>  <td>    0.1377</td> <td>    0.081</td> <td>    1.701</td> <td> 0.089</td> <td>   -0.021</td> <td>    0.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>  <td>   -0.0398</td> <td>    0.041</td> <td>   -0.977</td> <td> 0.329</td> <td>   -0.120</td> <td>    0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>  <td>   -0.0867</td> <td>    0.045</td> <td>   -1.937</td> <td> 0.053</td> <td>   -0.174</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>  <td>   -0.1128</td> <td>    0.059</td> <td>   -1.900</td> <td> 0.057</td> <td>   -0.229</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>  <td>   -0.0542</td> <td>    0.037</td> <td>   -1.454</td> <td> 0.146</td> <td>   -0.127</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>  <td>   -0.0554</td> <td>    0.040</td> <td>   -1.381</td> <td> 0.167</td> <td>   -0.134</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>  <td>   -0.0982</td> <td>    0.041</td> <td>   -2.411</td> <td> 0.016</td> <td>   -0.178</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>  <td>    0.0289</td> <td>    0.092</td> <td>    0.313</td> <td> 0.754</td> <td>   -0.152</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>  <td>    0.0325</td> <td>    0.097</td> <td>    0.334</td> <td> 0.738</td> <td>   -0.158</td> <td>    0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>  <td>    0.0329</td> <td>    0.093</td> <td>    0.355</td> <td> 0.723</td> <td>   -0.149</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>  <td>    0.1211</td> <td>    0.081</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.037</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>  <td>    0.1300</td> <td>    0.091</td> <td>    1.424</td> <td> 0.154</td> <td>   -0.049</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>  <td>    0.1131</td> <td>    0.057</td> <td>    1.970</td> <td> 0.049</td> <td>    0.001</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>  <td>    0.1718</td> <td>    0.082</td> <td>    2.087</td> <td> 0.037</td> <td>    0.010</td> <td>    0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>  <td>    0.1454</td> <td>    0.060</td> <td>    2.426</td> <td> 0.015</td> <td>    0.028</td> <td>    0.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>  <td>    0.0387</td> <td>    0.061</td> <td>    0.631</td> <td> 0.528</td> <td>   -0.082</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>  <td>    0.1289</td> <td>    0.064</td> <td>    2.006</td> <td> 0.045</td> <td>    0.003</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>  <td>    0.1594</td> <td>    0.063</td> <td>    2.534</td> <td> 0.011</td> <td>    0.036</td> <td>    0.283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>  <td>    0.0921</td> <td>    0.063</td> <td>    1.470</td> <td> 0.142</td> <td>   -0.031</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>  <td>    0.1171</td> <td>    0.063</td> <td>    1.867</td> <td> 0.062</td> <td>   -0.006</td> <td>    0.240</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>  <td>    0.1370</td> <td>    0.068</td> <td>    2.027</td> <td> 0.043</td> <td>    0.005</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>  <td>    0.1199</td> <td>    0.063</td> <td>    1.893</td> <td> 0.058</td> <td>   -0.004</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th> <td>    0.1063</td> <td>    0.063</td> <td>    1.701</td> <td> 0.089</td> <td>   -0.016</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th> <td>    0.0361</td> <td>    0.061</td> <td>    0.588</td> <td> 0.556</td> <td>   -0.084</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th> <td>    0.0716</td> <td>    0.060</td> <td>    1.200</td> <td> 0.230</td> <td>   -0.045</td> <td>    0.188</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th> <td>    0.0808</td> <td>    0.059</td> <td>    1.369</td> <td> 0.171</td> <td>   -0.035</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th> <td>    0.0518</td> <td>    0.059</td> <td>    0.878</td> <td> 0.380</td> <td>   -0.064</td> <td>    0.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th> <td>    0.0188</td> <td>    0.060</td> <td>    0.315</td> <td> 0.753</td> <td>   -0.098</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th> <td>    0.0884</td> <td>    0.061</td> <td>    1.440</td> <td> 0.150</td> <td>   -0.032</td> <td>    0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th> <td>    0.0178</td> <td>    0.062</td> <td>    0.287</td> <td> 0.774</td> <td>   -0.104</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th> <td>    0.0530</td> <td>    0.060</td> <td>    0.886</td> <td> 0.376</td> <td>   -0.064</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th> <td>    0.2322</td> <td>    0.040</td> <td>    5.749</td> <td> 0.000</td> <td>    0.153</td> <td>    0.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th> <td>    0.1425</td> <td>    0.071</td> <td>    2.011</td> <td> 0.044</td> <td>    0.004</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th> <td>   -0.3244</td> <td>    0.117</td> <td>   -2.783</td> <td> 0.005</td> <td>   -0.553</td> <td>   -0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th> <td>   -0.3001</td> <td>    0.118</td> <td>   -2.536</td> <td> 0.011</td> <td>   -0.532</td> <td>   -0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th> <td>    0.0968</td> <td>    0.061</td> <td>    1.577</td> <td> 0.115</td> <td>   -0.024</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th> <td>    0.0472</td> <td>    0.059</td> <td>    0.799</td> <td> 0.424</td> <td>   -0.069</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th> <td>    0.0841</td> <td>    0.063</td> <td>    1.340</td> <td> 0.180</td> <td>   -0.039</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th> <td>   -0.0553</td> <td>    0.062</td> <td>   -0.888</td> <td> 0.375</td> <td>   -0.177</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th> <td>    0.0810</td> <td>    0.066</td> <td>    1.229</td> <td> 0.219</td> <td>   -0.048</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th> <td>    0.0868</td> <td>    0.044</td> <td>    1.952</td> <td> 0.051</td> <td>   -0.000</td> <td>    0.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th> <td>    0.0937</td> <td>    0.045</td> <td>    2.102</td> <td> 0.036</td> <td>    0.006</td> <td>    0.181</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>803.205</td> <th>  Durbin-Watson:     </th> <td>   1.986</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1119.486</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.938</td>  <th>  Prob(JB):          </th> <td>8.07e-244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.663</td>  <th>  Cond. No.          </th> <td>    181.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:         occupancy_rate   R-squared (uncentered):                   0.560\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.552\n",
       "Method:                 Least Squares   F-statistic:                              71.21\n",
       "Date:                Mon, 27 Jul 2020   Prob (F-statistic):                        0.00\n",
       "Time:                        19:55:04   Log-Likelihood:                         -606.54\n",
       "No. Observations:                6783   AIC:                                      1451.\n",
       "Df Residuals:                    6664   BIC:                                      2263.\n",
       "Df Model:                         119                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0026      0.004      0.700      0.484      -0.005       0.010\n",
       "x2             0.0194      0.004      4.548      0.000       0.011       0.028\n",
       "x3            -0.0054      0.004     -1.549      0.121      -0.012       0.001\n",
       "x4            -0.0133      0.003     -3.994      0.000      -0.020      -0.007\n",
       "x5            -0.0020      0.004     -0.509      0.611      -0.010       0.006\n",
       "x6             0.0005      0.004      0.141      0.888      -0.007       0.008\n",
       "x7             0.0126      0.003      3.608      0.000       0.006       0.019\n",
       "x8            -0.0011      0.003     -0.327      0.744      -0.008       0.006\n",
       "x9            -0.0049      0.003     -1.436      0.151      -0.011       0.002\n",
       "x10            0.0045      0.004      1.272      0.204      -0.002       0.011\n",
       "x11           -0.0083      0.003     -2.431      0.015      -0.015      -0.002\n",
       "x12            0.0096      0.004      2.544      0.011       0.002       0.017\n",
       "x13           -0.0117      0.003     -3.349      0.001      -0.019      -0.005\n",
       "x14            0.0530      0.004     14.487      0.000       0.046       0.060\n",
       "x15           -0.0033      0.004     -0.900      0.368      -0.011       0.004\n",
       "x16            0.0340      0.005      7.373      0.000       0.025       0.043\n",
       "x17           -0.0085      0.004     -2.428      0.015      -0.015      -0.002\n",
       "x18            0.0235      0.005      4.286      0.000       0.013       0.034\n",
       "x19            0.0123      0.004      2.733      0.006       0.003       0.021\n",
       "x20            0.0650      0.004     16.801      0.000       0.057       0.073\n",
       "x21            0.0443      0.003     12.673      0.000       0.037       0.051\n",
       "x22           -0.0748      0.004    -20.763      0.000      -0.082      -0.068\n",
       "x23            0.0030      0.005      0.564      0.573      -0.007       0.013\n",
       "x24           -0.0114      0.005     -2.442      0.015      -0.020      -0.002\n",
       "x25            0.0076      0.003      2.252      0.024       0.001       0.014\n",
       "x26            0.0008      0.003      0.234      0.815      -0.006       0.007\n",
       "x27            0.0092      0.004      2.394      0.017       0.002       0.017\n",
       "x28            0.0007      0.004      0.175      0.861      -0.007       0.008\n",
       "x29            0.0036      0.004      0.969      0.332      -0.004       0.011\n",
       "x30           -0.0093      0.004     -2.387      0.017      -0.017      -0.002\n",
       "x31           -0.0266      0.004     -7.283      0.000      -0.034      -0.019\n",
       "x32           -0.0750      0.005    -14.392      0.000      -0.085      -0.065\n",
       "x33           -0.0145      0.004     -3.927      0.000      -0.022      -0.007\n",
       "x34            0.0394      0.009      4.150      0.000       0.021       0.058\n",
       "x35           -0.0069      0.010     -0.717      0.473      -0.026       0.012\n",
       "x36           -0.0114      0.004     -2.989      0.003      -0.019      -0.004\n",
       "x37            0.0172      0.009      1.892      0.059      -0.001       0.035\n",
       "x38            0.0168      0.009      1.849      0.065      -0.001       0.035\n",
       "x39           -0.0973      0.043     -2.260      0.024      -0.182      -0.013\n",
       "x40            0.1804      0.048      3.753      0.000       0.086       0.275\n",
       "x41            0.3211      0.061      5.246      0.000       0.201       0.441\n",
       "x42            0.1993      0.059      3.376      0.001       0.084       0.315\n",
       "x43            0.1437      0.071      2.033      0.042       0.005       0.282\n",
       "x44            0.0984      0.063      1.555      0.120      -0.026       0.222\n",
       "x45            0.3340      0.019     17.699      0.000       0.297       0.371\n",
       "x46            0.1857      0.085      2.185      0.029       0.019       0.352\n",
       "x47            0.2101      0.054      3.897      0.000       0.104       0.316\n",
       "x48            0.4895      0.108      4.519      0.000       0.277       0.702\n",
       "x49            0.3741      0.037     10.234      0.000       0.302       0.446\n",
       "x50            0.0443      0.060      0.734      0.463      -0.074       0.163\n",
       "x51           -0.0463      0.162     -0.286      0.775      -0.363       0.271\n",
       "x52            0.1771      0.049      3.631      0.000       0.081       0.273\n",
       "x53            0.1022      0.058      1.767      0.077      -0.011       0.216\n",
       "x54            0.1110      0.054      2.062      0.039       0.005       0.217\n",
       "x55            0.2039      0.079      2.566      0.010       0.048       0.360\n",
       "x56            0.1872      0.052      3.580      0.000       0.085       0.290\n",
       "x57            0.1862      0.062      2.987      0.003       0.064       0.308\n",
       "x58            0.0404      0.059      0.685      0.493      -0.075       0.156\n",
       "x59            0.1056      0.050      2.104      0.035       0.007       0.204\n",
       "x60            0.0821      0.045      1.841      0.066      -0.005       0.170\n",
       "x61           -0.0985      0.073     -1.349      0.177      -0.242       0.045\n",
       "x62           -0.0565      0.025     -2.258      0.024      -0.105      -0.007\n",
       "x63           -0.0212      0.020     -1.086      0.278      -0.059       0.017\n",
       "x64           -0.0059      0.034     -0.174      0.862      -0.072       0.061\n",
       "x65           -0.0576      0.071     -0.812      0.417      -0.197       0.081\n",
       "x66           -0.1001      0.036     -2.817      0.005      -0.170      -0.030\n",
       "x67           -0.0732      0.010     -7.701      0.000      -0.092      -0.055\n",
       "x68           -0.1787      0.039     -4.629      0.000      -0.254      -0.103\n",
       "x69          1.35e-05      0.029      0.000      1.000      -0.056       0.056\n",
       "x70           -0.0136      0.026     -0.526      0.599      -0.064       0.037\n",
       "x71            0.0409      0.032      1.275      0.202      -0.022       0.104\n",
       "x72           -0.0280      0.030     -0.931      0.352      -0.087       0.031\n",
       "x73            0.0079      0.065      0.121      0.903      -0.119       0.135\n",
       "x74           -0.0471      0.063     -0.745      0.456      -0.171       0.077\n",
       "x75           -0.0381      0.063     -0.610      0.542      -0.161       0.084\n",
       "x76           -0.0658      0.063     -1.040      0.299      -0.190       0.058\n",
       "x77            0.3759      0.165      2.281      0.023       0.053       0.699\n",
       "x78            0.1377      0.081      1.701      0.089      -0.021       0.296\n",
       "x79           -0.0398      0.041     -0.977      0.329      -0.120       0.040\n",
       "x80           -0.0867      0.045     -1.937      0.053      -0.174       0.001\n",
       "x81           -0.1128      0.059     -1.900      0.057      -0.229       0.004\n",
       "x82           -0.0542      0.037     -1.454      0.146      -0.127       0.019\n",
       "x83           -0.0554      0.040     -1.381      0.167      -0.134       0.023\n",
       "x84           -0.0982      0.041     -2.411      0.016      -0.178      -0.018\n",
       "x85            0.0289      0.092      0.313      0.754      -0.152       0.210\n",
       "x86            0.0325      0.097      0.334      0.738      -0.158       0.223\n",
       "x87            0.0329      0.093      0.355      0.723      -0.149       0.215\n",
       "x88            0.1211      0.081      1.499      0.134      -0.037       0.279\n",
       "x89            0.1300      0.091      1.424      0.154      -0.049       0.309\n",
       "x90            0.1131      0.057      1.970      0.049       0.001       0.226\n",
       "x91            0.1718      0.082      2.087      0.037       0.010       0.333\n",
       "x92            0.1454      0.060      2.426      0.015       0.028       0.263\n",
       "x93            0.0387      0.061      0.631      0.528      -0.082       0.159\n",
       "x94            0.1289      0.064      2.006      0.045       0.003       0.255\n",
       "x95            0.1594      0.063      2.534      0.011       0.036       0.283\n",
       "x96            0.0921      0.063      1.470      0.142      -0.031       0.215\n",
       "x97            0.1171      0.063      1.867      0.062      -0.006       0.240\n",
       "x98            0.1370      0.068      2.027      0.043       0.005       0.269\n",
       "x99            0.1199      0.063      1.893      0.058      -0.004       0.244\n",
       "x100           0.1063      0.063      1.701      0.089      -0.016       0.229\n",
       "x101           0.0361      0.061      0.588      0.556      -0.084       0.156\n",
       "x102           0.0716      0.060      1.200      0.230      -0.045       0.188\n",
       "x103           0.0808      0.059      1.369      0.171      -0.035       0.197\n",
       "x104           0.0518      0.059      0.878      0.380      -0.064       0.168\n",
       "x105           0.0188      0.060      0.315      0.753      -0.098       0.136\n",
       "x106           0.0884      0.061      1.440      0.150      -0.032       0.209\n",
       "x107           0.0178      0.062      0.287      0.774      -0.104       0.139\n",
       "x108           0.0530      0.060      0.886      0.376      -0.064       0.170\n",
       "x109           0.2322      0.040      5.749      0.000       0.153       0.311\n",
       "x110           0.1425      0.071      2.011      0.044       0.004       0.281\n",
       "x111          -0.3244      0.117     -2.783      0.005      -0.553      -0.096\n",
       "x112          -0.3001      0.118     -2.536      0.011      -0.532      -0.068\n",
       "x113           0.0968      0.061      1.577      0.115      -0.024       0.217\n",
       "x114           0.0472      0.059      0.799      0.424      -0.069       0.163\n",
       "x115           0.0841      0.063      1.340      0.180      -0.039       0.207\n",
       "x116          -0.0553      0.062     -0.888      0.375      -0.177       0.067\n",
       "x117           0.0810      0.066      1.229      0.219      -0.048       0.210\n",
       "x118           0.0868      0.044      1.952      0.051      -0.000       0.174\n",
       "x119           0.0937      0.045      2.102      0.036       0.006       0.181\n",
       "==============================================================================\n",
       "Omnibus:                      803.205   Durbin-Watson:                   1.986\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1119.486\n",
       "Skew:                           0.938   Prob(JB):                    8.07e-244\n",
       "Kurtosis:                       3.663   Cond. No.                         181.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model summary\n",
    "reg_ols.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Predict target (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply linear regression w/o preprocessing/differently (to roughly see feature importance)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get num_features as string as basis for model\n",
    "num_feat_list = str(num_features)\n",
    "num_feat_list = num_feat_list.strip(\"[\").strip(\"]\").replace(\"'\", \"\").replace(\n",
    "    \", \", \" + \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define target and features for model\n",
    "model = f'{target} ~ {num_feat_list}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "reg_ols_wo = smf.ols(formula=model, data=data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>occupancy_rate</td>  <th>  R-squared:         </th> <td>   0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   75.95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 27 Jul 2020</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:55:42</td>     <th>  Log-Likelihood:    </th> <td> -1012.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8479</td>      <th>  AIC:               </th> <td>   2099.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8442</td>      <th>  BIC:               </th> <td>   2360.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    36</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                      <td>  -21.8752</td> <td>    5.051</td> <td>   -4.331</td> <td> 0.000</td> <td>  -31.776</td> <td>  -11.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accommodates_per_bed</th>           <td>    0.0104</td> <td>    0.005</td> <td>    2.255</td> <td> 0.024</td> <td>    0.001</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>accommodates_per_room</th>          <td>    0.0138</td> <td>    0.003</td> <td>    5.077</td> <td> 0.000</td> <td>    0.008</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_balcony</th>                     <td>   -0.0262</td> <td>    0.007</td> <td>   -3.608</td> <td> 0.000</td> <td>   -0.040</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_breakfast</th>                   <td>   -0.0687</td> <td>    0.014</td> <td>   -4.781</td> <td> 0.000</td> <td>   -0.097</td> <td>   -0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_child_friendly</th>              <td>   -0.0076</td> <td>    0.008</td> <td>   -1.004</td> <td> 0.316</td> <td>   -0.022</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_elevator</th>                    <td>    0.0139</td> <td>    0.007</td> <td>    1.920</td> <td> 0.055</td> <td>   -0.000</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_essentials</th>                  <td>    0.0597</td> <td>    0.016</td> <td>    3.796</td> <td> 0.000</td> <td>    0.029</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_nature_and_views</th>            <td>   -0.0309</td> <td>    0.015</td> <td>   -2.023</td> <td> 0.043</td> <td>   -0.061</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_pets_allowed</th>                <td>   -0.0192</td> <td>    0.008</td> <td>   -2.381</td> <td> 0.017</td> <td>   -0.035</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_private_entrance</th>            <td>    0.0167</td> <td>    0.007</td> <td>    2.227</td> <td> 0.026</td> <td>    0.002</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_smoking_allowed</th>             <td>   -0.0272</td> <td>    0.009</td> <td>   -2.968</td> <td> 0.003</td> <td>   -0.045</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_tv</th>                          <td>    0.0147</td> <td>    0.007</td> <td>    2.225</td> <td> 0.026</td> <td>    0.002</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>am_white_goods</th>                 <td>   -0.0357</td> <td>    0.008</td> <td>   -4.497</td> <td> 0.000</td> <td>   -0.051</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>availability_90</th>                <td>    0.0012</td> <td> 9.87e-05</td> <td>   12.213</td> <td> 0.000</td> <td>    0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms_log</th>                  <td>   -0.0531</td> <td>    0.015</td> <td>   -3.649</td> <td> 0.000</td> <td>   -0.082</td> <td>   -0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bedrooms</th>                       <td>    0.0439</td> <td>    0.006</td> <td>    7.192</td> <td> 0.000</td> <td>    0.032</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>binary_chg</th>                     <td>   -0.0262</td> <td>    0.009</td> <td>   -3.025</td> <td> 0.002</td> <td>   -0.043</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>calculated_host_listings_count</th> <td>    0.0015</td> <td>    0.001</td> <td>    2.919</td> <td> 0.004</td> <td>    0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>first_review_days</th>              <td> 3.142e-05</td> <td>  5.9e-06</td> <td>    5.329</td> <td> 0.000</td> <td> 1.99e-05</td> <td>  4.3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>host_is_superhost</th>              <td>    0.1270</td> <td>    0.007</td> <td>   17.439</td> <td> 0.000</td> <td>    0.113</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>instant_bookable</th>               <td>    0.0852</td> <td>    0.006</td> <td>   13.387</td> <td> 0.000</td> <td>    0.073</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_review_days</th>               <td>   -0.0015</td> <td> 5.56e-05</td> <td>  -26.148</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>latitude</th>                       <td>    0.4333</td> <td>    0.094</td> <td>    4.595</td> <td> 0.000</td> <td>    0.248</td> <td>    0.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>longitude</th>                      <td>   -0.0410</td> <td>    0.048</td> <td>   -0.854</td> <td> 0.393</td> <td>   -0.135</td> <td>    0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>maximum_nights</th>                 <td> 1.526e-05</td> <td>  5.5e-06</td> <td>    2.776</td> <td> 0.006</td> <td> 4.48e-06</td> <td>  2.6e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights_chg</th>             <td>    0.0004</td> <td>    0.001</td> <td>    0.394</td> <td> 0.693</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>minimum_nights_log</th>             <td>    0.0143</td> <td>    0.003</td> <td>    5.198</td> <td> 0.000</td> <td>    0.009</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numeric_chg</th>                    <td>    0.0173</td> <td>    0.008</td> <td>    2.131</td> <td> 0.033</td> <td>    0.001</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_chg_2020_01</th>              <td>   -0.0003</td> <td>    0.000</td> <td>   -0.696</td> <td> 0.487</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_extra_fees_sqrt</th>          <td>   -0.0003</td> <td>    0.000</td> <td>   -0.667</td> <td> 0.505</td> <td>   -0.001</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_extra_people</th>             <td>   -0.0026</td> <td>    0.000</td> <td>   -7.384</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>price_log</th>                      <td>   -0.0671</td> <td>    0.007</td> <td>   -9.928</td> <td> 0.000</td> <td>   -0.080</td> <td>   -0.054</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>review_scores_rating_sqrt</th>      <td>   -0.0125</td> <td>    0.003</td> <td>   -4.865</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>text_len_chg</th>                   <td>    0.7512</td> <td>    0.182</td> <td>    4.117</td> <td> 0.000</td> <td>    0.394</td> <td>    1.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>text_len_sqrt</th>                  <td>    0.0005</td> <td>    0.052</td> <td>    0.011</td> <td> 0.992</td> <td>   -0.101</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wk_mth_discount</th>                <td>   -0.1279</td> <td>    0.035</td> <td>   -3.679</td> <td> 0.000</td> <td>   -0.196</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1046.174</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1473.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.974</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.615</td>  <th>  Cond. No.          </th> <td>1.98e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.98e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         occupancy_rate   R-squared:                       0.245\n",
       "Model:                            OLS   Adj. R-squared:                  0.241\n",
       "Method:                 Least Squares   F-statistic:                     75.95\n",
       "Date:                Mon, 27 Jul 2020   Prob (F-statistic):               0.00\n",
       "Time:                        19:55:42   Log-Likelihood:                -1012.6\n",
       "No. Observations:                8479   AIC:                             2099.\n",
       "Df Residuals:                    8442   BIC:                             2360.\n",
       "Df Model:                          36                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "Intercept                        -21.8752      5.051     -4.331      0.000     -31.776     -11.975\n",
       "accommodates_per_bed               0.0104      0.005      2.255      0.024       0.001       0.019\n",
       "accommodates_per_room              0.0138      0.003      5.077      0.000       0.008       0.019\n",
       "am_balcony                        -0.0262      0.007     -3.608      0.000      -0.040      -0.012\n",
       "am_breakfast                      -0.0687      0.014     -4.781      0.000      -0.097      -0.041\n",
       "am_child_friendly                 -0.0076      0.008     -1.004      0.316      -0.022       0.007\n",
       "am_elevator                        0.0139      0.007      1.920      0.055      -0.000       0.028\n",
       "am_essentials                      0.0597      0.016      3.796      0.000       0.029       0.090\n",
       "am_nature_and_views               -0.0309      0.015     -2.023      0.043      -0.061      -0.001\n",
       "am_pets_allowed                   -0.0192      0.008     -2.381      0.017      -0.035      -0.003\n",
       "am_private_entrance                0.0167      0.007      2.227      0.026       0.002       0.031\n",
       "am_smoking_allowed                -0.0272      0.009     -2.968      0.003      -0.045      -0.009\n",
       "am_tv                              0.0147      0.007      2.225      0.026       0.002       0.028\n",
       "am_white_goods                    -0.0357      0.008     -4.497      0.000      -0.051      -0.020\n",
       "availability_90                    0.0012   9.87e-05     12.213      0.000       0.001       0.001\n",
       "bathrooms_log                     -0.0531      0.015     -3.649      0.000      -0.082      -0.025\n",
       "bedrooms                           0.0439      0.006      7.192      0.000       0.032       0.056\n",
       "binary_chg                        -0.0262      0.009     -3.025      0.002      -0.043      -0.009\n",
       "calculated_host_listings_count     0.0015      0.001      2.919      0.004       0.000       0.002\n",
       "first_review_days               3.142e-05    5.9e-06      5.329      0.000    1.99e-05     4.3e-05\n",
       "host_is_superhost                  0.1270      0.007     17.439      0.000       0.113       0.141\n",
       "instant_bookable                   0.0852      0.006     13.387      0.000       0.073       0.098\n",
       "last_review_days                  -0.0015   5.56e-05    -26.148      0.000      -0.002      -0.001\n",
       "latitude                           0.4333      0.094      4.595      0.000       0.248       0.618\n",
       "longitude                         -0.0410      0.048     -0.854      0.393      -0.135       0.053\n",
       "maximum_nights                  1.526e-05    5.5e-06      2.776      0.006    4.48e-06     2.6e-05\n",
       "minimum_nights_chg                 0.0004      0.001      0.394      0.693      -0.002       0.002\n",
       "minimum_nights_log                 0.0143      0.003      5.198      0.000       0.009       0.020\n",
       "numeric_chg                        0.0173      0.008      2.131      0.033       0.001       0.033\n",
       "price_chg_2020_01                 -0.0003      0.000     -0.696      0.487      -0.001       0.001\n",
       "price_extra_fees_sqrt             -0.0003      0.000     -0.667      0.505      -0.001       0.000\n",
       "price_extra_people                -0.0026      0.000     -7.384      0.000      -0.003      -0.002\n",
       "price_log                         -0.0671      0.007     -9.928      0.000      -0.080      -0.054\n",
       "review_scores_rating_sqrt         -0.0125      0.003     -4.865      0.000      -0.018      -0.007\n",
       "text_len_chg                       0.7512      0.182      4.117      0.000       0.394       1.109\n",
       "text_len_sqrt                      0.0005      0.052      0.011      0.992      -0.101       0.102\n",
       "wk_mth_discount                   -0.1279      0.035     -3.679      0.000      -0.196      -0.060\n",
       "==============================================================================\n",
       "Omnibus:                     1046.174   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1473.087\n",
       "Skew:                           0.974   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.615   Cond. No.                     1.98e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.98e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print model summary\n",
    "reg_ols_wo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Feature Importance (R_Squared) for all features in \"data\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select explanatory variables\n",
    "explanatory_vars = list(X.columns)\n",
    "explanatory_vars = [e for e in explanatory_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared for each possible feature:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>R_SQUARED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>last_review_days</td>\n",
       "      <td>0.112698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>host_is_superhost</td>\n",
       "      <td>0.057308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>instant_bookable</td>\n",
       "      <td>0.041860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text_len_chg</td>\n",
       "      <td>0.035603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text_len_sqrt</td>\n",
       "      <td>0.032148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zipcode</td>\n",
       "      <td>0.026706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neighbourhood</td>\n",
       "      <td>0.023476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>availability_90</td>\n",
       "      <td>0.018410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cancellation_policy</td>\n",
       "      <td>0.014955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>review_scores_rating_sqrt</td>\n",
       "      <td>0.009727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>calculated_host_listings_count</td>\n",
       "      <td>0.009414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>accommodates_per_room</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>am_white_goods</td>\n",
       "      <td>0.008084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>room_type</td>\n",
       "      <td>0.007447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>first_review_days</td>\n",
       "      <td>0.007202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>am_tv</td>\n",
       "      <td>0.006270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>am_smoking_allowed</td>\n",
       "      <td>0.005776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>am_breakfast</td>\n",
       "      <td>0.005464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>property_type</td>\n",
       "      <td>0.004091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.004073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           FEATURE  R_SQUARED\n",
       "18                last_review_days   0.112698\n",
       "20               host_is_superhost   0.057308\n",
       "19                instant_bookable   0.041860\n",
       "3                     text_len_chg   0.035603\n",
       "2                    text_len_sqrt   0.032148\n",
       "0                          zipcode   0.026706\n",
       "12                   neighbourhood   0.023476\n",
       "27                 availability_90   0.018410\n",
       "22             cancellation_policy   0.014955\n",
       "5        review_scores_rating_sqrt   0.009727\n",
       "23  calculated_host_listings_count   0.009414\n",
       "39           accommodates_per_room   0.008417\n",
       "28                  am_white_goods   0.008084\n",
       "4                        room_type   0.007447\n",
       "21               first_review_days   0.007202\n",
       "29                           am_tv   0.006270\n",
       "30              am_smoking_allowed   0.005776\n",
       "37                    am_breakfast   0.005464\n",
       "6                    property_type   0.004091\n",
       "17                        latitude   0.004073"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Top 10 sorted R_Squared among possible features\n",
    "feat_imp_ols = pd.DataFrame([[\"baseline\", 0.0]])\n",
    "print('R squared for each possible feature:')\n",
    "for explanatory_var in explanatory_vars:\n",
    "    model = '{target} ~ {feature}'.format(target=target,\n",
    "                                          feature=explanatory_var)\n",
    "    rs = smf.ols(formula=model, data=data).fit().rsquared\n",
    "    new_row = pd.DataFrame([[model.split(\" ~ \")[-1], rs]])\n",
    "    feat_imp_ols = pd.concat([new_row, feat_imp_ols], ignore_index=True)\n",
    "feat_imp_ols.columns = [\"FEATURE\", \"R_SQUARED\"]\n",
    "feat_imp_ols.sort_values(by=[\"R_SQUARED\"],\n",
    "                         axis=0,\n",
    "                         ascending=False,\n",
    "                         inplace=True)\n",
    "feat_imp_ols.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mOCCUPANCY_RATE\u001b[0m as the target\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "y_upper = y_train.name.upper()\n",
    "print(\"You are currently using \" + f\"\\033[1m{target_upper}\\033[0m\" +\n",
    "      \" as the target\")\n",
    "print(\"The target variable y is currently set to \" +\n",
    "      f\"\\033[1m{y_upper}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Select models for comparison\n",
    "models = {\n",
    "    'Baseline':\n",
    "    DummyRegressor(strategy='mean'),\n",
    "    'LinReg':\n",
    "    LinearRegression(),\n",
    "    'Passive Aggressive':\n",
    "    PassiveAggressiveRegressor(),\n",
    "    #        'RANSAC' : RANSACRegressor(),\n",
    "    'ElasticNet':\n",
    "    ElasticNet(),\n",
    "    'Stochastic Gradient Descent':\n",
    "    SGDRegressor(max_iter=1000, tol=1e-3),\n",
    "    'Decision Tree':\n",
    "    DecisionTreeRegressor(criterion=\"mse\",\n",
    "                          max_depth=3,\n",
    "                          random_state=random_state),\n",
    "    'Random Forest':\n",
    "    RandomForestRegressor(random_state=random_state,\n",
    "                          max_features='sqrt',\n",
    "                          n_jobs=-1),\n",
    "    'Gradient Boost':\n",
    "    GradientBoostingRegressor(random_state=random_state),\n",
    "    'XGBoost':\n",
    "    XGBRegressor(),\n",
    "    'AdaBoost':\n",
    "    AdaBoostRegressor(random_state=random_state)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.6s remaining:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.7s remaining:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    3.7s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    4.8s remaining:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.8s remaining:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passive Aggressive</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RANSAC</td>\n",
       "      <td>15387083049859152871424.00</td>\n",
       "      <td>124044681666.97</td>\n",
       "      <td>-156693053427880508260352.00</td>\n",
       "      <td>14563282270.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boost</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model                         MSE             RMSE  \\\n",
       "0                      Baseline                        0.10             0.31   \n",
       "1                        LinReg                        0.07             0.27   \n",
       "2            Passive Aggressive                        0.13             0.36   \n",
       "3                        RANSAC  15387083049859152871424.00  124044681666.97   \n",
       "4                    ElasticNet                        0.10             0.31   \n",
       "5   Stochastic Gradient Descent                        0.07             0.27   \n",
       "6                 Decision Tree                        0.07             0.26   \n",
       "7                 Random Forest                        0.06             0.24   \n",
       "8                Gradient Boost                        0.06             0.24   \n",
       "9                       XGBoost                        0.06             0.24   \n",
       "10                     AdaBoost                        0.07             0.26   \n",
       "\n",
       "                              R2             MAE  \n",
       "0                          -0.00            0.26  \n",
       "1                           0.26            0.21  \n",
       "2                          -0.32            0.28  \n",
       "3   -156693053427880508260352.00  14563282270.37  \n",
       "4                          -0.00            0.26  \n",
       "5                           0.25            0.21  \n",
       "6                           0.31            0.19  \n",
       "7                           0.41            0.18  \n",
       "8                           0.43            0.17  \n",
       "9                           0.43            0.17  \n",
       "10                          0.29            0.22  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display results\n",
    "results = pd.DataFrame(columns=['Model', 'MSE', 'RMSE', 'R2'])\n",
    "i = 0\n",
    "for m in models.items():\n",
    "    # Building a full pipeline with our preprocessor and a Classifier\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), (m[0], m[1])])\n",
    "    # Making predictions on the training set using cross validation as well as calculating the probabilities\n",
    "    y_train_pred = cross_val_predict(pipe,\n",
    "                                     X_train,\n",
    "                                     y_train.values.ravel(),\n",
    "                                     cv=5,\n",
    "                                     verbose=4,\n",
    "                                     n_jobs=-1)\n",
    "    # Calculating metrices\n",
    "    temp = pd.DataFrame(\n",
    "        {\n",
    "            'Model':\n",
    "            m[0],\n",
    "            'MSE':\n",
    "            \"{:.2f}\".format(mean_squared_error(y_train, y_train_pred)),\n",
    "            'RMSE':\n",
    "            \"{:.2f}\".format(\n",
    "                mean_squared_error(y_train, y_train_pred, squared=False)),\n",
    "            'MAE':\n",
    "            \"{:.2f}\".format(mean_absolute_error(y_train, y_train_pred)),\n",
    "            'R2':\n",
    "            \"{:.2f}\".format(r2_score(y_train, y_train_pred))\n",
    "        },\n",
    "        index=[i])\n",
    "    i += 1\n",
    "    results = pd.concat([results, temp])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 1: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are currently using \u001b[1mOCCUPANCY_RATE\u001b[0m as the target\n"
     ]
    }
   ],
   "source": [
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "y_upper = y_train.name.upper()\n",
    "print(\"You are currently using \" + f\"\\033[1m{target_upper}\\033[0m\" +\n",
    "      \" as the target\")\n",
    "print(\"The target variable y is currently set to \" +\n",
    "      f\"\\033[1m{y_upper}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomSearchCV and GridSearchCV\n",
    "pipeline_rf_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                            ('rf_reg',\n",
    "                             RandomForestRegressor(n_estimators=110,\n",
    "                                                   random_state=random_state,\n",
    "                                                   max_depth=5,\n",
    "                                                   max_features=20,\n",
    "                                                   scoring=scoring,\n",
    "                                                   n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for RandomForestRegressor\n",
    "test_rf_reg = RandomForestRegressor()\n",
    "test_rf_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for RandomForestRegressor** (as base for hyperparameter search):\n",
    "\n",
    "n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_rf_reg = {\n",
    "    'rf_reg__n_estimators': randint(low=10, high=200),\n",
    "    'rf_reg__max_features': randint(low=1, high=50),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:   34.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   41.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_rf_reg = RandomizedSearchCV(pipeline_rf_reg,\n",
    "                                param_distribs_rf_reg,\n",
    "                                cv=5,\n",
    "                                n_iter=20,\n",
    "                                return_train_score=True,\n",
    "                                verbose=4,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=random_state)\n",
    "\n",
    "best_model_rnd_rf_reg = rnd_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.38\n",
      "Best parameters:\n",
      "{'rf_reg__max_features': 47, 'rf_reg__n_estimators': 199}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_rf_reg_fi = pipeline_rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = list(\n",
    "    pipeline_rf_reg_fi.named_steps['preprocessor'].named_transformers_['cat'].\n",
    "    named_steps['1hot'].get_feature_names(input_features=cat_features))\n",
    "features_prep_list = list(num_features)\n",
    "features_prep_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.3967\n",
       "                \n",
       "                    &plusmn; 0.4092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                last_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1576\n",
       "                \n",
       "                    &plusmn; 0.2850\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                availability_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0824\n",
       "                \n",
       "                    &plusmn; 0.1641\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                host_is_superhost\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.27%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0665\n",
       "                \n",
       "                    &plusmn; 0.1344\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                review_scores_rating_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0498\n",
       "                \n",
       "                    &plusmn; 0.1196\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                instant_bookable\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0431\n",
       "                \n",
       "                    &plusmn; 0.1076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                text_len_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0323\n",
       "                \n",
       "                    &plusmn; 0.0721\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                text_len_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0280\n",
       "                \n",
       "                    &plusmn; 0.0541\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                minimum_nights_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0252\n",
       "                \n",
       "                    &plusmn; 0.0651\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                calculated_host_listings_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0167\n",
       "                \n",
       "                    &plusmn; 0.0387\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0126\n",
       "                \n",
       "                    &plusmn; 0.0280\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                first_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "                    &plusmn; 0.0223\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0070\n",
       "                \n",
       "                    &plusmn; 0.0214\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0061\n",
       "                \n",
       "                    &plusmn; 0.0186\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_fees_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 98.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0055\n",
       "                \n",
       "                    &plusmn; 0.0217\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_nb_other\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.03%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0052\n",
       "                \n",
       "                    &plusmn; 0.0220\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                accommodates_per_room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0043\n",
       "                \n",
       "                    &plusmn; 0.0214\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_other\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0042\n",
       "                \n",
       "                    &plusmn; 0.0185\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_white_goods\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0041\n",
       "                \n",
       "                    &plusmn; 0.0138\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                minimum_nights_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0036\n",
       "                \n",
       "                    &plusmn; 0.0173\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Private room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0035\n",
       "                \n",
       "                    &plusmn; 0.0154\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_people\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0025\n",
       "                \n",
       "                    &plusmn; 0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                maximum_nights\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.49%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0021\n",
       "                \n",
       "                    &plusmn; 0.0094\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                accommodates_per_bed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0019\n",
       "                \n",
       "                    &plusmn; 0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Mitte\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0017\n",
       "                \n",
       "                    &plusmn; 0.0149\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Prenzlauer Berg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0016\n",
       "                \n",
       "                    &plusmn; 0.0106\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                binary_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0013\n",
       "                \n",
       "                    &plusmn; 0.0087\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10435\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wk_mth_discount\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0074\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_tv\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10243\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.68%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0011\n",
       "                \n",
       "                    &plusmn; 0.0077\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_essentials\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0055\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bathrooms_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0010\n",
       "                \n",
       "                    &plusmn; 0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_smoking_allowed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10179\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0009\n",
       "                \n",
       "                    &plusmn; 0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bedrooms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0080\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_breakfast\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.75%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0008\n",
       "                \n",
       "                    &plusmn; 0.0066\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10117\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.75%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                numeric_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0052\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10178\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0064\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10965\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.77%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0007\n",
       "                \n",
       "                    &plusmn; 0.0085\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cancellation_policy_super_strict\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0053\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                property_type_House\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0006\n",
       "                \n",
       "                    &plusmn; 0.0049\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_13353\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0057\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Hotel room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0031\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_chg_2020_01\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0039\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_pets_allowed\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0048\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_balcony\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Kreuzberg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0040\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_private_entrance\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0005\n",
       "                \n",
       "                    &plusmn; 0.0045\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12047\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 69 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='RandomForestRegressor(max_depth=5, max_features=20, n_estimators=110, n_jobs=-1,\\n                      random_state=42)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='last_review_days', weight=0.39666678360576463, std=0.20460178161785617, value=None), FeatureWeight(feature='availability_90', weight=0.15762668187773074, std=0.14249247263132106, value=None), FeatureWeight(feature='host_is_superhost', weight=0.08241232154481126, std=0.08204028253861732, value=None), FeatureWeight(feature='review_scores_rating_sqrt', weight=0.06653890467483278, std=0.06719211850455566, value=None), FeatureWeight(feature='instant_bookable', weight=0.04984753617166597, std=0.0597896760052855, value=None), FeatureWeight(feature='text_len_chg', weight=0.04305045256366493, std=0.053783295776308075, value=None), FeatureWeight(feature='text_len_sqrt', weight=0.03233587707087533, std=0.03607263353408465, value=None), FeatureWeight(feature='minimum_nights_log', weight=0.027981563063367278, std=0.027058558946733598, value=None), FeatureWeight(feature='calculated_host_listings_count', weight=0.025215593811484176, std=0.03255140399834609, value=None), FeatureWeight(feature='latitude', weight=0.01668076442416417, std=0.019325764354567874, value=None), FeatureWeight(feature='first_review_days', weight=0.012638648457097145, std=0.013977943034158922, value=None), FeatureWeight(feature='longitude', weight=0.007418351169857617, std=0.011149994852579448, value=None), FeatureWeight(feature='price_log', weight=0.007038997847945371, std=0.010719354756888896, value=None), FeatureWeight(feature='price_extra_fees_sqrt', weight=0.006080006249544726, std=0.009277737444973289, value=None), FeatureWeight(feature='neighbourhood_nb_other', weight=0.005546309198150814, std=0.010837936111791091, value=None), FeatureWeight(feature='accommodates_per_room', weight=0.005236329407104609, std=0.011020560889000355, value=None), FeatureWeight(feature='zipcode_zip_other', weight=0.004262378293983613, std=0.010687188829213887, value=None), FeatureWeight(feature='am_white_goods', weight=0.004234694060449545, std=0.009239879998658208, value=None), FeatureWeight(feature='minimum_nights_chg', weight=0.0041054698901420725, std=0.006886414857929292, value=None), FeatureWeight(feature='room_type_Private room', weight=0.0036498906469993493, std=0.008664641382940057, value=None), FeatureWeight(feature='price_extra_people', weight=0.0034521482042688526, std=0.007704916035999039, value=None), FeatureWeight(feature='maximum_nights', weight=0.0024993688164391364, std=0.005208925390373565, value=None), FeatureWeight(feature='accommodates_per_bed', weight=0.002071688125001538, std=0.00472360215031763, value=None), FeatureWeight(feature='neighbourhood_Mitte', weight=0.0018994642044971037, std=0.0048767196944892125, value=None), FeatureWeight(feature='neighbourhood_Prenzlauer Berg', weight=0.0017417236442114508, std=0.007435363709458473, value=None), FeatureWeight(feature='binary_chg', weight=0.0016072913927467041, std=0.00531805426808875, value=None), FeatureWeight(feature='zipcode_zip_10435', weight=0.0013425833973608056, std=0.004369366985721831, value=None), FeatureWeight(feature='wk_mth_discount', weight=0.0011152500467423742, std=0.0032892242614950724, value=None), FeatureWeight(feature='am_tv', weight=0.001091850048331304, std=0.003688403114331644, value=None), FeatureWeight(feature='zipcode_zip_10243', weight=0.0010805026617257847, std=0.0032222509685956636, value=None), FeatureWeight(feature='am_essentials', weight=0.0010800794994044434, std=0.003839520644902805, value=None), FeatureWeight(feature='bathrooms_log', weight=0.0009667652358732738, std=0.002756801097208028, value=None), FeatureWeight(feature='am_smoking_allowed', weight=0.0009582664439695119, std=0.004488004099853761, value=None), FeatureWeight(feature='zipcode_zip_10179', weight=0.0009032452581432124, std=0.0037797867183627805, value=None), FeatureWeight(feature='bedrooms', weight=0.0008880954965140033, std=0.003671670315049593, value=None), FeatureWeight(feature='am_breakfast', weight=0.0007799444304841409, std=0.00399848864645728, value=None), FeatureWeight(feature='zipcode_zip_10117', weight=0.0007706939257032843, std=0.0032822605722292344, value=None), FeatureWeight(feature='numeric_chg', weight=0.0007390872855698239, std=0.0023844141877543035, value=None), FeatureWeight(feature='zipcode_zip_10178', weight=0.000731589839183387, std=0.002610947664024712, value=None), FeatureWeight(feature='zipcode_zip_10965', weight=0.0007289394376307596, std=0.00321117717042301, value=None), FeatureWeight(feature='cancellation_policy_super_strict', weight=0.0006862196043729512, std=0.004227199651123061, value=None), FeatureWeight(feature='property_type_House', weight=0.0005717656472066388, std=0.0026403951856613533, value=None), FeatureWeight(feature='zipcode_zip_13353', weight=0.0005592724247906118, std=0.002455771303591391, value=None), FeatureWeight(feature='room_type_Hotel room', weight=0.0005355834284938766, std=0.002847315511107575, value=None), FeatureWeight(feature='price_chg_2020_01', weight=0.0005312416680897433, std=0.001566787893882162, value=None), FeatureWeight(feature='am_pets_allowed', weight=0.0005223808911742417, std=0.0019565245493655082, value=None), FeatureWeight(feature='am_balcony', weight=0.0005106912545776236, std=0.0023963689092664866, value=None), FeatureWeight(feature='neighbourhood_Kreuzberg', weight=0.0004955618432084947, std=0.00253662620919533, value=None), FeatureWeight(feature='am_private_entrance', weight=0.0004901156854050469, std=0.00202089133473326, value=None), FeatureWeight(feature='zipcode_zip_12047', weight=0.0004731822308273469, std=0.0022608210432371262, value=None)], remaining=69), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(pipeline_rf_reg_fi.named_steps['rf_reg'],\n",
    "                     top=50,\n",
    "                     feature_names=features_prep_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_rf_reg = [\n",
    "    {\n",
    "        'rf_reg__n_estimators': [190, 230, 290],\n",
    "        'rf_reg__max_features': [45, 60, 75]\n",
    "    },\n",
    "    {\n",
    "        'rf_reg__bootstrap': [False],\n",
    "        'rf_reg__n_estimators': [190, 230, 290],\n",
    "        'rf_reg__max_features': [45, 60, 75]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:  2.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_rf_reg = GridSearchCV(pipeline_rf_reg,\n",
    "                           param_grid_rf_reg,\n",
    "                           cv=5,\n",
    "                           return_train_score=True,\n",
    "                           verbose=4,\n",
    "                           n_jobs=-1)\n",
    "\n",
    "grid_rf_reg.fit(X_train, y_train)\n",
    "best_model_rf_reg = grid_rf_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.38\n",
      "Best parameters:\n",
      "{'rf_reg__max_features': 45, 'rf_reg__n_estimators': 230}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_rf_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_rf_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get and print feature_importances\n",
    "#feature_importances = grid_rf_reg.best_estimator_.feature_importances_\n",
    "#feature_importances\n",
    "#cat_encoder = preprocessor.named_transformers_[\"cat\"]\n",
    "#cat_one_hot_features = list(cat_encoder.categories_[0])\n",
    "#attributes = num_features + cat_one_hot_features\n",
    "#sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed evaluation with training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-529-14fa9d71d116>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict target with \"best model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_pred_rf_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_rf_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;31m# TODO: also call _check_n_features(reset=False) in 0.24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_feature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 467\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ColumnTransformer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m--> 466\u001b[0;31m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0m\u001b[1;32m    467\u001b[0m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindices_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         raise ValueError(\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;34m\"Specifying the columns using strings is only supported for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;34m\"pandas DataFrames\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_rf_reg = best_model_rf_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "print(\"MSE: {:.2f}\".format(mean_squared_error(y_test, y_train_pred_rf_reg))),\n",
    "print(\"RMSE: {:.2f}\".format(\n",
    "    mean_squared_error(y_test, y_train_pred_rf_reg, squared=False))),\n",
    "print(\"MAE: {:.2f}\".format(mean_absolute_error(y_test, y_train_pred_rf_reg))),\n",
    "print(\"R2: {:.2f}\".format(r2_score(y_test, y_train_pred_rf_reg))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_train_pred_rf_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reg Model 2: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Print current setting for TARGET\n",
    "target_upper = target.upper()\n",
    "y_upper = y_train.name.upper()\n",
    "print(\"You are currently using \" + f\"\\033[1m{target_upper}\\033[0m\" +\n",
    "      \" as the target\")\n",
    "print(\"The target variable y is currently set to \" +\n",
    "      f\"\\033[1m{y_upper}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create pipeline to use in RandomSearchCV and GridSearchCV\n",
    "pipeline_xgb_reg = Pipeline([('preprocessor', preprocessor),\n",
    "                             ('xgb_reg',\n",
    "                              XGBRegressor(n_estimators=110,\n",
    "                                           random_state=random_state,\n",
    "                                           max_depth=5,\n",
    "                                           max_features=20,\n",
    "                                           scoring=scoring,\n",
    "                                           n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Pre-Tuning with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'importance_type', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample', 'verbosity'])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display possible hyperparameters for XGBoost Regressor\n",
    "test_xgb_reg = XGBRegressor()\n",
    "test_xgb_reg.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default values for XGBRegressor** (as base for hyperparameter search):\n",
    "\n",
    "max_depth=3, learning_rate=0.1, n_estimators=100, verbosity=1, silent=None, objective='reg:linear', booster='gbtree', n_jobs=1, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, colsample_bynode=1, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0, seed=None, missing=None, importance_type='gain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter distribution\n",
    "param_distribs_xgb_reg = {\n",
    "    'xgb_reg__n_estimators': randint(low=10, high=200),\n",
    "    'xgb_reg__max_depth': randint(low=1, high=10),\n",
    "    'xgb_reg__learning_rate': [0.05, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:29:24] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit RandomizedSearchCV, save \"best_model\"\n",
    "rnd_xgb_reg = RandomizedSearchCV(pipeline_xgb_reg,\n",
    "                                 param_distribs_xgb_reg,\n",
    "                                 cv=5,\n",
    "                                 n_iter=20,\n",
    "                                 return_train_score=True,\n",
    "                                 verbose=4,\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "best_model_rnd_xgb_reg = rnd_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.43\n",
      "Best parameters:\n",
      "{'xgb_reg__learning_rate': 0.05, 'xgb_reg__max_depth': 7, 'xgb_reg__n_estimators': 131}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(rnd_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rnd_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:31:52] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Fit XGB pipeline\n",
    "pipeline_xgb_reg_fi = pipeline_xgb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Get feature names from pipeline\n",
    "onehot_columns = list(\n",
    "    pipeline_xgb_reg_fi.named_steps['preprocessor'].named_transformers_['cat'].\n",
    "    named_steps['1hot'].get_feature_names(input_features=cat_features))\n",
    "features_prep_list = list(num_features)\n",
    "features_prep_list.extend(onehot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0702\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                last_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 85.47%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0445\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_other\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0409\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                availability_90\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0403\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                instant_bookable\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0394\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_nb_other\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.40%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0363\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                host_is_superhost\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0273\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10965\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.45%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0209\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                minimum_nights_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0180\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                review_scores_rating_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0168\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Pankow\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0149\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10117\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                calculated_host_listings_count\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                text_len_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.88%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0129\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Mitte\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.07%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0124\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                text_len_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0123\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                property_type_Boutique hotel\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.17%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0121\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12051\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0120\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_white_goods\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0119\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12059\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.25%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0118\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Prenzlauer Berg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.65%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0107\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10178\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0105\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_fees_sqrt\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0104\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                minimum_nights_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0103\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_13353\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0102\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10439\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0101\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Hotel room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.87%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                longitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.89%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0100\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10405\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0099\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10777\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0098\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_extra_people\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.99%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0097\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                wk_mth_discount\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.06%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0095\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Charlottenburg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.09%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0094\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10243\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                latitude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10179\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Neukölln\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                price_log\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.21%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0091\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                am_essentials\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.24%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0090\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                first_review_days\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0088\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room_type_Private room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.48%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10119\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0077\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_12045\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0077\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                neighbourhood_Tiergarten\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.78%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10365\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                cancellation_policy_moderate\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0076\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10551\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.81%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0075\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_10999\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                zipcode_zip_nan\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.91%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0073\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bedrooms\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0072\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                binary_chg\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 69 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='XGBRegressor(max_depth=5, max_features=20, n_estimators=110, n_jobs=-1,\\n             random_state=42)', description='\\nXGBoost feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=True, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='last_review_days', weight=0.07018636, std=None, value=None), FeatureWeight(feature='zipcode_zip_other', weight=0.044482216, std=None, value=None), FeatureWeight(feature='availability_90', weight=0.040906016, std=None, value=None), FeatureWeight(feature='instant_bookable', weight=0.040255673, std=None, value=None), FeatureWeight(feature='neighbourhood_nb_other', weight=0.039410677, std=None, value=None), FeatureWeight(feature='host_is_superhost', weight=0.036261994, std=None, value=None), FeatureWeight(feature='zipcode_zip_10965', weight=0.027323404, std=None, value=None), FeatureWeight(feature='minimum_nights_log', weight=0.020857468, std=None, value=None), FeatureWeight(feature='review_scores_rating_sqrt', weight=0.017969606, std=None, value=None), FeatureWeight(feature='neighbourhood_Pankow', weight=0.016818658, std=None, value=None), FeatureWeight(feature='zipcode_zip_10117', weight=0.014905225, std=None, value=None), FeatureWeight(feature='calculated_host_listings_count', weight=0.013152952, std=None, value=None), FeatureWeight(feature='text_len_chg', weight=0.013076956, std=None, value=None), FeatureWeight(feature='neighbourhood_Mitte', weight=0.012938838, std=None, value=None), FeatureWeight(feature='text_len_sqrt', weight=0.012364213, std=None, value=None), FeatureWeight(feature='property_type_Boutique hotel', weight=0.012250639, std=None, value=None), FeatureWeight(feature='zipcode_zip_12051', weight=0.012050055, std=None, value=None), FeatureWeight(feature='am_white_goods', weight=0.011985026, std=None, value=None), FeatureWeight(feature='zipcode_zip_12059', weight=0.011937442, std=None, value=None), FeatureWeight(feature='neighbourhood_Prenzlauer Berg', weight=0.011830475, std=None, value=None), FeatureWeight(feature='zipcode_zip_10178', weight=0.01067689, std=None, value=None), FeatureWeight(feature='price_extra_fees_sqrt', weight=0.0104812095, std=None, value=None), FeatureWeight(feature='minimum_nights_chg', weight=0.010365092, std=None, value=None), FeatureWeight(feature='zipcode_zip_13353', weight=0.010252073, std=None, value=None), FeatureWeight(feature='zipcode_zip_10439', weight=0.010226946, std=None, value=None), FeatureWeight(feature='room_type_Hotel room', weight=0.010050045, std=None, value=None), FeatureWeight(feature='longitude', weight=0.0100486055, std=None, value=None), FeatureWeight(feature='zipcode_zip_10405', weight=0.009989016, std=None, value=None), FeatureWeight(feature='zipcode_zip_10777', weight=0.009924746, std=None, value=None), FeatureWeight(feature='price_extra_people', weight=0.009753377, std=None, value=None), FeatureWeight(feature='wk_mth_discount', weight=0.009707777, std=None, value=None), FeatureWeight(feature='neighbourhood_Charlottenburg', weight=0.009517271, std=None, value=None), FeatureWeight(feature='zipcode_zip_10243', weight=0.009431402, std=None, value=None), FeatureWeight(feature='latitude', weight=0.009170891, std=None, value=None), FeatureWeight(feature='zipcode_zip_10179', weight=0.00915277, std=None, value=None), FeatureWeight(feature='neighbourhood_Neukölln', weight=0.009124419, std=None, value=None), FeatureWeight(feature='price_log', weight=0.009117072, std=None, value=None), FeatureWeight(feature='am_essentials', weight=0.009100618, std=None, value=None), FeatureWeight(feature='first_review_days', weight=0.009021176, std=None, value=None), FeatureWeight(feature='room_type_Private room', weight=0.008820748, std=None, value=None), FeatureWeight(feature='zipcode_zip_10119', weight=0.008389733, std=None, value=None), FeatureWeight(feature='zipcode_zip_12045', weight=0.00774513, std=None, value=None), FeatureWeight(feature='neighbourhood_Tiergarten', weight=0.0077342987, std=None, value=None), FeatureWeight(feature='zipcode_zip_10365', weight=0.0075986604, std=None, value=None), FeatureWeight(feature='cancellation_policy_moderate', weight=0.007573784, std=None, value=None), FeatureWeight(feature='zipcode_zip_10551', weight=0.0075671785, std=None, value=None), FeatureWeight(feature='zipcode_zip_10999', weight=0.0075190356, std=None, value=None), FeatureWeight(feature='zipcode_zip_nan', weight=0.007393606, std=None, value=None), FeatureWeight(feature='bedrooms', weight=0.0072755693, std=None, value=None), FeatureWeight(feature='binary_chg', weight=0.007244817, std=None, value=None)], remaining=69), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine and print feature importance\n",
    "eli5.explain_weights(pipeline_xgb_reg_fi.named_steps['xgb_reg'],\n",
    "                     top=50,\n",
    "                     feature_names=features_prep_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid_xgb_reg = {\n",
    "    'xgb_reg__n_estimators': [110, 130, 150],\n",
    "    'xgb_reg__max_depth': [5, 7, 9],\n",
    "    'xgb_reg__learning_rate': [0.01, 0.03, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   49.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:49:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "# Create and fit GridSearchCV, save \"best_model\"\n",
    "grid_xgb_reg = GridSearchCV(pipeline_xgb_reg,\n",
    "                            param_grid_xgb_reg,\n",
    "                            cv=5,\n",
    "                            return_train_score=True,\n",
    "                            verbose=4,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "grid_xgb_reg.fit(X_train, y_train)\n",
    "best_model_xgb_reg = grid_xgb_reg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:\n",
      "0.43\n",
      "Best parameters:\n",
      "{'xgb_reg__learning_rate': 0.05, 'xgb_reg__max_depth': 7, 'xgb_reg__n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Display best_score_, best_params_ and best_estimator_\n",
    "print('Best score:\\n{:.2f}'.format(grid_xgb_reg.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid_xgb_reg.best_params_))\n",
    "#print(\"Best estimator:\\n{}\".format(grid_rf_reg.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detailed evaluation with training set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py:440: FutureWarning: Given feature/column names or counts do not match the ones for the data given during fit. This will fail from v0.24.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Specifying the columns using strings is only supported for pandas DataFrames",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-bc928897f7a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict target with \"best model\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_train_pred_xgb_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_xgb_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_prep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;31m# TODO: also call _check_n_features(reset=False) in 0.24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_feature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mXs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[1;32m    466\u001b[0m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0;32m--> 467\u001b[0;31m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected 2D array, got 1D array instead\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    817\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    464\u001b[0m                     \u001b[0mmessage_clsname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ColumnTransformer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                     message=self._log_message(name, idx, len(transformers)))\n\u001b[0;32m--> 466\u001b[0;31m                 for idx, (name, trans, column, weight) in enumerate(\n\u001b[0m\u001b[1;32m    467\u001b[0m                         self._iter(fitted=fitted, replace_strings=True), 1))\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/nf/lib/python3.6/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindices_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         raise ValueError(\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;34m\"Specifying the columns using strings is only supported for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;34m\"pandas DataFrames\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Specifying the columns using strings is only supported for pandas DataFrames"
     ]
    }
   ],
   "source": [
    "# Predict target with \"best model\"\n",
    "y_train_pred_xgb_reg = best_model_xgb_reg.predict(X_train_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "print(\"MSE: {:.2f}\".format(mean_squared_error(y_test, y_train_pred_xgb_reg))),\n",
    "print(\"RMSE: {:.2f}\".format(\n",
    "    mean_squared_error(y_test, y_train_pred_xgb_reg, squared=False))),\n",
    "print(\"MAE: {:.2f}\".format(mean_absolute_error(y_test, y_train_pred_xgb_reg))),\n",
    "print(\"R2: {:.2f}\".format(r2_score(y_test, y_train_pred_xgb_reg))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "confidence = 0.95\n",
    "squared_errors = (y_train_pred_xgb_reg - y_test)**2\n",
    "np.sqrt(\n",
    "    stats.t.interval(confidence,\n",
    "                     len(squared_errors) - 1,\n",
    "                     loc=squared_errors.mean(),\n",
    "                     scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation with Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Transform X_test for final evaluation\n",
    "#X_test_prep = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Predict target with \"best model\"\n",
    "#y_pred_rf_reg = best_model_rf_reg.predict(X_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Final evaluation of \"best model\"\n",
    "#print(\"MSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"RMSE: {:.2f}\".format(mean_squared_error(y_test, y_pred_rf_reg, squared=False))),\n",
    "#print(\"MAE: {:.2f}\".format(mean_absolute_error(y_test, y_pred_rf_reg))),\n",
    "#print(\"R2: {:.2f}\".format(r2_score(y_test, y_pred_rf_reg))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Display confidence interval (scipy stats)\n",
    "#confidence = 0.95\n",
    "#squared_errors = (y_pred_rf_reg - y_test) ** 2\n",
    "#np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "#                         loc=squared_errors.mean(),\n",
    "#                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
